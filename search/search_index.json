{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the website for the MSU Cloud Computing Fellowship for 2022-2022. See our \" about \" page for more information about the program. Syllabus Fall 2022 - Spring 2023 The program runs Fall semester through Winder/Spring semester. Fall Sessions are approximately bi-weekly with breaks for holidays. A session includes preparatory readings and activities to orient you to the topic, followed by an in-person meeting on a Friday to review the materials, seminar, provide a venue for discussion, hands-on collaborative activities, or presentations by the fellows. Winter/Spring sessions are for discussion and to provide updates to your project. Symposium and Project Presentations The culmination of the fellowship is a project resulting in a write-up and presentation during the spring symposium, typically held late-April or early-May. Slide deck with an overview of the projects (PDF) We will post more details about the project during the semeseter See Winter 2023 schedule below for due dates We will finalize the date for the cloud fellowship symposium date in 2023 Meeting location At this time all meetings are in-person in the training room of the Institute for Cyber-Enabled Research, located on the first floor of the MSU Biomedical & Physical Sciences Building Biomedical and Physical Science (BPS) Building , Room 1445 567 Wilson Road Michigan State University. East Lansing, MI 48824 enter the doors marked 1440, in the center of the BPS atrium Schedule for Fall 2022 Note since our meeting for September 2 was cancalled The schedule has been revised Introduction to the 22-23 Fellowship Meeting September 16: Introductions, Cloud background and hands-on with Azure portal Hands-on Introduction to Cloud computing Using Virtual Machines self-paced readings and activies: Using the Azure portal creating an connecting to a virtual machine Optional help/office hours September 23 2pm Cloud Storage Meeting September 30: Discussion & Cloud Storage Workshop. Databases and Data Analytics Systems on the Cloud for research Meeting October 14: Seminar on Database and data systems. Hands-on: Using Cosmos DB Big Data Systems and the cloud Meeting October 28: Overview of Big Data on Azure with DataBricks Serverless Cloud Computing Meeting November 4: Overview of Serverless and FaaS, Demonstration of Real-world project Overview of Web Application Development in the cloud. Meeting November 18: Details about the Project Synthesis and time to develope project proposal Discussion of Fellowship Projects. First draft proposal due (1-2 sentence) Session materials for 2022 are in development. For examples of previous materials, see the schedule for 2021 Schedule for Winter/Spring 2023 The second semester of the fellowship is focused on completing a project based on fellow research interests. We will meet approximately bi-weekly for fellows to present, get feedback, ask questions, and group discussions. For some of these dates/times, fellows will deliver a short presentation about their projects as follows: All meetings are in the ICER training room, 1455A BPS, from 2:00 to 3:30 pm January 8th Written project proposal due (via email). January 13 Project proposal presentations January 27 Discussion & help session February 10 Discussion & helpsession February 24 Project status presentations March 10 Discussion & help session March 24 Project status presentations April 10 : Discussion & help session April TBD : Final project write-up due April TBD : Fellowship symposium and final presentation On-going help We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general. Textbook We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters. Communications Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Home"},{"location":"#syllabus-fall-2022-spring-2023","text":"The program runs Fall semester through Winder/Spring semester. Fall Sessions are approximately bi-weekly with breaks for holidays. A session includes preparatory readings and activities to orient you to the topic, followed by an in-person meeting on a Friday to review the materials, seminar, provide a venue for discussion, hands-on collaborative activities, or presentations by the fellows. Winter/Spring sessions are for discussion and to provide updates to your project.","title":"Syllabus Fall 2022 - Spring 2023"},{"location":"#symposium-and-project-presentations","text":"The culmination of the fellowship is a project resulting in a write-up and presentation during the spring symposium, typically held late-April or early-May. Slide deck with an overview of the projects (PDF) We will post more details about the project during the semeseter See Winter 2023 schedule below for due dates We will finalize the date for the cloud fellowship symposium date in 2023","title":"Symposium and Project Presentations"},{"location":"#meeting-location","text":"At this time all meetings are in-person in the training room of the Institute for Cyber-Enabled Research, located on the first floor of the MSU Biomedical & Physical Sciences Building Biomedical and Physical Science (BPS) Building , Room 1445 567 Wilson Road Michigan State University. East Lansing, MI 48824 enter the doors marked 1440, in the center of the BPS atrium","title":"Meeting location"},{"location":"#schedule-for-fall-2022","text":"Note since our meeting for September 2 was cancalled The schedule has been revised Introduction to the 22-23 Fellowship Meeting September 16: Introductions, Cloud background and hands-on with Azure portal Hands-on Introduction to Cloud computing Using Virtual Machines self-paced readings and activies: Using the Azure portal creating an connecting to a virtual machine Optional help/office hours September 23 2pm Cloud Storage Meeting September 30: Discussion & Cloud Storage Workshop. Databases and Data Analytics Systems on the Cloud for research Meeting October 14: Seminar on Database and data systems. Hands-on: Using Cosmos DB Big Data Systems and the cloud Meeting October 28: Overview of Big Data on Azure with DataBricks Serverless Cloud Computing Meeting November 4: Overview of Serverless and FaaS, Demonstration of Real-world project Overview of Web Application Development in the cloud. Meeting November 18: Details about the Project Synthesis and time to develope project proposal Discussion of Fellowship Projects. First draft proposal due (1-2 sentence) Session materials for 2022 are in development. For examples of previous materials, see the schedule for 2021","title":"Schedule for Fall 2022"},{"location":"#schedule-for-winterspring-2023","text":"The second semester of the fellowship is focused on completing a project based on fellow research interests. We will meet approximately bi-weekly for fellows to present, get feedback, ask questions, and group discussions. For some of these dates/times, fellows will deliver a short presentation about their projects as follows: All meetings are in the ICER training room, 1455A BPS, from 2:00 to 3:30 pm January 8th Written project proposal due (via email). January 13 Project proposal presentations January 27 Discussion & help session February 10 Discussion & helpsession February 24 Project status presentations March 10 Discussion & help session March 24 Project status presentations April 10 : Discussion & help session April TBD : Final project write-up due April TBD : Fellowship symposium and final presentation","title":"Schedule for Winter/Spring 2023"},{"location":"#on-going-help","text":"We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general.","title":"On-going help"},{"location":"#textbook","text":"We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters.","title":"Textbook"},{"location":"#communications","text":"Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Communications"},{"location":"about/","text":"About The MSU Cloud Computing Fellowship The MSU Cloud Computing Fellowship is a cross-disciplinary program produced by MSU\u2019s Institute of Cyber-Enabled Research (ICER) and the IT Services Analytics and Data Solutions (ADS) group for invited MSU doctoral students and postdoctoral researchers. As a part of this program, fellows will participate in a series of workshops during the fall semester to: Determine the aspects of your research that can be accomplished with cloud computing; Incorporate cloud-based systems into your research application or workflow; and Understand the strengths and limitations of commercial cloud computing with the goal of improving research yield and minimizing cost, and to develop a workflow that utilizes that knowledge. Background MSU doctoral students and postdoctoral researchers are invited to apply in the summer and approximately 18 are selected each year. The program started in 2019. If you are an MSU graduate student or post-doc and interested in participating next year, please check back in the Summer of 2022 for announcements on the invitation to participate, or request to join the MSU ICER mailing list Citing the MSU ICER Cloud Computing Fellowship in Research Publications We encourage cloud fellows to acknowledge the fellowship in publications arising from computational work performed during your fellowship project. Please let us know that you have referenced the fellowship, and we will link to your publication on the ICER publication site, which will further increase the visibility of your work. A sample statement can be: \"This work was supported in part through Michigan State University\u2019s Institute for Cyber-Enabled Research Cloud Computing Fellowship, with computational resources and services provided by Information Technology Services and the Office of Research and Innovation at Michigan State University.\u201d Cloud Computing Fellowship Organizers Dr. Brian O'Shea Professor and Director, MSU ICER Role: Program Lead, ICER Dr. Brian O'Shea is a computational and theoretical astrophysicist studying cosmological structure formation, including galaxy formation and the behavior of the hot, diffuse plasma in the intergalactic medium and within galaxy clusters. He is also a co-author of the Enzo AMR code, an expert in high performance computing, and an advocate for open-source computing and open-source science. He received his B.S. in Engineering Physics at the University of Illinois in Urbana-Champaign (UIUC) in 2000, and his PhD in physics from UIUC in 2005 (with 2002-2005 being spent as a graduate student in residence at the Laboratory for Computational Astrophysics at UC San Diego and in the Theoretical Astrophysics Group at Los Alamos National Laboratory). Following that, he was a Director's Postdoctoral Fellow at Los Alamos National Laboratory, with a joint appointment between the Theoretical Astrophysics Group and the Applied Physics Division. Since 2008, he has been a member of the faculty at Michigan State University, with a joint appointment between the Department of Computational Mathematics, Science and Engineering (2015-present), the Department of Physics and Astronomy (2008-present), and the National Superconducting Cyclotron Laboratory (2014-present). From 2008-2015, Dr. O'Shea was a member of Lyman Briggs College. He has authored or co-authored over 75 peer-reviewed journal articles in astrophysics, computer science, and education research journals, and has received a variety of awards for his teaching and public outreach efforts. In 2016, he became a Fellow of the American Physical Society, and in 2019 he became the director of MSU's Institute for Cyber-Enabled Research. Danielle Barnes Assistant Director, ADS, MSU IT Services Role: Program Lead, IT Services Patrick Bills Data Science Technical Lead, MSU IT Services Role: Lead Instructor Pat Bills research background is in data systems for ecology (MS Entomology, MSU). He has experience in database design, R, Python, and web application programming. Pat has worked in research IT for over 25 yrs for departments and labs across MSU, including for MSU ICER as a research consultant and trainer. He is currently the technical lead for the data science team within ADS. Like many, he has built and worked with on-campus linux systems for many years including the MSU HPC. Pat started my cloud journey in 2017 during a workshop at the HPC conference where he saw Ian Foster (our textbook author) present his vision of research on the cloud. Since then he has used cloud services from Google, Amazon, and Azure - currently focusing on Microsoft Azure. ADS uses cloud services where appropriate for their data systems or applications, and he will use examples directly from that work in this class. Dr. Mahmoud Parvizi Research Consultant, MSU ICER Role: Assistant Instructor Mahmoud earned his PhD in physics from Vanderbilt University with research in high-energy theory in the context of early universe cosmology as well as computational astrophysics. In addition, Mahmoud earned an MBA with a concentration in finance from the University of Michigan - Flint. Mahmoud was formerly a postdoctoral research associate in the Department of Physics and Astronomy at Michigan State University with a focus on machine learning applications of cloud-computing workflows and currently a research consultant for the MSU Institute for Cyber-Enabled Research (ICER). He participated as a cloud fellow in 2019 and co-instructor of the Cloud Computing Fellowship in 2020. Mahmoud\u2019s diverse research interests include mathematical and theoretical physics, data-intensive astrophysics, machine learning for precision health, and cloud-computing platforms for academic research. His expertise includes 1) quantum field theory in curved/non-stationary spacetimes; 2) finite temperature quantum field theory and open quantum systems; 3) automated and end-to-end intelligent data pipelines for signal processing using compressed sensing and applied harmonic analysis; 4) machine learning and cloud-computing applications for precision health. Chelsea Beck Data Warehouse Lead, ADS, MSU IT Services Role: Logistics and Organizational expertise Previous Cloud Fellows 2019-2020 MSU Cloud Computing Fellows Summary of the first cohort of MSU Cloud Computing Fellows 2020-2021 Introducing the 2020 Cloud Fellows 20-21 Cloud Computing Fellowship Culminates in Impressive Symposium","title":"About"},{"location":"about/#about-the-msu-cloud-computing-fellowship","text":"The MSU Cloud Computing Fellowship is a cross-disciplinary program produced by MSU\u2019s Institute of Cyber-Enabled Research (ICER) and the IT Services Analytics and Data Solutions (ADS) group for invited MSU doctoral students and postdoctoral researchers. As a part of this program, fellows will participate in a series of workshops during the fall semester to: Determine the aspects of your research that can be accomplished with cloud computing; Incorporate cloud-based systems into your research application or workflow; and Understand the strengths and limitations of commercial cloud computing with the goal of improving research yield and minimizing cost, and to develop a workflow that utilizes that knowledge.","title":"About The MSU Cloud Computing Fellowship"},{"location":"about/#background","text":"MSU doctoral students and postdoctoral researchers are invited to apply in the summer and approximately 18 are selected each year. The program started in 2019. If you are an MSU graduate student or post-doc and interested in participating next year, please check back in the Summer of 2022 for announcements on the invitation to participate, or request to join the MSU ICER mailing list","title":"Background"},{"location":"about/#citing-the-msu-icer-cloud-computing-fellowship-in-research-publications","text":"We encourage cloud fellows to acknowledge the fellowship in publications arising from computational work performed during your fellowship project. Please let us know that you have referenced the fellowship, and we will link to your publication on the ICER publication site, which will further increase the visibility of your work. A sample statement can be: \"This work was supported in part through Michigan State University\u2019s Institute for Cyber-Enabled Research Cloud Computing Fellowship, with computational resources and services provided by Information Technology Services and the Office of Research and Innovation at Michigan State University.\u201d","title":"Citing the MSU ICER Cloud Computing Fellowship in Research Publications"},{"location":"about/#cloud-computing-fellowship-organizers","text":"Dr. Brian O'Shea Professor and Director, MSU ICER Role: Program Lead, ICER Dr. Brian O'Shea is a computational and theoretical astrophysicist studying cosmological structure formation, including galaxy formation and the behavior of the hot, diffuse plasma in the intergalactic medium and within galaxy clusters. He is also a co-author of the Enzo AMR code, an expert in high performance computing, and an advocate for open-source computing and open-source science. He received his B.S. in Engineering Physics at the University of Illinois in Urbana-Champaign (UIUC) in 2000, and his PhD in physics from UIUC in 2005 (with 2002-2005 being spent as a graduate student in residence at the Laboratory for Computational Astrophysics at UC San Diego and in the Theoretical Astrophysics Group at Los Alamos National Laboratory). Following that, he was a Director's Postdoctoral Fellow at Los Alamos National Laboratory, with a joint appointment between the Theoretical Astrophysics Group and the Applied Physics Division. Since 2008, he has been a member of the faculty at Michigan State University, with a joint appointment between the Department of Computational Mathematics, Science and Engineering (2015-present), the Department of Physics and Astronomy (2008-present), and the National Superconducting Cyclotron Laboratory (2014-present). From 2008-2015, Dr. O'Shea was a member of Lyman Briggs College. He has authored or co-authored over 75 peer-reviewed journal articles in astrophysics, computer science, and education research journals, and has received a variety of awards for his teaching and public outreach efforts. In 2016, he became a Fellow of the American Physical Society, and in 2019 he became the director of MSU's Institute for Cyber-Enabled Research. Danielle Barnes Assistant Director, ADS, MSU IT Services Role: Program Lead, IT Services Patrick Bills Data Science Technical Lead, MSU IT Services Role: Lead Instructor Pat Bills research background is in data systems for ecology (MS Entomology, MSU). He has experience in database design, R, Python, and web application programming. Pat has worked in research IT for over 25 yrs for departments and labs across MSU, including for MSU ICER as a research consultant and trainer. He is currently the technical lead for the data science team within ADS. Like many, he has built and worked with on-campus linux systems for many years including the MSU HPC. Pat started my cloud journey in 2017 during a workshop at the HPC conference where he saw Ian Foster (our textbook author) present his vision of research on the cloud. Since then he has used cloud services from Google, Amazon, and Azure - currently focusing on Microsoft Azure. ADS uses cloud services where appropriate for their data systems or applications, and he will use examples directly from that work in this class. Dr. Mahmoud Parvizi Research Consultant, MSU ICER Role: Assistant Instructor Mahmoud earned his PhD in physics from Vanderbilt University with research in high-energy theory in the context of early universe cosmology as well as computational astrophysics. In addition, Mahmoud earned an MBA with a concentration in finance from the University of Michigan - Flint. Mahmoud was formerly a postdoctoral research associate in the Department of Physics and Astronomy at Michigan State University with a focus on machine learning applications of cloud-computing workflows and currently a research consultant for the MSU Institute for Cyber-Enabled Research (ICER). He participated as a cloud fellow in 2019 and co-instructor of the Cloud Computing Fellowship in 2020. Mahmoud\u2019s diverse research interests include mathematical and theoretical physics, data-intensive astrophysics, machine learning for precision health, and cloud-computing platforms for academic research. His expertise includes 1) quantum field theory in curved/non-stationary spacetimes; 2) finite temperature quantum field theory and open quantum systems; 3) automated and end-to-end intelligent data pipelines for signal processing using compressed sensing and applied harmonic analysis; 4) machine learning and cloud-computing applications for precision health. Chelsea Beck Data Warehouse Lead, ADS, MSU IT Services Role: Logistics and Organizational expertise","title":"Cloud Computing Fellowship Organizers"},{"location":"about/#previous-cloud-fellows","text":"2019-2020 MSU Cloud Computing Fellows Summary of the first cohort of MSU Cloud Computing Fellows 2020-2021 Introducing the 2020 Cloud Fellows 20-21 Cloud Computing Fellowship Culminates in Impressive Symposium","title":"Previous Cloud Fellows"},{"location":"cloud_glossary/","text":"Glossary of Cloud Terms Why? Researchers using the cloud must know a little about a lot of information technology to get computational work done in their domain specialty. Most cloud glossaries are for systems administrators, not the rest of us. This glossary is much more brief than Wikipedia and hopefully also provides the context a researcher needs to find what you need to use cloud services in your work. Do you have an item to add? Please contact us ! Other Glossaries https://www.cloudbank.org/cloud-terms The Glossary Arm CPU CPU from \"Advanced RISC Machines, ltd. While historically most computers used Intel CPUs, ARM provides an alternative CPU that is becoming more popular and present as an option in HPC and Cloud Virtual Machine options. The vast majority of software written for Intel computers is compatible with ARM. Some computational work is sensitive to CPU choice, and CPU choice can affect cost and speed of excecution, so it may be important to understand the implications of this choice of CPU. ARM Template A specification file listing all of the cloud resources and configuration settings tha that the Azure Resource Manager can use to create resources for you when you submit it a certain way. Templates are a great shortcut and automation feature but difficult to edit. For details see Azure Documentation: What are ARM templates? Azure Resource Manager (ARM) see Resource Manager =#### Blob Storage Azure calls there object cloud storage \"Blobs\". It is similar to Amazon Web Service 'S3' and Google cloud storage buckets. Azure Documentation: Introduction to Azure Blob storage While it's possible to 'mount' blob storage to linux VMs using 'blob fuse' or similar packages, it can not work as you may expect and so in practice Azure Files are a better solution for that. See File Storage Client-Server Client/Server model of computing is something we use everyday but perhaps dont' use this term. See https://techterms.com/definition/client-server_model You are used to using maybe a dozen clients everyday (phone apps, web browser, ssh to connect to a remote linux, Remote Desktop client to connect to remote desktop server, etc). Cloud computing provides all the infrastructure needed to create servers quickly and easily. Containers Or Docker Containers (not all containers need to be Docker the vast majority of container system use Docker). For R users, see https://colinfay.me/docker-r-reproducibility/ For Python users, there is https://www.netguru.com/blog/python-docker-tutorial although you could read either. Linux Containers is a term for a collection of methods and technologies that allows a multiple isolated systems to be run on one Linux computer. This is differnet from virtual machines in that a VM host provides abstract or virtualized hardware so each VM requires it's own portion of memory and CPU cores whereas containers share the main part of Linux (the kernel), memory and CPU more dynamically. The primary comercial company for containers is \"Docker\" so Docker is sometimes used synonymously with 'container' but it is just one form. In addition to being more efficient than VMs, most container systems have a system and scripting language for building containers. The means onecan provision an entire system from code. Containers are widely use to package and distribute complex research software systems for example Bioinformatics workflow system \"Cromwell.\" This way reseearches can download and use a pre-installed system without the trouble of getting all of the pre-requistes (dependencies) installed on their machine. CPU Central Processing Unit, the main 'chip' of a computer, and a core component when specifying a Virtual Machine 'size' DevOps This has many definitions but for researchers the shortcut is using code to make IT infrastructure. Helping developers (like you) do Ops (like sysadmins) with code. see IaC. Docker Docker is the most prevalent form of \"Containers\", e.g Docker is to containers as google is to search. See containers above for details. Note that Docker is many things as once: a method and format for Linux containers, a program for working with container ( e.g. docker build... ), a Company, and that's company's hub or repository for storing and access free containers (or your own). Cloud companies also have \"hubs\" or repositories for storing your own Docker containers. File Storage (Azure) Also called \"Azure Files.\" Azure cloud storage that is more traditional file sharing, and that can be connected (mounted) to computers and other services using the SMB protocal, making it similar experience to departmental shared fileservers. See https://azure.microsoft.com/en-us/services/storage/files/ and compare with Blob Storage Firewall A common concept in networking, firewall software on a computer's networking components limits which kind of traffic can come in or out, and restricts which computer internet addresses can connect. Best practices suggest closing all connections via the firewall, only opening those connections for services you need, and only to those users (e.g. your own computer) you need to. Azure additionally has an option to \"allow connections from Azure networks\" so that you can freely connect from the portal, 'cloud shell', or connect from on azure service to another. The implication is that you trust all Azure services. GPU From Wikipedia: https://en.wikipedia.org/wiki/Graphics_processing_unit GPUs can be very helpful for some code written to use them, especially many machine learning libraries, and Virtual Machines may be provisioned with GPUs. Infrastructure as Code (IaC) In stead of using a GUI, or manual steps to create cloud computing, cloud resources may be created using scripts that interact with the cloud provider's api, and additional scripts can configure individual resources (such as to install software on a VM or configure a database). Doing this kind of \"provisioning\" with scripts makes it reproducible and debuggable which is at the heart of the Workflow or DevOps mentality. IP Address a unique string of characters that identifies each computer using the Internet Protocol to communicate over a network. Your computer will have a different IP address depending on where you are located (home, work, field). In addition, a home wifi router will assign a 'local' ip address for inside your home, but your 'public' internet IP address will be different. To find your own IP address, simply google \"what is my ip.\" All Azure services (VMs, data systems, etc) are assigned IP addresses via networking. see https://docs.microsoft.com/en-us/azure/virtual-network/public-ip-addresses Object Storage From NetApp \"What is object storage? : \"...also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. These objects are kept in a single storehouse and are not ingrained in files inside other folders. Instead, object storage combines the pieces of data that make up a file, adds all its relevant metadata to that file, and attaches a custom identifier.\" Blob storage is object storage. Objects (e.g. files) are retrieved from a large system via their identifier, not their name. Amazon S3 and Google Cloud storage are also object stores. On-prem \"On Premise\" refers to technology (computers, disks, networking, etc) that are on your institutions computer centers or in your own lab. Note that for some researchers, \"on-prem\" can still mean remove (e.g. our HPC is only accessible remotely, so it may not be obvious that it's on premise to users). Resource For AWS and Azure, a resource is an entity that you can work with. The means something you can created, edit or delete via their cloud interface. Could be a computer (virtual machine), a whole cluster (azure batch pool), or some tiny network setting (IP address). Resoures almost always cost money. Resources are listed in your standard dashboard. Resource Group Organizational scheme unique to Azure. Nearly all resources must be part of a group and the resource group must be selected (or created ) when creating other resources. Resource groups could be used for specific projects, for 'personal' resources used for multiple projects (or for azure things like cloud shell). Resource Manager Azure calls the system they use to interface between you and cloud resources the \"Azure Resource Manager\" or ARM. There used to be a different way to interact with Azure resources, hence this has a specific name and is referred to in Microsoft documentation. Serverless This buzz-word applies to many different cloud services, primarily those that the cloud company manages for you, usually referring to cloud functions (AWS Lamba) and sometimes others in the \"Platform As A Service\" service model . The origin is that, if you run virtual machines with operating systems and software install, your are maintaining servers to support that software. If the cloud service does not require you to provision and maintain a server, it is often marketed as \"serverless\" (e.g. recent marketing of Azure Files as \"Serverless file shares\" where on-premise File Sharing requires staff to manage and maintain Windows File Servers. Service Models This is related to the \"... as a service\" (..aaS) phrases defined in the NIST document which included \"Infrastructure\", \"Platform\" and \"Softare\" as a service (IaaS, PaaS and SaaS). It's a conceptual organization of cloud services based on the stack model of computating with the infrastructure (network, hardware, CPU, etc) at the bottom and Software on the top. See The NIST Definition of Cloud Computing Service Level Agreement (SLA) Level of service you expect from a vendor, laying out the metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved. In Cloud this is often spells out 'uptime,' which is percent of time the system is not down, e.g. 99.99%, and guarantees against data loss and availability. For most research, uptime is not important as we are our own customer and can tolerate some downtime. Services Cloud \"services\" are often bundles of resources pulled together for coordinate function. Cloud companies offer hundreds of often closely overlapping services. Tags AWS and Azure allow you add meta data to resource in the form of tags (e.g. hashtags, etc) which are keys and values. When you create a resource you can add a tag indicating the project it is for e.g. \"project\" = \"dna-methylation\" To add more detail if your DNA methylation has multiple aspects or experiments, add more tags like \"experiment\" = \"Fall 2021\" For workgroups it's stronlgy suggested you add a \"created_by\" = your netid because it's often difficult in Azure to determine who created a resource if it needs to be turned off or deleted. Use tags to organize your Azure resources and management hierarchy Tensor Processing Unit (TPU) Google Tensor Processing Unit is specialized computer chip similar to GPUs , used by deep learning libraries such as TensorFlow ( which leads to the question of \"what is a tensor\" and that depends on who you ask but similar to matrix. Virtual Machine (aka VM) Creating a simulated computer hardware using software, to be able run a guest operating system inside a host system, such that the guest thinks it's running on an actual computer.","title":"Cloud Glossary"},{"location":"cloud_glossary/#glossary-of-cloud-terms","text":"","title":"Glossary of Cloud Terms"},{"location":"cloud_glossary/#why","text":"Researchers using the cloud must know a little about a lot of information technology to get computational work done in their domain specialty. Most cloud glossaries are for systems administrators, not the rest of us. This glossary is much more brief than Wikipedia and hopefully also provides the context a researcher needs to find what you need to use cloud services in your work. Do you have an item to add? Please contact us !","title":"Why?"},{"location":"cloud_glossary/#other-glossaries","text":"https://www.cloudbank.org/cloud-terms","title":"Other Glossaries"},{"location":"cloud_glossary/#the-glossary","text":"","title":"The Glossary"},{"location":"cloud_glossary/#arm-cpu","text":"CPU from \"Advanced RISC Machines, ltd. While historically most computers used Intel CPUs, ARM provides an alternative CPU that is becoming more popular and present as an option in HPC and Cloud Virtual Machine options. The vast majority of software written for Intel computers is compatible with ARM. Some computational work is sensitive to CPU choice, and CPU choice can affect cost and speed of excecution, so it may be important to understand the implications of this choice of CPU.","title":"Arm CPU"},{"location":"cloud_glossary/#arm-template","text":"A specification file listing all of the cloud resources and configuration settings tha that the Azure Resource Manager can use to create resources for you when you submit it a certain way. Templates are a great shortcut and automation feature but difficult to edit. For details see Azure Documentation: What are ARM templates?","title":"ARM Template"},{"location":"cloud_glossary/#azure-resource-manager-arm","text":"see Resource Manager =#### Blob Storage Azure calls there object cloud storage \"Blobs\". It is similar to Amazon Web Service 'S3' and Google cloud storage buckets. Azure Documentation: Introduction to Azure Blob storage While it's possible to 'mount' blob storage to linux VMs using 'blob fuse' or similar packages, it can not work as you may expect and so in practice Azure Files are a better solution for that. See File Storage","title":"Azure Resource Manager (ARM)"},{"location":"cloud_glossary/#client-server","text":"Client/Server model of computing is something we use everyday but perhaps dont' use this term. See https://techterms.com/definition/client-server_model You are used to using maybe a dozen clients everyday (phone apps, web browser, ssh to connect to a remote linux, Remote Desktop client to connect to remote desktop server, etc). Cloud computing provides all the infrastructure needed to create servers quickly and easily.","title":"Client-Server"},{"location":"cloud_glossary/#containers","text":"Or Docker Containers (not all containers need to be Docker the vast majority of container system use Docker). For R users, see https://colinfay.me/docker-r-reproducibility/ For Python users, there is https://www.netguru.com/blog/python-docker-tutorial although you could read either. Linux Containers is a term for a collection of methods and technologies that allows a multiple isolated systems to be run on one Linux computer. This is differnet from virtual machines in that a VM host provides abstract or virtualized hardware so each VM requires it's own portion of memory and CPU cores whereas containers share the main part of Linux (the kernel), memory and CPU more dynamically. The primary comercial company for containers is \"Docker\" so Docker is sometimes used synonymously with 'container' but it is just one form. In addition to being more efficient than VMs, most container systems have a system and scripting language for building containers. The means onecan provision an entire system from code. Containers are widely use to package and distribute complex research software systems for example Bioinformatics workflow system \"Cromwell.\" This way reseearches can download and use a pre-installed system without the trouble of getting all of the pre-requistes (dependencies) installed on their machine.","title":"Containers"},{"location":"cloud_glossary/#cpu","text":"Central Processing Unit, the main 'chip' of a computer, and a core component when specifying a Virtual Machine 'size'","title":"CPU"},{"location":"cloud_glossary/#devops","text":"This has many definitions but for researchers the shortcut is using code to make IT infrastructure. Helping developers (like you) do Ops (like sysadmins) with code. see IaC.","title":"DevOps"},{"location":"cloud_glossary/#docker","text":"Docker is the most prevalent form of \"Containers\", e.g Docker is to containers as google is to search. See containers above for details. Note that Docker is many things as once: a method and format for Linux containers, a program for working with container ( e.g. docker build... ), a Company, and that's company's hub or repository for storing and access free containers (or your own). Cloud companies also have \"hubs\" or repositories for storing your own Docker containers.","title":"Docker"},{"location":"cloud_glossary/#file-storage-azure","text":"Also called \"Azure Files.\" Azure cloud storage that is more traditional file sharing, and that can be connected (mounted) to computers and other services using the SMB protocal, making it similar experience to departmental shared fileservers. See https://azure.microsoft.com/en-us/services/storage/files/ and compare with Blob Storage","title":"File Storage (Azure)"},{"location":"cloud_glossary/#firewall","text":"A common concept in networking, firewall software on a computer's networking components limits which kind of traffic can come in or out, and restricts which computer internet addresses can connect. Best practices suggest closing all connections via the firewall, only opening those connections for services you need, and only to those users (e.g. your own computer) you need to. Azure additionally has an option to \"allow connections from Azure networks\" so that you can freely connect from the portal, 'cloud shell', or connect from on azure service to another. The implication is that you trust all Azure services.","title":"Firewall"},{"location":"cloud_glossary/#gpu","text":"From Wikipedia: https://en.wikipedia.org/wiki/Graphics_processing_unit GPUs can be very helpful for some code written to use them, especially many machine learning libraries, and Virtual Machines may be provisioned with GPUs.","title":"GPU"},{"location":"cloud_glossary/#infrastructure-as-code-iac","text":"In stead of using a GUI, or manual steps to create cloud computing, cloud resources may be created using scripts that interact with the cloud provider's api, and additional scripts can configure individual resources (such as to install software on a VM or configure a database). Doing this kind of \"provisioning\" with scripts makes it reproducible and debuggable which is at the heart of the Workflow or DevOps mentality.","title":"Infrastructure as Code (IaC)"},{"location":"cloud_glossary/#ip-address","text":"a unique string of characters that identifies each computer using the Internet Protocol to communicate over a network. Your computer will have a different IP address depending on where you are located (home, work, field). In addition, a home wifi router will assign a 'local' ip address for inside your home, but your 'public' internet IP address will be different. To find your own IP address, simply google \"what is my ip.\" All Azure services (VMs, data systems, etc) are assigned IP addresses via networking. see https://docs.microsoft.com/en-us/azure/virtual-network/public-ip-addresses","title":"IP Address"},{"location":"cloud_glossary/#object-storage","text":"From NetApp \"What is object storage? : \"...also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. These objects are kept in a single storehouse and are not ingrained in files inside other folders. Instead, object storage combines the pieces of data that make up a file, adds all its relevant metadata to that file, and attaches a custom identifier.\" Blob storage is object storage. Objects (e.g. files) are retrieved from a large system via their identifier, not their name. Amazon S3 and Google Cloud storage are also object stores.","title":"Object Storage"},{"location":"cloud_glossary/#on-prem","text":"\"On Premise\" refers to technology (computers, disks, networking, etc) that are on your institutions computer centers or in your own lab. Note that for some researchers, \"on-prem\" can still mean remove (e.g. our HPC is only accessible remotely, so it may not be obvious that it's on premise to users).","title":"On-prem"},{"location":"cloud_glossary/#resource","text":"For AWS and Azure, a resource is an entity that you can work with. The means something you can created, edit or delete via their cloud interface. Could be a computer (virtual machine), a whole cluster (azure batch pool), or some tiny network setting (IP address). Resoures almost always cost money. Resources are listed in your standard dashboard.","title":"Resource"},{"location":"cloud_glossary/#resource-group","text":"Organizational scheme unique to Azure. Nearly all resources must be part of a group and the resource group must be selected (or created ) when creating other resources. Resource groups could be used for specific projects, for 'personal' resources used for multiple projects (or for azure things like cloud shell).","title":"Resource Group"},{"location":"cloud_glossary/#resource-manager","text":"Azure calls the system they use to interface between you and cloud resources the \"Azure Resource Manager\" or ARM. There used to be a different way to interact with Azure resources, hence this has a specific name and is referred to in Microsoft documentation.","title":"Resource Manager"},{"location":"cloud_glossary/#serverless","text":"This buzz-word applies to many different cloud services, primarily those that the cloud company manages for you, usually referring to cloud functions (AWS Lamba) and sometimes others in the \"Platform As A Service\" service model . The origin is that, if you run virtual machines with operating systems and software install, your are maintaining servers to support that software. If the cloud service does not require you to provision and maintain a server, it is often marketed as \"serverless\" (e.g. recent marketing of Azure Files as \"Serverless file shares\" where on-premise File Sharing requires staff to manage and maintain Windows File Servers.","title":"Serverless"},{"location":"cloud_glossary/#service-models","text":"This is related to the \"... as a service\" (..aaS) phrases defined in the NIST document which included \"Infrastructure\", \"Platform\" and \"Softare\" as a service (IaaS, PaaS and SaaS). It's a conceptual organization of cloud services based on the stack model of computating with the infrastructure (network, hardware, CPU, etc) at the bottom and Software on the top. See The NIST Definition of Cloud Computing","title":"Service Models"},{"location":"cloud_glossary/#service-level-agreement-sla","text":"Level of service you expect from a vendor, laying out the metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved. In Cloud this is often spells out 'uptime,' which is percent of time the system is not down, e.g. 99.99%, and guarantees against data loss and availability. For most research, uptime is not important as we are our own customer and can tolerate some downtime.","title":"Service Level Agreement (SLA)"},{"location":"cloud_glossary/#services","text":"Cloud \"services\" are often bundles of resources pulled together for coordinate function. Cloud companies offer hundreds of often closely overlapping services.","title":"Services"},{"location":"cloud_glossary/#tags","text":"AWS and Azure allow you add meta data to resource in the form of tags (e.g. hashtags, etc) which are keys and values. When you create a resource you can add a tag indicating the project it is for e.g. \"project\" = \"dna-methylation\" To add more detail if your DNA methylation has multiple aspects or experiments, add more tags like \"experiment\" = \"Fall 2021\" For workgroups it's stronlgy suggested you add a \"created_by\" = your netid because it's often difficult in Azure to determine who created a resource if it needs to be turned off or deleted. Use tags to organize your Azure resources and management hierarchy","title":"Tags"},{"location":"cloud_glossary/#tensor-processing-unit-tpu","text":"Google Tensor Processing Unit is specialized computer chip similar to GPUs , used by deep learning libraries such as TensorFlow ( which leads to the question of \"what is a tensor\" and that depends on who you ask but similar to matrix.","title":"Tensor Processing Unit (TPU)"},{"location":"cloud_glossary/#virtual-machine","text":"(aka VM) Creating a simulated computer hardware using software, to be able run a guest operating system inside a host system, such that the guest thinks it's running on an actual computer.","title":"Virtual Machine"},{"location":"contact/","text":"Contacting Us If you are a Cloud Computing Fellowship participant this year (or past participant!), please contact the instructors Pat Bills or Mahmoud Parvizi with any issues or questions related to the material or activities. The session meetings are designed to have plenty of time for questions, troubleshooting and discussion. We will also schedule office hours prior to meeting times to help with pre-meeting activities. If you have general questions about the MSU Cloud Computing Fellowship, please contact Brian O'Shea or Danielle Barnes If you will be an MSU graduate student or post-doc in Fall 2022 and are interested in participating next year, please check back in the Summer of 2022 for announcements for invitation to participate, or request to join the MSU ICER mailing list If you are an MSU Researcher interested in using cloud for your research, please contact IT Services or MSU ICER via our ticketing systems and describe your needs.","title":"Contact"},{"location":"contact/#contacting-us","text":"If you are a Cloud Computing Fellowship participant this year (or past participant!), please contact the instructors Pat Bills or Mahmoud Parvizi with any issues or questions related to the material or activities. The session meetings are designed to have plenty of time for questions, troubleshooting and discussion. We will also schedule office hours prior to meeting times to help with pre-meeting activities. If you have general questions about the MSU Cloud Computing Fellowship, please contact Brian O'Shea or Danielle Barnes If you will be an MSU graduate student or post-doc in Fall 2022 and are interested in participating next year, please check back in the Summer of 2022 for announcements for invitation to participate, or request to join the MSU ICER mailing list If you are an MSU Researcher interested in using cloud for your research, please contact IT Services or MSU ICER via our ticketing systems and describe your needs.","title":"Contacting Us"},{"location":"index2021/","text":"This is the schedule for a previous year provided as an example. Please see our home page for the current year MSU Cloud Computing Fellowship 2021-2022 Welcome to the website for the MSU Cloud fellowship for 2021-2022. See our \" about \" page for more information about the program. Syllabus The program runs from Fall 2021 to Spring 2022 semester. Sessions are organized with pre-meeting materials (readings and videos), pre-requisites, and activities, which allow fellows to prepare for our Friday meetings where we will have hands-on activities and discussion. Schedule for Fall 2021 Session 1 : Introduction to the 21-22 Fellowship Sept 3: Meeting : program introductions and program overview (via zoom) Session 2 : Using the cloud for computing Sept 10: Using Virtual Machines workshop Session 3 : Cloud Storage Sept 24: Cloud Storage Workshop Session 4 : Moving data to the cloud October 8: Data utilities and services workshop (Azure Data Factory) Session 5 : Big Data Systems and the cloud Oct 22: Overview of Big Data on Azure with DataBricks Session 6 : Databases and Data Analytics Systems on the Cloud Oct 29: Overview of Databases on the cloud, SQL demonstration Session 7 : Serverless and Application Development Nov 12: Overview of Serverless and FaaS, Demonstration of Real-world project Session 8: Wrap up and project proposals Dec 3: Meeting : review and feedback on project proposals & general discussion Dec 17: Final Cloud Computing Fellowship project proposal submission date Schedule for Winter/Spring 2022 Meetings We will meet virtually according to the schedule below for 'project update' presentations and group discussions. If you have a scheduling conflict, please let us know as soon as possible. February 4th : Presentation of Revised Project and current status March 4th : TBD April 8th : TBD All sessions 2:00-4:00pm EST Zoom links and password will be sent over email. Virtual Office Hours Sessions We will also hold two Friday virtual helpdesk sessions per month. Feel free to take advantage of these voluntary sessions for help with specifics on your project, presentations, and/or general research computing topics. January 14th and 28th February 11th and 25th March 18th and 25th April 1st and 15th all office hours sessions 2:00-3:30pm EST Zoom links and password will be sent over email but will be the same as for the meetings above. We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general. We will get back with you when we can and schedule a time for a virtual 1-1 meeting. Symposium and Project Presentations Participants will present projects in late April at a symposium for the Cloud Computing Fellowship. The exact date and time to be determined, and virtual vs in-person also to be determined. Textbook We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters. Communications Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! Meeting location Given the state of the pandemic in late summer 2021, we are hosting our first meeting (September 3) via zoom. Participants will be sent a link via email. Locations for future meetings are to be determined and based on participant feedback. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Previous 21-22 syllabus"},{"location":"index2021/#msu-cloud-computing-fellowship-2021-2022","text":"Welcome to the website for the MSU Cloud fellowship for 2021-2022. See our \" about \" page for more information about the program.","title":"MSU Cloud Computing Fellowship 2021-2022"},{"location":"index2021/#syllabus","text":"The program runs from Fall 2021 to Spring 2022 semester. Sessions are organized with pre-meeting materials (readings and videos), pre-requisites, and activities, which allow fellows to prepare for our Friday meetings where we will have hands-on activities and discussion.","title":"Syllabus"},{"location":"index2021/#schedule-for-fall-2021","text":"Session 1 : Introduction to the 21-22 Fellowship Sept 3: Meeting : program introductions and program overview (via zoom) Session 2 : Using the cloud for computing Sept 10: Using Virtual Machines workshop Session 3 : Cloud Storage Sept 24: Cloud Storage Workshop Session 4 : Moving data to the cloud October 8: Data utilities and services workshop (Azure Data Factory) Session 5 : Big Data Systems and the cloud Oct 22: Overview of Big Data on Azure with DataBricks Session 6 : Databases and Data Analytics Systems on the Cloud Oct 29: Overview of Databases on the cloud, SQL demonstration Session 7 : Serverless and Application Development Nov 12: Overview of Serverless and FaaS, Demonstration of Real-world project Session 8: Wrap up and project proposals Dec 3: Meeting : review and feedback on project proposals & general discussion Dec 17: Final Cloud Computing Fellowship project proposal submission date","title":"Schedule for Fall 2021"},{"location":"index2021/#schedule-for-winterspring-2022","text":"","title":"Schedule for Winter/Spring 2022"},{"location":"index2021/#meetings","text":"We will meet virtually according to the schedule below for 'project update' presentations and group discussions. If you have a scheduling conflict, please let us know as soon as possible. February 4th : Presentation of Revised Project and current status March 4th : TBD April 8th : TBD All sessions 2:00-4:00pm EST Zoom links and password will be sent over email.","title":"Meetings"},{"location":"index2021/#virtual-office-hours-sessions","text":"We will also hold two Friday virtual helpdesk sessions per month. Feel free to take advantage of these voluntary sessions for help with specifics on your project, presentations, and/or general research computing topics. January 14th and 28th February 11th and 25th March 18th and 25th April 1st and 15th all office hours sessions 2:00-3:30pm EST Zoom links and password will be sent over email but will be the same as for the meetings above. We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general. We will get back with you when we can and schedule a time for a virtual 1-1 meeting.","title":"Virtual Office Hours Sessions"},{"location":"index2021/#symposium-and-project-presentations","text":"Participants will present projects in late April at a symposium for the Cloud Computing Fellowship. The exact date and time to be determined, and virtual vs in-person also to be determined.","title":"Symposium and Project Presentations"},{"location":"index2021/#textbook","text":"We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters.","title":"Textbook"},{"location":"index2021/#communications","text":"Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions!","title":"Communications"},{"location":"index2021/#meeting-location","text":"Given the state of the pandemic in late summer 2021, we are hosting our first meeting (September 3) via zoom. Participants will be sent a link via email. Locations for future meetings are to be determined and based on participant feedback. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Meeting location"},{"location":"miniproject/","text":"MSU Cloud Computing Fellowship \"miniproject\" git repo: here is the data, here is the analysis script (R vs Python) basic architecture schematic for what they will create elements - create storage - put data into storage - spin up VM with these parameters - include CLI code for the adventurous - can use portal instead - attach the storage - log-in and install software - run analysis, run script, - save output to cloud - storage - database - turn off - determine total costs - table of costs by resource for the time period the analysis would made - by the end of the workshop/assignment. - Move data into the cloud, analyze it, save output, and determine the costs Script for the end goal general : calculate something. R: Python:","title":"Miniproject"},{"location":"miniproject/#msu-cloud-computing-fellowship-miniproject","text":"git repo: here is the data, here is the analysis script (R vs Python) basic architecture schematic for what they will create elements - create storage - put data into storage - spin up VM with these parameters - include CLI code for the adventurous - can use portal instead - attach the storage - log-in and install software - run analysis, run script, - save output to cloud - storage - database - turn off - determine total costs - table of costs by resource for the time period the analysis would made - by the end of the workshop/assignment. - Move data into the cloud, analyze it, save output, and determine the costs Script for the end goal general : calculate something. R: Python:","title":"MSU Cloud Computing Fellowship \"miniproject\""},{"location":"projects/","text":"About The Fellowship Projects The fellowship is structured to first provide materials and help to learn core cloud concepts and activies, and to promote how to learn about cloud from existing documentation. This is to support a small, cloud-based research project that is the main object of the fellowship Introduction to CCF Projects , Slides as PDF from Dr. Mahmoud Parvizi Qs and Notes about projects Q. Do I have to use my own data for my project or can I use data from the web or other public data? A. you can bring any data that you may use for your research, or that demonstrates cloud processes you may use in your research. Q. I don't know how to use the stuff I'm learning so far for my project. Wat do I do? A. We will cover several new topics that are adjacent to cloud computing that may be suited for you. Databases for tabular or structured data Data systems in general Big data processing with Python notebooks Q. Do I have to use programming in my project? A. Most of the examples provided in the fellowship talk about processing data with scripts such as R or Python and many researchers are using these for data analysis, but it's not required for a successful project. You could install a program on a powerful virtual machine and show how to use that software along with cloud storage to tackle a large data set (for example). Secondly there are many forms of cloud computing that are not traditional such as data systems which may use a GUI or a language like SQL. One important aspect of a successful project is \"workflow thinking\" or how could you design your process so that you could do it 100 times or with some form of automation. That often requires programming but there are cloud systems that don't require programming (e.g. Azure Data Factory). Accumulating and organizing data is a huge part of successful research and using cloud tools to facilitate that and documenting the process, advantages and costs would be a successful project. Q. Do I have to use Virtual Machine as part of my project? No you don't, and in fact we encourage you to look for other services in the cloud to work with your data or your research processes. Q. Are there constraints on the things I want do with my project? Can I do whatever I want? A. Our goal is to facilitate your education and advancing your research program as it relates to cloud computing. This is a large topic If you use the fellowship to develop only a small system to show what's possible or not possible, even on public data, that uses cloud computing, that is an acceptable project. Q. I want to make a web site or application for my project, can I use a VM? how do I do that? A. This is a common request and the cloud was invented in part to run web applications. However web application design is a huge subject and the programming involved is almost as complex as any programming or data work you've done for your research. We tend to discourage projects focused on web applications because of the work involved to both 1) create the infrastructure for a website (web server, storage, databases, possibly docker containers, etc) and 2) the web application itself (Python/PHP other language, HTML, Javascript, Style Sheets, etc). However Azure has services for hosting websites but don't attempt this for your project unless you have previous experience making websites or web applications, or if you are up for the big challenge of learning webdev along with cloud computing because the research you are showing off is mostly complete. Secondly web services must be on-line 24/7 and the cost may accumulate quickly. Finally cybsecurity is a major issues for websites which present an open door to anyone on the Internet. keeping your site secure is a major challenge so during development please turn it off when you are not using it, and consider that web applications are hacked routinely. However if this is a goal for your and your advisor please come speak with us as we have experience creating research web applications.","title":"About The Fellowship Projects"},{"location":"projects/#about-the-fellowship-projects","text":"The fellowship is structured to first provide materials and help to learn core cloud concepts and activies, and to promote how to learn about cloud from existing documentation. This is to support a small, cloud-based research project that is the main object of the fellowship Introduction to CCF Projects , Slides as PDF from Dr. Mahmoud Parvizi Qs and Notes about projects Q. Do I have to use my own data for my project or can I use data from the web or other public data? A. you can bring any data that you may use for your research, or that demonstrates cloud processes you may use in your research. Q. I don't know how to use the stuff I'm learning so far for my project. Wat do I do? A. We will cover several new topics that are adjacent to cloud computing that may be suited for you. Databases for tabular or structured data Data systems in general Big data processing with Python notebooks Q. Do I have to use programming in my project? A. Most of the examples provided in the fellowship talk about processing data with scripts such as R or Python and many researchers are using these for data analysis, but it's not required for a successful project. You could install a program on a powerful virtual machine and show how to use that software along with cloud storage to tackle a large data set (for example). Secondly there are many forms of cloud computing that are not traditional such as data systems which may use a GUI or a language like SQL. One important aspect of a successful project is \"workflow thinking\" or how could you design your process so that you could do it 100 times or with some form of automation. That often requires programming but there are cloud systems that don't require programming (e.g. Azure Data Factory). Accumulating and organizing data is a huge part of successful research and using cloud tools to facilitate that and documenting the process, advantages and costs would be a successful project. Q. Do I have to use Virtual Machine as part of my project? No you don't, and in fact we encourage you to look for other services in the cloud to work with your data or your research processes. Q. Are there constraints on the things I want do with my project? Can I do whatever I want? A. Our goal is to facilitate your education and advancing your research program as it relates to cloud computing. This is a large topic If you use the fellowship to develop only a small system to show what's possible or not possible, even on public data, that uses cloud computing, that is an acceptable project. Q. I want to make a web site or application for my project, can I use a VM? how do I do that? A. This is a common request and the cloud was invented in part to run web applications. However web application design is a huge subject and the programming involved is almost as complex as any programming or data work you've done for your research. We tend to discourage projects focused on web applications because of the work involved to both 1) create the infrastructure for a website (web server, storage, databases, possibly docker containers, etc) and 2) the web application itself (Python/PHP other language, HTML, Javascript, Style Sheets, etc). However Azure has services for hosting websites but don't attempt this for your project unless you have previous experience making websites or web applications, or if you are up for the big challenge of learning webdev along with cloud computing because the research you are showing off is mostly complete. Secondly web services must be on-line 24/7 and the cost may accumulate quickly. Finally cybsecurity is a major issues for websites which present an open door to anyone on the Internet. keeping your site secure is a major challenge so during development please turn it off when you are not using it, and consider that web applications are hacked routinely. However if this is a goal for your and your advisor please come speak with us as we have experience creating research web applications.","title":"About The Fellowship Projects"},{"location":"index2021/session_bigdata/","text":"Session 5: Big Data on Azure Cloud Featuring Spark You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that build complex data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling. Meeting October 22 2:00-3:30pm Discussion and Questions of material from previous sessions Project related questions Lecture Overview of Big Data with Spark for Researchers Big Data Q & A Videos Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code Readings Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by Cloud Computing Fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and readable introductions to \"big data\" I've ever seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial) For R users You can use R commands with Spark, and Databricks has the eoption of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark in their projects The book above describes how to use it in detail As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describee how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft. Activities There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"Session 5: Big Data on Azure Cloud Featuring Spark"},{"location":"index2021/session_bigdata/#session-5-big-data-on-azure-cloud-featuring-spark","text":"You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that build complex data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling.","title":"Session 5: Big Data on Azure Cloud Featuring Spark"},{"location":"index2021/session_bigdata/#meeting-october-22-200-330pm","text":"Discussion and Questions of material from previous sessions Project related questions Lecture Overview of Big Data with Spark for Researchers Big Data Q & A","title":"Meeting October 22 2:00-3:30pm"},{"location":"index2021/session_bigdata/#videos","text":"Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code","title":"Videos"},{"location":"index2021/session_bigdata/#readings","text":"Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by Cloud Computing Fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and readable introductions to \"big data\" I've ever seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial)","title":"Readings"},{"location":"index2021/session_bigdata/#for-r-users","text":"You can use R commands with Spark, and Databricks has the eoption of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark in their projects The book above describes how to use it in detail As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describee how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft.","title":"For R users"},{"location":"index2021/session_bigdata/#activities","text":"There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"Activities"},{"location":"index2021/session_bigdata/principles_using_databricks/","text":"DRAFT Using Databricks and References Basic function Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .). How tos Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"DRAFT Using Databricks and References"},{"location":"index2021/session_bigdata/principles_using_databricks/#draft-using-databricks-and-references","text":"","title":"DRAFT Using Databricks and References"},{"location":"index2021/session_bigdata/principles_using_databricks/#basic-function","text":"Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .).","title":"Basic function"},{"location":"index2021/session_bigdata/principles_using_databricks/#how-tos","text":"Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"How tos"},{"location":"index2021/session_cloud_storage/","text":"Session 3: Cloud Storage Introduction Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size. The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud companies think of \"storage\" as anything that save files, or perhaps more importantly anything they can market to you as something to save files. Readings Storage as a Service from \"Cloud Computing for Science and Engineering\" Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) Table of Azure Storage Product Offerings Azure Documentation: Introduction to the core Azure Storage services Slides/Lecture: Azure Cloud Storage for Researchers with links for details on each slide optional Understanding block blobs, append blobs, and page blobs Activities Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Using Azure Cloud Storage to create and use storage Azure Storage Pricing Exercise Meeting September 24 2:00-3:30pm About Projects, Mahmoud Parvizi Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines What is cloud storage? concept review: cloud storage vs VM disks discuss exercises to be worked on next week Review of Broad Cloud Concepts: On-Demand, Compute, Storage, Identity Management Discussion : future activities and needs Optional Activity: Python And Cloud Storage For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: use the blob storage account you created in the exercise above familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line","title":"Session 3: Cloud Storage"},{"location":"index2021/session_cloud_storage/#session-3-cloud-storage","text":"","title":"Session 3: Cloud Storage"},{"location":"index2021/session_cloud_storage/#introduction","text":"Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size. The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud companies think of \"storage\" as anything that save files, or perhaps more importantly anything they can market to you as something to save files.","title":"Introduction"},{"location":"index2021/session_cloud_storage/#readings","text":"Storage as a Service from \"Cloud Computing for Science and Engineering\" Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) Table of Azure Storage Product Offerings Azure Documentation: Introduction to the core Azure Storage services Slides/Lecture: Azure Cloud Storage for Researchers with links for details on each slide optional Understanding block blobs, append blobs, and page blobs","title":"Readings"},{"location":"index2021/session_cloud_storage/#activities","text":"Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Using Azure Cloud Storage to create and use storage Azure Storage Pricing Exercise","title":"Activities"},{"location":"index2021/session_cloud_storage/#meeting-september-24-200-330pm","text":"About Projects, Mahmoud Parvizi Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines What is cloud storage? concept review: cloud storage vs VM disks discuss exercises to be worked on next week Review of Broad Cloud Concepts: On-Demand, Compute, Storage, Identity Management Discussion : future activities and needs","title":"Meeting September 24 2:00-3:30pm"},{"location":"index2021/session_cloud_storage/#optional-activity","text":"Python And Cloud Storage For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: use the blob storage account you created in the exercise above familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line","title":"Optional Activity:"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/","text":"Exercise: Using Azure Cloud Storage Pre-requisites Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item. Azure Quickstart Tutorials Storage Account We created a storage account in one of the first activities, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far. Blob Storage Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob File Storage In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"Exercise: Using Azure Cloud Storage"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#exercise-using-azure-cloud-storage","text":"","title":"Exercise: Using Azure Cloud Storage"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#pre-requisites","text":"Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item.","title":"Pre-requisites"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#azure-quickstart-tutorials","text":"","title":"Azure Quickstart Tutorials"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#storage-account","text":"We created a storage account in one of the first activities, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far.","title":"Storage Account"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#blob-storage","text":"Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob","title":"Blob Storage"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#file-storage","text":"In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"File Storage"},{"location":"index2021/session_cloud_storage/storage_pricing_exercise/","text":"Prior to doing this exercise, See the reading and lecture slides linked in this session for definitions of terms. How large, approximately, is your data? If you are unsure, estimate 100 gb. How much would it cost to keep it in the cloud? Compare the pricing for Blob, Files and Disk storage for 6 months Aspects Of Storage: Redunancy: Always slect \"LRS\" as that is almost always sufficient and for con Storage prices are not the same across regions, but the default (\"East US\") works for this exercise Consider only the \"Hot\" storage of the different tiers (\"Premium\", \"Hot\", \"Cool\", and \"Archive\") for some high performance applications, Premium is required, but look at the price difference! Operations, Transactions and data transfer costs charged per 10K operations really hard to estimate unless you know your workload very low costs, e.g. reading 10K Blobs costs 1/2 of one cent. I would not bother estimating this cost unless you know you will have very high disk operations Types of Storage to Compare: Azure Blob Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/blobs/ select \"Hierachcial namespace\" Azure Files Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/files/ Managed Disk Pricing : https://azure.microsoft.com/en-us/pricing/details/managed-disks/ note these are in different sizes and types, select 128gb size if you are estimating 100gb data, Standard SSD when you create a disk in the protal, it defaults to 1 TiB size, which is quite expensive / month Optional: compare with On-premise storage costs The MSU HPC offers 1TB storage with redundant backups and high-speed access for free, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?","title":"Storage pricing exercise"},{"location":"index2021/session_cloud_storage/storage_pricing_exercise/#optional-compare-with-on-premise-storage-costs","text":"The MSU HPC offers 1TB storage with redundant backups and high-speed access for free, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?","title":"Optional: compare with On-premise storage costs"},{"location":"index2021/session_datasystems/","text":"Session 6: Data Servers on the Cloud Introduction Data servers like Relational Databases can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s but there are many other types. A central advantage of data servers is ability to have multiple econnections at once from many users, a busy web application, or parallel processing. Like Big Data tools, these data systems don't require cloud computing, but cloud companies offer database servers with a few clicks that require very littls management. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project. Meeting October 29 2:00-3:30pm Discussion of Previous Topics, Q&A Slide Presentation: Introduction to Data Servers on the Cloud Q & A, Discussion of Data Servers and Systems on the Cloud Readings From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" see the Chapter 4. Databases by Foster, Ghani, Jarmin, Kreuter and Lane which could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read Activities Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help provisioning and connecting to a SQL system. Optional : Data Analytics on the Google Platform Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"Session 6: Data Servers on the Cloud"},{"location":"index2021/session_datasystems/#session-6-data-servers-on-the-cloud","text":"","title":"Session 6: Data Servers on the Cloud"},{"location":"index2021/session_datasystems/#introduction","text":"Data servers like Relational Databases can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s but there are many other types. A central advantage of data servers is ability to have multiple econnections at once from many users, a busy web application, or parallel processing. Like Big Data tools, these data systems don't require cloud computing, but cloud companies offer database servers with a few clicks that require very littls management. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project.","title":"Introduction"},{"location":"index2021/session_datasystems/#meeting-october-29-200-330pm","text":"Discussion of Previous Topics, Q&A Slide Presentation: Introduction to Data Servers on the Cloud Q & A, Discussion of Data Servers and Systems on the Cloud","title":"Meeting October 29 2:00-3:30pm"},{"location":"index2021/session_datasystems/#readings","text":"From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" see the Chapter 4. Databases by Foster, Ghani, Jarmin, Kreuter and Lane which could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read","title":"Readings"},{"location":"index2021/session_datasystems/#activities","text":"Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help provisioning and connecting to a SQL system.","title":"Activities"},{"location":"index2021/session_datasystems/#optional-data-analytics-on-the-google-platform","text":"Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"Optional : Data Analytics on the Google Platform"},{"location":"index2021/session_datasystems/data_servers_intro_for_researchers_edited_with_typora/","text":"Overview of Data Servers and Databases on the Cloud for Researchers","title":"Data servers intro for researchers edited with typora"},{"location":"index2021/session_datasystems/table_of_responsibilties_by_service_level/","text":"Layer Responsibility On-Prem IAAS (VM) PAAS SAAS Network Connectivity & Security Campus IT Service Service Service Hardware Disk Failures You Service Service Service Operating System Updates, installation, security You You Service Service Security Software Install and maintain You You Service Service Server Software Install, maintain You You Service Service Server Configuration Tune, Speed, You You You (limited) Service User Configuration Who can access, user accounts You You You Service Code/Data You You You You","title":"Table of responsibilties by service level"},{"location":"index2021/session_how_to_cloud/","text":"Session 2: What is the cloud and how does it work? An introduction using Virtual Machines When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\" Readings Cloud background The NIST Definition of Cloud Computing The framework that most widely used to describe aspects of cloud computing, and categorize cloud sevices. Microsoft Reference Architecture: What is Infrastructure as a Service? Orientation Azure Portal Other References These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf) Fellowship Materials Top-down description of how Azure is organized Summary of Cloud Interfaces Virtual Machine Background What is a virtual machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company Activities Using the Azure Portal : tutorial and video This is a more detailed tutorial and video of the quick walk-through we did during our live session for Week 1 on September 3 Fellowship Meeting September 10, 2021. Zoom link sent via email Presentation (PDF) Review of Introduction to Cloud materials: discussion and questions Questions about the nature of cloud Activity: Creating (and deleting) a Virtual Machine with Azure updated 9/16; includes instructions for Linux Additional Post-session materials Determining Azure Costs","title":"Session 2: What is the cloud and how does it work?  An introduction using Virtual Machines"},{"location":"index2021/session_how_to_cloud/#session-2-what-is-the-cloud-and-how-does-it-work-an-introduction-using-virtual-machines","text":"When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\"","title":"Session 2: What is the cloud and how does it work?  An introduction using Virtual Machines"},{"location":"index2021/session_how_to_cloud/#readings","text":"","title":"Readings"},{"location":"index2021/session_how_to_cloud/#cloud-background","text":"The NIST Definition of Cloud Computing The framework that most widely used to describe aspects of cloud computing, and categorize cloud sevices. Microsoft Reference Architecture: What is Infrastructure as a Service? Orientation Azure Portal","title":"Cloud background"},{"location":"index2021/session_how_to_cloud/#other-references","text":"These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)","title":"Other References"},{"location":"index2021/session_how_to_cloud/#fellowship-materials","text":"Top-down description of how Azure is organized Summary of Cloud Interfaces","title":"Fellowship Materials"},{"location":"index2021/session_how_to_cloud/#virtual-machine-background","text":"What is a virtual machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company","title":"Virtual Machine Background"},{"location":"index2021/session_how_to_cloud/#activities","text":"Using the Azure Portal : tutorial and video This is a more detailed tutorial and video of the quick walk-through we did during our live session for Week 1 on September 3","title":"Activities"},{"location":"index2021/session_how_to_cloud/#fellowship-meeting","text":"September 10, 2021. Zoom link sent via email Presentation (PDF) Review of Introduction to Cloud materials: discussion and questions Questions about the nature of cloud Activity: Creating (and deleting) a Virtual Machine with Azure updated 9/16; includes instructions for Linux","title":"Fellowship Meeting"},{"location":"index2021/session_how_to_cloud/#additional-post-session-materials","text":"Determining Azure Costs","title":"Additional Post-session materials"},{"location":"index2021/session_how_to_cloud/azure_organization/","text":"Azure Organization This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful. Azure Locations or Regions Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Organization"},{"location":"index2021/session_how_to_cloud/azure_organization/#azure-organization","text":"This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful.","title":"Azure Organization"},{"location":"index2021/session_how_to_cloud/azure_organization/#azure-locations-or-regions","text":"Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Locations or Regions"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/","text":"Exercise: Azure Portal Walk-through and Storage account creation MSU Cloud Computing Fellowship About This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure , but it can be a great place to start exploring and trying new services. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material. Orientation to the Azure Portal The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in) This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal: cloud shell: see (link TBD) directories: about your subscription notifications: alerts when things change (when they are created, deleted) settings : most will not be valuable unless you create many resources, but feel free to change these, although do not change your email address help/support feedback : to the Azure people A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere. Creating storage account with the Azure portal Note: It's ok if you would like to repeat this tutorial, there will be minimal costs and you may delete the resources you create (instructions for deleting at the end). You don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. You need a place to keep your stuff for a long time (persist your data) and cloud storage is a durable and inexpensive system for storage nearly unlimited files (or 'objects' in cloud terms). However as we will discover cloud storage is not the same as \"disk storage\" and works differently. Hence you need a storage \"account.\" Requirements: An Azure Account with valid subscription A Resource group All members of the current Cloud Computing Fellowship cohort have these things Tutorial Steps. Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Computing Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: This name must be unique for this region in azure, so Use your NetID for part of the name replace \"NETID\" with your MSU NetID here: \"cf21NETIDstorage\" e.g. cf21billspatstorage If you are repeating this tutorial, simply add a \"2\" or \"cf21billspatstorage2\" some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) Region (Location): You may leave US East, or click to select something closer to MSU (e.g. North Central US) Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS) although we won't see a different, LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. Networking: leave all of these settings as-is Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing Tags tags are optional but highly recommended. Tags are notes to yourself about the resource, use them for metadata. At MSU ADS we always have a tag with the key \"created by\" and value the netid of the creator. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa About Portal \"Resource\" Pages Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#exercise-azure-portal-walk-through-and-storage-account-creation","text":"MSU Cloud Computing Fellowship","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#about","text":"This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure , but it can be a great place to start exploring and trying new services. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material.","title":"About"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#orientation-to-the-azure-portal","text":"The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in) This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal: cloud shell: see (link TBD) directories: about your subscription notifications: alerts when things change (when they are created, deleted) settings : most will not be valuable unless you create many resources, but feel free to change these, although do not change your email address help/support feedback : to the Azure people A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere.","title":"Orientation to the Azure Portal"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#creating-storage-account-with-the-azure-portal","text":"Note: It's ok if you would like to repeat this tutorial, there will be minimal costs and you may delete the resources you create (instructions for deleting at the end). You don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. You need a place to keep your stuff for a long time (persist your data) and cloud storage is a durable and inexpensive system for storage nearly unlimited files (or 'objects' in cloud terms). However as we will discover cloud storage is not the same as \"disk storage\" and works differently. Hence you need a storage \"account.\" Requirements: An Azure Account with valid subscription A Resource group All members of the current Cloud Computing Fellowship cohort have these things","title":"Creating storage account with the Azure portal"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#tutorial-steps","text":"Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Computing Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: This name must be unique for this region in azure, so Use your NetID for part of the name replace \"NETID\" with your MSU NetID here: \"cf21NETIDstorage\" e.g. cf21billspatstorage If you are repeating this tutorial, simply add a \"2\" or \"cf21billspatstorage2\" some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) Region (Location): You may leave US East, or click to select something closer to MSU (e.g. North Central US) Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS) although we won't see a different, LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. Networking: leave all of these settings as-is Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing Tags tags are optional but highly recommended. Tags are notes to yourself about the resource, use them for metadata. At MSU ADS we always have a tag with the key \"created by\" and value the netid of the creator. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa","title":"Tutorial Steps."},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#about-portal-resource-pages","text":"Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"About Portal \"Resource\" Pages"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/","text":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session. Requirements for both activities You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux) Creating a Windows Virtual Machine This section is based on Windows. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. Requirements for Windows VMs To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/ Optional: Creating a Linux Virtual Machine This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible). Requirements To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in but there are other programs Linux desktop/laptops come with an ssh client Creating a Linux Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-linuxdsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. 1. Authentication Type For the purpose of this exercise, select \"password\" If you are very familiar with ssh keys, this is the recommended method. You will be asked to download a key and use that key in your ssh command. The key is only available for download when you create this vm and if you lose it you can't connect. We can definitely cover how to use ssh keys as this is the preferred method for connecting. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.1000 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section Viewing VM Resources in your Resource group (Windows and Linux) While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) Connecting Connecting to a Windows VM using Remote Desktop Protocol (RDP) client You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines. Connecting to a Linux VM using SSH We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Starting and Stopping the VM (both Windows and Linux) There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal: Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. Deleting the Resources (both Windows and Linux) Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges. More Refereences Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#exercise-creating-and-connecting-to-a-virtual-machine-vm-for-both-windows-and-linux","text":"Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session.","title":"About"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements-for-both-activities","text":"You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux)","title":"Requirements for both activities"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#creating-a-windows-virtual-machine","text":"This section is based on Windows. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements-for-windows-vms","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements for Windows VMs"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows.","title":"Basics"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#tags","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/","title":"Review and Create"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#optional-creating-a-linux-virtual-machine","text":"This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible).","title":"Optional:  Creating a Linux Virtual Machine"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements","text":"To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in but there are other programs Linux desktop/laptops come with an ssh client","title":"Requirements"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#creating-a-linux-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Linux Virtual Machine"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template_1","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration_1","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal_1","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#basics_1","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-linuxdsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. 1. Authentication Type For the purpose of this exercise, select \"password\" If you are very familiar with ssh keys, this is the recommended method. You will be asked to download a key and use that key in your ssh command. The key is only available for download when you create this vm and if you lose it you can't connect. We can definitely cover how to use ssh keys as this is the preferred method for connecting. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use","title":"Basics"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings_1","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#tags_1","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#review-and-create_1","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.1000 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section","title":"Review and Create"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#viewing-vm-resources-in-your-resource-group-windows-and-linux","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"Viewing VM Resources in your Resource group (Windows and Linux)"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"The VM Resource Page"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting","text":"","title":"Connecting"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-windows-vm-using-remote-desktop-protocol-rdp-client","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines.","title":"Connecting to a Windows VM using Remote Desktop Protocol (RDP) client"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-linux-vm-using-ssh","text":"We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt.","title":"Connecting to a Linux VM using SSH"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#starting-and-stopping-the-vm-both-windows-and-linux","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it.","title":"Starting and Stopping the VM (both Windows and Linux)"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#stopping-deallocating-the-vm-with-the-portal","text":"Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"Stopping (deallocating) the VM with the Portal:"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#deleting-the-resources-both-windows-and-linux","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges.","title":"Deleting the Resources (both Windows and Linux)"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#more-refereences","text":"Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring","title":"More Refereences"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/","text":"Exercise: Creating a Windows Virtual Machine (VM) Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in) About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ Requirements You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided. Creating and Connecting to a Windows Virtual Machine Requirements To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. Creating a Windows Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. 4. The Resources While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) 5. The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) 6. Connecting You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. 7. Starting and Stopping the VM There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. 8. Deleting the Resources Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#exercise-creating-a-windows-virtual-machine-vm","text":"Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in)","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/","title":"About"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#requirements","text":"You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided.","title":"Requirements "},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#creating-and-connecting-to-a-windows-virtual-machine","text":"","title":"Creating and Connecting to a Windows Virtual Machine"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#requirements_1","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#creating-a-windows-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked.","title":"Basics"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#tags","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes.","title":"Review and Create"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#4-the-resources","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"4. The Resources"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#5-the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"5. The VM Resource Page"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#6-connecting","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt.","title":"6. Connecting"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#7-starting-and-stopping-the-vm","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"7. Starting and Stopping the VM"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#8-deleting-the-resources","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"8. Deleting the Resources"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/","text":"Interfacing with Cloud Services Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad. Summary of Cloud Interfaces This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html Graphical Web Interface Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface. Desktop Applications Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure Command Line For those not familar wiht the command line, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell. SDK : Software Developer Kit A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to? Python SDK All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors. R Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages. Cloud company frameworks In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation . Azure: ARM templates Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates Third-party programming with Terraform There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The ad - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary Building Cloud from Cloud This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language. References See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"Interfacing with Cloud Services"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#interfacing-with-cloud-services","text":"Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad.","title":"Interfacing with Cloud Services"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#summary-of-cloud-interfaces","text":"This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html","title":"Summary of Cloud Interfaces"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#graphical-web-interface","text":"Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface.","title":"Graphical Web Interface"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#desktop-applications","text":"Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure","title":"Desktop Applications"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#command-line","text":"For those not familar wiht the command line, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell.","title":"Command Line"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#sdk-software-developer-kit","text":"A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to?","title":"SDK : Software Developer Kit"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#python-sdk","text":"All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors.","title":"Python SDK"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#r","text":"Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages.","title":"R"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#cloud-company-frameworks","text":"In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation .","title":"Cloud company frameworks"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#azure-arm-templates","text":"Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates","title":"Azure: ARM templates"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#third-party-programming-with-terraform","text":"There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The ad - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary","title":"Third-party programming with Terraform"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#building-cloud-from-cloud","text":"This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language.","title":"Building Cloud from Cloud"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#references","text":"See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"References"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/","text":"Workshop : Creating your own cloud computer Introduction This workshop walks you though , using Microsoft Azure, the creation of a cloud virtual machine and opens access to it. We will use command line access to use the remote machine to download data and run a calculation. this is a similar experience to using any remote Linux system, such as the MSU HPCC. Pre-requistites Microsoft Azure account (provisioned for participants) No previous experience with cloud virtual machines necessary Using the Azure portal to create a resource group (should this be creatd ahead of time?) Create a virtual machine using a template Create a data science virtual machine using a template. portal create... in search bar type \"data science virtual machine select \"d s v m Ubuntu\" select \"pre-configured\" click \"dev test\" and then below click \"general purpose\", and then 'next' \"Basics\" Section: in next screen select or entered the following options. Resource Group: select your resource group VM Name: please enter a name with the following pattern cf-dvsm-netid using your own netid Region : select the default Image : should say \"Data Science Virtual machine - Unbuntu 18.0.4 - Gen 1\" Azure Spot Instance : leave unchecked Size : Standard_D2s_v3 ($80/month) note: it will only cost pennies per hour Administrator account : select \"password\" note: ssh key is more secure but requires time consuming setup Username : enter your netid this is easy to remember Password : please enter a complex password don't use your actual netid password, also write it down as we will only use it once and it can't be recovered click \"next (disks)\" Note in this \"Create a Virtual Machine page, there are several sections across the top Basics Disks Networking Management Advanced Tags Review + create We can skip all sections now and go to \"Review + create\" Product details: note the costs (mine is 0.1100 USD/hr) click the \"Create\" button at the bottom of this screen wait. the screen should say \"Deployment in Progress\" report any errors or problems click \"Go to Resource\" when it's complete Exploring the Azure portal this portal page lists details about this virtual machine. Connect options to connect to remote linux computer: ssh , alwayws works, requires Mac terminal or windows or mobaxterm Rstudio Server (must be started) Jupyter Notebooks (must be started) Remote desktop (must be installed on VM, and a client must be installed on laptop) test connection: in the left hand menu of the VM resource, find the \"connect\" section click the \"ssh\" section if not already selected near the bottom click \"test your connection\" connect with ssh: open your terminal program in the portal, find the machine ip address issue command ssh azureuser@<ip> Download Data Using standard Linux tools we will download data onto this remote computer Log-in via ssh if you haven't already use the following command to download data set git clone https://github.com/fivethirtyeight/data/tree/master/college-majors review the files using linux commands cd college-majors; ls head grad-students.csv Start R studio Server","title":"Workshop : Creating your own cloud computer"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#workshop-creating-your-own-cloud-computer","text":"","title":"Workshop : Creating your own cloud computer"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#introduction","text":"This workshop walks you though , using Microsoft Azure, the creation of a cloud virtual machine and opens access to it. We will use command line access to use the remote machine to download data and run a calculation. this is a similar experience to using any remote Linux system, such as the MSU HPCC.","title":"Introduction"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#pre-requistites","text":"Microsoft Azure account (provisioned for participants) No previous experience with cloud virtual machines necessary","title":"Pre-requistites"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#using-the-azure-portal-to-create-a-resource-group","text":"(should this be creatd ahead of time?)","title":"Using the Azure portal to create a resource group"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#create-a-virtual-machine-using-a-template","text":"Create a data science virtual machine using a template. portal create... in search bar type \"data science virtual machine select \"d s v m Ubuntu\" select \"pre-configured\" click \"dev test\" and then below click \"general purpose\", and then 'next' \"Basics\" Section: in next screen select or entered the following options. Resource Group: select your resource group VM Name: please enter a name with the following pattern cf-dvsm-netid using your own netid Region : select the default Image : should say \"Data Science Virtual machine - Unbuntu 18.0.4 - Gen 1\" Azure Spot Instance : leave unchecked Size : Standard_D2s_v3 ($80/month) note: it will only cost pennies per hour Administrator account : select \"password\" note: ssh key is more secure but requires time consuming setup Username : enter your netid this is easy to remember Password : please enter a complex password don't use your actual netid password, also write it down as we will only use it once and it can't be recovered click \"next (disks)\" Note in this \"Create a Virtual Machine page, there are several sections across the top Basics Disks Networking Management Advanced Tags Review + create We can skip all sections now and go to \"Review + create\" Product details: note the costs (mine is 0.1100 USD/hr) click the \"Create\" button at the bottom of this screen wait. the screen should say \"Deployment in Progress\" report any errors or problems click \"Go to Resource\" when it's complete","title":"Create a virtual machine using a template"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#exploring-the-azure-portal","text":"this portal page lists details about this virtual machine.","title":"Exploring the Azure portal"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#connect","text":"options to connect to remote linux computer: ssh , alwayws works, requires Mac terminal or windows or mobaxterm Rstudio Server (must be started) Jupyter Notebooks (must be started) Remote desktop (must be installed on VM, and a client must be installed on laptop) test connection: in the left hand menu of the VM resource, find the \"connect\" section click the \"ssh\" section if not already selected near the bottom click \"test your connection\" connect with ssh: open your terminal program in the portal, find the machine ip address issue command ssh azureuser@<ip>","title":"Connect"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#download-data","text":"Using standard Linux tools we will download data onto this remote computer Log-in via ssh if you haven't already use the following command to download data set git clone https://github.com/fivethirtyeight/data/tree/master/college-majors review the files using linux commands cd college-majors; ls head grad-students.csv","title":"Download Data"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#start-r-studio-server","text":"","title":"Start R studio Server"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm/","text":"Workshop : Creating your own cloud computer For Session 2 of the MSU Cloud Computing Fellowship Details of the workshop and recording will be posted after our remote session on Sept 10","title":"Workshop : Creating your own cloud computer"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm/#workshop-creating-your-own-cloud-computer","text":"For Session 2 of the MSU Cloud Computing Fellowship Details of the workshop and recording will be posted after our remote session on Sept 10","title":"Workshop : Creating your own cloud computer"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/","text":"Intro to Cloud Costs on Azure You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background. 1. Pricing Pages. All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services. 2. Build something and check the cost The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view 3. Pricing Calculators All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/ Summary and other notes Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries). Azure Pricing Resources Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Intro to Cloud Costs on Azure"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#intro-to-cloud-costs-on-azure","text":"You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background.","title":"Intro to Cloud Costs on Azure"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#1-pricing-pages","text":"All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services.","title":"1. Pricing Pages."},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#2-build-something-and-check-the-cost","text":"The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view","title":"2. Build something and check the cost"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#3-pricing-calculators","text":"All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/","title":"3. Pricing Calculators"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#summary-and-other-notes","text":"Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries).","title":"Summary and other notes"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#azure-pricing-resources","text":"Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Azure Pricing Resources"},{"location":"index2021/session_introduction/","text":"Session 1: Introduction to the 2021-22 MSU Cloud Computing Fellowship You don't have to face the clouds alone Welcome! The goals of this session are to orient you to this program, set up our technology, introduce ourselves, provide some background on cloud computing, and discuss what all of our expectations are. For this session, like the others, we have some pre-session activities for the week, followed by a meeting Friday, September 3, from 2:00-3:30pm. Activities: Please complete the following activities prior to our first synchronous meeting September 3. Complete a Brief Survey All 2021-22 participants were sent an introductory email that included a link to a brief survey. preferences and techmology exposure. Please complete this survey prior to our first meeting. Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting. If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us . Note there will be time for questions and dicussion during our first meeting. Readings Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version) Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review Meeting: Introductions and program overview. September 3rd, 2021 : Zoom meeting included in introductory email to participants Introductions Brian O'shea, ICER Danielle Barnes, MSU Analytics and Data Solutions Mahmoud Parvizi, Instructor Past experience & current role Cloud facilitator Participant in first Fellowship cohort Pat Bills, Main Instructor A video of our introductions is avaialble on the MSU MediaSpace (requires MSU log-in) Participant Introductions & Discussion Introductions Research synopsis, Research Methods skills (non-IT) Current research computing hurdles, roadblocks, challenges & triumphs How will (or has) cloud computing affected your research? Your goals for this fellowship What do you think the cloud is or is good for? Discussion on availability to complete class and projects Fellowship Program Overview Why and What: 15 minute lecture on broad topics and goals of the course Review our \" syllabus \" Pre-session materials and activities, \"textbook\" Session activity Expectations Projects: Mahmoud Parvizi Lecture: About Cloud Computing Introducing computing vs. research computing vs. HPC vs. cloud computing Learning how to learn about cloud Cloud perceptions vantage points Using workflow computational and computational thinking The interfaces to cloud computing About cloud security Costs and budget overview Acknowledging bias in access to cloud computing across research cultures References: The NIST definition of cloud computing Additional comments from program organizers Demonstration: Using the Azure Portal A quick, live demonstration orienting you to the Azure portal. Our next session activities will include a more thorough workshop on creating cloud computing resources A more complete tutorial and video of this walk-through is available in Session 2 activities. Questions and Discussion What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)?","title":"Session 1: Introduction to the 2021-22 MSU Cloud Computing Fellowship"},{"location":"index2021/session_introduction/#session-1-introduction-to-the-2021-22-msu-cloud-computing-fellowship","text":"You don't have to face the clouds alone","title":"Session 1: Introduction to the 2021-22 MSU Cloud Computing Fellowship"},{"location":"index2021/session_introduction/#welcome","text":"The goals of this session are to orient you to this program, set up our technology, introduce ourselves, provide some background on cloud computing, and discuss what all of our expectations are. For this session, like the others, we have some pre-session activities for the week, followed by a meeting Friday, September 3, from 2:00-3:30pm.","title":"Welcome!"},{"location":"index2021/session_introduction/#activities","text":"Please complete the following activities prior to our first synchronous meeting September 3. Complete a Brief Survey All 2021-22 participants were sent an introductory email that included a link to a brief survey. preferences and techmology exposure. Please complete this survey prior to our first meeting. Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting. If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us . Note there will be time for questions and dicussion during our first meeting.","title":"Activities:"},{"location":"index2021/session_introduction/#readings","text":"Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version) Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review","title":"Readings"},{"location":"index2021/session_introduction/#meeting-introductions-and-program-overview","text":"September 3rd, 2021 : Zoom meeting included in introductory email to participants","title":"Meeting: Introductions and program overview."},{"location":"index2021/session_introduction/#introductions","text":"Brian O'shea, ICER Danielle Barnes, MSU Analytics and Data Solutions Mahmoud Parvizi, Instructor Past experience & current role Cloud facilitator Participant in first Fellowship cohort Pat Bills, Main Instructor A video of our introductions is avaialble on the MSU MediaSpace (requires MSU log-in)","title":"Introductions"},{"location":"index2021/session_introduction/#participant-introductions-discussion","text":"Introductions Research synopsis, Research Methods skills (non-IT) Current research computing hurdles, roadblocks, challenges & triumphs How will (or has) cloud computing affected your research? Your goals for this fellowship What do you think the cloud is or is good for? Discussion on availability to complete class and projects","title":"Participant Introductions &amp; Discussion"},{"location":"index2021/session_introduction/#fellowship-program-overview","text":"Why and What: 15 minute lecture on broad topics and goals of the course Review our \" syllabus \" Pre-session materials and activities, \"textbook\" Session activity Expectations Projects: Mahmoud Parvizi","title":"Fellowship Program Overview"},{"location":"index2021/session_introduction/#lecture-about-cloud-computing","text":"Introducing computing vs. research computing vs. HPC vs. cloud computing Learning how to learn about cloud Cloud perceptions vantage points Using workflow computational and computational thinking The interfaces to cloud computing About cloud security Costs and budget overview Acknowledging bias in access to cloud computing across research cultures References: The NIST definition of cloud computing","title":"Lecture: About Cloud Computing"},{"location":"index2021/session_introduction/#additional-comments-from-program-organizers","text":"","title":"Additional comments from program organizers"},{"location":"index2021/session_introduction/#demonstration-using-the-azure-portal","text":"A quick, live demonstration orienting you to the Azure portal. Our next session activities will include a more thorough workshop on creating cloud computing resources A more complete tutorial and video of this walk-through is available in Session 2 activities.","title":"Demonstration: Using the Azure Portal"},{"location":"index2021/session_introduction/#questions-and-discussion","text":"What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)?","title":"Questions and Discussion"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/","text":"Practical Introduction for Researchers on Azure Introducing cloud computing vs. research computing Learning how to learn about cloud You may have looked at the various websites and poked around the web, and found it's just not clear at all how cloud computing may be helpful to you, even though it all sounds great. The challenge for researchers learning about cloud is that most cloud documentation for isn't written for you. Cloud training and documentation are mostly written for IT professionals like system admins and architects, software developers, business people, and agency managers. Researchers tend to be a little of all of those things. Training materials ofen have an embedded conceptual models of computing, and this model depend on your approach. Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. That can make it difficult to decipher which kind of cloud service will work best for your use case. As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. The target audience for most cloud companies are IT professional building IT systems for public or institutational use. Let's call this the \"Systems\" perspective: built for someone else to use, e.g. a service must be available at scale and ultimately reliable documentation is in terms of historic IT systems house in on-premise corporate data centers \"production\" systems often very concerned with authentication and security The second audience are corporate software engineers, or dot-com or app software companies. We'll call this the \"developer perspective need to easily create systems to run their software for demonstration and testing complete interelate goal is a robust sytem that can handle many users, e.g. the performance of a \"production\" systems are often top of mind And finally most closely related to your work are data science, \"machine learning\" or an \"analytical\" perspective systems to achieve computation. May work like our local HPC systems built only for small work groups, not for public can still scale but must be reproducible to document methods even this documentation can quickly veer off in to building production systems for companies to re-run inference say many times a data or with a constant stream of corporate data What is are the goals from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others? What documentation is available for researchers? There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos NIST defintions of cloud: Service Levels and You The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researhces who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. Cloud \"Services\" and the Packaging of Open Source Systems Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ? Caveats and help As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing, even slightly, making technology-specific tutorials obsolete in months. For example last year Azure had a \"Notebook Service\" for running Python notebooks, and now there is this in place of the regular documentation: What happened to Azure Notebooks? There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. During the Cloud Computing Fellowship we are here to provide some answers, context for what you are seeing, or possible directions to explore. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. The Interfaces to Cloud A defining aspect of cloud computing is that it's \"on-demand\" hence creation of resources must be automated or \"scriptable.\" All Cloud providers have various 'interfaces' to their services that include both programmatic and web-based. We will talk about about how these in detail next sesion, but at the end of this session we will do a walk through of using the Azure portal, which is also an exercise for next session. Using workflow and computational thinking Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research computing and one of much academic work. To enhance reproducibility in your own work, consider documenting all the steps needed for create the environment to run your computation. For many on-premise academic systems (e.g. the MSU HPCC), we depend upon the system administrators to create that environment, but we may install and configure all the software we need to run our code. Workflow thinking can apply to the scienfic domain itself (e.g. \"Principles for data analysis workflows\" https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008770 ) and to the provisioning of the cloud computing environment. That is, we may use a workflow system for creating all the cloud stuff we need, and then a different workflow system that runs on that cloud stuff. One example is we may create an HPC system on Azure using templates and then launch the Slurm scheduler on that HPC to run our jobs. ( note the complexity of running our own HPC is beyond the scope of this fellowship and used as an example only ) A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. This can dramatically save on costs . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need. About Cloud Security Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Attackers may use the services you create to launch attacks on other services, leaving you liable. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security: Microsoft Model of Shared Responsibility for Cloud Computing We will come back to this model as we gain deeper understanding of research computing on the cloud. Costs and Budget overview We will cover the details of pricing, examine costs, and controlling costs in future sessions. Each participant has a budget for their Azure resources that they should stay under. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Briefly: Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk HPCC vs Cloud Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers. Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never): Big Data systems (see magpie project) Long-running Data Systems like database servers Web-based applications (see on-demand project) Containers (see singularity project) Acknowledging bias in access to cloud computing across research cultures Additional comments from instructors and organizers Summary and additional comments","title":"Practical Introduction for Researchers on Azure"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-on-azure","text":"","title":"Practical Introduction for Researchers on Azure"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#introducing-cloud-computing-vs-research-computing","text":"","title":"Introducing cloud computing vs. research computing"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","text":"You may have looked at the various websites and poked around the web, and found it's just not clear at all how cloud computing may be helpful to you, even though it all sounds great. The challenge for researchers learning about cloud is that most cloud documentation for isn't written for you. Cloud training and documentation are mostly written for IT professionals like system admins and architects, software developers, business people, and agency managers. Researchers tend to be a little of all of those things. Training materials ofen have an embedded conceptual models of computing, and this model depend on your approach. Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. That can make it difficult to decipher which kind of cloud service will work best for your use case. As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. The target audience for most cloud companies are IT professional building IT systems for public or institutational use. Let's call this the \"Systems\" perspective: built for someone else to use, e.g. a service must be available at scale and ultimately reliable documentation is in terms of historic IT systems house in on-premise corporate data centers \"production\" systems often very concerned with authentication and security The second audience are corporate software engineers, or dot-com or app software companies. We'll call this the \"developer perspective need to easily create systems to run their software for demonstration and testing complete interelate goal is a robust sytem that can handle many users, e.g. the performance of a \"production\" systems are often top of mind And finally most closely related to your work are data science, \"machine learning\" or an \"analytical\" perspective systems to achieve computation. May work like our local HPC systems built only for small work groups, not for public can still scale but must be reproducible to document methods even this documentation can quickly veer off in to building production systems for companies to re-run inference say many times a data or with a constant stream of corporate data What is are the goals from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others?","title":"Learning how to learn about cloud"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","text":"There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos","title":"What documentation is available for researchers?"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#nist-defintions-of-cloud-service-levels-and-you","text":"The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researhces who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls.","title":"NIST defintions of cloud: Service Levels and You"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems","text":"Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ?","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#caveats-and-help","text":"As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing, even slightly, making technology-specific tutorials obsolete in months. For example last year Azure had a \"Notebook Service\" for running Python notebooks, and now there is this in place of the regular documentation: What happened to Azure Notebooks? There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. During the Cloud Computing Fellowship we are here to provide some answers, context for what you are seeing, or possible directions to explore. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those.","title":"Caveats and help"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#the-interfaces-to-cloud","text":"A defining aspect of cloud computing is that it's \"on-demand\" hence creation of resources must be automated or \"scriptable.\" All Cloud providers have various 'interfaces' to their services that include both programmatic and web-based. We will talk about about how these in detail next sesion, but at the end of this session we will do a walk through of using the Azure portal, which is also an exercise for next session.","title":"The Interfaces to Cloud"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#using-workflow-and-computational-thinking","text":"Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research computing and one of much academic work. To enhance reproducibility in your own work, consider documenting all the steps needed for create the environment to run your computation. For many on-premise academic systems (e.g. the MSU HPCC), we depend upon the system administrators to create that environment, but we may install and configure all the software we need to run our code. Workflow thinking can apply to the scienfic domain itself (e.g. \"Principles for data analysis workflows\" https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008770 ) and to the provisioning of the cloud computing environment. That is, we may use a workflow system for creating all the cloud stuff we need, and then a different workflow system that runs on that cloud stuff. One example is we may create an HPC system on Azure using templates and then launch the Slurm scheduler on that HPC to run our jobs. ( note the complexity of running our own HPC is beyond the scope of this fellowship and used as an example only ) A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. This can dramatically save on costs . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need.","title":"Using workflow and computational thinking"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#about-cloud-security","text":"Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Attackers may use the services you create to launch attacks on other services, leaving you liable. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security: Microsoft Model of Shared Responsibility for Cloud Computing We will come back to this model as we gain deeper understanding of research computing on the cloud.","title":"About Cloud Security"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#costs-and-budget-overview","text":"We will cover the details of pricing, examine costs, and controlling costs in future sessions. Each participant has a budget for their Azure resources that they should stay under. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Briefly: Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk","title":"Costs and Budget overview"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#hpcc-vs-cloud","text":"Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers. Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never): Big Data systems (see magpie project) Long-running Data Systems like database servers Web-based applications (see on-demand project) Containers (see singularity project)","title":"HPCC vs Cloud"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","text":"","title":"Acknowledging bias in access to cloud computing across research cultures"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#additional-comments-from-instructors-and-organizers","text":"Summary and additional comments","title":"Additional comments from instructors and organizers"},{"location":"index2021/session_moving_data/","text":"Session 4: Moving Data in The Cloud There are many ways to move data around in the cloud. They are based on the limitations of data movement across complex and distant networks and the scale of cloud networks and storage, and the needs of companies to move and process huge amounts of data on a schedule. Reading Session Slides: Azure Techniques for Moving Data Optional Reading Adding a data disk to virtual machine: A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these. Overview of Azure Data Factory (ADF): See a description and more links in the session slides above If ADS seems interesting to you, read the following introductory material https://docs.microsoft.com/en-us/azure/data-factory/introduction Visual authoring in Azure Data Factory this is interesting as a case study for gui-based 'plaform as a service' cloud computing Activities For those who completed the storage pricing activity from session #3, post your estimated stoarge costs to teams. If they are very different, from others, or different than you expect, please explain or ask how folks got their numbers Select any one or more of these activities that seems relevant to you for your project, or minimally the first exercise Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. We want your feedback! We have some topics we plan to cover, but at this stage you've looked at cloud documentation and thought about your projects, via teams or email, contact us to let us know if there are topics you would like to hear about. These could be upcoming topics that you are particularly interested in. For example, we offered a specially session on \"command line techniques\" and we are prepping materials for that. Meeting October 8 2:00-3:30pm Questions from previous session on storage Presentation: Azure Techniques for Moving Data (slides linked in Reading section above) Note about future material and projects Discussion or questions about this or previous topic or projects","title":"Session 4: Moving Data in The Cloud"},{"location":"index2021/session_moving_data/#session-4-moving-data-in-the-cloud","text":"There are many ways to move data around in the cloud. They are based on the limitations of data movement across complex and distant networks and the scale of cloud networks and storage, and the needs of companies to move and process huge amounts of data on a schedule.","title":"Session 4: Moving Data in The Cloud"},{"location":"index2021/session_moving_data/#reading","text":"Session Slides: Azure Techniques for Moving Data","title":"Reading"},{"location":"index2021/session_moving_data/#optional-reading","text":"Adding a data disk to virtual machine: A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these. Overview of Azure Data Factory (ADF): See a description and more links in the session slides above If ADS seems interesting to you, read the following introductory material https://docs.microsoft.com/en-us/azure/data-factory/introduction Visual authoring in Azure Data Factory this is interesting as a case study for gui-based 'plaform as a service' cloud computing","title":"Optional Reading"},{"location":"index2021/session_moving_data/#activities","text":"For those who completed the storage pricing activity from session #3, post your estimated stoarge costs to teams. If they are very different, from others, or different than you expect, please explain or ask how folks got their numbers Select any one or more of these activities that seems relevant to you for your project, or minimally the first exercise Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. We want your feedback! We have some topics we plan to cover, but at this stage you've looked at cloud documentation and thought about your projects, via teams or email, contact us to let us know if there are topics you would like to hear about. These could be upcoming topics that you are particularly interested in. For example, we offered a specially session on \"command line techniques\" and we are prepping materials for that.","title":"Activities"},{"location":"index2021/session_moving_data/#meeting-october-8-200-330pm","text":"Questions from previous session on storage Presentation: Azure Techniques for Moving Data (slides linked in Reading section above) Note about future material and projects Discussion or questions about this or previous topic or projects","title":"Meeting October 8 2:00-3:30pm"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/","text":"Creating a Storage Account SAS token for allowing access to storage from another service or person How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility References Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"Creating a Storage Account SAS token"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#creating-a-storage-account-sas-token","text":"","title":"Creating a Storage Account SAS token"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#for-allowing-access-to-storage-from-another-service-or-person","text":"How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility","title":"for allowing access to storage from another service or person"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#references","text":"Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"References"},{"location":"index2021/session_moving_data/how_to_azure_files/","text":"How to Use Azure Files with Windows and Linux VMs The Azure cloud storage session materials describes \"Azure Files\" as one of several types of storage available. Here are some details about using Azure Files in practice to read and write data from a virtual machine Please review the Azure Documentation describing the \"Azure Files\" service Summary The \"Azure Files\" (or File Shares) service is Microsoft's attempt to provide storage with an interface that many IT people are familiar with, but at Cloud scale. They market it heavily as a replacement for File servers that an institution or company have to maintain. The alternative is blog storage, which works well when you alter your program code to read and write to blob storage, and for users of existing software (e.g. GUI software for your scientific application) you can't change the code. In practice, Azure File storage does work like cloud in that there are few limits on storage but you can also attach it as if it were network storage (\"network attach\") so you don't have to change your software. However it is more expensive than Blob storage and it is slower than network storage, especially much slower than storage in an HPC environment. So what to do? One method I've used to take advantage of the convenience of Azure Files storage but I need speed, I'll copy those files that need to have fast access onto the local disk of the VM (or service), but still use Azure files to save files (write output). There are several ways to use Network Attach Storage, and they are named for the file sharing protocol. A very common protocol invented by Microsoft in the 90s is Server Message Block or SMB. You don't have to know how it works, just that Windows, Mac and Linux have SMB file connection software built-in. Most on-premise network disk systems use SMB. Details using \"File Shares\" in a storage account A storage account is the entry point in Azure to any kind of storage service ( see materials in the Cloud Storage session ), so you need to first create a storage account. You can use an existing storage account for any tutorials or quickstarts linked below (though many of them have you create a resource group and storage account in the tutorial, can skip that although you'll have to adjust the names used). Note that storage account can have both blog storage containers and file shares in the same account. When you open a storage account resource in the portal, there is a \"File Shares\" option on the left-side menu which opens the form to add file shares to your storage account. Follow this quick start to create a file share, which also walks through creating a storage account if you need one : https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-portal?tabs=azure-portal Overview of process to use with a VM create a file share and upload your data using the Storage Explorer or other data movement method (e.g. Azure Data Factory, azcopy from your on-premise computer such as the HPC) create a Virtual Machine. since the data will stay on the File Share (but see below for performance) you may not need to provisions a VM disk much larger than 30gb after the VM is started and you are logged in, see methods below for attaching File share run your software but adjust the code or select folders on the connected file share (e.g. D:\\\\ on windows or the mount path in linux) save output the the cloud Storage File Share when finished, close and delete the VM and associated resources access output files using Storage Explorer, or another method See below for Azure instructions for each type of machine (Windows, Linux) Connecting File Share to Windows to read or save data If you are using Windows to run your software, you may want to read/write data to a file share, so you can delete the Windows VM when you are finished with a session, but keep your results. If you attach a file share to the windows VM, use that. After creating a file share, you can connect that to a windows VM. In session #2 we created a Windows VM based on the Data Science Virtual Machine image. The following uses a different image (Windows Server) but the process is the same: Mount SMB Azure file share on Windows Connecting File Share to Linux to read and/or save data These command-line based intructions show how to install the necesssary software and create a connection to a file share using SMB. Like the windows example, this would be a method for accessing data on in cloud storage so that you can remove [Mount SMB Azure file share on Linux] https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux?tabs=smb311 Performance issues with using File Shares and a work-around File shares are not as fast as a virtual machine disk, and those are not as fast as a disk on your physcial computer, or even as fast as on-premise Network Attached storage. If your process does a lot of reading/writing and needs to be faster, one solution is to 'stage' the data to the VM disk assuming you have file share storage and a new VM with a large enough disk to hold data connect/mount the file share storage as describe above to the VM before running your program, copy the input data from file share storage to the VM disk, (e.g. C:\\ for Windows or perhaps the homedir /mnt/home in linux ) Ensure you've created a large enough VM OS Disk to hold your data run your software, selecting this folder when the program/script is completed, copy the ooutput back to your file share shutdown and delete the VM access the output data from file share d","title":"How to Use Azure Files with Windows and Linux VMs"},{"location":"index2021/session_moving_data/how_to_azure_files/#how-to-use-azure-files-with-windows-and-linux-vms","text":"The Azure cloud storage session materials describes \"Azure Files\" as one of several types of storage available. Here are some details about using Azure Files in practice to read and write data from a virtual machine Please review the Azure Documentation describing the \"Azure Files\" service","title":"How to Use Azure Files with Windows and Linux VMs"},{"location":"index2021/session_moving_data/how_to_azure_files/#summary","text":"The \"Azure Files\" (or File Shares) service is Microsoft's attempt to provide storage with an interface that many IT people are familiar with, but at Cloud scale. They market it heavily as a replacement for File servers that an institution or company have to maintain. The alternative is blog storage, which works well when you alter your program code to read and write to blob storage, and for users of existing software (e.g. GUI software for your scientific application) you can't change the code. In practice, Azure File storage does work like cloud in that there are few limits on storage but you can also attach it as if it were network storage (\"network attach\") so you don't have to change your software. However it is more expensive than Blob storage and it is slower than network storage, especially much slower than storage in an HPC environment. So what to do? One method I've used to take advantage of the convenience of Azure Files storage but I need speed, I'll copy those files that need to have fast access onto the local disk of the VM (or service), but still use Azure files to save files (write output). There are several ways to use Network Attach Storage, and they are named for the file sharing protocol. A very common protocol invented by Microsoft in the 90s is Server Message Block or SMB. You don't have to know how it works, just that Windows, Mac and Linux have SMB file connection software built-in. Most on-premise network disk systems use SMB.","title":"Summary"},{"location":"index2021/session_moving_data/how_to_azure_files/#details","text":"","title":"Details"},{"location":"index2021/session_moving_data/how_to_azure_files/#using-file-shares-in-a-storage-account","text":"A storage account is the entry point in Azure to any kind of storage service ( see materials in the Cloud Storage session ), so you need to first create a storage account. You can use an existing storage account for any tutorials or quickstarts linked below (though many of them have you create a resource group and storage account in the tutorial, can skip that although you'll have to adjust the names used). Note that storage account can have both blog storage containers and file shares in the same account. When you open a storage account resource in the portal, there is a \"File Shares\" option on the left-side menu which opens the form to add file shares to your storage account. Follow this quick start to create a file share, which also walks through creating a storage account if you need one : https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-portal?tabs=azure-portal","title":"using  \"File Shares\" in a storage account"},{"location":"index2021/session_moving_data/how_to_azure_files/#overview-of-process-to-use-with-a-vm","text":"create a file share and upload your data using the Storage Explorer or other data movement method (e.g. Azure Data Factory, azcopy from your on-premise computer such as the HPC) create a Virtual Machine. since the data will stay on the File Share (but see below for performance) you may not need to provisions a VM disk much larger than 30gb after the VM is started and you are logged in, see methods below for attaching File share run your software but adjust the code or select folders on the connected file share (e.g. D:\\\\ on windows or the mount path in linux) save output the the cloud Storage File Share when finished, close and delete the VM and associated resources access output files using Storage Explorer, or another method See below for Azure instructions for each type of machine (Windows, Linux)","title":"Overview of process to use with a VM"},{"location":"index2021/session_moving_data/how_to_azure_files/#connecting-file-share-to-windows-to-read-or-save-data","text":"If you are using Windows to run your software, you may want to read/write data to a file share, so you can delete the Windows VM when you are finished with a session, but keep your results. If you attach a file share to the windows VM, use that. After creating a file share, you can connect that to a windows VM. In session #2 we created a Windows VM based on the Data Science Virtual Machine image. The following uses a different image (Windows Server) but the process is the same: Mount SMB Azure file share on Windows","title":"Connecting File Share to Windows to read or save data"},{"location":"index2021/session_moving_data/how_to_azure_files/#connecting-file-share-to-linux-to-read-andor-save-data","text":"These command-line based intructions show how to install the necesssary software and create a connection to a file share using SMB. Like the windows example, this would be a method for accessing data on in cloud storage so that you can remove [Mount SMB Azure file share on Linux] https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux?tabs=smb311","title":"Connecting File Share to Linux to read and/or save data"},{"location":"index2021/session_moving_data/how_to_azure_files/#performance-issues-with-using-file-shares-and-a-work-around","text":"File shares are not as fast as a virtual machine disk, and those are not as fast as a disk on your physcial computer, or even as fast as on-premise Network Attached storage. If your process does a lot of reading/writing and needs to be faster, one solution is to 'stage' the data to the VM disk assuming you have file share storage and a new VM with a large enough disk to hold data connect/mount the file share storage as describe above to the VM before running your program, copy the input data from file share storage to the VM disk, (e.g. C:\\ for Windows or perhaps the homedir /mnt/home in linux ) Ensure you've created a large enough VM OS Disk to hold your data run your software, selecting this folder when the program/script is completed, copy the ooutput back to your file share shutdown and delete the VM access the output data from file share d","title":"Performance issues with using File Shares and a work-around"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/","text":"How to move data between the MSU HPC and Azure Introduction A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory) Method 1. using scp with a virtual machine Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results. Requirements an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine A little about the scp utility The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk. Method 2. azcopy Requirements A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation) Alternative Methods Method 3. Azure data factory We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility. Method 4. Python We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda . Method 5. Python with URL Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"How to move data between the MSU HPC and Azure"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#how-to-move-data-between-the-msu-hpc-and-azure","text":"","title":"How to move data between the MSU HPC and Azure"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#introduction","text":"A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory)","title":"Introduction"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-1-using-scp-with-a-virtual-machine","text":"Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results.","title":"Method 1. using scp with a virtual machine"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#requirements","text":"an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine","title":"Requirements"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#a-little-about-the-scp-utility","text":"The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk.","title":"A little about the scp utility"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-2-azcopy","text":"","title":"Method 2. azcopy"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#requirements_1","text":"A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation)","title":"Requirements"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#alternative-methods","text":"","title":"Alternative Methods"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-3-azure-data-factory","text":"We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility.","title":"Method 3. Azure data factory"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-4-python","text":"We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda .","title":"Method 4. Python"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-5-python-with-url","text":"Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"Method 5. Python with URL"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/","text":"Exercise: moving data using storage URL The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files) Upload file via portal Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise Get a URL to download this file back to your own laptop (or a different computer) determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard Test Download In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Exercise: moving data using storage URL"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#exercise-moving-data-using-storage-url","text":"The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files)","title":"Exercise: moving data using storage URL"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#upload-file-via-portal","text":"Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise","title":"Upload file via portal"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#get-a-url-to-download-this-file-back-to-your-own-laptop-or-a-different-computer","text":"determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard","title":"Get a URL to download this file back to your own laptop (or a different computer)"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#test-download","text":"In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Test Download"},{"location":"index2021/session_serverless/","text":"Session 6: Serverless Cloud Computing example real-world cloud application Introductory Material by topic Overview of Serverless About Linux Containers with readings and activities Serverless and FaaS Readings As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349 Activities https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/ For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell Fellowship Meeting November 12, 2021 : Zoom Announcements, survey request Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction","title":"Session 6: Serverless Cloud Computing"},{"location":"index2021/session_serverless/#session-6-serverless-cloud-computing","text":"example real-world cloud application Introductory Material by topic Overview of Serverless About Linux Containers with readings and activities","title":"Session 6: Serverless Cloud Computing"},{"location":"index2021/session_serverless/#serverless-and-faas-readings","text":"As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349","title":"Serverless and FaaS Readings"},{"location":"index2021/session_serverless/#activities","text":"https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/ For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell","title":"Activities"},{"location":"index2021/session_serverless/#fellowship-meeting","text":"November 12, 2021 : Zoom Announcements, survey request Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction","title":"Fellowship Meeting"},{"location":"index2021/session_serverless/about_web_applications_and_the_cloud/","text":"","title":"About web applications and the cloud"},{"location":"index2021/session_serverless/end_of_session_survey/","text":"","title":"End of session survey"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/","text":"Linux Containers & the Cloud For Session 7: Overview of Serverless The container metaphor relfects the nature of a standardized box can be carried on ships, trains, and trucks at different scales Introduction Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. However containers have several advantages to virtual machines which is why Google invested in their invention 15 yrs ago. you can use code to define exactly what will go into a container, making it reproducible. You can to this with VMs but it's more difficult and/or dependent on the cloud company (e.g an AWS linux VM is different from an Azure Linux VM)/ you can run a container on any vendor or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. In addition you can find container solutions from others, or from the software producers themselves. Notes Containers often are for running web applications, and great for running complex web systems, but they can be used for other types of servers, or for batch computing as well. Most of the examples may involve running a website. \"Docker\" is the company that popularized container technology and made it easy to share ideas, but they are only one of several systems that work with the Linux Container specification. Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the HPC we use Singularity . However to get started I suggest using Docker, installing docker desktop, and following docker tutorials. Azure is compatible with docker (that's what we use) You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. Azure has many docker-like features, and you can build and use containers with Azure without installing Docker on your computer, but I recommend working from your computer first to ensure it works The main code file that docker looks for is named \"Dockerfile\" with no extension, and so we say we are using a 'dockerfile' to build a container however this is just the default and the file name can be anything when using the command line You will hear alot about a technology platform called \"Kubernetes\" which was invented (at Google) to be able to manage dozens,hundreds or thousands of containers working together to support large web applications (like Google but also Walmart.com). This is called \"container orchestration.\" You don't need Kubernetes to run single or even a couple of containers. There are other solutions, or you can connect them yourself. Using Kubernetes can be an entire career but the promise is easy building an elastic cluster for HPC-style computing. The \"serverless\" infrastructure of Azure is built on containers. Containers are the heart of how the cloud works, and provide a way for developers of complex research software to provide a mechanism for users to launch their software quickly. Many bioinformatics or genomics packages now include Containers are complex and especially how they work but if you can use them in practice you don't need to know the details. Reading An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Docker Overview Azure Container Service Overview Activity Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance","title":"Linux Containers & the Cloud"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#linux-containers-the-cloud","text":"","title":"Linux Containers &amp; the Cloud"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#for-session-7-overview-of-serverless","text":"The container metaphor relfects the nature of a standardized box can be carried on ships, trains, and trucks at different scales","title":"For Session 7: Overview of Serverless"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#introduction","text":"Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. However containers have several advantages to virtual machines which is why Google invested in their invention 15 yrs ago. you can use code to define exactly what will go into a container, making it reproducible. You can to this with VMs but it's more difficult and/or dependent on the cloud company (e.g an AWS linux VM is different from an Azure Linux VM)/ you can run a container on any vendor or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. In addition you can find container solutions from others, or from the software producers themselves. Notes Containers often are for running web applications, and great for running complex web systems, but they can be used for other types of servers, or for batch computing as well. Most of the examples may involve running a website. \"Docker\" is the company that popularized container technology and made it easy to share ideas, but they are only one of several systems that work with the Linux Container specification. Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the HPC we use Singularity . However to get started I suggest using Docker, installing docker desktop, and following docker tutorials. Azure is compatible with docker (that's what we use) You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. Azure has many docker-like features, and you can build and use containers with Azure without installing Docker on your computer, but I recommend working from your computer first to ensure it works The main code file that docker looks for is named \"Dockerfile\" with no extension, and so we say we are using a 'dockerfile' to build a container however this is just the default and the file name can be anything when using the command line You will hear alot about a technology platform called \"Kubernetes\" which was invented (at Google) to be able to manage dozens,hundreds or thousands of containers working together to support large web applications (like Google but also Walmart.com). This is called \"container orchestration.\" You don't need Kubernetes to run single or even a couple of containers. There are other solutions, or you can connect them yourself. Using Kubernetes can be an entire career but the promise is easy building an elastic cluster for HPC-style computing. The \"serverless\" infrastructure of Azure is built on containers. Containers are the heart of how the cloud works, and provide a way for developers of complex research software to provide a mechanism for users to launch their software quickly. Many bioinformatics or genomics packages now include Containers are complex and especially how they work but if you can use them in practice you don't need to know the details.","title":"Introduction"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#reading","text":"An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Docker Overview Azure Container Service Overview","title":"Reading"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#activity","text":"Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance","title":"Activity"},{"location":"index2021/session_serverless/serverless_overview/","text":"Introduction to Serverless and Azure For Session 7: Overview of Serverless *Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that. Many problems that \"serverless\" can be applied to short and 'stateless' function execution, where functions can scale at will (Python, Java, C, C# etc) event processing, handling huge streams of data in small chunks components of a cloud-based workflow web application engines Main distinction for 'serverless' is that even though in the end of course your website or function run on a server somewhere that has an operating system installed on it, you don't have to know. Server Process : provission machine --> install OS --> install software --> add your code, read your data and run --> delete and/or keep it maintained Serverlesss Process : provision resource --> add code --> and run Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed? Key points about serverless goal is to have aa workflow of components that communicate with each other, but can be indepedently managed a primary communication method is using web api's, aka REST aka","title":"Introduction to Serverless and Azure"},{"location":"index2021/session_serverless/serverless_overview/#introduction-to-serverless-and-azure","text":"","title":"Introduction to Serverless and Azure"},{"location":"index2021/session_serverless/serverless_overview/#for-session-7-overview-of-serverless","text":"*Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that. Many problems that \"serverless\" can be applied to short and 'stateless' function execution, where functions can scale at will (Python, Java, C, C# etc) event processing, handling huge streams of data in small chunks components of a cloud-based workflow web application engines Main distinction for 'serverless' is that even though in the end of course your website or function run on a server somewhere that has an operating system installed on it, you don't have to know. Server Process : provission machine --> install OS --> install software --> add your code, read your data and run --> delete and/or keep it maintained Serverlesss Process : provision resource --> add code --> and run Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed? Key points about serverless goal is to have aa workflow of components that communicate with each other, but can be indepedently managed a primary communication method is using web api's, aka REST aka","title":"For Session 7: Overview of Serverless"},{"location":"index2021/session_serverless/container_scripts/rstudio_container_script/","text":"Containers on Azure: example Script echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf21-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"},{"location":"index2021/session_serverless/container_scripts/rstudio_container_script/#containers-on-azure-example-script","text":"echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf21-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"},{"location":"references/","text":"Azure Resources General Resources Main Azue Documentation : https://docs.microsoft.com/en-us/azure/ List of All Azure Services : https://portal.azure.com/#allservices Azure Tips and Tricks : https://microsoft.github.io/AzureTipsAndTricks/ Azure Portal \"How to\" series - focused on using the Azure portal to do several different things. This is mostly about the services themselves, not the portal, and many topics do not apply to us (e.g. Azure Arc) but there are some very useful videos : https://youtube.com/playlist?list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR These look like really good intros to Azure, but requires a time investment. The examples are not really research computing examples but may be valuable learning examples. Most of these lessons were taken from other 'learning paths' and are still oriented towards IT professionals Microsoft Learn : - Azure for Researchers part 1: Introduction to Cloud Computing - Azure for Researchers part 2: Cloud Security and Cost Management Interface: Azure Portal Azure Portal Documentation : https://docs.microsoft.com/en-us/azure/azure-portal/ Microsoft Azure Hierarchy: Organize your Azure resources effectively Re-organize your portal view by creating a new dashboard (optional) : https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards Azure portal productivity Tips : https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html#azure-portal-productivity-tips https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html Interface: Command Line Command-line progamming of Cloud Services Azure PowerShell (Windows) https://docs.microsoft.com/en-us/powershell/azure/ Introduction to PowerShell : https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-3.0.0 Azure Command Line Interface (CLI) (MacOS, Linux): https://docs.microsoft.com/en-us/cli/azure Introduction to Azure CLI https://docs.microsoft.com/en-us/cli/azure/get-started-with-azure-cli?view=azure-cli-latest Hybrid inferface: using the CLI inside the Azure Portal You can install and use the az CLI program on your own computer, but Azure also has a way you can use the CLI without installing anything, with a cloud-based terminal interface called the \"cloud shell.\" For an overview see https://docs.microsoft.com/en-us/azure/cloud-shell/overview and for a great 'quickstart' see https://docs.microsoft.com/en-us/azure/cloud-shell/quickstart for a quick tutorial for how to use it. In the quickstart, the first example shows you how to create a resource group using the CLI in the cloudshell. If you don't have permissions to create a new resource group, skip to the next example (\"Create a Linux VM\") and put your own resource group in the command for the -g parameter and perhaps use a very unique name for the VM parameter. Storage Create a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Create and Manage a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Using the CLI with Storage Reference: https://docs.microsoft.com/en-us/cli/azure/storage/account Using PowerShell Storage Reference: https://docs.microsoft.com/en-us/powershell/module/azure.storage Create blob storage with CLI: https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli Create blob storage with PowerShell: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-powershell Compute Overview of Compute Options: https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-overview Choosing an Azure Compute Service (Decision Tree): https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree Interface: ARM templates Azure Resource Manager Templates are JSON-formatted configuration files that dictate which resources to create. Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview explore quick start ARM templates (web): https://azure.microsoft.com/en-us/resources/templates/ explore quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates many of these github repositories include a \"deploy to Azure\" button that will run the template via the portal and create resources. Programming with SDKs R and Azure https://blog.revolutionanalytics.com/2018/12/azurestor.html https://cloudblogs.microsoft.com/opensource/2019/07/01/azurer-available-create-manage-monitor-azure-services-r/ https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/r-packages-supported-by-azure-machine-learning https://github.com/Azure/AzureContainers https://github.com/Azure/AzureR https://github.com/Azure/AzureRMR Python and Azure https://azure.microsoft.com/en-us/develop/python/ https://docs.microsoft.com/en-us/azure/python/ https://github.com/Azure/azure-sdk-for-python https://github.com/Azure/azure-storage-python https://azure.github.io/azure-sdk/releases/latest/all/python.html (Note that pypi.org/project/azure/ is deprecated/obsolete if you find that via google) MATLAB and Azure https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/06/29/running-matlab-on-azure-provision-a-matlab-distributed-computing-server-using-azure-vms/ https://github.com/mathworks-ref-arch/matlab-on-azure https://www.itcentralstation.com/products/comparisons/mathworks-matlab_vs_microsoft-azure-machine-learning-studio https://www.mathworks.com/solutions/cloud.html Microsoft Azure Cosmos DB CosmosDB is a very large scale data system that can act like other database systems including SQL, MongoDB (a popular no-sql database), and others. It's advantage is that it can handle extremely large data sets (65tB) but is easy to get started. Google and AWS have similar offereings ( \"BigQuery\" and \"Aurora\" respectively). If your data is not large, consider using SQL data systems which are also very widely used (and can be used on your own computer) Intro: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction It can be free to use, but you have to turn that on when creating the service for your account: https://docs.microsoft.com/en-us/azure/cosmos-db/free-tier You can run a notebook inside the databaase to queery data with python : Notebook Description: https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks Service announcement: https://azure.microsoft.com/en-us/blog/analyze-and-visualize-your-data-with-azure-cosmos-db-notebooks/ Video: https://www.youtube.com/watch?v=OrnZMkP5Eq4&list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR&index=7 Cloud Architecture This section has resources for advanced to intermediate cloud users who are interested in much more details that most researchers will ever need, and are really geared for IT staff. However, sometimes to find insight into how to approach your problem (especially for cloud timing ooptimazation projects) these may have useful sections. Microsoft Azure Infrastructure Services for Architects by John Savill, Oct 2019, available from the MSU Library : http://catalog.lib.msu.edu/record=b13538669~S39 Azure has changed since 2019 but may still be relevant","title":"References"},{"location":"references/#azure-resources","text":"","title":"Azure Resources"},{"location":"references/#general-resources","text":"Main Azue Documentation : https://docs.microsoft.com/en-us/azure/ List of All Azure Services : https://portal.azure.com/#allservices Azure Tips and Tricks : https://microsoft.github.io/AzureTipsAndTricks/ Azure Portal \"How to\" series - focused on using the Azure portal to do several different things. This is mostly about the services themselves, not the portal, and many topics do not apply to us (e.g. Azure Arc) but there are some very useful videos : https://youtube.com/playlist?list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR These look like really good intros to Azure, but requires a time investment. The examples are not really research computing examples but may be valuable learning examples. Most of these lessons were taken from other 'learning paths' and are still oriented towards IT professionals Microsoft Learn : - Azure for Researchers part 1: Introduction to Cloud Computing - Azure for Researchers part 2: Cloud Security and Cost Management","title":"General Resources"},{"location":"references/#interface-azure-portal","text":"Azure Portal Documentation : https://docs.microsoft.com/en-us/azure/azure-portal/ Microsoft Azure Hierarchy: Organize your Azure resources effectively Re-organize your portal view by creating a new dashboard (optional) : https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards Azure portal productivity Tips : https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html#azure-portal-productivity-tips https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html","title":"Interface: Azure Portal"},{"location":"references/#interface-command-line","text":"Command-line progamming of Cloud Services Azure PowerShell (Windows) https://docs.microsoft.com/en-us/powershell/azure/ Introduction to PowerShell : https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-3.0.0 Azure Command Line Interface (CLI) (MacOS, Linux): https://docs.microsoft.com/en-us/cli/azure Introduction to Azure CLI https://docs.microsoft.com/en-us/cli/azure/get-started-with-azure-cli?view=azure-cli-latest Hybrid inferface: using the CLI inside the Azure Portal You can install and use the az CLI program on your own computer, but Azure also has a way you can use the CLI without installing anything, with a cloud-based terminal interface called the \"cloud shell.\" For an overview see https://docs.microsoft.com/en-us/azure/cloud-shell/overview and for a great 'quickstart' see https://docs.microsoft.com/en-us/azure/cloud-shell/quickstart for a quick tutorial for how to use it. In the quickstart, the first example shows you how to create a resource group using the CLI in the cloudshell. If you don't have permissions to create a new resource group, skip to the next example (\"Create a Linux VM\") and put your own resource group in the command for the -g parameter and perhaps use a very unique name for the VM parameter.","title":"Interface: Command Line"},{"location":"references/#storage","text":"Create a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Create and Manage a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Using the CLI with Storage Reference: https://docs.microsoft.com/en-us/cli/azure/storage/account Using PowerShell Storage Reference: https://docs.microsoft.com/en-us/powershell/module/azure.storage Create blob storage with CLI: https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli Create blob storage with PowerShell: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-powershell","title":"Storage"},{"location":"references/#compute","text":"Overview of Compute Options: https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-overview Choosing an Azure Compute Service (Decision Tree): https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree","title":"Compute"},{"location":"references/#interface-arm-templates","text":"Azure Resource Manager Templates are JSON-formatted configuration files that dictate which resources to create. Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview explore quick start ARM templates (web): https://azure.microsoft.com/en-us/resources/templates/ explore quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates many of these github repositories include a \"deploy to Azure\" button that will run the template via the portal and create resources.","title":"Interface: ARM templates"},{"location":"references/#programming-with-sdks","text":"","title":"Programming with SDKs"},{"location":"references/#r-and-azure","text":"https://blog.revolutionanalytics.com/2018/12/azurestor.html https://cloudblogs.microsoft.com/opensource/2019/07/01/azurer-available-create-manage-monitor-azure-services-r/ https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/r-packages-supported-by-azure-machine-learning https://github.com/Azure/AzureContainers https://github.com/Azure/AzureR https://github.com/Azure/AzureRMR","title":"R and Azure"},{"location":"references/#python-and-azure","text":"https://azure.microsoft.com/en-us/develop/python/ https://docs.microsoft.com/en-us/azure/python/ https://github.com/Azure/azure-sdk-for-python https://github.com/Azure/azure-storage-python https://azure.github.io/azure-sdk/releases/latest/all/python.html (Note that pypi.org/project/azure/ is deprecated/obsolete if you find that via google)","title":"Python and Azure"},{"location":"references/#matlab-and-azure","text":"https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/06/29/running-matlab-on-azure-provision-a-matlab-distributed-computing-server-using-azure-vms/ https://github.com/mathworks-ref-arch/matlab-on-azure https://www.itcentralstation.com/products/comparisons/mathworks-matlab_vs_microsoft-azure-machine-learning-studio https://www.mathworks.com/solutions/cloud.html","title":"MATLAB and Azure"},{"location":"references/#microsoft-azure-cosmos-db","text":"CosmosDB is a very large scale data system that can act like other database systems including SQL, MongoDB (a popular no-sql database), and others. It's advantage is that it can handle extremely large data sets (65tB) but is easy to get started. Google and AWS have similar offereings ( \"BigQuery\" and \"Aurora\" respectively). If your data is not large, consider using SQL data systems which are also very widely used (and can be used on your own computer) Intro: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction It can be free to use, but you have to turn that on when creating the service for your account: https://docs.microsoft.com/en-us/azure/cosmos-db/free-tier You can run a notebook inside the databaase to queery data with python : Notebook Description: https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks Service announcement: https://azure.microsoft.com/en-us/blog/analyze-and-visualize-your-data-with-azure-cosmos-db-notebooks/ Video: https://www.youtube.com/watch?v=OrnZMkP5Eq4&list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR&index=7","title":"Microsoft Azure Cosmos DB"},{"location":"references/#cloud-architecture","text":"This section has resources for advanced to intermediate cloud users who are interested in much more details that most researchers will ever need, and are really geared for IT staff. However, sometimes to find insight into how to approach your problem (especially for cloud timing ooptimazation projects) these may have useful sections. Microsoft Azure Infrastructure Services for Architects by John Savill, Oct 2019, available from the MSU Library : http://catalog.lib.msu.edu/record=b13538669~S39 Azure has changed since 2019 but may still be relevant","title":"Cloud Architecture"},{"location":"session_bigdata/","text":"Session 5: Big Data on Azure Cloud Featuring Spark You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that provide data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Your Python or R script Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling. Videos Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code Readings Slide Deck: Overview of Big Data with Spark for Researchers Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by Cloud Computing Fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and more readable introductions to \"big data\" I've seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial) For R users The Spark big data system we introduce above is focused on Python and it's native language (calls \"Scala\"). However you can use R commands with Spark, and Databricks has the option of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark with R in their projects. The book above describes how to use it in great detail. As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describe how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft. Activities There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"\u00b7 Big Data and the cloud"},{"location":"session_bigdata/#session-5-big-data-on-azure-cloud-featuring-spark","text":"You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that provide data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Your Python or R script Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling.","title":"Session 5: Big Data on Azure Cloud Featuring Spark"},{"location":"session_bigdata/#videos","text":"Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code","title":"Videos"},{"location":"session_bigdata/#readings","text":"Slide Deck: Overview of Big Data with Spark for Researchers Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by Cloud Computing Fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and more readable introductions to \"big data\" I've seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial)","title":"Readings"},{"location":"session_bigdata/#for-r-users","text":"The Spark big data system we introduce above is focused on Python and it's native language (calls \"Scala\"). However you can use R commands with Spark, and Databricks has the option of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark with R in their projects. The book above describes how to use it in great detail. As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describe how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft.","title":"For R users"},{"location":"session_bigdata/#activities","text":"There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"Activities"},{"location":"session_bigdata/principles_using_databricks/","text":"DRAFT Using Databricks and References Basic function Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .). How tos Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"DRAFT Using Databricks and References"},{"location":"session_bigdata/principles_using_databricks/#draft-using-databricks-and-references","text":"","title":"DRAFT Using Databricks and References"},{"location":"session_bigdata/principles_using_databricks/#basic-function","text":"Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .).","title":"Basic function"},{"location":"session_bigdata/principles_using_databricks/#how-tos","text":"Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"How tos"},{"location":"session_cloud_storage/","text":"Session 3: Cloud Storage Introduction Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size and scope The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud storage was engineered to save millions of files for millions of users and will take some changes to your approach to understanding how it works. Meeting September 30 2:00-3:30pm Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines Seminar What is cloud storage? Azure Cloud Storage for Researchers Azure Storage Pricing Exercise Readings Storage as a Service from \"Cloud Computing for Science and Engineering\" Azure Documentation: Introduction to the core Azure Storage services Table of Azure Storage Product Offerings Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) optional Understanding block blobs, append blobs, and page blobs Introduction to Azure managed disks This has more techincal background than necessary but could be very helpful. Activities Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Creating Azure Cloud Storage Accounts to create and use storage https://learn.microsoft.com/en-us/azure/storage/files/storage-files-quick-create-use-windows?source=recommendations Post-session discussion points There are several options when creating a storage account. For example, what is the difference LRS vs GRS? Is the documentation describing these clear or confusing? What conditions might you consider LRS vs GRS? Is it worth the cost? How would you share data with colleagues outside of MSU using cloud storage? Where did you find the information for how to do that (Microsoft, Azure, Blog post, other)? Let's say need to share 5gb of data. After doing the pricing exercise above just for storage, what are the costs for each upload and download of 5gb? Does it make a difference if it's Blob or File storage? Optional Activities: The following two activities walk through attaching Azure files to a VM so you can use it just like any other disk. This is only one method for moving data to/from cloud storage to your VM, but it does not require changing your program code. For Windows Users: Using File Storage with Windows VM Microsoft Tutorial: Create an SMB Azure file share and connect it to a Windows VM using the Azure portal Notes: - The tutorial has you create a storage account, but you can re-use the one you've already created (and change the names), or follow the tutorial and create another one. - Not all versions of Windows can use this. For much more detail, see the Azure documentation page \"Mount SMB Azure file share on Windows\" For Linux Users: Mounting File Storage with Linux VMs using NFS Microsoft Tutorial: Create an NFS Azure file share and mount it on a Linux VM using the Azure portal How to mount Azure Files on Linux using SMB Notes: - SMB (invented by Microsoft for Windows) and NFS (invented by Sun Microsystems from Unix) are competing methods for attaching network storage. Both were created for on-premise servers, but Azure Files storage brings this to the cloud. - this tutorial uses command line, and requires an ssh connection to the VM you create. - Knowledge of Linux systems (mount points, fstab, etc) required Optional: Python And Blob Storage This describes an a different method for moving files to/from cloud storage: using code. This does not require you to 'mount' the storage to your VM. For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: knowledge of Python use the blob storage account you created in the exercise above or createa a new one familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line **Optional: Using Managed Disks with Linux Azure Learning Tutorial : Add and size disks in Azure virtual machines Notes: - Uses the Azure Command line interface which we have not discussed. For","title":"\u00b7 Cloud Storage"},{"location":"session_cloud_storage/#session-3-cloud-storage","text":"","title":"Session 3: Cloud Storage"},{"location":"session_cloud_storage/#introduction","text":"Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size and scope The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud storage was engineered to save millions of files for millions of users and will take some changes to your approach to understanding how it works.","title":"Introduction"},{"location":"session_cloud_storage/#meeting-september-30-200-330pm","text":"Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines Seminar What is cloud storage? Azure Cloud Storage for Researchers Azure Storage Pricing Exercise","title":"Meeting September 30 2:00-3:30pm"},{"location":"session_cloud_storage/#readings","text":"Storage as a Service from \"Cloud Computing for Science and Engineering\" Azure Documentation: Introduction to the core Azure Storage services Table of Azure Storage Product Offerings Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) optional Understanding block blobs, append blobs, and page blobs Introduction to Azure managed disks This has more techincal background than necessary but could be very helpful.","title":"Readings"},{"location":"session_cloud_storage/#activities","text":"Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Creating Azure Cloud Storage Accounts to create and use storage https://learn.microsoft.com/en-us/azure/storage/files/storage-files-quick-create-use-windows?source=recommendations","title":"Activities"},{"location":"session_cloud_storage/#post-session-discussion-points","text":"There are several options when creating a storage account. For example, what is the difference LRS vs GRS? Is the documentation describing these clear or confusing? What conditions might you consider LRS vs GRS? Is it worth the cost? How would you share data with colleagues outside of MSU using cloud storage? Where did you find the information for how to do that (Microsoft, Azure, Blog post, other)? Let's say need to share 5gb of data. After doing the pricing exercise above just for storage, what are the costs for each upload and download of 5gb? Does it make a difference if it's Blob or File storage?","title":"Post-session discussion points"},{"location":"session_cloud_storage/#optional-activities","text":"The following two activities walk through attaching Azure files to a VM so you can use it just like any other disk. This is only one method for moving data to/from cloud storage to your VM, but it does not require changing your program code. For Windows Users: Using File Storage with Windows VM Microsoft Tutorial: Create an SMB Azure file share and connect it to a Windows VM using the Azure portal Notes: - The tutorial has you create a storage account, but you can re-use the one you've already created (and change the names), or follow the tutorial and create another one. - Not all versions of Windows can use this. For much more detail, see the Azure documentation page \"Mount SMB Azure file share on Windows\" For Linux Users: Mounting File Storage with Linux VMs using NFS Microsoft Tutorial: Create an NFS Azure file share and mount it on a Linux VM using the Azure portal How to mount Azure Files on Linux using SMB Notes: - SMB (invented by Microsoft for Windows) and NFS (invented by Sun Microsystems from Unix) are competing methods for attaching network storage. Both were created for on-premise servers, but Azure Files storage brings this to the cloud. - this tutorial uses command line, and requires an ssh connection to the VM you create. - Knowledge of Linux systems (mount points, fstab, etc) required Optional: Python And Blob Storage This describes an a different method for moving files to/from cloud storage: using code. This does not require you to 'mount' the storage to your VM. For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: knowledge of Python use the blob storage account you created in the exercise above or createa a new one familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line **Optional: Using Managed Disks with Linux Azure Learning Tutorial : Add and size disks in Azure virtual machines Notes: - Uses the Azure Command line interface which we have not discussed. For","title":"Optional Activities:"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/","text":"Exercise: Creating Azure Cloud Storage Accounts These exercises are for the Cloud Computing Fellowship session on cloud storage . They focus on creating the account(s) necessary to use storage. Pre-requisites Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item. Azure Quickstart Tutorials Storage Account We created a storage account in one of the first activities using the portal, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far. Blob Storage Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob File Storage In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"Exercise: Creating Azure Cloud Storage Accounts"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#exercise-creating-azure-cloud-storage-accounts","text":"These exercises are for the Cloud Computing Fellowship session on cloud storage . They focus on creating the account(s) necessary to use storage.","title":"Exercise: Creating Azure Cloud Storage Accounts"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#pre-requisites","text":"Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item.","title":"Pre-requisites"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#azure-quickstart-tutorials","text":"","title":"Azure Quickstart Tutorials"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#storage-account","text":"We created a storage account in one of the first activities using the portal, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far.","title":"Storage Account"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#blob-storage","text":"Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob","title":"Blob Storage"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#file-storage","text":"In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"File Storage"},{"location":"session_cloud_storage/storage_pricing_exercise/","text":"Prior to doing this exercise, See the reading and lecture slides linked in this session for definitions of terms. How large, approximately, is your data? If you are unsure, estimate 100 gb. How much would it cost to keep it in the cloud? Compare the pricing for Blob, Files and Disk storage for 6 months Aspects Of Storage: Redunancy: Always slect \"LRS\" as that is almost always sufficient. Storage prices are not the same across regions, but the default (\"East US\") works for this exercise Consider only the \"Hot\" storage of the different tiers (\"Premium\", \"Hot\", \"Cool\", and \"Archive\") for some high performance applications, Premium is required, but look at the price difference! Operations, Transactions and data transfer costs charged per 10K operations really hard to estimate unless you know your workload very low costs, e.g. reading 10K Blobs costs 1/2 of one cent. I would not bother estimating this cost unless you know you will have very high disk operations Types of Storage to Compare: Azure Blob Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/blobs/ select \"Hierachcial namespace\" Azure Files Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/files/ Managed Disk Pricing : https://azure.microsoft.com/en-us/pricing/details/managed-disks/ note these are in different sizes and types, select 128gb size if you are estimating 100gb data, Standard SSD when you create a disk in the protal, it defaults to 1 TiB size, which is quite expensive / month Optional: compare with on-premise storage costs The MSU HPC offers 1TB storage free to any MSU Researcher with redundant backups and high-speed access, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)? There are a few options for redundancy (global vs local) and other aspects. What is the cheapest combination of options?","title":"Storage pricing exercise"},{"location":"session_cloud_storage/storage_pricing_exercise/#optional-compare-with-on-premise-storage-costs","text":"The MSU HPC offers 1TB storage free to any MSU Researcher with redundant backups and high-speed access, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)? There are a few options for redundancy (global vs local) and other aspects. What is the cheapest combination of options?","title":"Optional: compare with on-premise storage costs"},{"location":"session_datasystems/","text":"Session 4: Data Servers on the Cloud Introduction Data servers (like Relational Databases) can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s, but there are many other types. A central advantage of data servers is ability to handle many conncurrent connections. Connections can be from many users, a web application serving many uers, or many other concurrent processes. Like other systems (such as VMs, File storage servers, big data tools, etc), these data systems don't require cloud computing, but cloud companies offer database services such taht with a few clicks you can have a server that would take a week to provision and years to maintain. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project. I have use databases with many research projects that had significant data entry burden requiring many work-hours of students typing in data, or shared systems. Readings Introduction to Data Servers on the Cloud Slide Presentation Chapter 4. Databases From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" by Foster, Ghani, Jarmin, Kreuter and Lane. The book itself could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read Activities Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL In depth SQL Tutorial: After completing the two activities above, If you are interested in starting with SQL, this free tutorial looks pretty good. Let us know if you tried it and it was not helpful: PostgreSQL Tutorial from TutorialsPoint.com . NOTE: A Database server can house many \"databases\" , and sometimes a database is called a \"schema\" so you can use the database server you created above, and the same steps for how to connect to the server, then create a new database inside the server for the tutorial. Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help for incorporating SQL into your research. References A list of the commands you may use to manage a database for the Postgresql variety: https://zaiste.net/posts/postgresql-primer-for-busy-people/ Optional : Data Analytics on the Google Platform Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"\u00b7 Data Systems"},{"location":"session_datasystems/#session-4-data-servers-on-the-cloud","text":"","title":"Session 4: Data Servers on the Cloud"},{"location":"session_datasystems/#introduction","text":"Data servers (like Relational Databases) can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s, but there are many other types. A central advantage of data servers is ability to handle many conncurrent connections. Connections can be from many users, a web application serving many uers, or many other concurrent processes. Like other systems (such as VMs, File storage servers, big data tools, etc), these data systems don't require cloud computing, but cloud companies offer database services such taht with a few clicks you can have a server that would take a week to provision and years to maintain. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project. I have use databases with many research projects that had significant data entry burden requiring many work-hours of students typing in data, or shared systems.","title":"Introduction"},{"location":"session_datasystems/#readings","text":"Introduction to Data Servers on the Cloud Slide Presentation Chapter 4. Databases From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" by Foster, Ghani, Jarmin, Kreuter and Lane. The book itself could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read","title":"Readings"},{"location":"session_datasystems/#activities","text":"Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL In depth SQL Tutorial: After completing the two activities above, If you are interested in starting with SQL, this free tutorial looks pretty good. Let us know if you tried it and it was not helpful: PostgreSQL Tutorial from TutorialsPoint.com . NOTE: A Database server can house many \"databases\" , and sometimes a database is called a \"schema\" so you can use the database server you created above, and the same steps for how to connect to the server, then create a new database inside the server for the tutorial. Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help for incorporating SQL into your research.","title":"Activities"},{"location":"session_datasystems/#references","text":"A list of the commands you may use to manage a database for the Postgresql variety: https://zaiste.net/posts/postgresql-primer-for-busy-people/","title":"References"},{"location":"session_datasystems/#optional-data-analytics-on-the-google-platform","text":"Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"Optional : Data Analytics on the Google Platform"},{"location":"session_datasystems/data_servers_intro_for_researchers_edited_with_typora/","text":"Overview of Data Servers and Databases on the Cloud for Researchers","title":"Data servers intro for researchers edited with typora"},{"location":"session_datasystems/table_of_responsibilties_by_service_level/","text":"Layer Responsibility On-Prem IAAS (VM) PAAS SAAS Network Connectivity & Security Campus IT Service Service Service Hardware Disk Failures You Service Service Service Operating System Updates, installation, security You You Service Service Security Software Install and maintain You You Service Service Server Software Install, maintain You You Service Service Server Configuration Tune, Speed, You You You (limited) Service User Configuration Who can access, user accounts You You You Service Code/Data You You You You","title":"Table of responsibilties by service level"},{"location":"session_how_to_cloud/","text":"Session 2: What is the cloud and how does it work? An introduction using storage and virtual machines About this Session We are providing materials and activities for this session for you to read and attempt at your own pace. Please attempt these and see how far you can get. Feel free to post on Microsoft Teams if you have any issues, find things that need correcting, or have general questions. We will host an optional, additional, in-person session to provide help to anyone who wants to attend, Friday September 23 2pm to 3:30p. Since this is outside of pre-arranged schedule, anyone who would like help but can't attend during this please contact us and we will arrange a time for you. We will discuss all of this material and more during our next regularly scheduled in-person session Friday September 30th. Overview When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\" Overview Presentation Cloud Concepts & Virtualization Slides (PDF) About the Azure Portal We demonstrated the azure portal quickly in our last session when we set a budget alert . The following dives into more detail about 'resource groups' which is the core of how Azure is organized. Note that, as we get started, fellows have access to just a single resource group that we've created for you. You can't create your own but you can create as many resources as yuo need inside this single resource group. Azure Portal Reading Top-down description of how Azure is organized Azure Portal Activity Using the Azure Portal : tutorial and video Optional Follow-ons: Azure Storage The Activity above had you creat a 'storage account' with no background. If you are interested in learning more about storage, this is a prety good, high-level introduction : Edureka Azure Storage Tutorial (there are several pop-ups and ads, but it's a good level of of information ) You will see there are different types of storage, but all types must be inside a \"storage account\" and this \"storage account\" must be inside a resource group. We will re-visit concepts and usage of cloud storage in detail, as it's a core aspect of cloud computing. Virtual Machines We introduced \"virtualization\" during our introduction. For IT this means flexibly creating multiple resources on one piece of hardware using software. The main use case is many virtual computers (or servers) on one large computer hardware. This was create prior to cloud, but when you create your own computer in the cloud, it's based on the technology. To a user it may seem very similar, but to the systems IT engineer, it's very different. However these readings may help give you an Readings: Chapter 4: Computing as a Service from \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 What is a Virtual Machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company Activity: A long activity to create (and delete) a Virtual Machine with the Azure Portal for both windows and Linux. Why create a VM What is a VM good for? The activity above does not discuss why you'd create a VM and connect with remote desktop, only that you can do it. We will discuss that at our next session. Can you think of possible use cases for your research, or other types of research, for a remote computer that could be very powerful or very small?","title":"\u00b7 How does the cloud work?"},{"location":"session_how_to_cloud/#session-2-what-is-the-cloud-and-how-does-it-work-an-introduction-using-storage-and-virtual-machines","text":"","title":"Session 2: What is the cloud and how does it work?  An introduction using storage and virtual machines"},{"location":"session_how_to_cloud/#about-this-session","text":"We are providing materials and activities for this session for you to read and attempt at your own pace. Please attempt these and see how far you can get. Feel free to post on Microsoft Teams if you have any issues, find things that need correcting, or have general questions. We will host an optional, additional, in-person session to provide help to anyone who wants to attend, Friday September 23 2pm to 3:30p. Since this is outside of pre-arranged schedule, anyone who would like help but can't attend during this please contact us and we will arrange a time for you. We will discuss all of this material and more during our next regularly scheduled in-person session Friday September 30th.","title":"About this Session"},{"location":"session_how_to_cloud/#overview","text":"When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\"","title":"Overview"},{"location":"session_how_to_cloud/#overview-presentation","text":"Cloud Concepts & Virtualization Slides (PDF)","title":"Overview Presentation"},{"location":"session_how_to_cloud/#about-the-azure-portal","text":"We demonstrated the azure portal quickly in our last session when we set a budget alert . The following dives into more detail about 'resource groups' which is the core of how Azure is organized. Note that, as we get started, fellows have access to just a single resource group that we've created for you. You can't create your own but you can create as many resources as yuo need inside this single resource group.","title":"About the Azure Portal"},{"location":"session_how_to_cloud/#azure-portal-reading","text":"Top-down description of how Azure is organized","title":"Azure Portal Reading"},{"location":"session_how_to_cloud/#azure-portal-activity","text":"Using the Azure Portal : tutorial and video","title":"Azure Portal Activity"},{"location":"session_how_to_cloud/#optional-follow-ons","text":"Azure Storage The Activity above had you creat a 'storage account' with no background. If you are interested in learning more about storage, this is a prety good, high-level introduction : Edureka Azure Storage Tutorial (there are several pop-ups and ads, but it's a good level of of information ) You will see there are different types of storage, but all types must be inside a \"storage account\" and this \"storage account\" must be inside a resource group. We will re-visit concepts and usage of cloud storage in detail, as it's a core aspect of cloud computing.","title":"Optional Follow-ons:"},{"location":"session_how_to_cloud/#virtual-machines","text":"We introduced \"virtualization\" during our introduction. For IT this means flexibly creating multiple resources on one piece of hardware using software. The main use case is many virtual computers (or servers) on one large computer hardware. This was create prior to cloud, but when you create your own computer in the cloud, it's based on the technology. To a user it may seem very similar, but to the systems IT engineer, it's very different. However these readings may help give you an","title":"Virtual Machines"},{"location":"session_how_to_cloud/#readings","text":"Chapter 4: Computing as a Service from \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 What is a Virtual Machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company Activity: A long activity to create (and delete) a Virtual Machine with the Azure Portal for both windows and Linux.","title":"Readings:"},{"location":"session_how_to_cloud/#why-create-a-vm","text":"What is a VM good for? The activity above does not discuss why you'd create a VM and connect with remote desktop, only that you can do it. We will discuss that at our next session. Can you think of possible use cases for your research, or other types of research, for a remote computer that could be very powerful or very small?","title":"Why create a VM"},{"location":"session_how_to_cloud/azure_organization/","text":"Azure Organization This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful. Azure Locations or Regions Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Organization"},{"location":"session_how_to_cloud/azure_organization/#azure-organization","text":"This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful.","title":"Azure Organization"},{"location":"session_how_to_cloud/azure_organization/#azure-locations-or-regions","text":"Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Locations or Regions"},{"location":"session_how_to_cloud/azure_portal_walkthrough/","text":"Exercise: Azure Portal Walk-through and Storage account creation MSU Cloud Computing Fellowship About This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure that we will learn about. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material. There is a corresponding video that we've made that includes infrmation about the portal, and also creating a storage account. Orientation to the Azure Portal The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in). Note this video also walks through creating a storage account. This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal that we will cover in the future. Most are not critical. A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere. Bonus: What can you do here? The primary purpose of using the portal and your resource group is to create things, and manage and monitor those things. For the purpose of this activity - since you don't really have anything - we can simply look at the 'activity log' in the left side-panel near the top. - this opens a new table of columns Operation name, Status, Time, Time stamp, etc that is probably empty for you. - Tables of information like this in the portal have filters at the top. The default activity is just for the previous 6 hours. If you click on the Find that filter called \"timespan\" and select 1 week (or longer) you can see when I created the resource group and the budget. Optional Activity: creating a \"storage account\" with the Azure portal If you would like to explore the azure portal by creating a new resources, then read on. We have not talked about cloud storage, and you don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. Note that a \"storage account\" is not the same as \"disk\" you will see when you create a virtual machine. We will discuss the difference in detail in the session on storage. Requirements: An Azure Account with valid subscription A Resource group All members of the current Cloud Computing Fellowship cohort have these things creating a \"storage account\" tutorial step-by-step. Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a green spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" under \"Storage account\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Computing Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) use your MSU ID (NetID) when you name things so help me keep track and also to help find a name that is unique. So, replace \"NETID\" with your MSU NetID here: \"stNETIDccf22\" e.g. stbillspatccf22 If you are repeating this tutorial, simply add a \"2\" or \"B\" e.g. \"stbillspatccf22B\" We can delete these experiments later. Region (Location): You may leave US East. Click in here to see the options. In practice, pick the region that is closest to you or where your data will be moving to (e.g. North Central US for MSU) but there are other considerations. select Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS). We won't see a difference, and LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. click 'next...' Networking: leave all of these settings as-is for this tutorial. click 'next...' Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing. click 'next...' Encryption: leave all as is. click 'next...' Tags tags are optional but, eventually highly recommended. For now you can leave them blank. Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa About Portal \"Resource\" Pages Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#exercise-azure-portal-walk-through-and-storage-account-creation","text":"MSU Cloud Computing Fellowship","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about","text":"This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure that we will learn about. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material. There is a corresponding video that we've made that includes infrmation about the portal, and also creating a storage account.","title":"About"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#orientation-to-the-azure-portal","text":"The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in). Note this video also walks through creating a storage account. This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal that we will cover in the future. Most are not critical. A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere.","title":"Orientation to the Azure Portal"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#bonus-what-can-you-do-here","text":"The primary purpose of using the portal and your resource group is to create things, and manage and monitor those things. For the purpose of this activity - since you don't really have anything - we can simply look at the 'activity log' in the left side-panel near the top. - this opens a new table of columns Operation name, Status, Time, Time stamp, etc that is probably empty for you. - Tables of information like this in the portal have filters at the top. The default activity is just for the previous 6 hours. If you click on the Find that filter called \"timespan\" and select 1 week (or longer) you can see when I created the resource group and the budget.","title":"Bonus: What can you do here?"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#optional-activity-creating-a-storage-account-with-the-azure-portal","text":"If you would like to explore the azure portal by creating a new resources, then read on. We have not talked about cloud storage, and you don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. Note that a \"storage account\" is not the same as \"disk\" you will see when you create a virtual machine. We will discuss the difference in detail in the session on storage. Requirements: An Azure Account with valid subscription A Resource group All members of the current Cloud Computing Fellowship cohort have these things","title":"Optional Activity: creating a \"storage account\" with the Azure portal"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#creating-a-storage-account-tutorial-step-by-step","text":"Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a green spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" under \"Storage account\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Computing Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) use your MSU ID (NetID) when you name things so help me keep track and also to help find a name that is unique. So, replace \"NETID\" with your MSU NetID here: \"stNETIDccf22\" e.g. stbillspatccf22 If you are repeating this tutorial, simply add a \"2\" or \"B\" e.g. \"stbillspatccf22B\" We can delete these experiments later. Region (Location): You may leave US East. Click in here to see the options. In practice, pick the region that is closest to you or where your data will be moving to (e.g. North Central US for MSU) but there are other considerations. select Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS). We won't see a difference, and LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. click 'next...' Networking: leave all of these settings as-is for this tutorial. click 'next...' Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing. click 'next...' Encryption: leave all as is. click 'next...' Tags tags are optional but, eventually highly recommended. For now you can leave them blank. Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa","title":"creating a \"storage account\" tutorial step-by-step."},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about-portal-resource-pages","text":"Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"About Portal \"Resource\" Pages"},{"location":"session_how_to_cloud/azure_vm_walkthrough/","text":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session. Requirements for both activities You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux) Finally we find that there are many layers of concepts related in this exercise related to IT Infrastructure, and we are happy to provde clarification as needed. Creating a Windows Virtual Machine This section is based on Windows, and is recommended for everyone as it is the easy way to connect to remote machine. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. Requirements for Windows VMs To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. Region Select \"(US) North Central US\" Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may Azure Spot Instance leave unchecked. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. username : use any user name you will easily remember, perhaps your netid password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags For this exercise, using tags will be essential for identifying which components go to which VM. If you need more information see session 2 page for a readings about tags. Do the following: Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2_vm or similar unique value. click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/ Optional: Creating a Linux Virtual Machine This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible). Requirements To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in Linux desktop/laptops come with an ssh client Creating a Linux Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu 20.04 2. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). Virtual machine name Name: dsvm-YOURNETID-ccf22 Use your actual NetId , for example \"dsvm-billspat-ccf22\" Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. Region You may select \"(US) North Central US\" or any other US-based region. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. Security Type Leave as 'standard' Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. Any Linux image is fine for this tutorial as Run with Azure Spot discount leave unchecked. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 Click \"see all sizes\" if you are feeling adventurous -- there are maybe 100 options. (click the [x] in upper right to close the size selector window) Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Authentication Type For the purpose of this exercise, select \"password\" SSH Keys are strongly recommened but to keep this simple we will use a password. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. You can use your MSU NetID for your username so it's easy to remember. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use Disks and Other Settings For this exercise we'll be using the default values for almost all the pages, except for ' Basics ' page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using the Azure portal to create VM creates several resources (up to 12). Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.0730 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section Viewing VM Resources in your Resource group (Windows and Linux) While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) Connecting Connecting to a Windows VM using Remote Desktop Protocol (RDP) client You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. Every VM created in Azure has an \"IP Adress\" or internet address, and we use this to connect to. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). In the Azure portal: click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again On your computer: after it's downloaded, find the .rdp file and double click to open it which should start your remote desktop software. Mac users must have installed the Microsoft Remote Desktop client app ignore any security or error messages, click \"connect\" Enter the user name and password you used when you created the VM. Alternatively you may also open your RPD software, create a new connection, and copy the IP address listed in the portal, in the Azure VM. and paste the IP address that is listed on the resource page for the VM. When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines. Connecting to a Linux VM using SSH We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Starting and Stopping the VM (both Windows and Linux) There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal: Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. Deleting the Resources (both Windows and Linux) Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges. More References Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring Return to the Session 2 page","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#exercise-creating-and-connecting-to-a-virtual-machine-vm-for-both-windows-and-linux","text":"Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session.","title":"About"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-both-activities","text":"You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux) Finally we find that there are many layers of concepts related in this exercise related to IT Infrastructure, and we are happy to provde clarification as needed.","title":"Requirements for both activities"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-windows-virtual-machine","text":"This section is based on Windows, and is recommended for everyone as it is the easy way to connect to remote machine. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-windows-vms","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements for Windows VMs"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. Region Select \"(US) North Central US\" Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may Azure Spot Instance leave unchecked. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. username : use any user name you will easily remember, perhaps your netid password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows.","title":"Basics"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags","text":"For this exercise, using tags will be essential for identifying which components go to which VM. If you need more information see session 2 page for a readings about tags. Do the following: Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2_vm or similar unique value. click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/","title":"Review and Create"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#optional-creating-a-linux-virtual-machine","text":"This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible).","title":"Optional:  Creating a Linux Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements","text":"To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in Linux desktop/laptops come with an ssh client","title":"Requirements"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-linux-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Linux Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template_1","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu 20.04","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"2. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics_1","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). Virtual machine name Name: dsvm-YOURNETID-ccf22 Use your actual NetId , for example \"dsvm-billspat-ccf22\" Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. Region You may select \"(US) North Central US\" or any other US-based region. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. Security Type Leave as 'standard' Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. Any Linux image is fine for this tutorial as Run with Azure Spot discount leave unchecked. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 Click \"see all sizes\" if you are feeling adventurous -- there are maybe 100 options. (click the [x] in upper right to close the size selector window) Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Authentication Type For the purpose of this exercise, select \"password\" SSH Keys are strongly recommened but to keep this simple we will use a password. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. You can use your MSU NetID for your username so it's easy to remember. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use","title":"Basics"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings_1","text":"For this exercise we'll be using the default values for almost all the pages, except for ' Basics ' page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags_1","text":"Using the Azure portal to create VM creates several resources (up to 12). Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create_1","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.0730 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section","title":"Review and Create"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#viewing-vm-resources-in-your-resource-group-windows-and-linux","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"Viewing VM Resources in your Resource group (Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"The VM Resource Page"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting","text":"","title":"Connecting"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-windows-vm-using-remote-desktop-protocol-rdp-client","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. Every VM created in Azure has an \"IP Adress\" or internet address, and we use this to connect to. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). In the Azure portal: click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again On your computer: after it's downloaded, find the .rdp file and double click to open it which should start your remote desktop software. Mac users must have installed the Microsoft Remote Desktop client app ignore any security or error messages, click \"connect\" Enter the user name and password you used when you created the VM. Alternatively you may also open your RPD software, create a new connection, and copy the IP address listed in the portal, in the Azure VM. and paste the IP address that is listed on the resource page for the VM. When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines.","title":"Connecting to a Windows VM using Remote Desktop Protocol (RDP) client"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-linux-vm-using-ssh","text":"We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it.","title":"Connecting to a Linux VM using SSH"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#starting-and-stopping-the-vm-both-windows-and-linux","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it.","title":"Starting and Stopping the VM (both Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#stopping-deallocating-the-vm-with-the-portal","text":"Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"Stopping (deallocating) the VM with the Portal:"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#deleting-the-resources-both-windows-and-linux","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges.","title":"Deleting the Resources (both Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#more-references","text":"Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring Return to the Session 2 page","title":"More References"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/","text":"Exercise: Creating a Windows Virtual Machine (VM) Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in) About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ Requirements You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided. Creating and Connecting to a Windows Virtual Machine Requirements To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. Creating a Windows Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. 4. The Resources While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) 5. The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) 6. Connecting You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. 7. Starting and Stopping the VM There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. 8. Deleting the Resources Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#exercise-creating-a-windows-virtual-machine-vm","text":"Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in)","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/","title":"About"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements","text":"You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided.","title":"Requirements "},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-and-connecting-to-a-windows-virtual-machine","text":"","title":"Creating and Connecting to a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements_1","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-a-windows-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked.","title":"Basics"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#tags","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes.","title":"Review and Create"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#4-the-resources","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"4. The Resources"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#5-the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"5. The VM Resource Page"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#6-connecting","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt.","title":"6. Connecting"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#7-starting-and-stopping-the-vm","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"7. Starting and Stopping the VM"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#8-deleting-the-resources","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"8. Deleting the Resources"},{"location":"session_introduction/","text":"MSU Cloud Computing Fellowship 2022-23 1: Introduction to the 2022-23 MSU Cloud Computing Fellowship You don't have to face the clouds alone Welcome! This is the first 'session' of the MSU Cloud Computing Fellowship (CCF) for 2022-2023. For a description of the program and how sessions are organized, see the CCF home page The goals of this introductory session are to orient you to this program, introduce ourselves to each other, provide some background on cloud computing, set up our technology, and discuss what all of our expectations are. If possible during the first week of this semester, please complete the following activities prior to our first synchronous meeting September 2 . If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us . Activities: Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting. Readings Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version). Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review Introductions Mahmoud Parvizi, Instructor & Research Consultant, ICER Past experience & current role Cloud facilitator Participant in first Fellowship cohort Patrick Bills, Instructor & Staff, Data Management & Analytics Data Science Team. Brian O'shea, Director, MSU Institute for Cyber-Enabled Research (ICER) Danielle Barnes, Associate Director, Data Management & Analytics (DMA), MSU IT Services. A video of our introductions recorded in 2021 is avaialble on MSU MediaSpace (requires MSU log-in). Participant Introductions & Discussion Introductions from the 2022-23 Cloud Computing Fellows: About you: your preferred name and pronouns, which degree program or department if faculty. Research synopsis and methods Previous experience with reseach computing including cloud computing (if any) Current research computing hurdles, roadblocks, challenges & triumphs Your goals for this fellowship For example, how could cloud computing support yuor research? What do you think the cloud is or is good for, in general? Fellowship Program Overview Review our \" syllabus \" on the home page of this website for the schedule and topics we will cover. Program synopsis: Fall semester materials, activities, seminars and discussions (Pat Bills): Goal, scope and expectation; structure (pre-session materials and activities, \"textbook\"); in-person meeting approx bi-weekly and excluding holidays; our expectations. Winter/Spring semester Projects (Mahmoud Parvizi): Goal, scope and expectation; Proposal write-up and presentation early January; Check-points to discuss progress and hurdles Office hours & help Final presentation during Symposium late april Goals Help you get an understanding of: what is cloud computing? what is cloud computing useful for? when should it use it for my research computing? how can I use it? Understanding of the context of the technology we are learning about. Help you get some practical experience apply cloud to some aspect of your own research apply cloud to generic/canned research-like problem Non Goals: prepare you for a cloud computing certification (there are many existing resources for that. ) become experts in everything build a dot-com empire cover all aspects of cloud Introduction to Computing and Cloud Computing Seminar, Pat Bills References: The NIST definition of cloud computing Discussion Demonstration: Using the Azure Portal A quick, live demonstration orienting you to the Azure portal and working with budgets. Our next session activities will include a detailed workshop on creating cloud computing resources such as a virtual machine. Tutorial: \"Setting a Cost Alert Using the Azure Portal\" More information about the azure portal including a video walk-through of the Azure portal is available in Session 2 activities. Questions and Discussion What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)? Post-session After our introduction, you may have more qeustions than answers. Here are additional readings for details related Readings Additional Cloud background These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)","title":"\u00b7 Introduction"},{"location":"session_introduction/#msu-cloud-computing-fellowship-2022-23","text":"","title":"MSU Cloud Computing Fellowship 2022-23"},{"location":"session_introduction/#1-introduction-to-the-2022-23-msu-cloud-computing-fellowship","text":"You don't have to face the clouds alone","title":"1: Introduction to the 2022-23 MSU Cloud Computing Fellowship"},{"location":"session_introduction/#welcome","text":"This is the first 'session' of the MSU Cloud Computing Fellowship (CCF) for 2022-2023. For a description of the program and how sessions are organized, see the CCF home page The goals of this introductory session are to orient you to this program, introduce ourselves to each other, provide some background on cloud computing, set up our technology, and discuss what all of our expectations are. If possible during the first week of this semester, please complete the following activities prior to our first synchronous meeting September 2 . If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us .","title":"Welcome!"},{"location":"session_introduction/#activities","text":"Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting.","title":"Activities:"},{"location":"session_introduction/#readings","text":"Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version). Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review","title":"Readings"},{"location":"session_introduction/#introductions","text":"Mahmoud Parvizi, Instructor & Research Consultant, ICER Past experience & current role Cloud facilitator Participant in first Fellowship cohort Patrick Bills, Instructor & Staff, Data Management & Analytics Data Science Team. Brian O'shea, Director, MSU Institute for Cyber-Enabled Research (ICER) Danielle Barnes, Associate Director, Data Management & Analytics (DMA), MSU IT Services. A video of our introductions recorded in 2021 is avaialble on MSU MediaSpace (requires MSU log-in).","title":"Introductions"},{"location":"session_introduction/#participant-introductions-discussion","text":"Introductions from the 2022-23 Cloud Computing Fellows: About you: your preferred name and pronouns, which degree program or department if faculty. Research synopsis and methods Previous experience with reseach computing including cloud computing (if any) Current research computing hurdles, roadblocks, challenges & triumphs Your goals for this fellowship For example, how could cloud computing support yuor research? What do you think the cloud is or is good for, in general?","title":"Participant Introductions &amp; Discussion"},{"location":"session_introduction/#fellowship-program-overview","text":"Review our \" syllabus \" on the home page of this website for the schedule and topics we will cover. Program synopsis: Fall semester materials, activities, seminars and discussions (Pat Bills): Goal, scope and expectation; structure (pre-session materials and activities, \"textbook\"); in-person meeting approx bi-weekly and excluding holidays; our expectations. Winter/Spring semester Projects (Mahmoud Parvizi): Goal, scope and expectation; Proposal write-up and presentation early January; Check-points to discuss progress and hurdles Office hours & help Final presentation during Symposium late april","title":"Fellowship Program Overview"},{"location":"session_introduction/#goals","text":"Help you get an understanding of: what is cloud computing? what is cloud computing useful for? when should it use it for my research computing? how can I use it? Understanding of the context of the technology we are learning about. Help you get some practical experience apply cloud to some aspect of your own research apply cloud to generic/canned research-like problem Non Goals: prepare you for a cloud computing certification (there are many existing resources for that. ) become experts in everything build a dot-com empire cover all aspects of cloud","title":"Goals"},{"location":"session_introduction/#introduction-to-computing-and-cloud-computing","text":"Seminar, Pat Bills References: The NIST definition of cloud computing Discussion","title":"Introduction to Computing and Cloud Computing"},{"location":"session_introduction/#demonstration-using-the-azure-portal","text":"A quick, live demonstration orienting you to the Azure portal and working with budgets. Our next session activities will include a detailed workshop on creating cloud computing resources such as a virtual machine. Tutorial: \"Setting a Cost Alert Using the Azure Portal\" More information about the azure portal including a video walk-through of the Azure portal is available in Session 2 activities.","title":"Demonstration: Using the Azure Portal"},{"location":"session_introduction/#questions-and-discussion","text":"What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)?","title":"Questions and Discussion"},{"location":"session_introduction/#post-session","text":"After our introduction, you may have more qeustions than answers. Here are additional readings for details related","title":"Post-session"},{"location":"session_introduction/#readings_1","text":"","title":"Readings"},{"location":"session_introduction/#additional-cloud-background","text":"These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)","title":"Additional Cloud background"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/","text":"li { font-size: 0.9em; } section.gaia{--color-background: #209ECE;} Introducing cloud computing for research Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship Patrick Bills, Michigan State University Part 1: the \"computing\" in cloud computing Understanding of computing Fellowship Goal: help you connect cloud computing to your research in a meaningful way our original question: - How can cloud computing benefit help your research? Let's re-frame the question for this discussion: - Which kind of computing could help my research? - Can I find support for that kind of computing using cloud services? What is computing? Computing Vocabulary cloud computing is marketed to IT systems administrators, software developers, and managers -- not for us (unless you are a systems engineer). The primary function of cloud computing is to provide \"infrastructure\" aka the \"back-end\" or back room of a company's IT department, so we ware going to learn about that. cloud computing is defined and sold based on abstractions of physical components of computers and other infrastructure such as network. Learning about IT infrastructure may be helpful understanding the context of the computing and what you may need. Could you purchase your own infrastructure (computers, networks, disks, etc) and run it \"on-premise\" and get the same benefit as cloud computing? Or have your institution do that? Sometimes yes! About Computing: Major components of computer li { font-size:1em; } User software (scripts, user code, etc) Base Software Operating System Input/Ouput (I/O) Central Processor (CPU) & Memory (RAM) Computer Architecture (model type) Storage - local disk Storage - external ( attached or via network ) Network About Computing: What is a server? Cloud computing is all about \"servers,\" so we should define that. A server is any computer connected to a network, running software that listens for, and responsed to, messages - The 'server' is actually the software, not the hardware - The computer that runs the software is the 'host' - A 'client' is software sends the message, and receives and interprets the response. - the form the message can take is the API. About Computing: Example Server: Web server? client is the web browser message = URL which includes address, url paths, and additional parameters response = the code for the web page client interprets the code and renders the page. an alternate client could be a script, or the curl utility https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1 About Computing: Other Types of Servers Database Client: special database client (not web browser) sends data commands as messages, response is tabular outputs File Servers Share files. We use Cloud file sync services, but Collaboration Email, calendaring etc Enterprise Data Systems for loading, cataloging, transforming business data Security Firewalls, Proxy, network traffic management Monitoring system health data collection, accessible via another web server Web-based services For example D2L. About Computing: Servers and Networks Networking Requirements to access a server: the server must be on the same network as you to receive your message the more accessible the network, the more vulnerable, so partitioning is used servers that accept messages from the Internet are a major security risk network failure stops all work for everyone designing efficient, robust, and secure networks is a major resource drain Too much hardware? Virtualization to the rescue IT Departments 'serve' large user communities with large amounts of infrastructure, which is very in Techniques were invented to separate the 'server' or 'network' from the hardware. Virtualization: single box with a layer of software to share among different software. Software-defined networks: Many servers could be created and managed with software on a single hardware Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud. Networks followed suite with software to determine routes and paritioning on single physical layout Part 2: Nature of Cloud Computing Some Motivation at Amazon.com Massive IT infrastructure supports the Amazon store and company They wanted to sell shopping application as a service to a company like Target who didn't want to r-un their own store. T This required the software developers to have lots of flexible infrastructure (servers) to run on. They found team to build a service (with software) could spend 70% of their time setting up the 'back end' They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development. What they wanted in days actually took months. li { font-size:0.8em; } Eureka moment for Amazon: we could sell it Amazon automated their IT department so teams could order and provision the servers they needed on demand beyond just virtualization (\"everything was an API\") They got really good at running very large data centers for many customers as cheaply as possible and on-demand for Amazon.com and other stores and services. They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it. Their customers were other IT departments Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\" NIST defintion of cloud Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics On-demand self-service . Measured service : pay for what you get. Broad network access : accessible from the internet Rapid elasticity : no limits from a customer perspective. This word was invented by AWS Resource pooling : single resources serve many customers. What is Cloud Computing? Cloud concepts vs Cloud Providers Three major cloud providers are in a constant arms race, literally ( Azure vs. Amazon competed for a $10B defense contract ): Azure, Amazon Web Services and Google Cloud Platform Offerings are very similar so all are great choices other options, smaller companies, open source options (used by Indiana University JetSteam HPC, Osiris project from MSU, UMich, Wayne State and IU. Cyverse for running jobs. Benefits of Cloud Computing for Research Customized Computing: can create customized resources only when you need it Elastic/On-demand: can run ad-hoc computations on those on-demand resources Instant service: Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others? Benefits of Cloud for Research Restatement of goals of this fellowship: Learn which types of computing resources are beneficial to your research Learn how to use Cloud to create those resources Use the services packaged by cloud companies to discover new resources Learning how to learn about cloud Training materials and documentation is written for IT professionals - Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. <!-- That can make it difficult to decipher which kind of cloud service will work best for your use case. - As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. - There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. What documentation is available for researchers? There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster (U. Chicago) and Dennis Gannon (IU) , the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute, University of Washington. Unmaintained. source code https://cloudbank-project.github.io/cb-resources/ succesor to the cloudmaven? Cloudbank training videos Learning how to learn about cloud: Caveats and help As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. Theme: Using workflow and computational thinking Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research based on computing A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. . -Our first uses of cloud will use forms to create resources, but we encourage you to automation where possible About Cloud Security Security and Risk management are important issues even for researchers who's data are open - If your computer is a server , your responsibility just increased 100X: these are prime targets. Consider each component of a server to be a point of vulnerability. - Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security - We will cover methods to reduce security risks but it's important to consider the risk of hacking from the beginning HPCC vs Cloud Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never). Especially windows-based software. I will cover some of these types of systems in future sessions Acknowledging bias in access to cloud computing across research cultures It's widely recognized that AI is frequently bias. For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture, and background. System Engineering is it's own discipline and Cloud computing is arcane -our goal is to reduce conceptual barriers to using this technology Discussion Part 3: Introduction to the Azure using the Azure Portal About Azure We have funding for using Azure cloud, and we have experience using Azure. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (using a gmail address or other non-MSU email address). Each participant has a budget for using Azure and a \"resource group\" to create resources About Cloud Costs Cost management is a major hurdle for adopting CC (Almost) everything you do in Azure has a cost Costs often acrue over time, wether the resource is in use or not Deleting resources when are not using is a great way to reduce cost We want to encourage you to experiment! Using a very powerful machine for an hour may cost only $0.50 Just be aware that creating something and leaving it on will deplete your budget Solution: \"Budget Alerts\" Activity : Using the Azure Portal Demonstration","title":"Brief introduction to cloud computing research"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#introducing-cloud-computing-for-research","text":"","title":"Introducing cloud computing for research"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-using-microsoft-azure-for-the-msu-cloud-computing-fellowship","text":"Patrick Bills, Michigan State University","title":"Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-1","text":"","title":"Part 1:"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#the-computing-in-cloud-computing","text":"","title":"the \"computing\" in cloud computing"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#understanding-of-computing","text":"Fellowship Goal: help you connect cloud computing to your research in a meaningful way our original question: - How can cloud computing benefit help your research? Let's re-frame the question for this discussion: - Which kind of computing could help my research? - Can I find support for that kind of computing using cloud services?","title":"Understanding of computing"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-is-computing-computing-vocabulary","text":"cloud computing is marketed to IT systems administrators, software developers, and managers -- not for us (unless you are a systems engineer). The primary function of cloud computing is to provide \"infrastructure\" aka the \"back-end\" or back room of a company's IT department, so we ware going to learn about that. cloud computing is defined and sold based on abstractions of physical components of computers and other infrastructure such as network. Learning about IT infrastructure may be helpful understanding the context of the computing and what you may need. Could you purchase your own infrastructure (computers, networks, disks, etc) and run it \"on-premise\" and get the same benefit as cloud computing? Or have your institution do that? Sometimes yes!","title":"What is computing? Computing Vocabulary"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-major-components-of-computer","text":"li { font-size:1em; } User software (scripts, user code, etc) Base Software Operating System Input/Ouput (I/O) Central Processor (CPU) & Memory (RAM) Computer Architecture (model type) Storage - local disk Storage - external ( attached or via network ) Network","title":"About Computing: Major components of computer"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-what-is-a-server","text":"Cloud computing is all about \"servers,\" so we should define that. A server is any computer connected to a network, running software that listens for, and responsed to, messages - The 'server' is actually the software, not the hardware - The computer that runs the software is the 'host' - A 'client' is software sends the message, and receives and interprets the response. - the form the message can take is the API.","title":"About Computing: What is a server?"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-example-server-web-server","text":"client is the web browser message = URL which includes address, url paths, and additional parameters response = the code for the web page client interprets the code and renders the page. an alternate client could be a script, or the curl utility https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1","title":"About Computing: Example Server: Web server?"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-other-types-of-servers","text":"Database Client: special database client (not web browser) sends data commands as messages, response is tabular outputs File Servers Share files. We use Cloud file sync services, but Collaboration Email, calendaring etc Enterprise Data Systems for loading, cataloging, transforming business data Security Firewalls, Proxy, network traffic management Monitoring system health data collection, accessible via another web server Web-based services For example D2L.","title":"About Computing: Other Types of Servers"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-servers-and-networks","text":"Networking Requirements to access a server: the server must be on the same network as you to receive your message the more accessible the network, the more vulnerable, so partitioning is used servers that accept messages from the Internet are a major security risk network failure stops all work for everyone designing efficient, robust, and secure networks is a major resource drain","title":"About Computing: Servers and Networks"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#too-much-hardware-virtualization-to-the-rescue","text":"IT Departments 'serve' large user communities with large amounts of infrastructure, which is very in Techniques were invented to separate the 'server' or 'network' from the hardware. Virtualization: single box with a layer of software to share among different software. Software-defined networks: Many servers could be created and managed with software on a single hardware Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud. Networks followed suite with software to determine routes and paritioning on single physical layout","title":"Too much hardware? Virtualization to the rescue"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-2","text":"","title":"Part 2:"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#nature-of-cloud-computing","text":"","title":"Nature of Cloud Computing"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#some-motivation-at-amazoncom","text":"Massive IT infrastructure supports the Amazon store and company They wanted to sell shopping application as a service to a company like Target who didn't want to r-un their own store. T This required the software developers to have lots of flexible infrastructure (servers) to run on. They found team to build a service (with software) could spend 70% of their time setting up the 'back end' They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development. What they wanted in days actually took months. li { font-size:0.8em; }","title":"Some Motivation at Amazon.com"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#eureka-moment-for-amazon-we-could-sell-it","text":"Amazon automated their IT department so teams could order and provision the servers they needed on demand beyond just virtualization (\"everything was an API\") They got really good at running very large data centers for many customers as cheaply as possible and on-demand for Amazon.com and other stores and services. They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it. Their customers were other IT departments Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\"","title":"Eureka moment for Amazon: we could sell it"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#nist-defintion-of-cloud","text":"Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics On-demand self-service . Measured service : pay for what you get. Broad network access : accessible from the internet Rapid elasticity : no limits from a customer perspective. This word was invented by AWS Resource pooling : single resources serve many customers.","title":"NIST defintion of cloud"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-is-cloud-computing-cloud-concepts-vs-cloud-providers","text":"Three major cloud providers are in a constant arms race, literally ( Azure vs. Amazon competed for a $10B defense contract ): Azure, Amazon Web Services and Google Cloud Platform Offerings are very similar so all are great choices other options, smaller companies, open source options (used by Indiana University JetSteam HPC, Osiris project from MSU, UMich, Wayne State and IU. Cyverse for running jobs.","title":"What is Cloud Computing? Cloud concepts vs Cloud Providers"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#benefits-of-cloud-computing-for-research","text":"Customized Computing: can create customized resources only when you need it Elastic/On-demand: can run ad-hoc computations on those on-demand resources Instant service: Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others?","title":"Benefits of Cloud Computing for Research"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#benefits-of-cloud-for-research","text":"Restatement of goals of this fellowship: Learn which types of computing resources are beneficial to your research Learn how to use Cloud to create those resources Use the services packaged by cloud companies to discover new resources","title":"Benefits of Cloud for Research"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","text":"Training materials and documentation is written for IT professionals - Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. <!-- That can make it difficult to decipher which kind of cloud service will work best for your use case. - As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. - There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs.","title":"Learning how to learn about cloud"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","text":"There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster (U. Chicago) and Dennis Gannon (IU) , the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute, University of Washington. Unmaintained. source code https://cloudbank-project.github.io/cb-resources/ succesor to the cloudmaven? Cloudbank training videos","title":"What documentation is available for researchers?"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud-caveats-and-help","text":"As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those.","title":"Learning how to learn about cloud: Caveats and help"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#theme-using-workflow-and-computational-thinking","text":"Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research based on computing A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. . -Our first uses of cloud will use forms to create resources, but we encourage you to automation where possible","title":"Theme: Using workflow and computational thinking"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-cloud-security","text":"Security and Risk management are important issues even for researchers who's data are open - If your computer is a server , your responsibility just increased 100X: these are prime targets. Consider each component of a server to be a point of vulnerability. - Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security - We will cover methods to reduce security risks but it's important to consider the risk of hacking from the beginning","title":"About Cloud Security"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#hpcc-vs-cloud","text":"Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never). Especially windows-based software. I will cover some of these types of systems in future sessions","title":"HPCC vs Cloud"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","text":"It's widely recognized that AI is frequently bias. For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture, and background. System Engineering is it's own discipline and Cloud computing is arcane -our goal is to reduce conceptual barriers to using this technology","title":"Acknowledging bias in access to cloud computing across research cultures"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#discussion","text":"","title":"Discussion"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-3","text":"","title":"Part 3:"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#introduction-to-the-azure","text":"","title":"Introduction to the Azure"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#using-the-azure-portal","text":"","title":"using the Azure Portal"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-azure","text":"We have funding for using Azure cloud, and we have experience using Azure. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (using a gmail address or other non-MSU email address). Each participant has a budget for using Azure and a \"resource group\" to create resources","title":"About Azure"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-cloud-costs","text":"Cost management is a major hurdle for adopting CC (Almost) everything you do in Azure has a cost Costs often acrue over time, wether the resource is in use or not Deleting resources when are not using is a great way to reduce cost We want to encourage you to experiment! Using a very powerful machine for an hour may cost only $0.50 Just be aware that creating something and leaving it on will deplete your budget Solution: \"Budget Alerts\"","title":"About Cloud Costs"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#activity-using-the-azure-portal","text":"","title":"Activity : Using the Azure Portal"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#demonstration","text":"","title":"Demonstration"},{"location":"session_introduction/cost_alert/","text":"MSU Cloud Computing Fellowship: Session 1 Costs and Budgets with Microsoft Azure (Almost) everything you do in Azure has a cost, and costs for resources often acrue over time, wether the resource is in use or not. This is a short excercise to recieve an email when you have spent a certain amount of money. This can be valuable if you are experimenting and forget to delete a resource that you no longer need. For this work, You must first have a 'budget' in your resource group. We created a budget for 2022 for all fellowship participants that you can use for creating alerts. This does not explain any other aspect of Azure or the Azure portal. There are more materials for that in Session 2. If you get stuck, you may want to review those and come back. If at any point you have an issue, please contact us! Adding \"cost alert\" to your resource group. Log into https://portal.azure.com You should see a single resource group, or be put into one automatically. Open your resource group if is not already The left side bar had properties for the resource group. In the left side-bar, select \"budgets\" (scroll down) You should see a single budget named with the template \"ccf22_ _budget\" Click on that budget click 'edit budget' link near the top left review the information, then at the bottom, click 'next' We are now adding an 'alert' to that budget. Enter the following alert condition: type = Actual enter a percentage, say 50%. under action group, leave it as 'none' for email put your preferred email (I don't know if gmail etc will work) you can also add me if you like as a second email billspat@msu.edu select your preferred language, if it's available click 'Save' You may add additional alerts if you want to be reminded at different thresholds of spending, e.g. 25%, 50%, 80%. I hope these instructions were clear but again, any questions please contact us using email or MS Teams.","title":"MSU Cloud Computing Fellowship: Session 1"},{"location":"session_introduction/cost_alert/#msu-cloud-computing-fellowship-session-1","text":"","title":"MSU Cloud Computing Fellowship: Session 1"},{"location":"session_introduction/cost_alert/#costs-and-budgets-with-microsoft-azure","text":"(Almost) everything you do in Azure has a cost, and costs for resources often acrue over time, wether the resource is in use or not. This is a short excercise to recieve an email when you have spent a certain amount of money. This can be valuable if you are experimenting and forget to delete a resource that you no longer need. For this work, You must first have a 'budget' in your resource group. We created a budget for 2022 for all fellowship participants that you can use for creating alerts. This does not explain any other aspect of Azure or the Azure portal. There are more materials for that in Session 2. If you get stuck, you may want to review those and come back. If at any point you have an issue, please contact us!","title":"Costs and Budgets with Microsoft Azure"},{"location":"session_introduction/cost_alert/#adding-cost-alert-to-your-resource-group","text":"Log into https://portal.azure.com You should see a single resource group, or be put into one automatically. Open your resource group if is not already The left side bar had properties for the resource group. In the left side-bar, select \"budgets\" (scroll down) You should see a single budget named with the template \"ccf22_ _budget\" Click on that budget click 'edit budget' link near the top left review the information, then at the bottom, click 'next' We are now adding an 'alert' to that budget. Enter the following alert condition: type = Actual enter a percentage, say 50%. under action group, leave it as 'none' for email put your preferred email (I don't know if gmail etc will work) you can also add me if you like as a second email billspat@msu.edu select your preferred language, if it's available click 'Save' You may add additional alerts if you want to be reminded at different thresholds of spending, e.g. 25%, 50%, 80%. I hope these instructions were clear but again, any questions please contact us using email or MS Teams.","title":"Adding \"cost alert\" to your resource group."},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/","text":"li { font-size: 0.8em; } Introducing cloud computing for research Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship Patrick Bills, Michigan State University Part 1: what is computing You come to us with each a unique set of experiences with computing, with more or less experience depending on your previous needs. A challenge we have seen for the many years we've been helping people is understanding the context of computing in their research to understand the tools they have available Goal: help you connect cloud computing to your research in a meaningful way What is computing in Cloud Computing Part of this fellowship will be examining the 'computing' part of cloud computing. The application asks the question : \"How can cloud computing help your research?\" We may want to re-frame the question: \"What kinds of computing could help my research? How can cloud services support that kind of computing?\" What is computing in Cloud Computing Which is a reframing of first, understanding computational technology in general and cloud second. For example, while MSU provides email, storage, and high performance computing, it does not provide services for \"big data\" category, or relational databases for researchers. But you can provision such a service in minutes using the cloud. What is computing? Computing Vocabulary cloud computing is marketed to IT professionals and managers. They are who will make the recommendations for checks to be written. Cloud computing must tick their boxes. Services are organized and documented for them, not for us. while cloud computing abstracts away the physical components of a computer but companies use computing concepts as metaphors. see above. many of the capabilities that cloud computing offers could be done by purchasing computer hardware and software, setting it up and manageing it inside your lab. These concepts may help you What is computing: Major components of computer li { font-size:1em; } User software (scripts, user code, etc) Base Software Operating System Input/Ouput (I/O) Central Processor (CPU) & Memory (RAM) Computer Architecture (model type) Storage - local disk Storage - external ( attached or via network ) Network What is Computing: What is a server? The 'Client/server' model invented in the 60s is so successful that we use servers for our daily lives and don't think about it (except when the server is down). This model of computing is important because it's at the basis for of cloud computing. A server is any computer that is running software that listens for messages, and then responds. - The 'server' is actually the software - The computer that runs the software is the 'host' - A 'client' is software sends the message, and receives and interprets the response. - the form the message can take is the API. What is Computing: What is a Web server? client is the web browser message = URL which includes address, url paths, and additional parameters response = the code for the web page client interprets the code and renders the page. an alternate client could be a script, or the curl utility https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1 What is Computing: Data Server Example Client: special database client (not web browser) message : insert these 5 rows of data response: inserted 5 rows message: select rows of students in Math 101 response: data such as \"First Name\",\"Last Name\",\"Email\",\"Level\" \"Lucy\",\"Grant\",\"l.grant@randatmail.com\",\"7\" \"Emily\",\"Russell\",\"e.russell@randatmail.com\",\"5\" \"Annabella\",\"Ferguson\",\"a.ferguson@randatmail.com\",\"8\" etc What is computing: Major components of server computer The components are nearly the same as a personal computer Server Software set to listen on network (remote management systems) Operating System (hardened for security) Central Processor (CPU) & Memory (RAM) (large) Computer Architecture (designed for high availability) Storage - local disk (designed for high availability) Storage - external ( attached or via network ) Network (high-speed) Computing Concept: Virtualization Given the strain on IT Departments to provide servers dynamically and the time to provision the hardware to do so, and the fact that many servers are idle much of the time. A technique of hosting multiple software servers on a single hardware unit was invented. 1 server = 1 box : too many boxes many virtual servers = 1 box: more efficient use of hardware Servers could be provisioned automatically! Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud. What is Computing: Servers and Networks Networking Requirements to access a server: the server must be on the same network as you to receive your message some networks block some traffic (for security) servers that accept messages from the Internet are a major security risk network failure stops all work for everyone IT spend a lot of time designing efficient, robust, and secure networks Computing Concept: Software-defined networks A server on a network accessible to possible hackers is increases security vulnerability Data networks can be designed to partition servers so only accessibles from some locations, or with credentials, or with a single point of entry e.g. gateway) In 1990s nnetwork systems configurable by software Like virtual machines, system architecture could be flexibly changes with software. What is Cloud Computing? History Amazon want to provide their store as a service to a company like Target who didn't want to run their own store. They found it very difficult to re-organize their IT infrastructure, and be flexible. In a start-up (or a research group!) A software team could spend 70% of their time setting up the 'back end' It took months to get the infrastructure in place. They ran massive data centers and need to automate. li { font-size:0.8em; } What is Cloud Computing? History The IT department at Amazon was tasked with rapidly responding to any need the Amzon store developers needed to build new features immeidately They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development. Teams could order and provision the IT servers they needed via the web forms and did not need to burden the IT staff, individual teams in IT worked with each others services with APIs. They were great a running very large data centers for many customers as cheaply as possible. And not just for Amazon.com but other stores li { font-size:0.8em; } What is Cloud Computing? History Amazon IT configured all of their components to communicate with software APIs, very novel at the time, and used software to make it super efficient to configure all the hardware, at a massive scale They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it. Their original and main customers are IT departments of organizations. Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\" What is Cloud Computing? NIST defintion of cloud Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics On-demand self-service . Measured service : pay for what you get. Broad network access : accessible from the internet Rapid elasticity : no limits from a customer perspective. This word was invented by AWS Resource pooling : single resources serve many customers. Other Web-based services that are not cloud computing Web hosting Focused on providing offered many of these features but was limited in service offerings. I've used a company called dreamhost since early 2000 to provide websites for non-profits and commercial customers, but also email and storage and limited database services. Co-location Bring your own hardware, eg. Data Center only Server Rental Servers on the internet you could use for various things, primarily web sites & applications. (Rackspace) Other remote computing services example sending your accounting data to an external service for processing (which now seems quaint). EDS from the 80s 90s by Ross Perot provided IT and Data services to major corporations primarily GM. What is Cloud Computing? Cloud concepts vs Cloud Providers Three major cloud providers are in a constant arms race to capture the large contracts (e.g. Azure vs. Amazon competed for a $10B defense contract ): Azure, Amazon Web Services and Google Cloud Platform Offerings are very similar so all are great choices Many others provide Cloud : Oracle, IBM, Salesforce, Thousands of companies of specialized services to support the major vendors (e.g. for billing, management, security, etc) There is an open source version of cloud computing called \"OpenStack\" used by universities to build their own private or non-profit clouds. MSU/UMich uses that for the Osiris project. Indiana University uses it for their machine called \" JetSteam \" li { font-size: 0.75em; } Service-level Model of Cloud Computing Again, from the the NIST definition of cloud computing a perspective based on levels of service and responsibility of the consumer: Infrastructure as a service: Replacement for hardware but perhaps not software levels. This is often compared to making a data center and uses many of the terms. You need understanding of computing architecture as these services Platform as a service : Everything in between: pre-configured and managed infrastructure Software as a service : Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive Service-level Model of Cloud Computing \"service levels\" are only a model (or abstraction) for discussion cloud computing, widely used in the IT fields. \"X as a service\" where X is some aspect of IT, usually along the axis of customer responsibility. the model is abused like all concepts or acronyms in IT: How well does this model apply to the services that cloud providers give us? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Service-level Model of Cloud Computing Food Analogy Compare : - Restaurant vs Box Prepared food vs. Cooking from scratch vs. Farming - Google Search vs Google Docs vs Google Cloud Platform to push the analogy further, what would a growing supply company provide to a farmer vs a gardener? As we begin, we are gardners, not farmers and hence the cloud companies may not cater to us. We want 1 shovel, not dozens, or a huge tractor. Service-level model of Cloud Computing For many cases, the \"plaform\" is the sweet-spot for researchers do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. NIST Service-level model and Responsibility The \"Shared responsibility\" * model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security Cloud \"Services\" and the Packaging of Open Source Systems Like the concept that cloud simply makes creating servers easier, cloud goes a step further and packages servers+software and calls that a service. Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper Cloud \"Services\" and the Packaging of Open Source Systems Could you run this yourself? You would need: network (from university = free) (with opening in firewall) hardware (any old PC will do, so say 'free') software (free) install, configuration, understanding (not free!) keeping hackers away (not free!!!) keeping it updates, fixing hardware, helping others (not free) Cloud \"Services\" and the Packaging of Open Source Systems Compare cost of DIY with cloud service: provisioning and using a server in minutes on cloud (not free) cloud company provides configuration, security, and hardware maintance (not free) time to write your manuscript instead of spending on time on your MySQL server ( priceless ) Cloud \"Services\" and the Packaging of Open Source Systems What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ? How about a SaaS Map and Geospatial Processing system? Google Earth Engine or ESRI story maps In General Before you reach for the Cloud legos, look to see if there is a SaaS solution for your problem For this fellowship, using a SaaS is not the goal of the projects, but to strech and try using Cloud in order to learn it Cloud for Research What are the benefits from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others? Learning how to learn about cloud Training materials and documentation is written for IT professionals - Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. <!-- That can make it difficult to decipher which kind of cloud service will work best for your use case. - As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. - There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. What documentation is available for researchers? There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos Learning how to learn about cloud: Caveats and help As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need. --> About Cloud Security Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security. If your computer is a server , your responsibility just increased 100X as these are primary targets for hacking. Consider each component of a server to be a point of vulnerability. We will come back to this model as we gain deeper understanding of research computing on the cloud. Costs and Budget overview Each participant has a budget for their Azure resources. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk HPCC vs Cloud Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit Big Data systems Long-running Data Systems like database servers Web-based applications Windows Systems with complex or specific configuration needs Acknowledging bias in access to cloud computing across research cultures It's widely recognized that AI is frequently bias. For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture and our goal is to reduce conceptual barriers to using this technology Additional comments from instructors and organizers Source Materials https://softwaresim.com/blog/introduction-to-cloud-computing-for-research/","title":"Lecture introduction to cloud computing research"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#introducing-cloud-computing-for-research","text":"","title":"Introducing cloud computing for research"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-using-microsoft-azure-for-the-msu-cloud-computing-fellowship","text":"Patrick Bills, Michigan State University","title":"Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#part-1-what-is-computing","text":"You come to us with each a unique set of experiences with computing, with more or less experience depending on your previous needs. A challenge we have seen for the many years we've been helping people is understanding the context of computing in their research to understand the tools they have available Goal: help you connect cloud computing to your research in a meaningful way","title":"Part 1: what is computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-in-cloud-computing","text":"Part of this fellowship will be examining the 'computing' part of cloud computing. The application asks the question : \"How can cloud computing help your research?\" We may want to re-frame the question: \"What kinds of computing could help my research? How can cloud services support that kind of computing?\"","title":"What is computing in Cloud Computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-in-cloud-computing_1","text":"Which is a reframing of first, understanding computational technology in general and cloud second. For example, while MSU provides email, storage, and high performance computing, it does not provide services for \"big data\" category, or relational databases for researchers. But you can provision such a service in minutes using the cloud.","title":"What is computing in Cloud Computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-computing-vocabulary","text":"cloud computing is marketed to IT professionals and managers. They are who will make the recommendations for checks to be written. Cloud computing must tick their boxes. Services are organized and documented for them, not for us. while cloud computing abstracts away the physical components of a computer but companies use computing concepts as metaphors. see above. many of the capabilities that cloud computing offers could be done by purchasing computer hardware and software, setting it up and manageing it inside your lab. These concepts may help you","title":"What is computing? Computing Vocabulary"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-major-components-of-computer","text":"li { font-size:1em; } User software (scripts, user code, etc) Base Software Operating System Input/Ouput (I/O) Central Processor (CPU) & Memory (RAM) Computer Architecture (model type) Storage - local disk Storage - external ( attached or via network ) Network","title":"What is computing: Major components of computer"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-what-is-a-server","text":"The 'Client/server' model invented in the 60s is so successful that we use servers for our daily lives and don't think about it (except when the server is down). This model of computing is important because it's at the basis for of cloud computing. A server is any computer that is running software that listens for messages, and then responds. - The 'server' is actually the software - The computer that runs the software is the 'host' - A 'client' is software sends the message, and receives and interprets the response. - the form the message can take is the API.","title":"What is Computing: What is a server?"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-what-is-a-web-server","text":"client is the web browser message = URL which includes address, url paths, and additional parameters response = the code for the web page client interprets the code and renders the page. an alternate client could be a script, or the curl utility https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1","title":"What is Computing: What is a Web server?"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-data-server-example","text":"Client: special database client (not web browser) message : insert these 5 rows of data response: inserted 5 rows message: select rows of students in Math 101 response: data such as \"First Name\",\"Last Name\",\"Email\",\"Level\" \"Lucy\",\"Grant\",\"l.grant@randatmail.com\",\"7\" \"Emily\",\"Russell\",\"e.russell@randatmail.com\",\"5\" \"Annabella\",\"Ferguson\",\"a.ferguson@randatmail.com\",\"8\" etc","title":"What is Computing: Data Server Example"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-major-components-of-server-computer","text":"The components are nearly the same as a personal computer Server Software set to listen on network (remote management systems) Operating System (hardened for security) Central Processor (CPU) & Memory (RAM) (large) Computer Architecture (designed for high availability) Storage - local disk (designed for high availability) Storage - external ( attached or via network ) Network (high-speed)","title":"What is computing: Major components of server computer"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#computing-concept-virtualization","text":"Given the strain on IT Departments to provide servers dynamically and the time to provision the hardware to do so, and the fact that many servers are idle much of the time. A technique of hosting multiple software servers on a single hardware unit was invented. 1 server = 1 box : too many boxes many virtual servers = 1 box: more efficient use of hardware Servers could be provisioned automatically! Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud.","title":"Computing Concept: Virtualization"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-servers-and-networks","text":"Networking Requirements to access a server: the server must be on the same network as you to receive your message some networks block some traffic (for security) servers that accept messages from the Internet are a major security risk network failure stops all work for everyone IT spend a lot of time designing efficient, robust, and secure networks","title":"What is Computing: Servers and Networks"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#computing-concept-software-defined-networks","text":"A server on a network accessible to possible hackers is increases security vulnerability Data networks can be designed to partition servers so only accessibles from some locations, or with credentials, or with a single point of entry e.g. gateway) In 1990s nnetwork systems configurable by software Like virtual machines, system architecture could be flexibly changes with software.","title":"Computing Concept: Software-defined networks"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history","text":"Amazon want to provide their store as a service to a company like Target who didn't want to run their own store. They found it very difficult to re-organize their IT infrastructure, and be flexible. In a start-up (or a research group!) A software team could spend 70% of their time setting up the 'back end' It took months to get the infrastructure in place. They ran massive data centers and need to automate. li { font-size:0.8em; }","title":"What is Cloud Computing? History"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history_1","text":"The IT department at Amazon was tasked with rapidly responding to any need the Amzon store developers needed to build new features immeidately They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development. Teams could order and provision the IT servers they needed via the web forms and did not need to burden the IT staff, individual teams in IT worked with each others services with APIs. They were great a running very large data centers for many customers as cheaply as possible. And not just for Amazon.com but other stores li { font-size:0.8em; }","title":"What is Cloud Computing? History"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history_2","text":"Amazon IT configured all of their components to communicate with software APIs, very novel at the time, and used software to make it super efficient to configure all the hardware, at a massive scale They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it. Their original and main customers are IT departments of organizations. Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\"","title":"What is Cloud Computing? History"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-nist-defintion-of-cloud","text":"Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics On-demand self-service . Measured service : pay for what you get. Broad network access : accessible from the internet Rapid elasticity : no limits from a customer perspective. This word was invented by AWS Resource pooling : single resources serve many customers.","title":"What is Cloud Computing? NIST defintion of cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#other-web-based-services-that-are-not-cloud-computing","text":"Web hosting Focused on providing offered many of these features but was limited in service offerings. I've used a company called dreamhost since early 2000 to provide websites for non-profits and commercial customers, but also email and storage and limited database services. Co-location Bring your own hardware, eg. Data Center only Server Rental Servers on the internet you could use for various things, primarily web sites & applications. (Rackspace) Other remote computing services example sending your accounting data to an external service for processing (which now seems quaint). EDS from the 80s 90s by Ross Perot provided IT and Data services to major corporations primarily GM.","title":"Other Web-based services that are not cloud computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-cloud-concepts-vs-cloud-providers","text":"Three major cloud providers are in a constant arms race to capture the large contracts (e.g. Azure vs. Amazon competed for a $10B defense contract ): Azure, Amazon Web Services and Google Cloud Platform Offerings are very similar so all are great choices Many others provide Cloud : Oracle, IBM, Salesforce, Thousands of companies of specialized services to support the major vendors (e.g. for billing, management, security, etc) There is an open source version of cloud computing called \"OpenStack\" used by universities to build their own private or non-profit clouds. MSU/UMich uses that for the Osiris project. Indiana University uses it for their machine called \" JetSteam \" li { font-size: 0.75em; }","title":"What is Cloud Computing? Cloud concepts vs Cloud Providers"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing","text":"Again, from the the NIST definition of cloud computing a perspective based on levels of service and responsibility of the consumer: Infrastructure as a service: Replacement for hardware but perhaps not software levels. This is often compared to making a data center and uses many of the terms. You need understanding of computing architecture as these services Platform as a service : Everything in between: pre-configured and managed infrastructure Software as a service : Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive","title":"Service-level Model of Cloud Computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing_1","text":"\"service levels\" are only a model (or abstraction) for discussion cloud computing, widely used in the IT fields. \"X as a service\" where X is some aspect of IT, usually along the axis of customer responsibility. the model is abused like all concepts or acronyms in IT: How well does this model apply to the services that cloud providers give us? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum","title":"Service-level Model of Cloud Computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing-food-analogy","text":"Compare : - Restaurant vs Box Prepared food vs. Cooking from scratch vs. Farming - Google Search vs Google Docs vs Google Cloud Platform to push the analogy further, what would a growing supply company provide to a farmer vs a gardener? As we begin, we are gardners, not farmers and hence the cloud companies may not cater to us. We want 1 shovel, not dozens, or a huge tractor.","title":"Service-level Model of Cloud Computing Food Analogy"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing_2","text":"For many cases, the \"plaform\" is the sweet-spot for researchers do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls.","title":"Service-level model of Cloud Computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#nist-service-level-model-and-responsibility","text":"The \"Shared responsibility\" * model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security","title":"NIST Service-level model and Responsibility"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems","text":"Like the concept that cloud simply makes creating servers easier, cloud goes a step further and packages servers+software and calls that a service. Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_1","text":"Could you run this yourself? You would need: network (from university = free) (with opening in firewall) hardware (any old PC will do, so say 'free') software (free) install, configuration, understanding (not free!) keeping hackers away (not free!!!) keeping it updates, fixing hardware, helping others (not free)","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_2","text":"Compare cost of DIY with cloud service: provisioning and using a server in minutes on cloud (not free) cloud company provides configuration, security, and hardware maintance (not free) time to write your manuscript instead of spending on time on your MySQL server ( priceless )","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_3","text":"What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ? How about a SaaS Map and Geospatial Processing system? Google Earth Engine or ESRI story maps In General Before you reach for the Cloud legos, look to see if there is a SaaS solution for your problem For this fellowship, using a SaaS is not the goal of the projects, but to strech and try using Cloud in order to learn it","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-for-research","text":"What are the benefits from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others?","title":"Cloud for Research"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","text":"Training materials and documentation is written for IT professionals - Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. <!-- That can make it difficult to decipher which kind of cloud service will work best for your use case. - As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. - There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs.","title":"Learning how to learn about cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","text":"There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos","title":"What documentation is available for researchers?"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud-caveats-and-help","text":"As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need. -->","title":"Learning how to learn about cloud: Caveats and help"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#about-cloud-security","text":"Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security. If your computer is a server , your responsibility just increased 100X as these are primary targets for hacking. Consider each component of a server to be a point of vulnerability. We will come back to this model as we gain deeper understanding of research computing on the cloud.","title":"About Cloud Security"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#costs-and-budget-overview","text":"Each participant has a budget for their Azure resources. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk","title":"Costs and Budget overview"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#hpcc-vs-cloud","text":"Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit Big Data systems Long-running Data Systems like database servers Web-based applications Windows Systems with complex or specific configuration needs","title":"HPCC vs Cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","text":"It's widely recognized that AI is frequently bias. For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture and our goal is to reduce conceptual barriers to using this technology","title":"Acknowledging bias in access to cloud computing across research cultures"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#additional-comments-from-instructors-and-organizers","text":"","title":"Additional comments from instructors and organizers"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#source-materials","text":"https://softwaresim.com/blog/introduction-to-cloud-computing-for-research/","title":"Source Materials"},{"location":"session_organization/","text":"Special Session: Cloud Services Organization Goals We hope to provide you with the following understanding of: what are the \"service levels\" and the related responsibilities for different kinds of cloud resources, and how does that help you choose a service what options for interacting with cloud services Understand difference between the cloud manager and resource you've created Know how to use program to automate the creation and deletion of cloud resources How to find basic cost estimates Introduction We might think of using cloud computing in 3 areas: using the resources (which is our real goal), definining and creating these resources, and manageing them. We may need a virtual machine to run our program to calculate or analyze our data, but we need to determine the properties of that virtual machine and create it first. Surrounding all of that is how we interact with the cloud service to do that, how we estimate and observe the costs, manage and identify all the other components a cloud VM needs, and make it as secure as possible. I'm lumping all of these last pieces into 'managing' cloud resources. It may be the most boring of all the topics. The concepts may cover any resource you create in the cloud, and in general apply to all cloud service providers. However the details of how you do it are very specific to each cloud vendor. In fact the methods may be convoluted or less than straightforward, so there are many companies that provide additional tools just to manage cloud resources in a more consistent or easier way than the cloud providers allow you Service Level Model of Cloud The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researchers who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. Cloud \"Services\" and the Packaging of Open Source Systems Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for your research look like? A \"Google Docs\" for your databases? How about a \"PasS\" that you could build? Would it be reproducible by anyone doing the kind of research you do? Costs Review: About Cloud Costs Interfaces In session one we talked about the client/server model of computing which is so ubiquotous is seems like the only model of computing. The core of the cloud model is that \"everything has an API\" or Application Programming Interface: the commands that can be used for code-to-code interaction. Reading: Interfacing with Cloud Services About the Microsoft Resource Manager: https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/overview Acivity: Create a Linux virtual machine with the Azure Command Line Interface ( CLI) Note the \"Interface\" is for interacting with Azure to manage resources. The resources them selves will have their OWN interface. Moving Data Moving Data in the cloud Staying Organized in Azure You've seen that using the web portal to create a virtual machine creats a dozen resources. Then you may have other resources (e.g. a storage account) you want to connect to them. How do you keep them all straight? Naming things Microsoft suggestion for creating names: https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming Why do names have an \"Environment\" element? IT professionals tend to think of the world in two ways: the stuff I'm doing to try things, and the stuff I've done that now the world can use. That's because once a system is open or connected to a public interface, they have to keep it running. Some use the term \"production\" or in-production. development (dev): in progress experimental versions, never intended for public use, strictly for our use test: optional state, the system is as close to finished as possible and given to staff to do formal testing to ensure it's ready for publication production (prod): final version released to the public optional \"preview\" or \"beta\" : companies use this to get themselves off the hook. It's not really done and they may just remove the service, no guarantees. A production environment is deploying resources so that they are unchanged, stable and don't have down time. A \"site reliability engineer\" (SRE) is paid to avoid downtime. Why do they call out 'region' in this naming scheme? For global web companies, they may deploy duplicate resources in many regions. In addition resources that interaction should be in the same region, e.g. a storage acccount and a VM that uses it should be in the same region to keep the connection fast. using Azure 'Tags' Optional: Short note about Using Azure Tags for Organization ( Pat Bills, MSU) \"Use tags to organize your Azure resources and management hierarchy\" from Microsoft Microsoft suggested naming scheme for Azure resources Monitoring You want to keep an eye on the resources you create: how healthy are they, are they performing as expected? Is there some problem that makes them slow or unresponsive? This is especially true of servers, created by IT staff, that others are using that need to stay up and running. For us as researchers creating resources to do our calculations, we want to know how long it's taking and hence how much will it cost? Do we need to add more power to get it to work? This is an esoteric topic and is really specific to each type of service, but it's something to consider as 1) you may need to engage in a resource outside of the azure portal (e.g. in a VM, log-in and check the performance with standard tools like 'top' in Linux and the task manger in Windows) 2) create (and pay for!) yet another cloud resource for collective and 'managed' monitoring. Why use cloud monitoring at all? If you were running a bunch of your own computers in your lab, you would just sit down and check on them using tools the operating system provided. In many systems you open and read the 'logs' or text files with a stream of the events and times they occured. Machines in the cloud provide new challenges. An obvious one is to be able to see statistics for many resources at once. How then does Azure collect data from each machine into central place and then let you browse it? A second challenge is, what happens to that information for a virtual machine that has crashed and is unresponsive, or has been intentionally turned off and deleted? Monitoring Examples For Azure virtual machines, Azure offers \"Azure Monitor\" . Using it is completely optional and I don't have activities related to this service. If for your project you are working with a group of VM's, you are interested in performance, or you need performance information because your analysis is not completing then I would investigate this service.","title":"Cloud Services Organization"},{"location":"session_organization/#special-session-cloud-services-organization","text":"","title":"Special Session: Cloud Services Organization"},{"location":"session_organization/#goals","text":"We hope to provide you with the following understanding of: what are the \"service levels\" and the related responsibilities for different kinds of cloud resources, and how does that help you choose a service what options for interacting with cloud services Understand difference between the cloud manager and resource you've created Know how to use program to automate the creation and deletion of cloud resources How to find basic cost estimates","title":"Goals"},{"location":"session_organization/#introduction","text":"We might think of using cloud computing in 3 areas: using the resources (which is our real goal), definining and creating these resources, and manageing them. We may need a virtual machine to run our program to calculate or analyze our data, but we need to determine the properties of that virtual machine and create it first. Surrounding all of that is how we interact with the cloud service to do that, how we estimate and observe the costs, manage and identify all the other components a cloud VM needs, and make it as secure as possible. I'm lumping all of these last pieces into 'managing' cloud resources. It may be the most boring of all the topics. The concepts may cover any resource you create in the cloud, and in general apply to all cloud service providers. However the details of how you do it are very specific to each cloud vendor. In fact the methods may be convoluted or less than straightforward, so there are many companies that provide additional tools just to manage cloud resources in a more consistent or easier way than the cloud providers allow you","title":"Introduction"},{"location":"session_organization/#service-level-model-of-cloud","text":"The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researchers who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls.","title":"Service Level Model of Cloud"},{"location":"session_organization/#cloud-services-and-the-packaging-of-open-source-systems","text":"Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for your research look like? A \"Google Docs\" for your databases? How about a \"PasS\" that you could build? Would it be reproducible by anyone doing the kind of research you do?","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_organization/#costs","text":"Review: About Cloud Costs","title":"Costs"},{"location":"session_organization/#interfaces","text":"In session one we talked about the client/server model of computing which is so ubiquotous is seems like the only model of computing. The core of the cloud model is that \"everything has an API\" or Application Programming Interface: the commands that can be used for code-to-code interaction. Reading: Interfacing with Cloud Services About the Microsoft Resource Manager: https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/overview Acivity: Create a Linux virtual machine with the Azure Command Line Interface ( CLI) Note the \"Interface\" is for interacting with Azure to manage resources. The resources them selves will have their OWN interface.","title":"Interfaces"},{"location":"session_organization/#moving-data","text":"Moving Data in the cloud","title":"Moving Data"},{"location":"session_organization/#staying-organized-in-azure","text":"You've seen that using the web portal to create a virtual machine creats a dozen resources. Then you may have other resources (e.g. a storage account) you want to connect to them. How do you keep them all straight?","title":"Staying Organized in Azure"},{"location":"session_organization/#naming-things","text":"Microsoft suggestion for creating names: https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming Why do names have an \"Environment\" element? IT professionals tend to think of the world in two ways: the stuff I'm doing to try things, and the stuff I've done that now the world can use. That's because once a system is open or connected to a public interface, they have to keep it running. Some use the term \"production\" or in-production. development (dev): in progress experimental versions, never intended for public use, strictly for our use test: optional state, the system is as close to finished as possible and given to staff to do formal testing to ensure it's ready for publication production (prod): final version released to the public optional \"preview\" or \"beta\" : companies use this to get themselves off the hook. It's not really done and they may just remove the service, no guarantees. A production environment is deploying resources so that they are unchanged, stable and don't have down time. A \"site reliability engineer\" (SRE) is paid to avoid downtime. Why do they call out 'region' in this naming scheme? For global web companies, they may deploy duplicate resources in many regions. In addition resources that interaction should be in the same region, e.g. a storage acccount and a VM that uses it should be in the same region to keep the connection fast. using Azure 'Tags' Optional: Short note about Using Azure Tags for Organization ( Pat Bills, MSU) \"Use tags to organize your Azure resources and management hierarchy\" from Microsoft Microsoft suggested naming scheme for Azure resources","title":"Naming things"},{"location":"session_organization/#monitoring","text":"You want to keep an eye on the resources you create: how healthy are they, are they performing as expected? Is there some problem that makes them slow or unresponsive? This is especially true of servers, created by IT staff, that others are using that need to stay up and running. For us as researchers creating resources to do our calculations, we want to know how long it's taking and hence how much will it cost? Do we need to add more power to get it to work? This is an esoteric topic and is really specific to each type of service, but it's something to consider as 1) you may need to engage in a resource outside of the azure portal (e.g. in a VM, log-in and check the performance with standard tools like 'top' in Linux and the task manger in Windows) 2) create (and pay for!) yet another cloud resource for collective and 'managed' monitoring. Why use cloud monitoring at all? If you were running a bunch of your own computers in your lab, you would just sit down and check on them using tools the operating system provided. In many systems you open and read the 'logs' or text files with a stream of the events and times they occured. Machines in the cloud provide new challenges. An obvious one is to be able to see statistics for many resources at once. How then does Azure collect data from each machine into central place and then let you browse it? A second challenge is, what happens to that information for a virtual machine that has crashed and is unresponsive, or has been intentionally turned off and deleted?","title":"Monitoring"},{"location":"session_organization/#monitoring-examples","text":"For Azure virtual machines, Azure offers \"Azure Monitor\" . Using it is completely optional and I don't have activities related to this service. If for your project you are working with a group of VM's, you are interested in performance, or you need performance information because your analysis is not completing then I would investigate this service.","title":"Monitoring Examples"},{"location":"session_organization/azure_tags/","text":"Using Tags to organize resources in Azure Tags are notes to yourself about the resource, use them for metadata. As the number of cloud resources blossom (e.g. cloud sprawl) it can be important to find related resources quickly. The azure portal has a way to see resource within and across resource groups using different filtering methods. One of those is the with resource meta-data, and you can add meta data using 'tags.' In my group we always have a tag with the key \"created by\" and value the netid of the creator. This may be redundant here becuase all the resources you create will be a in resource group with your NetID already in it, but add this for practice. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. For now you have only one resource group, but tags are also used to find things across different resource groups, e.g. if by project name. Tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work. Example usage: When creating resources using the wizard, many resources are created at once. For example creating a virtual machine may create 12 resources. Adding a tagl to ID those resources together can really help to delet them. use the Portal to create a test virtual machine (VM), which creates 12 resources add a unique tag to those during the VM creation process, e.g. tag \"id\" = \"test VM Oct 1\" when you later need to delete the VM becuase you are done with it, or it wasn't what you needed, you can filter resources in your group on this this so you can select those 12 resources, and not any others, without having to hunt for them by name.","title":"Azure tags"},{"location":"session_organization/azure_tags/#using-tags-to-organize-resources-in-azure","text":"Tags are notes to yourself about the resource, use them for metadata. As the number of cloud resources blossom (e.g. cloud sprawl) it can be important to find related resources quickly. The azure portal has a way to see resource within and across resource groups using different filtering methods. One of those is the with resource meta-data, and you can add meta data using 'tags.' In my group we always have a tag with the key \"created by\" and value the netid of the creator. This may be redundant here becuase all the resources you create will be a in resource group with your NetID already in it, but add this for practice. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. For now you have only one resource group, but tags are also used to find things across different resource groups, e.g. if by project name. Tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work.","title":"Using Tags to organize resources in Azure"},{"location":"session_organization/azure_tags/#example-usage","text":"When creating resources using the wizard, many resources are created at once. For example creating a virtual machine may create 12 resources. Adding a tagl to ID those resources together can really help to delet them. use the Portal to create a test virtual machine (VM), which creates 12 resources add a unique tag to those during the VM creation process, e.g. tag \"id\" = \"test VM Oct 1\" when you later need to delete the VM becuase you are done with it, or it wasn't what you needed, you can filter resources in your group on this this so you can select those 12 resources, and not any others, without having to hunt for them by name.","title":"Example usage:"},{"location":"session_organization/exercise_vm_via_cli/","text":"CLI Interface Tutorial / Exercise MSU Cloud Computing Fellowship, Pat Bills, IT Services This tutorial walks through using the CLI with code you can copy, modify and try. This will run in the Azure portal \"cloud shell\" if you have set it up to use the CLI interface (not the PowerShell interface) You can refer to the original tutorial which is perhaps more clear, but doesn't quite fit our situation : Quickstart: Create a Linux virtual machine with the Azure CLI If you follow this - please don't delete your resource group! In the code below, lines that start with # are comments only, but the other lines are commands. You can copy/paste one command at at time into the CLI of the cloud shell. Since these are long commands, a long command can be broken up using the line-continuation character which is the back-slash \\ so one command are all the lines until the last one that does not end with a back-slash First, Launch Azure Cloud Shell The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account. To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also open Cloud Shell in a separate browser tab by going to https://shell.azure.com/bash . Select Copy to copy the blocks of code, paste it into the Cloud Shell, and select Enter to run it. Try running the following commands # create a VM and all of the items needed for it : OS Disk, network security group, etc. # replace the names with your own group and other names. # Remember to change the group and VM name az vm create \\ --resource-group mygroupname \\ --name mytestvm \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username azureuser \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys Here is a real example command for my own resource group: az vm create \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --image Debian \\ --public-ip-sku Standard --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys The output will look something like this: { \"fqdns\": \"\", \"id\": \"/subscriptions/047e742e-cb26-41e6-a9d6-9d42c67f43e6/resourceGroups/ccf22_billspat/providers/Microsoft.Compute/virtualMachines/billspat-tutorial-vm\", \"location\": \"northcentralus\", \"macAddress\": \"00-22-48-8F-48-C2\", \"powerState\": \"VM running\", \"privateIpAddress\": \"10.4.0.5\", \"publicIpAddress\": \"20.236.78.140\", \"resourceGroup\": \"ccf22_billspat\", \"zones\": \"\" } Copy and paste that somewhere for reference last. Now give that VM a purpose and install a web server . There are many webserver that you can install, but nginx is easy to install and open source. You can do this in two ways 1) use the CLI to run a command on the VM directly az vm run-command invoke \\ --resource-group mygroupname \\ --name mytestvm \\ --command-id RunShellScript \\ --scripts \"sudo apt-get update && sudo apt-get install -y nginx\" 2) use SSH to connect to the VM and run it directly. that will be for another tutorial! The output from the command above will be something like { \"value\" : [ { \"code\" : \"ProvisioningState/succeeded\" , \"displayStatus\" : \"Provisioning succeeded\" , \"level\" : \"Info\" , \"message\" : \"Enable succeeded: \\n[stdout]\\ne libnginx-mod-http-xslt-filter.\\r\\nPreparing to unpack .../23-libnginx-mod-http-xslt-filter_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-http-xslt-filter (1.14.2-2+deb10u4) ...\\r\\nSelecting previously unselected package libnginx-mod-mail.\\r\\nPreparing to unpack .../24-libnginx-mod-mail_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-mail (1.14.2-2+deb10u4) ...\\r\\nSelect etc Open port 80 for web traffic By default, only SSH connections are opened when you create a Linux VM in Azure. Use az vm open-port to open TCP port 80 for use with the NGINX web server: az vm open-port --port 80 --resource-group mygroupname --name mytestvm check that it's working Put the IP address from the output above (or use the portal to find it) into your browser to see if you can connect,. If so, then great! you've just built a web server. Delete everything You can't delete your how resource group, but luckily we used tags to create the VM so we can just delete resource by tag. You can use the portal to delete these resources, but if here are commands to do it with the CLI. You can delete things by name, like this az vm delete \\ --resource-group mygroup \\ --name myvm but every resource has a unique ID, and can be deteled using that ID with the command az resource delete --ids IDVALUE You can get those IDs using az resource list... # list all resources just created (change the tag to match what you used if necessary) az resource list --tag activity = cli_tutorial # The CLI can filter and change the format of it's output # list ONLY the resource IDs using the \"query\" and tabular output az resource list --tag activity = cli_tutorial --query \"[].id\" -o table # delete them all using a shell loop (tsv does not output a header line) IDS = $( az resource list --tag activity = cli_tutorial --query \"[].id\" -o tsv ) for id in $IDS ; do az resource delete --ids $id ; done Complete example commands (using my resource group) az vm create \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys # copy and paste the output of that az vm run-command invoke \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --command-id RunShellScript \\ --scripts \"sudo apt-get update && sudo apt-get install -y nginx\" az vm open-port --port 80 --resource-group ccf22_billspat --name billspat-tutorial-vm # list all resources just created az resource list --tag activity = cli_tutorial # list ONLY the resource IDs using the \"query\" and tabular output az resource list --tag activity = cli_tutorial --query \"[].id\" -o table # delete them all using a shell loop (tsv does not output a header line) IDS = $( az resource list --tag activity = cli_tutorial --query \"[].id\" -o tsv ) for id in $IDS ; do az resource delete --ids $id ; done bonus points : set shell variables for the resource group and name and use them in the commands. For example RG = ccf22_billspat VMNAME = billspat-tutorial-vm az vm create \\ --resource-group $RG \\ --name $VMNAME \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys # ... do other stuff, then delete az vm delete \\ --resource-group $RG \\ --name $VMNAME References: Quickstart: Create a Linux virtual machine with the Azure CLI https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-cli Azure Command-Line Interface (CLI) documentation https://learn.microsoft.com/en-us/cli/azure/ All az vm... command options : https://learn.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest Use tags to organize your Azure resources (with the Azure CLI)! https://techcommunity.microsoft.com/t5/azure/use-tags-to-organize-your-azure-resources-with-the-azure-cli/m-p/1798955","title":"Exercise vm via cli"},{"location":"session_organization/exercise_vm_via_cli/#cli-interface-tutorial-exercise","text":"MSU Cloud Computing Fellowship, Pat Bills, IT Services This tutorial walks through using the CLI with code you can copy, modify and try. This will run in the Azure portal \"cloud shell\" if you have set it up to use the CLI interface (not the PowerShell interface) You can refer to the original tutorial which is perhaps more clear, but doesn't quite fit our situation : Quickstart: Create a Linux virtual machine with the Azure CLI If you follow this - please don't delete your resource group! In the code below, lines that start with # are comments only, but the other lines are commands. You can copy/paste one command at at time into the CLI of the cloud shell. Since these are long commands, a long command can be broken up using the line-continuation character which is the back-slash \\ so one command are all the lines until the last one that does not end with a back-slash","title":"CLI Interface Tutorial / Exercise"},{"location":"session_organization/exercise_vm_via_cli/#first-launch-azure-cloud-shell","text":"The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account. To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also open Cloud Shell in a separate browser tab by going to https://shell.azure.com/bash . Select Copy to copy the blocks of code, paste it into the Cloud Shell, and select Enter to run it.","title":"First, Launch Azure Cloud Shell"},{"location":"session_organization/exercise_vm_via_cli/#try-running-the-following-commands","text":"# create a VM and all of the items needed for it : OS Disk, network security group, etc. # replace the names with your own group and other names. # Remember to change the group and VM name az vm create \\ --resource-group mygroupname \\ --name mytestvm \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username azureuser \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys Here is a real example command for my own resource group: az vm create \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --image Debian \\ --public-ip-sku Standard --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys The output will look something like this: { \"fqdns\": \"\", \"id\": \"/subscriptions/047e742e-cb26-41e6-a9d6-9d42c67f43e6/resourceGroups/ccf22_billspat/providers/Microsoft.Compute/virtualMachines/billspat-tutorial-vm\", \"location\": \"northcentralus\", \"macAddress\": \"00-22-48-8F-48-C2\", \"powerState\": \"VM running\", \"privateIpAddress\": \"10.4.0.5\", \"publicIpAddress\": \"20.236.78.140\", \"resourceGroup\": \"ccf22_billspat\", \"zones\": \"\" } Copy and paste that somewhere for reference last. Now give that VM a purpose and install a web server . There are many webserver that you can install, but nginx is easy to install and open source. You can do this in two ways 1) use the CLI to run a command on the VM directly az vm run-command invoke \\ --resource-group mygroupname \\ --name mytestvm \\ --command-id RunShellScript \\ --scripts \"sudo apt-get update && sudo apt-get install -y nginx\" 2) use SSH to connect to the VM and run it directly. that will be for another tutorial! The output from the command above will be something like { \"value\" : [ { \"code\" : \"ProvisioningState/succeeded\" , \"displayStatus\" : \"Provisioning succeeded\" , \"level\" : \"Info\" , \"message\" : \"Enable succeeded: \\n[stdout]\\ne libnginx-mod-http-xslt-filter.\\r\\nPreparing to unpack .../23-libnginx-mod-http-xslt-filter_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-http-xslt-filter (1.14.2-2+deb10u4) ...\\r\\nSelecting previously unselected package libnginx-mod-mail.\\r\\nPreparing to unpack .../24-libnginx-mod-mail_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-mail (1.14.2-2+deb10u4) ...\\r\\nSelect etc Open port 80 for web traffic By default, only SSH connections are opened when you create a Linux VM in Azure. Use az vm open-port to open TCP port 80 for use with the NGINX web server: az vm open-port --port 80 --resource-group mygroupname --name mytestvm check that it's working Put the IP address from the output above (or use the portal to find it) into your browser to see if you can connect,. If so, then great! you've just built a web server. Delete everything You can't delete your how resource group, but luckily we used tags to create the VM so we can just delete resource by tag. You can use the portal to delete these resources, but if here are commands to do it with the CLI. You can delete things by name, like this az vm delete \\ --resource-group mygroup \\ --name myvm but every resource has a unique ID, and can be deteled using that ID with the command az resource delete --ids IDVALUE You can get those IDs using az resource list... # list all resources just created (change the tag to match what you used if necessary) az resource list --tag activity = cli_tutorial # The CLI can filter and change the format of it's output # list ONLY the resource IDs using the \"query\" and tabular output az resource list --tag activity = cli_tutorial --query \"[].id\" -o table # delete them all using a shell loop (tsv does not output a header line) IDS = $( az resource list --tag activity = cli_tutorial --query \"[].id\" -o tsv ) for id in $IDS ; do az resource delete --ids $id ; done","title":"Try running the following commands"},{"location":"session_organization/exercise_vm_via_cli/#complete-example-commands-using-my-resource-group","text":"az vm create \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys # copy and paste the output of that az vm run-command invoke \\ --resource-group ccf22_billspat \\ --name billspat-tutorial-vm \\ --command-id RunShellScript \\ --scripts \"sudo apt-get update && sudo apt-get install -y nginx\" az vm open-port --port 80 --resource-group ccf22_billspat --name billspat-tutorial-vm # list all resources just created az resource list --tag activity = cli_tutorial # list ONLY the resource IDs using the \"query\" and tabular output az resource list --tag activity = cli_tutorial --query \"[].id\" -o table # delete them all using a shell loop (tsv does not output a header line) IDS = $( az resource list --tag activity = cli_tutorial --query \"[].id\" -o tsv ) for id in $IDS ; do az resource delete --ids $id ; done bonus points : set shell variables for the resource group and name and use them in the commands. For example RG = ccf22_billspat VMNAME = billspat-tutorial-vm az vm create \\ --resource-group $RG \\ --name $VMNAME \\ --image Debian \\ --public-ip-sku Standard \\ --admin-username billspat \\ --tags 'activity=cli_tutorial' \\ --generate-ssh-keys # ... do other stuff, then delete az vm delete \\ --resource-group $RG \\ --name $VMNAME","title":"Complete example commands (using my resource group)"},{"location":"session_organization/exercise_vm_via_cli/#references","text":"Quickstart: Create a Linux virtual machine with the Azure CLI https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-cli Azure Command-Line Interface (CLI) documentation https://learn.microsoft.com/en-us/cli/azure/ All az vm... command options : https://learn.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest Use tags to organize your Azure resources (with the Azure CLI)! https://techcommunity.microsoft.com/t5/azure/use-tags-to-organize-your-azure-resources-with-the-azure-cli/m-p/1798955","title":"References:"},{"location":"session_organization/intro_to_cloud_interfaces/","text":"Interfacing with Cloud Services Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad. Summary of Cloud Interfaces This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html Graphical Web Interface Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface. Desktop Applications Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure Command Line For those not familar with the command line at all, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell. SDK : Software Developer Kit A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to? Python SDK All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors. REST Knowing the details of REST is not important but it's the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 The parameters to the weather data fetch program are lon, lat, ac, unit, output=json, tzshift, and they are embedded in the URL itself. This is caled a \"request,\" and using a web API often requires sending parameters not just sin the URL, but as an attachment or in the 'body' of the request. Browsers don't have an automatic way of doing that, so we use scripts (python Requests library) or special programs for testing Web APIs that can send parameters and data in the request body. This is a good explanation of REST and part 2 describes the details. https://medium.com/extend/what-is-rest-a-simple-explanation-for-beginners-part-1-introduction-b4a072f8740f The Azure REST api is a an interface to the Azure Resource Manager via the web. Requests sent can get information about your resources, or create new resources, just like the portal, the command line and the SDKs. Those other interfaces typically translate to the REST API. Knowing about it may help diagnose why your method for interfacing with Azure is not working but not necesary to learn. For examples and more detail, see https://learn.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-rest Few of us would ever use the Azure REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. R Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages. Cloud company templating frameworks In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation . Azure: ARM templates Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates You may see reference to \"Bicep\" templates. This is simplified ARM templating language that may be easier to write, debug and maintain than the JSON format of ARM templates. AWS: Cloud Formation AWS also has templating language similar to Azure Resource Manager templates called cloud formation. If you are using AWS for your project, and want to automate the creation and deployment of resources, this may be a good option. AWS Documentation: What is AWS CloudFormation? How does AWS CloudFormation work? Third-party programming with Terraform There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The advantage to Terraform is that it's declarative in that you specific what you want, unlike say the Python or command line interface, where you have to create items with commands one at a time. Terraform is used by cloud professionals becuase it's designed to keep the resources youve created running and allow you to modify them in place. If you find you are using scripting to build resources (which is great!) but your scripts are becomming combersome to maintain and your cloud architecture is complex, consider using Terraform. - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary Building Cloud from Cloud This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language. References See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"Interfacing with Cloud Services"},{"location":"session_organization/intro_to_cloud_interfaces/#interfacing-with-cloud-services","text":"Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad.","title":"Interfacing with Cloud Services"},{"location":"session_organization/intro_to_cloud_interfaces/#summary-of-cloud-interfaces","text":"This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html","title":"Summary of Cloud Interfaces"},{"location":"session_organization/intro_to_cloud_interfaces/#graphical-web-interface","text":"Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface.","title":"Graphical Web Interface"},{"location":"session_organization/intro_to_cloud_interfaces/#desktop-applications","text":"Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure","title":"Desktop Applications"},{"location":"session_organization/intro_to_cloud_interfaces/#command-line","text":"For those not familar with the command line at all, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell.","title":"Command Line"},{"location":"session_organization/intro_to_cloud_interfaces/#sdk-software-developer-kit","text":"A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to?","title":"SDK : Software Developer Kit"},{"location":"session_organization/intro_to_cloud_interfaces/#python-sdk","text":"All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors.","title":"Python SDK"},{"location":"session_organization/intro_to_cloud_interfaces/#rest","text":"Knowing the details of REST is not important but it's the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 The parameters to the weather data fetch program are lon, lat, ac, unit, output=json, tzshift, and they are embedded in the URL itself. This is caled a \"request,\" and using a web API often requires sending parameters not just sin the URL, but as an attachment or in the 'body' of the request. Browsers don't have an automatic way of doing that, so we use scripts (python Requests library) or special programs for testing Web APIs that can send parameters and data in the request body. This is a good explanation of REST and part 2 describes the details. https://medium.com/extend/what-is-rest-a-simple-explanation-for-beginners-part-1-introduction-b4a072f8740f The Azure REST api is a an interface to the Azure Resource Manager via the web. Requests sent can get information about your resources, or create new resources, just like the portal, the command line and the SDKs. Those other interfaces typically translate to the REST API. Knowing about it may help diagnose why your method for interfacing with Azure is not working but not necesary to learn. For examples and more detail, see https://learn.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-rest Few of us would ever use the Azure REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work.","title":"REST"},{"location":"session_organization/intro_to_cloud_interfaces/#r","text":"Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages.","title":"R"},{"location":"session_organization/intro_to_cloud_interfaces/#cloud-company-templating-frameworks","text":"In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation .","title":"Cloud company templating frameworks"},{"location":"session_organization/intro_to_cloud_interfaces/#azure-arm-templates","text":"Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates You may see reference to \"Bicep\" templates. This is simplified ARM templating language that may be easier to write, debug and maintain than the JSON format of ARM templates.","title":"Azure: ARM templates"},{"location":"session_organization/intro_to_cloud_interfaces/#aws-cloud-formation","text":"AWS also has templating language similar to Azure Resource Manager templates called cloud formation. If you are using AWS for your project, and want to automate the creation and deployment of resources, this may be a good option. AWS Documentation: What is AWS CloudFormation? How does AWS CloudFormation work?","title":"AWS: Cloud Formation"},{"location":"session_organization/intro_to_cloud_interfaces/#third-party-programming-with-terraform","text":"There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The advantage to Terraform is that it's declarative in that you specific what you want, unlike say the Python or command line interface, where you have to create items with commands one at a time. Terraform is used by cloud professionals becuase it's designed to keep the resources youve created running and allow you to modify them in place. If you find you are using scripting to build resources (which is great!) but your scripts are becomming combersome to maintain and your cloud architecture is complex, consider using Terraform. - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary","title":"Third-party programming with Terraform"},{"location":"session_organization/intro_to_cloud_interfaces/#building-cloud-from-cloud","text":"This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language.","title":"Building Cloud from Cloud"},{"location":"session_organization/intro_to_cloud_interfaces/#references","text":"See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"References"},{"location":"session_organization/costs/azure_cloud_cost_basics/","text":"Intro to Cloud Costs on Azure You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background. 1. Pricing Pages. All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services. 2. Build something and check the cost The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view 3. Pricing Calculators All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/ Summary and other notes Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries). Azure Pricing Resources Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Intro to Cloud Costs on Azure"},{"location":"session_organization/costs/azure_cloud_cost_basics/#intro-to-cloud-costs-on-azure","text":"You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background.","title":"Intro to Cloud Costs on Azure"},{"location":"session_organization/costs/azure_cloud_cost_basics/#1-pricing-pages","text":"All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services.","title":"1. Pricing Pages."},{"location":"session_organization/costs/azure_cloud_cost_basics/#2-build-something-and-check-the-cost","text":"The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view","title":"2. Build something and check the cost"},{"location":"session_organization/costs/azure_cloud_cost_basics/#3-pricing-calculators","text":"All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/","title":"3. Pricing Calculators"},{"location":"session_organization/costs/azure_cloud_cost_basics/#summary-and-other-notes","text":"Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries).","title":"Summary and other notes"},{"location":"session_organization/costs/azure_cloud_cost_basics/#azure-pricing-resources","text":"Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Azure Pricing Resources"},{"location":"session_organization/moving_data/","text":"Moving Data in The Cloud Excercises Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. Optional Readings Adding a data disk to virtual machine (review): A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these.","title":"Index"},{"location":"session_organization/moving_data/#moving-data-in-the-cloud","text":"","title":"Moving Data in The Cloud"},{"location":"session_organization/moving_data/#excercises","text":"Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to.","title":"Excercises"},{"location":"session_organization/moving_data/#optional-readings","text":"Adding a data disk to virtual machine (review): A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these.","title":"Optional Readings"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/","text":"Creating a Storage Account SAS token for allowing access to storage from another service or person How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility References Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"Creating a Storage Account SAS token"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/#creating-a-storage-account-sas-token","text":"","title":"Creating a Storage Account SAS token"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/#for-allowing-access-to-storage-from-another-service-or-person","text":"How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility","title":"for allowing access to storage from another service or person"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/#references","text":"Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"References"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/","text":"How to move data between the MSU HPC and Azure Introduction A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory) Method 1. using scp with a virtual machine Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results. Requirements an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine A little about the scp utility The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk. Method 2. azcopy Requirements A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation) Alternative Methods Method 3. Azure data factory We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility. Method 4. Python We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda . Method 5. Python with URL Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"How to move data between the MSU HPC and Azure"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#how-to-move-data-between-the-msu-hpc-and-azure","text":"","title":"How to move data between the MSU HPC and Azure"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#introduction","text":"A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory)","title":"Introduction"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-1-using-scp-with-a-virtual-machine","text":"Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results.","title":"Method 1. using scp with a virtual machine"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#requirements","text":"an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine","title":"Requirements"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#a-little-about-the-scp-utility","text":"The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk.","title":"A little about the scp utility"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-2-azcopy","text":"","title":"Method 2. azcopy"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#requirements_1","text":"A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation)","title":"Requirements"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#alternative-methods","text":"","title":"Alternative Methods"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-3-azure-data-factory","text":"We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility.","title":"Method 3. Azure data factory"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-4-python","text":"We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda .","title":"Method 4. Python"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-5-python-with-url","text":"Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"Method 5. Python with URL"},{"location":"session_organization/moving_data/moving_data_with_url_activity/","text":"Exercise: moving data using storage URL The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files) Upload file via portal Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise Get a URL to download this file back to your own laptop (or a different computer) determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard Test Download In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Exercise: moving data using storage URL"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#exercise-moving-data-using-storage-url","text":"The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files)","title":"Exercise: moving data using storage URL"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#upload-file-via-portal","text":"Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise","title":"Upload file via portal"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#get-a-url-to-download-this-file-back-to-your-own-laptop-or-a-different-computer","text":"determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard","title":"Get a URL to download this file back to your own laptop (or a different computer)"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#test-download","text":"In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Test Download"},{"location":"session_serverless/","text":"Session 7: Serverless, Containers, and FaaS example real-world cloud application What is \"Serverless?\" There are many definitions that include more or less categories of cloud services. The primary concept is you create an 'exectution environment' to run your code, but you don't manage any aspect of the server. You can focus on your application or code and not the operating system. We will talk about two kinds of \"serverless\" computing: Cloud Functions: running code on demand in response to a trigger or event. This is sometimes called \"Function as a Service\" Linux Containers: sandbox environment for running software, even more abstract than Virtual Machines, s The relationship is the Cloud functions use Linux Containers as the basis for their architecture on Azure. However you can use Azure Functions without working with containers or even knowing that fact but if you need extreme customization. Serverless Readings As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon Containers Containers are a widespread technology not just for Azure. About Linux Containers from Pat Bills, with readings and activities Functions All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp Case Studies and Tutorials An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349 Activities Links and activities related to containers are in the Container Overview page. For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell Fellowship Meeting November 4, 2022 Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction: GenePlexus: a web-server for gene discovery using network-based machine learning","title":"\u00b7 Serverless, Containers, and FaaS"},{"location":"session_serverless/#session-7-serverless-containers-and-faas","text":"example real-world cloud application","title":"Session 7: Serverless, Containers, and FaaS"},{"location":"session_serverless/#what-is-serverless","text":"There are many definitions that include more or less categories of cloud services. The primary concept is you create an 'exectution environment' to run your code, but you don't manage any aspect of the server. You can focus on your application or code and not the operating system. We will talk about two kinds of \"serverless\" computing: Cloud Functions: running code on demand in response to a trigger or event. This is sometimes called \"Function as a Service\" Linux Containers: sandbox environment for running software, even more abstract than Virtual Machines, s The relationship is the Cloud functions use Linux Containers as the basis for their architecture on Azure. However you can use Azure Functions without working with containers or even knowing that fact but if you need extreme customization.","title":"What is \"Serverless?\""},{"location":"session_serverless/#serverless-readings","text":"As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon","title":"Serverless Readings"},{"location":"session_serverless/#containers","text":"Containers are a widespread technology not just for Azure. About Linux Containers from Pat Bills, with readings and activities","title":"Containers"},{"location":"session_serverless/#functions","text":"All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp","title":"Functions"},{"location":"session_serverless/#case-studies-and-tutorials","text":"An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349","title":"Case Studies and Tutorials"},{"location":"session_serverless/#activities","text":"Links and activities related to containers are in the Container Overview page. For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell","title":"Activities"},{"location":"session_serverless/#fellowship-meeting","text":"November 4, 2022 Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction: GenePlexus: a web-server for gene discovery using network-based machine learning","title":"Fellowship Meeting"},{"location":"session_serverless/_draft%20conrent%20Why%20Containers/","text":"Why Containers? challenge for IT systems administrators is efficiencly managing all the servers and systems they are respnosible for. in the history of cloud we described how Amazon wrote control software for all of this, and create \"API\" or consistent interface to all of this server management software, so anyone could hook into this. containers take this a step further in that they are very software controlled system. A server is a software application, and like any software you might use to compute something, has This article https://queue.acm.org/detail.cfm?id=2898444 describes how google started using containers early in their journey to scale their systems to billions of applications. They in essence were building a cloud-like system internally for their own sake. At one point the determined to rebuild and repackage this as an open system for everyone to use. and the result is Kubernetes. Kubernetes is not for everyone. You may see articles like the one above extolling it's virtues, and if you are manageming many systems that you need to keep up and running for customers (high availability) then it's amazing. For researchers it may be overkill. There are other options to using Kubernetes to running cluster (e.g. parallel) processes efficiently. In addition, we should consider why we are running our systems: are these systems for us and our labs, or for broader public use? For example, workflow systems. Using containers and an orchestration system like Kubernetes, I can run a script that will launch several parts to Building management APIs around containers rather than machines shifts the \"primary key\" of the data center from machine to application. This has many benefits: (1) it relieves application developers and operations teams from worrying about specific details of machines and operating systems; (2) it provides the infrastructure team flexibility to roll out new hardware and upgrade operating systems with minimal impact on running applications and their developers; (3) it ties telemetry collected by the management system (e.g., metrics such as CPU and memory usage) to applications rather than machines, which dramatically improves application monitoring and introspection, especially when scale-up, machine failures, or maintenance cause application instances to move.","title":" draft conrent Why Containers"},{"location":"session_serverless/docker_tutorial_for_researchers/","text":"Docker Tutorial for Researchers featuring Jupyter Lab: Part 1 for the 2022 MSU Cloud Computing Fellowship Session 6: Serverless, Containers, and FaaS Introduction This is a walkthrough for using Docker containers on your desktop and in the cloud using Microsoft Azure. See the main page for this session and also the introduction to containers along with other links for background on requirements to follow along azure account updated Azure command line utlities installed (az cli) logged into to Azure using az login examples depend on the Jupyter lab stack being available in Dockerhub (valid November 2022) Notes: Docker is not the only system for using containers, but it's the most popular and I won't cover the others. I mention this because the main documentation for the container we will be using (Jupyter stack) describes using 'Podman' but we will stick with Docker for now. A reminder that Docker is a company that hosts a service to upload/download container images, and the name of the softwae ('docker') that can run containers and the name of a file ('Dockerfile' ) to create containers. Windows users: Docker was created for Linux but Microsoft has worked hard to make it viable for Windows users as well. The primary examples in this tutorial for for the command line will be for Mac/Linux, but there should be an equivalant option for Windows users. One way to make your windows computer more like Linux is to install the Windows Subsystem for Linux (WSL) which would provide you with a Terminal program that runs the \"bash\" shell There are three parts to this tutorial: working with containers on your computer (this document) Launching containers on Azure ( in development ) Creating your own containers ( in development ) Let's get started Part 1. Using Docker on your computer step 1: install Docker Docker offers many products, some of which are underlying tools to use docker. You minmimally need the \"Docker Engine\" to run and manage docker containers via the command line (only). However they also offer \"Docker Desktop\": a GUI to work with images and containers, connect and download from Dockerhub, set preferences, and includes all the other tools they make (Docker Compose, etc). Hence we will install Docker Desktop to get everything but this tutorial will primarily work with Docker via command line interface. Most software that is based on docker will have instructions for running it using the command line. Install docker desktop using instructions here: https://docs.docker.com/desktop/ Windows users: Microsoft has provided some good information on their site for using docker with the WSL, but you muse install that first : https://learn.microsoft.com/en-us/windows/wsl/install then see https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers Note that Docker Desktop works differently on Mac and Windows. I recommend that you take some time to review the introduction from Docker desktop. Minimally, we want to open the \"dashboard\" and to that you find the docker icon in the system tray on windows, and menu bar on Mac, and select \"dashboard\" . This may be helpful: https://docs.docker.com/desktop/use-desktop/#the-docker-menu Step 2. Find/Select an image to run from the Internet Many programs and servers have a \"dockerized\" version of software someone has prepared, often linked on the software web page or in a a README file, and you could use almost anything with this tutorial. However for this tutorial we'll be running JupyterLab to use python notebooks on our laptop. The Jupyter Stacks project offers many different containers with different amounts of software installed (or 'stacked') along with Jupyter lab. The important section is https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks describing each of their offerings. I will install \"datascience-notebook\" using instructions similar but not exactly the same as theirs. R users could follow along using instructions from the \"Rocker\" project Containers when published are minimally named as follows (this is the URI for the container): registryaddress/author/imagename:tag Author can be a person or an organization Imagename is what the author named the container image tag is like a version, but is not limited to version (but is limited in size). Example tags could be 'v3' and the latest version is 'latest' by convention. Registry address is usually not needed because we are always using Dockerhuib. However The full name of container we pull from Dockerhub (99% are hosted on Dockerhub) includes the docker address, or docker.io/author/imagename:tag but the docker software automatically puts docker.io when needed Step 3. Download and run the image as a container using the command line In your terminal or cmd.exe program, use this command: docker run -p 8888 :8888 --name jupyter-datascience jupyter/datascience-notebook:latest You can do somethign similar in the desktop dashboard, but only if you log-in to a repository like DockerHub. So for this tutorial we'll be using the command line. See https://docs.docker.com/desktop/use-desktop/images/ for more on the desktop interface for using Images. Command breakdown for \"docker run\": docker - main program to work with images/containers run - command to docker. others include 'pull' to get image. this command will automatically pull the image from dockerhub first if you don't have it on your computer -p = port if the image runs a server, all servers need a 'port' to listen on, and you have to tell docker which port on your own computer you want to connect to the container. Note we could have used any port ( > 1024) but using the same port makes it easy to remember. See this doc for descriptions of ports]( https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/ ). The important thing is anything over >1024 is fair game to use, but software tends to have a port they use by convention. Jupyter lab uses 8888. Rstudio uses 8787. and Postgresql uses 5432, just because. name this is optional and you can use whatever name you need to help organize your containers. If you don't provide it, Docker will assign a random name. when you have several images/containers running for a complex system or as you develop new containers, assigning names willhelp you keep track. If all goes well you will see download progress, and then part of the log or command output: [ I 2022 -11-11 04 :59:32.704 ServerApp ] Jupyter Server 1 .23.0 is running at: [ I 2022 -11-11 04 :59:32.704 ServerApp ] http://801ec4713575:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 [ I 2022 -11-11 04 :59:32.705 ServerApp ] or http://127.0.0.1:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 [ I 2022 -11-11 04 :59:32.705 ServerApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . [ C 2022 -11-11 04 :59:32.707 ServerApp ] To access the server, open this file in a browser: file:///home/jovyan/.local/share/jupyter/runtime/jpserver-6-open.html Or copy and paste one of these URLs: http://801ec4713575:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 or http://127.0.0.1:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 When Jupyter Lab runs, it outputs messages, and Docker is simply forwarding those message to the \"log\" of output, which when you run on your computer shows up in your terminal. You can also view the log in the Docker desktop user interface. To open Jupyter lab, use the last URl in the list. Note about ports: These Jupyter lab docker images are set to run on port 8888 and will always report that. However, if you use a different port in the command, then that is the one you want to use. For exmaple the command docker run -p 9999:8888 jupyter/datascience-notebook:latest the URL would be http://127.0.0.1:9999/... etc but the log message will still say 88888 becuase that's the port used by the container internally - it doesn't know about the external port map. moral is to try to use the same port to reduce confusion. If it worked and you can log in, you can create a notebook, do some python (or R or Julia) and save the notebook. Great! But when yuo save, where does it go? Right now, everything is instde But that's all in the container. If you shut down the container, that is all lost, because internal container storage is ephemeral. In the same terminal you ran the command, use Ctrl+C to cancel it and stop running. You can also use the Docker desktop GUI to start and stop containers. Note if you run this again, you'll get the error ```docker: Error response from daemon: Conflict. The container name \"jupyter-datascience\" is already in use by container \"...\". You have to remove (or rename) that container to be able to reuse that name. #### Working with Containers After creating a container and stoppping it, you can do a copule things: re-start the container, delete it, start a second instance of the image in a new container, list all your containers. Note these containers are distinct from the images from which they are made. **Using the docker desktop user interface** You can accomplish all of the activities below using the \"Dashboard\" section of the Docker desktop user interface, which lists all of the containers on your system along with any images you've downloaded. See https://docs.docker.com/desktop/use-desktop/ for an introduction. **Using docker command line to manage containers** 1. re-run the container - it's still good! It's just paused. `docker container restart jupyter-datascience` Note you use the name you assigned the container when you ran it, not the name of the \"image\" 2. delete the container `docker container rm jupyter-datascience` Tou can run now a new one (perhaps to alter the port, or other options). The syntax is based on the Linux 'rm' command 3. start a different container from the same image `docker run -p 8889:8888 --name jupyter-datascience2 jupyter/datascience-notebook:latest` In this example I used a different port number, which would allow you to run _both_ containers at the same. I don't think, for this image, there is a reason to do that, but it's possible. Note that this will taks ` 4. An many others... https://docs.docker.com/engine/reference/commandline/container/ For example list all the containers on the system `docker container ls -a` ### Step 4. Connecting docker to your local files Containers are great because they are unchanging environments you can run repeatedly. They are not great becuase they are unchanging environments and anything you 'save' or change is lost when you shut down or delete the container. Computing is not very valuable unless you can save your output. Docker containers are walled off from your computer unless you explicitly connect a folder from your disk to a folder location in the container. There are two ways to do this but we are using \"volumes\" ( see docker Volumne documentation for details. The goal is to take a folder on your computer and tell Docker to make it look like it's a sub folder somewhere in the container. The folder on your computer is up to you, but the location in the docker image is very dependent on the structure and nature of the container. Some have strict requirments. Steps to use volumes on your computer 1. create the folder 1. use Docker desktop to give permission to use the folder 1. run the container with the command to 'mount' the folder into the Linux container **Volumes step 1. Create the folder** let's create a folder on your comptuer. You can use wahatever you want, and this is just an example. Let's create folder called \"notebooks\" right in your home directory. If you are unfamiliar with the command line there are some instructions for using the Docker Desktop below. On Mac, the folder would be in your home directory, or /Users/<username>/notebooks. In Mac/Linux terminal the short cut for home directory is `$HOME` so the command would be mkdir $HOME/notebooks On Windows the shortcut is `%HOMEPATH%` so the path to the notebooks folder is %HOMEPATH%/notebooks (see https://www.thewindowsclub.com/system-user-environment-variables-windows for what an enviroment variable is in Windows). **Volumes step 2. Give Permission to use the folder** There is a way to edit the configuration file for Docker to allow access to folders on your computer, but here we'll use the Docker Desktop GUI app. 1. Open the Docker Desktop, and go to preferences. See the bas The Jupyter stack containers have a long discussion on this in the documentation, but in short, there is a special user account inside the container, and to see notebooks yuo have to create a subfolder in that account's home directory. The user is named \"jovyan\" and so the home directory inside the container is \"/home/jovyan\" and that's where the notebooks are looked for. **Volumes step 3. Add volume when running the container** To add a volume to the Jupyter stack containers, try this command ```bash docker run -p 8888:8888 -v \"enter path to notebooks here\":/home/jovyan/notebooks jupyter/datascience-notebook:latest If you created the 'notebooks' folder under Document, the path on a Mac will look something like $HOME/Documents/notebooks so the command would be docker run -p 8888 :8888 -v $HOME /Documents/notebooks:/home/jovyan/notebooks jupyter/datascience-notebook:latest On Windows I don't know exactly what this will look like but you could try using variable %HOMEPATH%/Documents/notebooks in the command. # I don't have windows so this is a guess docker run -p 8888 :8888 -v %HOMEPATH%/Documents/notebooks:/home/jovyan/notebooks jupyter/datascience-notebook:latest But what about the other size of the \":\" ? I know from the Jupyter Stacks documentation that this image uses the folder /home/jovyan/ so this command maps the folder 'notebooks' on my computer to 'notebooks' to inside the the container. Now when you open the browser and copy/paste the URL for the new notebook server you've started, you'll see the \"notebooks\" folder on the left side, and any notebook you save there can be found on your computer. note that there are aother potentially more sophisticated ways of using Volumes than this, but this works for us! see the docker documenttaion for details. Part 2: using Azure to run containers Azure has several services for running containers or based on containers. For this example we will work with Azure Container Instances . (this link is the same as on the main page of the serverless session) If you have the [Azure command line utility installed] on your computer, and you know the name of your resource group ( for 2022-23 fellows we use the pattern \"ccf22_ \". You can run the Jupyter Lab container with just one command line: az container create --resource-group \"put your resource group name here\" --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest --dns-name-label \" put a unique name here\" --ports 8888 Note if you don't want to install the Azure command line (which is not small!) then you can use the Azure Cloud Shell \"resource-group\" = your group, which you can find with the command az group list \"name\" is the name of the container that could be anything, in the example below I use \"jupyterlab\" but could also be named for the project you are working on. It may be useful to add more information about how you ser using it , say \"jupyterlab-testing\" or add your netid to it. \"dns-name-label\" is used to create the URL that you will go to so it has to be unique. One option is to use your NetID as part of the name, e.g. \"jupyterlab-sparty\" \"image\" this is the URL of the image we need to tell Azure which container \"registry\" to look to, and for Docker that's docker.io The image I used in the command below is the Jupyter stacks data science image, but you could use any image that has a web server, for example About this command Just like the command on your own computer, this maps port 8888 used by the Jupyter server to the same number on the host. This once creates the Azure container instance resource in your group, uploads and configures the docker image, and starts the container. the output is a long text in JSON format that has some crucial information in it. You can always get this information again with the 'show' commands like this az container show -g $RG --name jupyterlab but also from the Azure portal. T\\he information you need in the output is this: \"ipAddress\" : { \"dnsNameLabel\" : \"jupyterlab-billspat\" , \"fqdn\" : \"jupyterlab-billspat.northcentralus.azurecontainer.io\" , \"ip\" : null , \"ports\" : [ { \"port\" : 8888 , \"protocol\" : \"TCP\" } ], \"type\" : \"Public\" }, and the FQDN is the fully qualified domain name or web address where the server is running. Note it starts with the 'dns-name-label' parameter you entered above. Put the \"FQDN\" in a browser, and add :8888 So for me, the URL is \" http://jupyterlab-billspat.northcentralus.azurecontainer.io:8888 \" - but that's not enough! You still need the security token! The challenge with getting the token is that when running on azure (unlike docker on your computer) you don't see the logs of the running container, and the token is output in the logs. There are two ways (at least) to get it: getting the docker container logs via command line az container logs --resource-group \"your resource group name here\" --name \"the --name option you used above here\" lists all the logs, but we just want the token. Here is what I run on my mac to filter the logs using grep az container logs --resource-group \"ccf22_billspat\" --name \"jupyterlab-test\" | grep token getting the docker container logs using the Azure portal: open portal.azure.com, go to your Resource Group if it's not already open find the new container instance in the list of resources, then open it up. inside that screen, look for the \"containers\" section on the left side. Then select the container (mine isa called \"jupyterlab-test\", select \"logs\", look in the looks for the token and copy and paste it Using Cloud Storage with Azure Container instances. Recall from the Storage session, when you create an Azure storage container, inside that you can created different types of storage, primarily \"blob\" or \"files.\" Files are modeled on network storage, hence easier to connect to running systems directly. If you have an Azure File share in one of your Azure Storage containers, you can connect to it The following doc from Azure describes how to use the Azure CLI and Bash to get the necessary information about file share and connect it to a container instance. https://learn.microsoft.com/en-us/azure/container-instances/container-instances-volume-azure-files Here is a shortened version based on the Portal Create a File share if you don't one already: Create or use your existing storage account in the portal Using the Portal open the storage account resource, then go to \"File shares\" on the left side and create a new file share using the \"[+ File share]\" button at the top. It can be named anything you like. If performance is not crucial, select \"hot\" tier storage. Get some security information from the portal STORAGE_ACCOUNT_NAME: the main name of the storage accoutn in which you created the File share SHARE_NAME the name of the file share you just created (or are using) STORAGE_KEY this takes the most work to find. - in the Portal, open the storage account main page (not the file share, but the storage account) - on the left side, find \"Access Keys\" - this will list the storage account name, and 2 keys - each key list both the key by itself, and a \"connection string\" useful for other services - you can use either key, it doesn't matter. Use the \"show\" button to show the key so you can copy/paste it Run the container as before, but now with file share: Note in the command below, I'm using the \"line continuation\" characther \"\\\" that works for Bash shell and maybe Powershell. If you are using Windows you may have to adjust the syntax In the command below, replace the az container create --resource-group \"put your resource group name here\" \\ --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest \\ --dns-name-label \" put a unique name here\" --ports 8888 \\ --azure-file-volume-account-name STORAGE_ACCOUNT_NAME \\ --azure-file-volume-share-name SHARE_NAME \\ --azure-file-volume-account-key STORAGE_KEY \\ --azure-file-volume-mount-path /home/jovyan/notebooks For example : az container create --resource-group \"ccf22_billspat\" \\ --name jupyterlab-test --image docker.io/jupyter/datascience-notebook:latest \\ --dns-name-label \"jupyterlab-test\" --ports 8888 \\ --azure-file-volume-account-name stbillspatccf22 \\ --azure-file-volume-share-name ccf22billspat \\ --azure-file-volume-account-key dve+w+fw8XUSLE91pKO2i6.....etc....KV49ZHYEY07qsvBBpnPV9+AStjQ7vFg == \\ --azure-file-volume-mount-path /home/jovyan/notebooks The web address for the Juypter lab server, after looking up the security Token using the methods describe above is: jupyterlab-test.northcentralus.azurecontainer.io:8888/lab?token=7e0ef407a591f10cfb358850c25cdc6529742309366382f0 note that if you use Azure Blob storage, you can read/write to it using Python commands without having to connect when you build the container. You need the connection string and to have the Azure python packages installed (see below for inforemation on how to modify the datascience-notebook image to install more python packages) Creating containers using the Azure Portal The portal has nice forms for creating container instances, but you will still need the three storage account information as described above. Managing Containers in Azure If you stop teh instance you are no longer charged. You can start/stop from the command line or from the portal az container stop --resource-group ccf22_billspat --name jupyterlab-test # later... az container start --resource-group ccf22_billspat --name jupyterlab-test # this does take a while, but may be easier than recreating it. However to keep your Resource group tidy, if you are finished with a container instannce for a while you should delete it. az container start --resource-group ccf22_billspat --name jupyterlab-test Azure Container Instance Alternate Method There are several ways to do this - of course there are, this is Microsoft! Microsoft worked with the Docker company to get commands built into the docker utility to be able to run docker files via your laptop. In Docker-world, a 'context' is how the container is run, which could be different folders on your laptop, some kind of fancy docker server, or a cloud service. The following are pretty clear instructions for using the Docker 'context' for connection to Azure container instance (ACI) and when you docker run the container will load on Azure instead of your laptop. It's not clear to me exactly which is a better method, however with this method you get all the options available to you via the docker run command, except mounting a volume from your laptop of course. https://devblogs.microsoft.com/devops/publishing-azure-container-instances-from-docker-cli/ Yet another method for Docker Containers from Microsoft : Visual Studio Code If you are a Visual Studio Code user, there is a Docker plugin for editing Dockerfiles and running them on Azure : https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker I have not tested this but if it may be useful for debugging a complex Dockerfile. Part III. DIY! While you may find a ready made Docker image that has all you need, chances are you'll need to modify it for your own work, and that means making your own images. Select a Base Image. We always start with an exissting image. Could be a very basic version of Linux that we install everything into, or an existing full image that we just add a little to. Write a Dockerfile : instructions for adding things to the base image (install software, configuration, copying code or data) Build: from the Dockerfile create an image. on your own computer using the Docker software on a remote repository, like Azure which lets you build on their system Option: upload to a remote repository to be able to pull the image from other places Run: run to create a container from the image the image you just built on your computer, or from the remote repository you just uploaed to (see optional step above) (e.g pull from remote and run) There is documentation from Docker about what does into a dockerfile, but I find that confusing as they talk about each command, but not how the commands go together. There are many tutorials for building Dockerfiles to run websites, but not many (if any ) for researchers! We've been using Docker images from Jupyter-Stacks. Here is their example Dockerfile that installs python packages on to their base image: https://github.com/jupyter/docker-stacks/blob/main/scipy-notebook/Dockerfile This is a bit complex example but it has many of the ingredients of a standard Dockerfile. Main sections: FROM always start with a base container. They ARGS set variables to re-use later in the file. This makes it easy to change in just one place RUN run a linux command in the base container to install something, or set configuration. Note that most of these try to bundle as many commands as possible into on RUN to save space, and hence use the \"Line continuation\" character to make the command readable. In the linux shell is usually the back slash or \\ - when you see that it means continue on the next line for this command. You will also see && operator which says keep going and run the next command. These two things allow for very very long commands to run at once (and make the container smaller) COPY copy something from your computer into the container : data, code, configuration files, etc This example uses the example Notebook file you downloaded for Part 1 above, but let's download it again. The datascience Jupyter is great, but what if you want to do Natural Language analysis? We need the [NLTK] package for that, along with the data file for stop words. Let's create new container that starts with the Jupyter Stacks data science image, and adds those things. FROM jupyter/datascience-notebook:latest RUN pip install nltk && python -c 'from nltk import download; download(\"stopwords\")' To build a new image called \"jupyter_nltk\", save this as a file called \"Dockerfile\" in a folder by itself and run cd \"folder where yuor docker file is\" docker build -t jupyter_nltk:latest -f Dockerfile . Note the command has a period / dot at the end and that's required if the docker file is in the directory from which your run the command To run this new container, use this command. Notice that since this Image is on your let's say you also wanted to copy a notebook file called \"example.ipynb\" from the same directoery that the docker into this container for demonstration. You could do this: FROM jupyter/datascience-notebook:latest RUN pip install nltk && python -c 'from nltk import download; download(\"stopwords\")' COPY example.ipynb $HOME Part III Bonus:DIY containers in Azure This is the culmination of all of knowledge above, and actually what researchers most likely need to do: run a container that they have created in the cloud The key concept here is a container registry, which contains \"repositories\" which are history and versions of container images. A registry is a web application to build and store Docker images. Dockerhub is the most widely used container repository and you could use that, but with Azure you can make your own private registry. Here are instructions for using Dockerhub: https://www.docker.com/blog/how-to-build-and-test-your-docker-images-in-the-cloud-with-docker-hub/ . Dockerhub is a great option if you want to share your images with others (at no cost to you!). However We will be using Azure since this A note about terminology: A \"registry\" is a service that can hold many images. Each image has versions (e.g. tags, latest, v1, v2, v2022, etc), and so this is called a \"repository\" you create your own registry/repository that is private just to you (and or your lab or workgroup). There is a fee for this but it's not much. The advantage to Azure Container registries is you can keep them private, and you can create the repository and build images with the az comnmand line (or the protal as usual) see https://learn.microsoft.com/en-us/cli/azure/acr?view=azure-cli-latest about the ACR service. Microsoft also has a tutorial for creating an Azure Container Registry using a container image from their own public registry https://learn.microsoft.com/en-us/azure/container-registry/container-registry-quickstart-task-cli that is pretty good. However the steps below build upon the Dockerfile created above. 1. Create a registry to hold your images Create an ACR (azure container repository)/ with the command line (replace ACR name and resource group name to match yours ): az acr create -n <UNIQUEREGISTRYNAME> -g RESOURCEGROUPNAME --sku Standard 2. then use that ACR to build the Docker image from your local Dockerfile. First, use cd to change to the directory with your dockerfile in it with cd /path/to/my/Docker/folder Assuming there is a Dockerfile in the currenct directory (e.g. if your terminal is in the same folder as the Dockerfile above) az acr build -t jupyter-nltk:latest --file Dockerfile --registry UNIQUEREGISTRYNAME . Command ends with a single \"dot\" indicating we are using the Dockerfile that is present in this folder. 3. Run the container on ACI from the ACR Once built, you can create containers from this image. By default any Container registry you created in Azure is private (unlike the public Dockerhub). So when you want to use image that's hosted in a private Azure container registry like the one created above, you must supply credentials to access the registry. get the full name of the container registry login server using the command line (or the Portal): az acr show --name <UNIQUEREGISTRYNAME> --query loginServer (this does not ahve storage account mounted): az container create --resource-group \"ccf22_billspat\" \\ --name jupyterlab-nltk --image jupyterlab-nltk:latest \\ --dns-name-label \"jupyterlab-nltk\" --ports 8888 You can find the web address by visiting the portal, using az container show as described above, and you'll also need to the token from the logs, which is also described. I put a collection of code to combine the steps for this online: https://gist.github.com/psbills/5d42a55d53f0403ba5770b876dd74a3d This should work on Mac, Linux, and the Azure Cloud shell. (Not tested on Windows)","title":"Docker Tutorial for Researchers featuring Jupyter Lab: Part 1"},{"location":"session_serverless/docker_tutorial_for_researchers/#docker-tutorial-for-researchers-featuring-jupyter-lab-part-1","text":"for the 2022 MSU Cloud Computing Fellowship Session 6: Serverless, Containers, and FaaS","title":"Docker Tutorial for Researchers featuring Jupyter Lab: Part 1"},{"location":"session_serverless/docker_tutorial_for_researchers/#introduction","text":"This is a walkthrough for using Docker containers on your desktop and in the cloud using Microsoft Azure. See the main page for this session and also the introduction to containers along with other links for background on","title":"Introduction"},{"location":"session_serverless/docker_tutorial_for_researchers/#requirements-to-follow-along","text":"azure account updated Azure command line utlities installed (az cli) logged into to Azure using az login examples depend on the Jupyter lab stack being available in Dockerhub (valid November 2022) Notes: Docker is not the only system for using containers, but it's the most popular and I won't cover the others. I mention this because the main documentation for the container we will be using (Jupyter stack) describes using 'Podman' but we will stick with Docker for now. A reminder that Docker is a company that hosts a service to upload/download container images, and the name of the softwae ('docker') that can run containers and the name of a file ('Dockerfile' ) to create containers. Windows users: Docker was created for Linux but Microsoft has worked hard to make it viable for Windows users as well. The primary examples in this tutorial for for the command line will be for Mac/Linux, but there should be an equivalant option for Windows users. One way to make your windows computer more like Linux is to install the Windows Subsystem for Linux (WSL) which would provide you with a Terminal program that runs the \"bash\" shell There are three parts to this tutorial: working with containers on your computer (this document) Launching containers on Azure ( in development ) Creating your own containers ( in development ) Let's get started","title":"requirements to follow along"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-1-using-docker-on-your-computer","text":"","title":"Part 1. Using Docker on your computer"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-1-install-docker","text":"Docker offers many products, some of which are underlying tools to use docker. You minmimally need the \"Docker Engine\" to run and manage docker containers via the command line (only). However they also offer \"Docker Desktop\": a GUI to work with images and containers, connect and download from Dockerhub, set preferences, and includes all the other tools they make (Docker Compose, etc). Hence we will install Docker Desktop to get everything but this tutorial will primarily work with Docker via command line interface. Most software that is based on docker will have instructions for running it using the command line. Install docker desktop using instructions here: https://docs.docker.com/desktop/ Windows users: Microsoft has provided some good information on their site for using docker with the WSL, but you muse install that first : https://learn.microsoft.com/en-us/windows/wsl/install then see https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers Note that Docker Desktop works differently on Mac and Windows. I recommend that you take some time to review the introduction from Docker desktop. Minimally, we want to open the \"dashboard\" and to that you find the docker icon in the system tray on windows, and menu bar on Mac, and select \"dashboard\" . This may be helpful: https://docs.docker.com/desktop/use-desktop/#the-docker-menu","title":"step 1: install Docker"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-2-findselect-an-image-to-run-from-the-internet","text":"Many programs and servers have a \"dockerized\" version of software someone has prepared, often linked on the software web page or in a a README file, and you could use almost anything with this tutorial. However for this tutorial we'll be running JupyterLab to use python notebooks on our laptop. The Jupyter Stacks project offers many different containers with different amounts of software installed (or 'stacked') along with Jupyter lab. The important section is https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks describing each of their offerings. I will install \"datascience-notebook\" using instructions similar but not exactly the same as theirs. R users could follow along using instructions from the \"Rocker\" project Containers when published are minimally named as follows (this is the URI for the container): registryaddress/author/imagename:tag Author can be a person or an organization Imagename is what the author named the container image tag is like a version, but is not limited to version (but is limited in size). Example tags could be 'v3' and the latest version is 'latest' by convention. Registry address is usually not needed because we are always using Dockerhuib. However The full name of container we pull from Dockerhub (99% are hosted on Dockerhub) includes the docker address, or docker.io/author/imagename:tag but the docker software automatically puts docker.io when needed","title":"Step 2. Find/Select an image to run from the Internet"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-3-download-and-run-the-image-as-a-container-using-the-command-line","text":"In your terminal or cmd.exe program, use this command: docker run -p 8888 :8888 --name jupyter-datascience jupyter/datascience-notebook:latest You can do somethign similar in the desktop dashboard, but only if you log-in to a repository like DockerHub. So for this tutorial we'll be using the command line. See https://docs.docker.com/desktop/use-desktop/images/ for more on the desktop interface for using Images.","title":"Step 3. Download and run the image as a container using the command line"},{"location":"session_serverless/docker_tutorial_for_researchers/#command-breakdown-for-docker-run","text":"docker - main program to work with images/containers run - command to docker. others include 'pull' to get image. this command will automatically pull the image from dockerhub first if you don't have it on your computer -p = port if the image runs a server, all servers need a 'port' to listen on, and you have to tell docker which port on your own computer you want to connect to the container. Note we could have used any port ( > 1024) but using the same port makes it easy to remember. See this doc for descriptions of ports]( https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/ ). The important thing is anything over >1024 is fair game to use, but software tends to have a port they use by convention. Jupyter lab uses 8888. Rstudio uses 8787. and Postgresql uses 5432, just because. name this is optional and you can use whatever name you need to help organize your containers. If you don't provide it, Docker will assign a random name. when you have several images/containers running for a complex system or as you develop new containers, assigning names willhelp you keep track. If all goes well you will see download progress, and then part of the log or command output: [ I 2022 -11-11 04 :59:32.704 ServerApp ] Jupyter Server 1 .23.0 is running at: [ I 2022 -11-11 04 :59:32.704 ServerApp ] http://801ec4713575:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 [ I 2022 -11-11 04 :59:32.705 ServerApp ] or http://127.0.0.1:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 [ I 2022 -11-11 04 :59:32.705 ServerApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . [ C 2022 -11-11 04 :59:32.707 ServerApp ] To access the server, open this file in a browser: file:///home/jovyan/.local/share/jupyter/runtime/jpserver-6-open.html Or copy and paste one of these URLs: http://801ec4713575:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 or http://127.0.0.1:8888/lab?token = 57fb181bc074c193095db3df8c245521d3acb83530078d73 When Jupyter Lab runs, it outputs messages, and Docker is simply forwarding those message to the \"log\" of output, which when you run on your computer shows up in your terminal. You can also view the log in the Docker desktop user interface. To open Jupyter lab, use the last URl in the list. Note about ports: These Jupyter lab docker images are set to run on port 8888 and will always report that. However, if you use a different port in the command, then that is the one you want to use. For exmaple the command docker run -p 9999:8888 jupyter/datascience-notebook:latest the URL would be http://127.0.0.1:9999/... etc but the log message will still say 88888 becuase that's the port used by the container internally - it doesn't know about the external port map. moral is to try to use the same port to reduce confusion. If it worked and you can log in, you can create a notebook, do some python (or R or Julia) and save the notebook. Great! But when yuo save, where does it go? Right now, everything is instde But that's all in the container. If you shut down the container, that is all lost, because internal container storage is ephemeral. In the same terminal you ran the command, use Ctrl+C to cancel it and stop running. You can also use the Docker desktop GUI to start and stop containers. Note if you run this again, you'll get the error ```docker: Error response from daemon: Conflict. The container name \"jupyter-datascience\" is already in use by container \"...\". You have to remove (or rename) that container to be able to reuse that name. #### Working with Containers After creating a container and stoppping it, you can do a copule things: re-start the container, delete it, start a second instance of the image in a new container, list all your containers. Note these containers are distinct from the images from which they are made. **Using the docker desktop user interface** You can accomplish all of the activities below using the \"Dashboard\" section of the Docker desktop user interface, which lists all of the containers on your system along with any images you've downloaded. See https://docs.docker.com/desktop/use-desktop/ for an introduction. **Using docker command line to manage containers** 1. re-run the container - it's still good! It's just paused. `docker container restart jupyter-datascience` Note you use the name you assigned the container when you ran it, not the name of the \"image\" 2. delete the container `docker container rm jupyter-datascience` Tou can run now a new one (perhaps to alter the port, or other options). The syntax is based on the Linux 'rm' command 3. start a different container from the same image `docker run -p 8889:8888 --name jupyter-datascience2 jupyter/datascience-notebook:latest` In this example I used a different port number, which would allow you to run _both_ containers at the same. I don't think, for this image, there is a reason to do that, but it's possible. Note that this will taks ` 4. An many others... https://docs.docker.com/engine/reference/commandline/container/ For example list all the containers on the system `docker container ls -a` ### Step 4. Connecting docker to your local files Containers are great because they are unchanging environments you can run repeatedly. They are not great becuase they are unchanging environments and anything you 'save' or change is lost when you shut down or delete the container. Computing is not very valuable unless you can save your output. Docker containers are walled off from your computer unless you explicitly connect a folder from your disk to a folder location in the container. There are two ways to do this but we are using \"volumes\" ( see docker Volumne documentation for details. The goal is to take a folder on your computer and tell Docker to make it look like it's a sub folder somewhere in the container. The folder on your computer is up to you, but the location in the docker image is very dependent on the structure and nature of the container. Some have strict requirments. Steps to use volumes on your computer 1. create the folder 1. use Docker desktop to give permission to use the folder 1. run the container with the command to 'mount' the folder into the Linux container **Volumes step 1. Create the folder** let's create a folder on your comptuer. You can use wahatever you want, and this is just an example. Let's create folder called \"notebooks\" right in your home directory. If you are unfamiliar with the command line there are some instructions for using the Docker Desktop below. On Mac, the folder would be in your home directory, or /Users/<username>/notebooks. In Mac/Linux terminal the short cut for home directory is `$HOME` so the command would be mkdir $HOME/notebooks On Windows the shortcut is `%HOMEPATH%` so the path to the notebooks folder is %HOMEPATH%/notebooks (see https://www.thewindowsclub.com/system-user-environment-variables-windows for what an enviroment variable is in Windows). **Volumes step 2. Give Permission to use the folder** There is a way to edit the configuration file for Docker to allow access to folders on your computer, but here we'll use the Docker Desktop GUI app. 1. Open the Docker Desktop, and go to preferences. See the bas The Jupyter stack containers have a long discussion on this in the documentation, but in short, there is a special user account inside the container, and to see notebooks yuo have to create a subfolder in that account's home directory. The user is named \"jovyan\" and so the home directory inside the container is \"/home/jovyan\" and that's where the notebooks are looked for. **Volumes step 3. Add volume when running the container** To add a volume to the Jupyter stack containers, try this command ```bash docker run -p 8888:8888 -v \"enter path to notebooks here\":/home/jovyan/notebooks jupyter/datascience-notebook:latest If you created the 'notebooks' folder under Document, the path on a Mac will look something like $HOME/Documents/notebooks so the command would be docker run -p 8888 :8888 -v $HOME /Documents/notebooks:/home/jovyan/notebooks jupyter/datascience-notebook:latest On Windows I don't know exactly what this will look like but you could try using variable %HOMEPATH%/Documents/notebooks in the command. # I don't have windows so this is a guess docker run -p 8888 :8888 -v %HOMEPATH%/Documents/notebooks:/home/jovyan/notebooks jupyter/datascience-notebook:latest But what about the other size of the \":\" ? I know from the Jupyter Stacks documentation that this image uses the folder /home/jovyan/ so this command maps the folder 'notebooks' on my computer to 'notebooks' to inside the the container. Now when you open the browser and copy/paste the URL for the new notebook server you've started, you'll see the \"notebooks\" folder on the left side, and any notebook you save there can be found on your computer. note that there are aother potentially more sophisticated ways of using Volumes than this, but this works for us! see the docker documenttaion for details.","title":"Command breakdown for \"docker run\":"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-2-using-azure-to-run-containers","text":"Azure has several services for running containers or based on containers. For this example we will work with Azure Container Instances . (this link is the same as on the main page of the serverless session) If you have the [Azure command line utility installed] on your computer, and you know the name of your resource group ( for 2022-23 fellows we use the pattern \"ccf22_ \". You can run the Jupyter Lab container with just one command line: az container create --resource-group \"put your resource group name here\" --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest --dns-name-label \" put a unique name here\" --ports 8888 Note if you don't want to install the Azure command line (which is not small!) then you can use the Azure Cloud Shell \"resource-group\" = your group, which you can find with the command az group list \"name\" is the name of the container that could be anything, in the example below I use \"jupyterlab\" but could also be named for the project you are working on. It may be useful to add more information about how you ser using it , say \"jupyterlab-testing\" or add your netid to it. \"dns-name-label\" is used to create the URL that you will go to so it has to be unique. One option is to use your NetID as part of the name, e.g. \"jupyterlab-sparty\" \"image\" this is the URL of the image we need to tell Azure which container \"registry\" to look to, and for Docker that's docker.io The image I used in the command below is the Jupyter stacks data science image, but you could use any image that has a web server, for example","title":"Part 2: using Azure to run containers"},{"location":"session_serverless/docker_tutorial_for_researchers/#about-this-command","text":"Just like the command on your own computer, this maps port 8888 used by the Jupyter server to the same number on the host. This once creates the Azure container instance resource in your group, uploads and configures the docker image, and starts the container. the output is a long text in JSON format that has some crucial information in it. You can always get this information again with the 'show' commands like this az container show -g $RG --name jupyterlab but also from the Azure portal. T\\he information you need in the output is this: \"ipAddress\" : { \"dnsNameLabel\" : \"jupyterlab-billspat\" , \"fqdn\" : \"jupyterlab-billspat.northcentralus.azurecontainer.io\" , \"ip\" : null , \"ports\" : [ { \"port\" : 8888 , \"protocol\" : \"TCP\" } ], \"type\" : \"Public\" }, and the FQDN is the fully qualified domain name or web address where the server is running. Note it starts with the 'dns-name-label' parameter you entered above. Put the \"FQDN\" in a browser, and add :8888 So for me, the URL is \" http://jupyterlab-billspat.northcentralus.azurecontainer.io:8888 \" - but that's not enough! You still need the security token! The challenge with getting the token is that when running on azure (unlike docker on your computer) you don't see the logs of the running container, and the token is output in the logs. There are two ways (at least) to get it:","title":"About this command"},{"location":"session_serverless/docker_tutorial_for_researchers/#getting-the-docker-container-logs-via-command-line","text":"az container logs --resource-group \"your resource group name here\" --name \"the --name option you used above here\" lists all the logs, but we just want the token. Here is what I run on my mac to filter the logs using grep az container logs --resource-group \"ccf22_billspat\" --name \"jupyterlab-test\" | grep token","title":"getting the docker container logs via command line"},{"location":"session_serverless/docker_tutorial_for_researchers/#getting-the-docker-container-logs-using-the-azure-portal","text":"open portal.azure.com, go to your Resource Group if it's not already open find the new container instance in the list of resources, then open it up. inside that screen, look for the \"containers\" section on the left side. Then select the container (mine isa called \"jupyterlab-test\", select \"logs\", look in the looks for the token and copy and paste it","title":"getting the docker container logs using the Azure portal:"},{"location":"session_serverless/docker_tutorial_for_researchers/#using-cloud-storage-with-azure-container-instances","text":"Recall from the Storage session, when you create an Azure storage container, inside that you can created different types of storage, primarily \"blob\" or \"files.\" Files are modeled on network storage, hence easier to connect to running systems directly. If you have an Azure File share in one of your Azure Storage containers, you can connect to it The following doc from Azure describes how to use the Azure CLI and Bash to get the necessary information about file share and connect it to a container instance. https://learn.microsoft.com/en-us/azure/container-instances/container-instances-volume-azure-files Here is a shortened version based on the Portal Create a File share if you don't one already: Create or use your existing storage account in the portal Using the Portal open the storage account resource, then go to \"File shares\" on the left side and create a new file share using the \"[+ File share]\" button at the top. It can be named anything you like. If performance is not crucial, select \"hot\" tier storage. Get some security information from the portal STORAGE_ACCOUNT_NAME: the main name of the storage accoutn in which you created the File share SHARE_NAME the name of the file share you just created (or are using) STORAGE_KEY this takes the most work to find. - in the Portal, open the storage account main page (not the file share, but the storage account) - on the left side, find \"Access Keys\" - this will list the storage account name, and 2 keys - each key list both the key by itself, and a \"connection string\" useful for other services - you can use either key, it doesn't matter. Use the \"show\" button to show the key so you can copy/paste it Run the container as before, but now with file share: Note in the command below, I'm using the \"line continuation\" characther \"\\\" that works for Bash shell and maybe Powershell. If you are using Windows you may have to adjust the syntax In the command below, replace the az container create --resource-group \"put your resource group name here\" \\ --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest \\ --dns-name-label \" put a unique name here\" --ports 8888 \\ --azure-file-volume-account-name STORAGE_ACCOUNT_NAME \\ --azure-file-volume-share-name SHARE_NAME \\ --azure-file-volume-account-key STORAGE_KEY \\ --azure-file-volume-mount-path /home/jovyan/notebooks For example : az container create --resource-group \"ccf22_billspat\" \\ --name jupyterlab-test --image docker.io/jupyter/datascience-notebook:latest \\ --dns-name-label \"jupyterlab-test\" --ports 8888 \\ --azure-file-volume-account-name stbillspatccf22 \\ --azure-file-volume-share-name ccf22billspat \\ --azure-file-volume-account-key dve+w+fw8XUSLE91pKO2i6.....etc....KV49ZHYEY07qsvBBpnPV9+AStjQ7vFg == \\ --azure-file-volume-mount-path /home/jovyan/notebooks The web address for the Juypter lab server, after looking up the security Token using the methods describe above is: jupyterlab-test.northcentralus.azurecontainer.io:8888/lab?token=7e0ef407a591f10cfb358850c25cdc6529742309366382f0 note that if you use Azure Blob storage, you can read/write to it using Python commands without having to connect when you build the container. You need the connection string and to have the Azure python packages installed (see below for inforemation on how to modify the datascience-notebook image to install more python packages) Creating containers using the Azure Portal The portal has nice forms for creating container instances, but you will still need the three storage account information as described above.","title":"Using Cloud Storage with Azure Container instances."},{"location":"session_serverless/docker_tutorial_for_researchers/#managing-containers-in-azure","text":"If you stop teh instance you are no longer charged. You can start/stop from the command line or from the portal az container stop --resource-group ccf22_billspat --name jupyterlab-test # later... az container start --resource-group ccf22_billspat --name jupyterlab-test # this does take a while, but may be easier than recreating it. However to keep your Resource group tidy, if you are finished with a container instannce for a while you should delete it. az container start --resource-group ccf22_billspat --name jupyterlab-test","title":"Managing Containers in Azure"},{"location":"session_serverless/docker_tutorial_for_researchers/#azure-container-instance-alternate-method","text":"There are several ways to do this - of course there are, this is Microsoft! Microsoft worked with the Docker company to get commands built into the docker utility to be able to run docker files via your laptop. In Docker-world, a 'context' is how the container is run, which could be different folders on your laptop, some kind of fancy docker server, or a cloud service. The following are pretty clear instructions for using the Docker 'context' for connection to Azure container instance (ACI) and when you docker run the container will load on Azure instead of your laptop. It's not clear to me exactly which is a better method, however with this method you get all the options available to you via the docker run command, except mounting a volume from your laptop of course. https://devblogs.microsoft.com/devops/publishing-azure-container-instances-from-docker-cli/","title":"Azure Container Instance Alternate Method"},{"location":"session_serverless/docker_tutorial_for_researchers/#yet-another-method-for-docker-containers-from-microsoft-visual-studio-code","text":"If you are a Visual Studio Code user, there is a Docker plugin for editing Dockerfiles and running them on Azure : https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker I have not tested this but if it may be useful for debugging a complex Dockerfile.","title":"Yet another method for Docker Containers from Microsoft : Visual Studio Code"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-iii-diy","text":"While you may find a ready made Docker image that has all you need, chances are you'll need to modify it for your own work, and that means making your own images. Select a Base Image. We always start with an exissting image. Could be a very basic version of Linux that we install everything into, or an existing full image that we just add a little to. Write a Dockerfile : instructions for adding things to the base image (install software, configuration, copying code or data) Build: from the Dockerfile create an image. on your own computer using the Docker software on a remote repository, like Azure which lets you build on their system Option: upload to a remote repository to be able to pull the image from other places Run: run to create a container from the image the image you just built on your computer, or from the remote repository you just uploaed to (see optional step above) (e.g pull from remote and run) There is documentation from Docker about what does into a dockerfile, but I find that confusing as they talk about each command, but not how the commands go together. There are many tutorials for building Dockerfiles to run websites, but not many (if any ) for researchers! We've been using Docker images from Jupyter-Stacks. Here is their example Dockerfile that installs python packages on to their base image: https://github.com/jupyter/docker-stacks/blob/main/scipy-notebook/Dockerfile This is a bit complex example but it has many of the ingredients of a standard Dockerfile. Main sections: FROM always start with a base container. They ARGS set variables to re-use later in the file. This makes it easy to change in just one place RUN run a linux command in the base container to install something, or set configuration. Note that most of these try to bundle as many commands as possible into on RUN to save space, and hence use the \"Line continuation\" character to make the command readable. In the linux shell is usually the back slash or \\ - when you see that it means continue on the next line for this command. You will also see && operator which says keep going and run the next command. These two things allow for very very long commands to run at once (and make the container smaller) COPY copy something from your computer into the container : data, code, configuration files, etc This example uses the example Notebook file you downloaded for Part 1 above, but let's download it again. The datascience Jupyter is great, but what if you want to do Natural Language analysis? We need the [NLTK] package for that, along with the data file for stop words. Let's create new container that starts with the Jupyter Stacks data science image, and adds those things. FROM jupyter/datascience-notebook:latest RUN pip install nltk && python -c 'from nltk import download; download(\"stopwords\")' To build a new image called \"jupyter_nltk\", save this as a file called \"Dockerfile\" in a folder by itself and run cd \"folder where yuor docker file is\" docker build -t jupyter_nltk:latest -f Dockerfile . Note the command has a period / dot at the end and that's required if the docker file is in the directory from which your run the command To run this new container, use this command. Notice that since this Image is on your let's say you also wanted to copy a notebook file called \"example.ipynb\" from the same directoery that the docker into this container for demonstration. You could do this: FROM jupyter/datascience-notebook:latest RUN pip install nltk && python -c 'from nltk import download; download(\"stopwords\")' COPY example.ipynb $HOME","title":"Part III.  DIY!"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-iii-bonusdiy-containers-in-azure","text":"This is the culmination of all of knowledge above, and actually what researchers most likely need to do: run a container that they have created in the cloud The key concept here is a container registry, which contains \"repositories\" which are history and versions of container images. A registry is a web application to build and store Docker images. Dockerhub is the most widely used container repository and you could use that, but with Azure you can make your own private registry. Here are instructions for using Dockerhub: https://www.docker.com/blog/how-to-build-and-test-your-docker-images-in-the-cloud-with-docker-hub/ . Dockerhub is a great option if you want to share your images with others (at no cost to you!). However We will be using Azure since this A note about terminology: A \"registry\" is a service that can hold many images. Each image has versions (e.g. tags, latest, v1, v2, v2022, etc), and so this is called a \"repository\" you create your own registry/repository that is private just to you (and or your lab or workgroup). There is a fee for this but it's not much. The advantage to Azure Container registries is you can keep them private, and you can create the repository and build images with the az comnmand line (or the protal as usual) see https://learn.microsoft.com/en-us/cli/azure/acr?view=azure-cli-latest about the ACR service. Microsoft also has a tutorial for creating an Azure Container Registry using a container image from their own public registry https://learn.microsoft.com/en-us/azure/container-registry/container-registry-quickstart-task-cli that is pretty good. However the steps below build upon the Dockerfile created above. 1. Create a registry to hold your images Create an ACR (azure container repository)/ with the command line (replace ACR name and resource group name to match yours ): az acr create -n <UNIQUEREGISTRYNAME> -g RESOURCEGROUPNAME --sku Standard 2. then use that ACR to build the Docker image from your local Dockerfile. First, use cd to change to the directory with your dockerfile in it with cd /path/to/my/Docker/folder Assuming there is a Dockerfile in the currenct directory (e.g. if your terminal is in the same folder as the Dockerfile above) az acr build -t jupyter-nltk:latest --file Dockerfile --registry UNIQUEREGISTRYNAME . Command ends with a single \"dot\" indicating we are using the Dockerfile that is present in this folder. 3. Run the container on ACI from the ACR Once built, you can create containers from this image. By default any Container registry you created in Azure is private (unlike the public Dockerhub). So when you want to use image that's hosted in a private Azure container registry like the one created above, you must supply credentials to access the registry. get the full name of the container registry login server using the command line (or the Portal): az acr show --name <UNIQUEREGISTRYNAME> --query loginServer (this does not ahve storage account mounted): az container create --resource-group \"ccf22_billspat\" \\ --name jupyterlab-nltk --image jupyterlab-nltk:latest \\ --dns-name-label \"jupyterlab-nltk\" --ports 8888 You can find the web address by visiting the portal, using az container show as described above, and you'll also need to the token from the logs, which is also described. I put a collection of code to combine the steps for this online: https://gist.github.com/psbills/5d42a55d53f0403ba5770b876dd74a3d This should work on Mac, Linux, and the Azure Cloud shell. (Not tested on Windows)","title":"Part III Bonus:DIY containers in Azure"},{"location":"session_serverless/linux_containers_and_the_cloud/","text":"Linux Containers, Research, & the cloud For Session 6: Serverless Cloud Computing The container metaphor for this kind of computing relfects how a standard-sized box can be carried on ships, trains, and trucks at different scales About this material Understading this material is not necessary to use cloud computing, and being advanced is optional for the cloud computing fellowship. However, Linux containers are the heart of much of the cloud works, and becoming more prevelant for running complex research software. Container technology was invented to support IT Systems (to run servers), like many things we discussed in the first session. However value was discovered for research (reproducibility, configuraiton management) and it's become more common to find research software and projects that provide a 'Dockerfile' and instructions for running using containers. Some workflows, especially in bioinformatics, are complete container based. One reason is that containers can be run (and be useful) on your own computer, on an on-premise server, and especially in the cloud with nearly identical results. VMs are great, but... The abstraction of a \"Virtual Machine\" (VM) solves the problem of requiring 1-1 physcial hardware-to-server. Now you can have one large computer that can host many smaller VMs which is more efficient. In addition, a VM can be saved as a \"virtual hard drive\" and turned off, or moved to a different physical hardware, or even backedup. Otherwise IT system administrators may have have to re-install everything over again. However becauase of the architecture there Virtual Machines can be unflexible. When you created your vitual machine, you specified how much memory you needed and how much disk space you needed. The physical machine must then reserve a part of it's memory and disk permanently, even if you your VM may not be working that hard. One IT Manager of a virtualization system reported that most of the VMs were only using 5% of what they had reserved. That's very inefficient! However the people that created the VMs (people like you ) wanted to ensure they had enough compute power to get done what they needed. Another problem is that each VM has a full copy of an operating system, like any computer. So a physical computer, you are responsible for keeping the operating system up-to-date, secure, and free from viruses. What if there was a way to share a large computers memory, diskspace and underlying operating system dynamically? Introduction to Containers Many different groups contributed to solutions to the problems of process isolation and management including Google. The most popular from a company called \"Docker.\" Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the MSU HPC we use Singularity containers but for now focus on Docker, which works with Azxure. Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. Unlike virtual machines, containers share the resources dynamically and are much more isolated. In addition, unlike virtual machines, Docker containers can be created from a code/configuration file that specifies what goes in them. That means someone can give you this file, and you can \"run\" it to create a whole system that does what you need, one time or many times. you can use code to define exactly what will go into a container, making it reproducible. Techincally you can to this with VMs with different kinds of platforms, but it's more difficult and requires more detailed knowledge of operating system you can run a container on any cloud service, or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. The Docker company created this format to be easy to use, so you can find someone who hs written the container code file to launch your system, or if you create complex software system for your research, you could provide a container file that makes it easy for others to run yuor scientific software. This is not uncommond for bioinformatics software. How can I use it on my computer? You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. The Docker is primarily an invisible background process, hidden system files, and CLI commands. However for Windows and Mac, the \"docker desktop\" wraps a user interface around those things. How can I used them on the Cloud? Azure offers several options, but to start Azure Container Instances (ACI) Azure alternative to \"Docker hub\" is the Azure Container Registry (ACR) . You can use the ACR to build images for you so you don't have to install docker to use them on Azure. Why use containers on the cloud The goal of using VMs and Containers can overlap. However there are some advantages to using Container Instances : You can create a working container instance from code without having to install anything manually as you do with a VM. The alternatives for VM is to find an existing VM image inthe azure marketplace, or to save your disk and use that as a template for additional VMs. You can run exactly the same software configuration on your laptop, on Azure, or on any other cloud vendor Dockerfiles can be shared with a colleague easier than sharing a VM disk image When a container instance is off, there is no charge. Yes! That's because resources are only allocated when it's running. Much less to manage. When a VM you are responsible for keeping the operation system up to date, all security patches installed and ensuring it does not get hacked. Better security since you are not maintaining an operating system. There are still some security implications for containers that run servers, but much fewer since you are reponsible for the application only. Advantages of VMs over ACI more control over networking many more options for machine types and sizes. Container instances are limited many more options for disk configurations, etc if you need to optimize performance or need very high performance from a single machine, VMS may be better choice more familiar and so conceptually easier to use can use Azure VM Scale Sets for multiple VMS (there is probably a similar service for ) What can I use it for? Following this process, you may find that a large research software project has a \"Dockerfile\" as part of it's code base. This is a set of instructions for building everything needed to run the software using containers. You may find that two commands docker build and docker run are all you need to have a working environment to use a program. Containers often are for running complex cloud-based applications that have manu components: Web servers, database servers, message managers, etc. Using containers allows companies to manage the components of the application instaed of all of the hardware and operating systems of the systems. This is a major shift and why it's called \"serverless. However containers can be useful for batch computing, that is running a calculation or building a machine learning model. With servers, you start a container and leave it running. But you can also \"docker run,\" the containers could take input, do their work, and exit. Everything needed to complete the calculation is bundled in the container, and does not pollute your computer with special software installs. What is Kubernetes? You will see a technology called Kubernetes mentioned everywhere. This is for \"orchestrating\" many containers: helping to create and launch many complete interrelated components, let components talk to each other, keeping them running, reporting on their healht, and for most companies now, scale them automaticaly by creating replicas to meet demand. Kubernetes is not widely used in research because of it's complexity but if you have complete workflows or systems to maintain it may be worth investigating. You don't need Kubernetes to run single or even a couple of containers, but could is known to be utilized for large compute clusters, running spark, or even HPC-type workloads. For small numbers of containers There are other solutions (such as Azure Batch ), or you can connect them yourself with coordinating code. Using Kubernetes can be an entire career but may be necessary when building complex systems with containers. Reading An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Great series introducting Docker For Science This is better than what I've written so far! Another very colloquial but helpful introduction to containers from \"MyGreatLearning.com\" : https://www.mygreatlearning.com/blog/docker-tutorial/ This describes a really important use case of containers which is to enhance reproducibility. How often have you been told \"this code works for me\" but you are unable to run it, or it's a huge task to get everything installed just right. Reproducibility is crucial software development requires a complex developer or running environment. Even simply the differences between Mac, Windows, and Linux! Docker Overview Azure Container Service Overview Tutorial There are many many tutorials, blogs, videos, etc for Container Technology. That didn't stop me from making one of my own, but geared for you, the researcher: Docker Tutorial for Researchers featuring Jupyter Lab . Activities For Windows users : Get started: Set up Linux Containers on Windows 10 and check the Pre-requisites . Also note on Windows and only windows you can run either a Linux container or a Windows container. The vast majority of published containers, and the containers we'll be using are Linux, and that's what this tutorial covers. Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure. We aren't suggesting you run a web application for your project, but almost all of the tutorials are about Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker Jupyter Hub: running Jupyter with everything installed just right can be problematic: The Jupyter Stacks Project is to create bundles to include everything you need for a particular kind of research. Note I have not tried to get this running on Azure - could it be done? Would it be helpful? optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance Optional training activity: Introduction to Kubernetes from Microsoft.","title":"Linux Containers, Research, & the cloud"},{"location":"session_serverless/linux_containers_and_the_cloud/#linux-containers-research-the-cloud","text":"","title":"Linux Containers, Research, &amp; the cloud"},{"location":"session_serverless/linux_containers_and_the_cloud/#for-session-6-serverless-cloud-computing","text":"The container metaphor for this kind of computing relfects how a standard-sized box can be carried on ships, trains, and trucks at different scales","title":"For Session 6: Serverless Cloud Computing"},{"location":"session_serverless/linux_containers_and_the_cloud/#about-this-material","text":"Understading this material is not necessary to use cloud computing, and being advanced is optional for the cloud computing fellowship. However, Linux containers are the heart of much of the cloud works, and becoming more prevelant for running complex research software. Container technology was invented to support IT Systems (to run servers), like many things we discussed in the first session. However value was discovered for research (reproducibility, configuraiton management) and it's become more common to find research software and projects that provide a 'Dockerfile' and instructions for running using containers. Some workflows, especially in bioinformatics, are complete container based. One reason is that containers can be run (and be useful) on your own computer, on an on-premise server, and especially in the cloud with nearly identical results.","title":"About this material"},{"location":"session_serverless/linux_containers_and_the_cloud/#vms-are-great-but","text":"The abstraction of a \"Virtual Machine\" (VM) solves the problem of requiring 1-1 physcial hardware-to-server. Now you can have one large computer that can host many smaller VMs which is more efficient. In addition, a VM can be saved as a \"virtual hard drive\" and turned off, or moved to a different physical hardware, or even backedup. Otherwise IT system administrators may have have to re-install everything over again. However becauase of the architecture there Virtual Machines can be unflexible. When you created your vitual machine, you specified how much memory you needed and how much disk space you needed. The physical machine must then reserve a part of it's memory and disk permanently, even if you your VM may not be working that hard. One IT Manager of a virtualization system reported that most of the VMs were only using 5% of what they had reserved. That's very inefficient! However the people that created the VMs (people like you ) wanted to ensure they had enough compute power to get done what they needed. Another problem is that each VM has a full copy of an operating system, like any computer. So a physical computer, you are responsible for keeping the operating system up-to-date, secure, and free from viruses. What if there was a way to share a large computers memory, diskspace and underlying operating system dynamically?","title":"VMs are great, but..."},{"location":"session_serverless/linux_containers_and_the_cloud/#introduction-to-containers","text":"Many different groups contributed to solutions to the problems of process isolation and management including Google. The most popular from a company called \"Docker.\" Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the MSU HPC we use Singularity containers but for now focus on Docker, which works with Azxure. Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. Unlike virtual machines, containers share the resources dynamically and are much more isolated. In addition, unlike virtual machines, Docker containers can be created from a code/configuration file that specifies what goes in them. That means someone can give you this file, and you can \"run\" it to create a whole system that does what you need, one time or many times. you can use code to define exactly what will go into a container, making it reproducible. Techincally you can to this with VMs with different kinds of platforms, but it's more difficult and requires more detailed knowledge of operating system you can run a container on any cloud service, or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. The Docker company created this format to be easy to use, so you can find someone who hs written the container code file to launch your system, or if you create complex software system for your research, you could provide a container file that makes it easy for others to run yuor scientific software. This is not uncommond for bioinformatics software.","title":"Introduction to Containers"},{"location":"session_serverless/linux_containers_and_the_cloud/#how-can-i-use-it-on-my-computer","text":"You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. The Docker is primarily an invisible background process, hidden system files, and CLI commands. However for Windows and Mac, the \"docker desktop\" wraps a user interface around those things.","title":"How can I use it on my computer?"},{"location":"session_serverless/linux_containers_and_the_cloud/#how-can-i-used-them-on-the-cloud","text":"Azure offers several options, but to start Azure Container Instances (ACI) Azure alternative to \"Docker hub\" is the Azure Container Registry (ACR) . You can use the ACR to build images for you so you don't have to install docker to use them on Azure.","title":"How can I used them on the Cloud?"},{"location":"session_serverless/linux_containers_and_the_cloud/#why-use-containers-on-the-cloud","text":"The goal of using VMs and Containers can overlap. However there are some advantages to using Container Instances : You can create a working container instance from code without having to install anything manually as you do with a VM. The alternatives for VM is to find an existing VM image inthe azure marketplace, or to save your disk and use that as a template for additional VMs. You can run exactly the same software configuration on your laptop, on Azure, or on any other cloud vendor Dockerfiles can be shared with a colleague easier than sharing a VM disk image When a container instance is off, there is no charge. Yes! That's because resources are only allocated when it's running. Much less to manage. When a VM you are responsible for keeping the operation system up to date, all security patches installed and ensuring it does not get hacked. Better security since you are not maintaining an operating system. There are still some security implications for containers that run servers, but much fewer since you are reponsible for the application only.","title":"Why use containers on the cloud"},{"location":"session_serverless/linux_containers_and_the_cloud/#advantages-of-vms-over-aci","text":"more control over networking many more options for machine types and sizes. Container instances are limited many more options for disk configurations, etc if you need to optimize performance or need very high performance from a single machine, VMS may be better choice more familiar and so conceptually easier to use can use Azure VM Scale Sets for multiple VMS (there is probably a similar service for )","title":"Advantages of VMs over ACI"},{"location":"session_serverless/linux_containers_and_the_cloud/#what-can-i-use-it-for","text":"Following this process, you may find that a large research software project has a \"Dockerfile\" as part of it's code base. This is a set of instructions for building everything needed to run the software using containers. You may find that two commands docker build and docker run are all you need to have a working environment to use a program. Containers often are for running complex cloud-based applications that have manu components: Web servers, database servers, message managers, etc. Using containers allows companies to manage the components of the application instaed of all of the hardware and operating systems of the systems. This is a major shift and why it's called \"serverless. However containers can be useful for batch computing, that is running a calculation or building a machine learning model. With servers, you start a container and leave it running. But you can also \"docker run,\" the containers could take input, do their work, and exit. Everything needed to complete the calculation is bundled in the container, and does not pollute your computer with special software installs.","title":"What can I use it for?"},{"location":"session_serverless/linux_containers_and_the_cloud/#what-is-kubernetes","text":"You will see a technology called Kubernetes mentioned everywhere. This is for \"orchestrating\" many containers: helping to create and launch many complete interrelated components, let components talk to each other, keeping them running, reporting on their healht, and for most companies now, scale them automaticaly by creating replicas to meet demand. Kubernetes is not widely used in research because of it's complexity but if you have complete workflows or systems to maintain it may be worth investigating. You don't need Kubernetes to run single or even a couple of containers, but could is known to be utilized for large compute clusters, running spark, or even HPC-type workloads. For small numbers of containers There are other solutions (such as Azure Batch ), or you can connect them yourself with coordinating code. Using Kubernetes can be an entire career but may be necessary when building complex systems with containers.","title":"What is Kubernetes?"},{"location":"session_serverless/linux_containers_and_the_cloud/#reading","text":"An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Great series introducting Docker For Science This is better than what I've written so far! Another very colloquial but helpful introduction to containers from \"MyGreatLearning.com\" : https://www.mygreatlearning.com/blog/docker-tutorial/ This describes a really important use case of containers which is to enhance reproducibility. How often have you been told \"this code works for me\" but you are unable to run it, or it's a huge task to get everything installed just right. Reproducibility is crucial software development requires a complex developer or running environment. Even simply the differences between Mac, Windows, and Linux! Docker Overview Azure Container Service Overview","title":"Reading"},{"location":"session_serverless/linux_containers_and_the_cloud/#tutorial","text":"There are many many tutorials, blogs, videos, etc for Container Technology. That didn't stop me from making one of my own, but geared for you, the researcher: Docker Tutorial for Researchers featuring Jupyter Lab .","title":"Tutorial"},{"location":"session_serverless/linux_containers_and_the_cloud/#activities","text":"For Windows users : Get started: Set up Linux Containers on Windows 10 and check the Pre-requisites . Also note on Windows and only windows you can run either a Linux container or a Windows container. The vast majority of published containers, and the containers we'll be using are Linux, and that's what this tutorial covers. Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure. We aren't suggesting you run a web application for your project, but almost all of the tutorials are about Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker Jupyter Hub: running Jupyter with everything installed just right can be problematic: The Jupyter Stacks Project is to create bundles to include everything you need for a particular kind of research. Note I have not tried to get this running on Azure - could it be done? Would it be helpful? optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance Optional training activity: Introduction to Kubernetes from Microsoft.","title":"Activities"},{"location":"session_serverless/serverless_overview/","text":"Introduction to Serverless Functions For Session 6: Overview of Serverless *Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * Intro The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that. Many problems that \"serverless\" functions can be applied to short focused function execution, many short functions triggered by external event (validate credit card) simplifying a main application into smaller functional units event processing, handling huge streams of data in small chunks components of a cloud-based workflow how to start a serverless function? if using http, use web api to send data via URL http://getweather.myfunction.azure?zipcode=48824 can listen for when a file is saved to a blob container or files folder other Azure events, database, etc Provisioning and Running code comparision VM Server : provision resources (VM, network etc) --> install OS --> install software --> add code --> give permission to read storage --> write to storage upload inputs --> start run --> outputs saved to disk or storage other tasks: update operating system and software, Serverlesss Function Process : provision resource (app service) --> grant permission to read storage --> publish code and config run on trigger --> inputs from binding --> outputs to binding Both run on a server, but or serverless Azure maintains the server - you don't even really care what it is. Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed? Example function https://github.com/bsab/azure-function-python-blob","title":"Introduction to Serverless Functions"},{"location":"session_serverless/serverless_overview/#introduction-to-serverless-functions","text":"For Session 6: Overview of Serverless *Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ *","title":"Introduction to Serverless Functions"},{"location":"session_serverless/serverless_overview/#intro","text":"The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that.","title":"Intro"},{"location":"session_serverless/serverless_overview/#many-problems-that-serverless-functions-can-be-applied-to","text":"short focused function execution, many short functions triggered by external event (validate credit card) simplifying a main application into smaller functional units event processing, handling huge streams of data in small chunks components of a cloud-based workflow","title":"Many problems that \"serverless\" functions can be applied to"},{"location":"session_serverless/serverless_overview/#how-to-start-a-serverless-function","text":"if using http, use web api to send data via URL http://getweather.myfunction.azure?zipcode=48824 can listen for when a file is saved to a blob container or files folder other Azure events, database, etc","title":"how to start a serverless function?"},{"location":"session_serverless/serverless_overview/#provisioning-and-running-code-comparision","text":"VM Server : provision resources (VM, network etc) --> install OS --> install software --> add code --> give permission to read storage --> write to storage upload inputs --> start run --> outputs saved to disk or storage other tasks: update operating system and software, Serverlesss Function Process : provision resource (app service) --> grant permission to read storage --> publish code and config run on trigger --> inputs from binding --> outputs to binding Both run on a server, but or serverless Azure maintains the server - you don't even really care what it is. Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed?","title":"Provisioning and Running code comparision"},{"location":"session_serverless/serverless_overview/#example-function","text":"https://github.com/bsab/azure-function-python-blob","title":"Example function"},{"location":"session_serverless/container_scripts/rstudio_container_script/","text":"Containers on Azure: example Script echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf22-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"},{"location":"session_serverless/container_scripts/rstudio_container_script/#containers-on-azure-example-script","text":"echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf22-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"},{"location":"session_serverless/docker_cloud_build_demo/readme/","text":"Example Docker on Azure This is a minimal example of building and running a docker container using Azure Container Registry and Azure Container Instances. Uses the smallest docker file in the world, which simply adds the NLTK python library to an existing JupyterLab server from Jupyter Docker Stacks Using an admin password for an Azure container registry is not the most secure solution for the purposes of this tutorial works. requirements azure account updated Azure command line utlities installed (az cli) logged into to Azure using az login an existing resource group Based on and depends on the Jupyter lab stack being available, see https://jupyter-docker-stacks.readthedocs.io/en/latest/ Dockerfile in the current directory written for the MSU Cloud Computing Fellowship","title":"Example Docker on Azure"},{"location":"session_serverless/docker_cloud_build_demo/readme/#example-docker-on-azure","text":"This is a minimal example of building and running a docker container using Azure Container Registry and Azure Container Instances. Uses the smallest docker file in the world, which simply adds the NLTK python library to an existing JupyterLab server from Jupyter Docker Stacks Using an admin password for an Azure container registry is not the most secure solution for the purposes of this tutorial works.","title":"Example Docker on Azure"},{"location":"session_serverless/docker_cloud_build_demo/readme/#requirements","text":"azure account updated Azure command line utlities installed (az cli) logged into to Azure using az login an existing resource group Based on and depends on the Jupyter lab stack being available, see https://jupyter-docker-stacks.readthedocs.io/en/latest/ Dockerfile in the current directory written for the MSU Cloud Computing Fellowship","title":"requirements"}]}