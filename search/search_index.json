{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MSU Cloud Fellowship 2021-2022 Welcome to the website for the MSU Cloud fellowship for 2021-2022. See our \" about \" page for more information about the program. Syllabus The program runs from Fall 2021 to Spring 2022 semester. Sessions are organized with pre-meeting materials (readings and videos), pre-requisites, and activities, which allow fellows to prepare for our Friday meetings where we will have hands-on activities and discussion. Schedule for Fall 2021 Session 1 : Introduction to the 21-22 Fellowship Sept 3: Meeting : program introductions and program overview (via zoom) Session 2 : Using the cloud for computing Sept 10: Using Virtual Machines workshop Session 3 : Cloud Storage Sept 24: Cloud Storage Workshop Session 4 : Moving data to the cloud October 8: Data utilities and services workshop (Azure Data Factory) Session 5 : Big Data Systems and the cloud Oct 22: Overview of Big Data on Azure with DataBricks Session 6 : Databases and Data Analytics Systems on the Cloud Oct 29: Overview of Databases on the cloud, SQL demonstration Session 7 : Serverless and Application Development Nov 12: Overview of Serverless and FaaS, Demonstration of Real-world project Session 8: Wrap up and project proposals Dec 3: Meeting : review and feedback on project proposals & general discussion Dec 17: Final cloud fellowship project proposal submission date Schedule for Winter/Spring 2022 2022 Cloud Fellowship Meetings We will meet virtually according to the schedule below for 'project update' presentations and group discussions. If you have a scheduling conflict, please let us know as soon as possible. February 4th : Presentation of Revised Project and current status March 4th : TBD April 8th : TBD All sessions 2:00-4:00pm EST Zoom links and password will be sent over email. Virtual Office Hours Sessions We will also hold two Friday virtual helpdesk sessions per month. Feel free to take advantage of these voluntary sessions for help with specifics on your project, presentations, and/or general research computing topics. January 14th and 28th February 11th and 25th March 18th and 25th April 1st and 15th all office hours sessions 2:00-3:30pm EST Zoom links and password will be sent over email but will be the same as for the meetings above. We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general. We will get back with you when we can and schedule a time for a virtual 1-1 meeting. Symposium and Project Presentations Participants will present projects in late April at a symposium for the Cloud Fellowship. The exact date and time to be determined, and virtual vs in-person also to be determined. Textbook We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters. Communications Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! Meeting location Given the state of the pandemic in late summer 2021, we are hosting our first meeting (September 3) via zoom. Participants will be sent a link via email. Locations for future meetings are to be determined and based on participant feedback. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Home"},{"location":"#msu-cloud-fellowship-2021-2022","text":"Welcome to the website for the MSU Cloud fellowship for 2021-2022. See our \" about \" page for more information about the program.","title":"MSU Cloud Fellowship 2021-2022"},{"location":"#syllabus","text":"The program runs from Fall 2021 to Spring 2022 semester. Sessions are organized with pre-meeting materials (readings and videos), pre-requisites, and activities, which allow fellows to prepare for our Friday meetings where we will have hands-on activities and discussion.","title":"Syllabus"},{"location":"#schedule-for-fall-2021","text":"Session 1 : Introduction to the 21-22 Fellowship Sept 3: Meeting : program introductions and program overview (via zoom) Session 2 : Using the cloud for computing Sept 10: Using Virtual Machines workshop Session 3 : Cloud Storage Sept 24: Cloud Storage Workshop Session 4 : Moving data to the cloud October 8: Data utilities and services workshop (Azure Data Factory) Session 5 : Big Data Systems and the cloud Oct 22: Overview of Big Data on Azure with DataBricks Session 6 : Databases and Data Analytics Systems on the Cloud Oct 29: Overview of Databases on the cloud, SQL demonstration Session 7 : Serverless and Application Development Nov 12: Overview of Serverless and FaaS, Demonstration of Real-world project Session 8: Wrap up and project proposals Dec 3: Meeting : review and feedback on project proposals & general discussion Dec 17: Final cloud fellowship project proposal submission date","title":"Schedule for Fall 2021"},{"location":"#schedule-for-winterspring-2022","text":"","title":"Schedule for Winter/Spring 2022"},{"location":"#2022-cloud-fellowship-meetings","text":"We will meet virtually according to the schedule below for 'project update' presentations and group discussions. If you have a scheduling conflict, please let us know as soon as possible. February 4th : Presentation of Revised Project and current status March 4th : TBD April 8th : TBD All sessions 2:00-4:00pm EST Zoom links and password will be sent over email.","title":"2022 Cloud Fellowship Meetings"},{"location":"#virtual-office-hours-sessions","text":"We will also hold two Friday virtual helpdesk sessions per month. Feel free to take advantage of these voluntary sessions for help with specifics on your project, presentations, and/or general research computing topics. January 14th and 28th February 11th and 25th March 18th and 25th April 1st and 15th all office hours sessions 2:00-3:30pm EST Zoom links and password will be sent over email but will be the same as for the meetings above. We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general. We will get back with you when we can and schedule a time for a virtual 1-1 meeting.","title":"Virtual Office Hours Sessions"},{"location":"#symposium-and-project-presentations","text":"Participants will present projects in late April at a symposium for the Cloud Fellowship. The exact date and time to be determined, and virtual vs in-person also to be determined.","title":"Symposium and Project Presentations"},{"location":"#textbook","text":"We will occasionally link to the following book: \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 MIT Press website Book Website : Cloud4SciEng.org The book website does provide open access to individual chapters.","title":"Textbook"},{"location":"#communications","text":"Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned. In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email). Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program. Mentioning one of us e.g. @billspat or @parvizm will help get our attention. Additionally you may email us at any time. If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us. If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue. If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support. This may be especially effective when fellows are developing their projects. We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions!","title":"Communications"},{"location":"#meeting-location","text":"Given the state of the pandemic in late summer 2021, we are hosting our first meeting (September 3) via zoom. Participants will be sent a link via email. Locations for future meetings are to be determined and based on participant feedback. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License","title":"Meeting location"},{"location":"about/","text":"About The MSU Cloud Fellowship The MSU Cloud Fellowship is a cross-disciplinary program produced by MSU\u2019s Institute of Cyber-Enabled Research (ICER) and the IT Services Analytics and Data Solutions (ADS) group for invited MSU doctoral students and postdoctoral researchers. As a part of this program, fellows will participate in a series of workshops during the fall semester to: Determine the aspects of your research that can be accomplished with cloud computing; Incorporate cloud-based systems into your research application or workflow; and Understand the strengths and limitations of commercial cloud computing with the goal of improving research yield and minimizing cost, and to develop a workflow that utilizes that knowledge. Background MSU doctoral students and postdoctoral researchers are invited to apply in the summer and approximately 18 are selected each year. The program started in 2019. If you are an MSU graduate student or post-doc and interested in participating next year, please check back in the Summer of 2022 for announcements on the invitation to participate, or request to join the MSU ICER mailing list Citing the MSU ICER Cloud Computing Fellowship in Research Publications We encourage cloud fellows to acknowledge the fellowship in publications arising from computational work performed during your fellowship project. Please let us know that you have referenced the fellowship, and we will link to your publication on the ICER publication site, which will further increase the visibility of your work. A sample statement can be: \"This work was supported in part through Michigan State University\u2019s Institute for Cyber-Enabled Research Cloud Computing Fellowship, with computational resources and services provided by Information Technology Services and the Office of Research and Innovation at Michigan State University.\u201d Cloud Fellowship Organizers Dr. Brian O'Shea Professor and Director, MSU ICER Role: Program Lead, ICER Dr. Brian O'Shea is a computational and theoretical astrophysicist studying cosmological structure formation, including galaxy formation and the behavior of the hot, diffuse plasma in the intergalactic medium and within galaxy clusters. He is also a co-author of the Enzo AMR code, an expert in high performance computing, and an advocate for open-source computing and open-source science. He received his B.S. in Engineering Physics at the University of Illinois in Urbana-Champaign (UIUC) in 2000, and his PhD in physics from UIUC in 2005 (with 2002-2005 being spent as a graduate student in residence at the Laboratory for Computational Astrophysics at UC San Diego and in the Theoretical Astrophysics Group at Los Alamos National Laboratory). Following that, he was a Director's Postdoctoral Fellow at Los Alamos National Laboratory, with a joint appointment between the Theoretical Astrophysics Group and the Applied Physics Division. Since 2008, he has been a member of the faculty at Michigan State University, with a joint appointment between the Department of Computational Mathematics, Science and Engineering (2015-present), the Department of Physics and Astronomy (2008-present), and the National Superconducting Cyclotron Laboratory (2014-present). From 2008-2015, Dr. O'Shea was a member of Lyman Briggs College. He has authored or co-authored over 75 peer-reviewed journal articles in astrophysics, computer science, and education research journals, and has received a variety of awards for his teaching and public outreach efforts. In 2016, he became a Fellow of the American Physical Society, and in 2019 he became the director of MSU's Institute for Cyber-Enabled Research. Danielle Barnes Assistant Director, ADS, MSU IT Services Role: Program Lead, IT Services Patrick Bills Data Science Technical Lead, MSU IT Services Role: Lead Instructor Pat Bills research background is in data systems for ecology (MS Entomology, MSU). He has experience in database design, R, Python, and web application programming. Pat has worked in research IT for over 25 yrs for departments and labs across MSU, including for MSU ICER as a research consultant and trainer. He is currently the technical lead for the data science team within ADS. Like many, he has built and worked with on-campus linux systems for many years including the MSU HPC. Pat started my cloud journey in 2017 during a workshop at the HPC conference where he saw Ian Foster (our textbook author) present his vision of research on the cloud. Since then he has used cloud services from Google, Amazon, and Azure - currently focusing on Microsoft Azure. ADS uses cloud services where appropriate for their data systems or applications, and he will use examples directly from that work in this class. Dr. Mahmoud Parvizi Research Consultant, MSU ICER Role: Assistant Instructor Mahmoud earned his PhD in physics from Vanderbilt University with research in high-energy theory in the context of early universe cosmology as well as computational astrophysics. In addition, Mahmoud earned an MBA with a concentration in finance from the University of Michigan - Flint. Mahmoud was formerly a postdoctoral research associate in the Department of Physics and Astronomy at Michigan State University with a focus on machine learning applications of cloud-computing workflows and currently a research consultant for the MSU Institute for Cyber-Enabled Research (ICER). He participated as a cloud fellow in 2019 and co-instructor of the cloud fellowship in 2020. Mahmoud\u2019s diverse research interests include mathematical and theoretical physics, data-intensive astrophysics, machine learning for precision health, and cloud-computing platforms for academic research. His expertise includes 1) quantum field theory in curved/non-stationary spacetimes; 2) finite temperature quantum field theory and open quantum systems; 3) automated and end-to-end intelligent data pipelines for signal processing using compressed sensing and applied harmonic analysis; 4) machine learning and cloud-computing applications for precision health. Chelsea Beck Data Warehouse Lead, ADS, MSU IT Services Role: Logistics and Organizational expertise Previous Cloud Fellows 2019-2020 MSU Cloud Computing Fellows Summary of the first cohort of MSU Cloud Computing Fellows 2020-2021 Introducing the 2020 Cloud Fellows 20-21 Cloud Computing Fellowship Culminates in Impressive Symposium","title":"About"},{"location":"about/#about-the-msu-cloud-fellowship","text":"The MSU Cloud Fellowship is a cross-disciplinary program produced by MSU\u2019s Institute of Cyber-Enabled Research (ICER) and the IT Services Analytics and Data Solutions (ADS) group for invited MSU doctoral students and postdoctoral researchers. As a part of this program, fellows will participate in a series of workshops during the fall semester to: Determine the aspects of your research that can be accomplished with cloud computing; Incorporate cloud-based systems into your research application or workflow; and Understand the strengths and limitations of commercial cloud computing with the goal of improving research yield and minimizing cost, and to develop a workflow that utilizes that knowledge.","title":"About The MSU Cloud Fellowship"},{"location":"about/#background","text":"MSU doctoral students and postdoctoral researchers are invited to apply in the summer and approximately 18 are selected each year. The program started in 2019. If you are an MSU graduate student or post-doc and interested in participating next year, please check back in the Summer of 2022 for announcements on the invitation to participate, or request to join the MSU ICER mailing list","title":"Background"},{"location":"about/#citing-the-msu-icer-cloud-computing-fellowship-in-research-publications","text":"We encourage cloud fellows to acknowledge the fellowship in publications arising from computational work performed during your fellowship project. Please let us know that you have referenced the fellowship, and we will link to your publication on the ICER publication site, which will further increase the visibility of your work. A sample statement can be: \"This work was supported in part through Michigan State University\u2019s Institute for Cyber-Enabled Research Cloud Computing Fellowship, with computational resources and services provided by Information Technology Services and the Office of Research and Innovation at Michigan State University.\u201d","title":"Citing the MSU ICER Cloud Computing Fellowship in Research Publications"},{"location":"about/#cloud-fellowship-organizers","text":"Dr. Brian O'Shea Professor and Director, MSU ICER Role: Program Lead, ICER Dr. Brian O'Shea is a computational and theoretical astrophysicist studying cosmological structure formation, including galaxy formation and the behavior of the hot, diffuse plasma in the intergalactic medium and within galaxy clusters. He is also a co-author of the Enzo AMR code, an expert in high performance computing, and an advocate for open-source computing and open-source science. He received his B.S. in Engineering Physics at the University of Illinois in Urbana-Champaign (UIUC) in 2000, and his PhD in physics from UIUC in 2005 (with 2002-2005 being spent as a graduate student in residence at the Laboratory for Computational Astrophysics at UC San Diego and in the Theoretical Astrophysics Group at Los Alamos National Laboratory). Following that, he was a Director's Postdoctoral Fellow at Los Alamos National Laboratory, with a joint appointment between the Theoretical Astrophysics Group and the Applied Physics Division. Since 2008, he has been a member of the faculty at Michigan State University, with a joint appointment between the Department of Computational Mathematics, Science and Engineering (2015-present), the Department of Physics and Astronomy (2008-present), and the National Superconducting Cyclotron Laboratory (2014-present). From 2008-2015, Dr. O'Shea was a member of Lyman Briggs College. He has authored or co-authored over 75 peer-reviewed journal articles in astrophysics, computer science, and education research journals, and has received a variety of awards for his teaching and public outreach efforts. In 2016, he became a Fellow of the American Physical Society, and in 2019 he became the director of MSU's Institute for Cyber-Enabled Research. Danielle Barnes Assistant Director, ADS, MSU IT Services Role: Program Lead, IT Services Patrick Bills Data Science Technical Lead, MSU IT Services Role: Lead Instructor Pat Bills research background is in data systems for ecology (MS Entomology, MSU). He has experience in database design, R, Python, and web application programming. Pat has worked in research IT for over 25 yrs for departments and labs across MSU, including for MSU ICER as a research consultant and trainer. He is currently the technical lead for the data science team within ADS. Like many, he has built and worked with on-campus linux systems for many years including the MSU HPC. Pat started my cloud journey in 2017 during a workshop at the HPC conference where he saw Ian Foster (our textbook author) present his vision of research on the cloud. Since then he has used cloud services from Google, Amazon, and Azure - currently focusing on Microsoft Azure. ADS uses cloud services where appropriate for their data systems or applications, and he will use examples directly from that work in this class. Dr. Mahmoud Parvizi Research Consultant, MSU ICER Role: Assistant Instructor Mahmoud earned his PhD in physics from Vanderbilt University with research in high-energy theory in the context of early universe cosmology as well as computational astrophysics. In addition, Mahmoud earned an MBA with a concentration in finance from the University of Michigan - Flint. Mahmoud was formerly a postdoctoral research associate in the Department of Physics and Astronomy at Michigan State University with a focus on machine learning applications of cloud-computing workflows and currently a research consultant for the MSU Institute for Cyber-Enabled Research (ICER). He participated as a cloud fellow in 2019 and co-instructor of the cloud fellowship in 2020. Mahmoud\u2019s diverse research interests include mathematical and theoretical physics, data-intensive astrophysics, machine learning for precision health, and cloud-computing platforms for academic research. His expertise includes 1) quantum field theory in curved/non-stationary spacetimes; 2) finite temperature quantum field theory and open quantum systems; 3) automated and end-to-end intelligent data pipelines for signal processing using compressed sensing and applied harmonic analysis; 4) machine learning and cloud-computing applications for precision health. Chelsea Beck Data Warehouse Lead, ADS, MSU IT Services Role: Logistics and Organizational expertise","title":"Cloud Fellowship Organizers"},{"location":"about/#previous-cloud-fellows","text":"2019-2020 MSU Cloud Computing Fellows Summary of the first cohort of MSU Cloud Computing Fellows 2020-2021 Introducing the 2020 Cloud Fellows 20-21 Cloud Computing Fellowship Culminates in Impressive Symposium","title":"Previous Cloud Fellows"},{"location":"cloud_glossary/","text":"Glossary of Cloud Terms Why? Researchers using the cloud must know a little about a lot of information technology to get computational work done in their domain specialty. Most cloud glossaries are for systems administrators, not the rest of us. This glossary is much more brief than Wikipedia and hopefully also provides the context a researcher needs to find what you need to use cloud services in your work. Do you have an item to add? Please contact us ! Other Glossaries https://www.cloudbank.org/cloud-terms The Glossary Arm CPU CPU from \"Advanced RISC Machines, ltd. While historically most computers used Intel CPUs, ARM provides an alternative CPU that is becoming more popular and present as an option in HPC and Cloud Virtual Machine options. The vast majority of software written for Intel computers is compatible with ARM. Some computational work is sensitive to CPU choice, and CPU choice can affect cost and speed of excecution, so it may be important to understand the implications of this choice of CPU. ARM Template A specification file listing all of the cloud resources and configuration settings tha that the Azure Resource Manager can use to create resources for you when you submit it a certain way. Templates are a great shortcut and automation feature but difficult to edit. For details see Azure Documentation: What are ARM templates? Azure Resource Manager (ARM) see Resource Manager =#### Blob Storage Azure calls there object cloud storage \"Blobs\". It is similar to Amazon Web Service 'S3' and Google cloud storage buckets. Azure Documentation: Introduction to Azure Blob storage While it's possible to 'mount' blob storage to linux VMs using 'blob fuse' or similar packages, it can not work as you may expect and so in practice Azure Files are a better solution for that. See File Storage Client-Server Client/Server model of computing is something we use everyday but perhaps dont' use this term. See https://techterms.com/definition/client-server_model You are used to using maybe a dozen clients everyday (phone apps, web browser, ssh to connect to a remote linux, Remote Desktop client to connect to remote desktop server, etc). Cloud computing provides all the infrastructure needed to create servers quickly and easily. Containers Or Docker Containers (not all containers need to be Docker the vast majority of container system use Docker). For R users, see https://colinfay.me/docker-r-reproducibility/ For Python users, there is https://www.netguru.com/blog/python-docker-tutorial although you could read either. Linux Containers is a term for a collection of methods and technologies that allows a multiple isolated systems to be run on one Linux computer. This is differnet from virtual machines in that a VM host provides abstract or virtualized hardware so each VM requires it's own portion of memory and CPU cores whereas containers share the main part of Linux (the kernel), memory and CPU more dynamically. The primary comercial company for containers is \"Docker\" so Docker is sometimes used synonymously with 'container' but it is just one form. In addition to being more efficient than VMs, most container systems have a system and scripting language for building containers. The means onecan provision an entire system from code. Containers are widely use to package and distribute complex research software systems for example Bioinformatics workflow system \"Cromwell.\" This way reseearches can download and use a pre-installed system without the trouble of getting all of the pre-requistes (dependencies) installed on their machine. CPU Central Processing Unit, the main 'chip' of a computer, and a core component when specifying a Virtual Machine 'size' DevOps This has many definitions but for researchers the shortcut is using code to make IT infrastructure. Helping developers (like you) do Ops (like sysadmins) with code. see IaC. Docker Docker is the most prevalent form of \"Containers\", e.g Docker is to containers as google is to search. See containers above for details. Note that Docker is many things as once: a method and format for Linux containers, a program for working with container ( e.g. docker build... ), a Company, and that's company's hub or repository for storing and access free containers (or your own). Cloud companies also have \"hubs\" or repositories for storing your own Docker containers. File Storage (Azure) Also called \"Azure Files.\" Azure cloud storage that is more traditional file sharing, and that can be connected (mounted) to computers and other services using the SMB protocal, making it similar experience to departmental shared fileservers. See https://azure.microsoft.com/en-us/services/storage/files/ and compare with Blob Storage Firewall A common concept in networking, firewall software on a computer's networking components limits which kind of traffic can come in or out, and restricts which computer internet addresses can connect. Best practices suggest closing all connections via the firewall, only opening those connections for services you need, and only to those users (e.g. your own computer) you need to. Azure additionally has an option to \"allow connections from Azure networks\" so that you can freely connect from the portal, 'cloud shell', or connect from on azure service to another. The implication is that you trust all Azure services. GPU From Wikipedia: https://en.wikipedia.org/wiki/Graphics_processing_unit GPUs can be very helpful for some code written to use them, especially many machine learning libraries, and Virtual Machines may be provisioned with GPUs. Infrastructure as Code (IaC) In stead of using a GUI, or manual steps to create cloud computing, cloud resources may be created using scripts that interact with the cloud provider's api, and additional scripts can configure individual resources (such as to install software on a VM or configure a database). Doing this kind of \"provisioning\" with scripts makes it reproducible and debuggable which is at the heart of the Workflow or DevOps mentality. IP Address a unique string of characters that identifies each computer using the Internet Protocol to communicate over a network. Your computer will have a different IP address depending on where you are located (home, work, field). In addition, a home wifi router will assign a 'local' ip address for inside your home, but your 'public' internet IP address will be different. To find your own IP address, simply google \"what is my ip.\" All Azure services (VMs, data systems, etc) are assigned IP addresses via networking. see https://docs.microsoft.com/en-us/azure/virtual-network/public-ip-addresses Object Storage From NetApp \"What is object storage? : \"...also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. These objects are kept in a single storehouse and are not ingrained in files inside other folders. Instead, object storage combines the pieces of data that make up a file, adds all its relevant metadata to that file, and attaches a custom identifier.\" Blob storage is object storage. Objects (e.g. files) are retrieved from a large system via their identifier, not their name. Amazon S3 and Google Cloud storage are also object stores. On-prem \"On Premise\" refers to technology (computers, disks, networking, etc) that are on your institutions computer centers or in your own lab. Note that for some researchers, \"on-prem\" can still mean remove (e.g. our HPC is only accessible remotely, so it may not be obvious that it's on premise to users). Resource For AWS and Azure, a resource is an entity that you can work with. The means something you can created, edit or delete via their cloud interface. Could be a computer (virtual machine), a whole cluster (azure batch pool), or some tiny network setting (IP address). Resoures almost always cost money. Resources are listed in your standard dashboard. Resource Group Organizational scheme unique to Azure. Nearly all resources must be part of a group and the resource group must be selected (or created ) when creating other resources. Resource groups could be used for specific projects, for 'personal' resources used for multiple projects (or for azure things like cloud shell). Resource Manager Azure calls the system they use to interface between you and cloud resources the \"Azure Resource Manager\" or ARM. There used to be a different way to interact with Azure resources, hence this has a specific name and is referred to in Microsoft documentation. Serverless This buzz-word applies to many different cloud services, primarily those that the cloud company manages for you, usually referring to cloud functions (AWS Lamba) and sometimes others in the \"Platform As A Service\" service model . The origin is that, if you run virtual machines with operating systems and software install, your are maintaining servers to support that software. If the cloud service does not require you to provision and maintain a server, it is often marketed as \"serverless\" (e.g. recent marketing of Azure Files as \"Serverless file shares\" where on-premise File Sharing requires staff to manage and maintain Windows File Servers. Service Models This is related to the \"... as a service\" (..aaS) phrases defined in the NIST document which included \"Infrastructure\", \"Platform\" and \"Softare\" as a service (IaaS, PaaS and SaaS). It's a conceptual organization of cloud services based on the stack model of computating with the infrastructure (network, hardware, CPU, etc) at the bottom and Software on the top. See The NIST Definition of Cloud Computing Service Level Agreement (SLA) Level of service you expect from a vendor, laying out the metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved. In Cloud this is often spells out 'uptime,' which is percent of time the system is not down, e.g. 99.99%, and guarantees against data loss and availability. For most research, uptime is not important as we are our own customer and can tolerate some downtime. Services Cloud \"services\" are often bundles of resources pulled together for coordinate function. Cloud companies offer hundreds of often closely overlapping services. Tags AWS and Azure allow you add meta data to resource in the form of tags (e.g. hashtags, etc) which are keys and values. When you create a resource you can add a tag indicating the project it is for e.g. \"project\" = \"dna-methylation\" To add more detail if your DNA methylation has multiple aspects or experiments, add more tags like \"experiment\" = \"Fall 2021\" For workgroups it's stronlgy suggested you add a \"created_by\" = your netid because it's often difficult in Azure to determine who created a resource if it needs to be turned off or deleted. Use tags to organize your Azure resources and management hierarchy Tensor Processing Unit (TPU) Google Tensor Processing Unit is specialized computer chip similar to GPUs , used by deep learning libraries such as TensorFlow ( which leads to the question of \"what is a tensor\" and that depends on who you ask but similar to matrix. Virtual Machine (aka VM) Creating a simulated computer hardware using software, to be able run a guest operating system inside a host system, such that the guest thinks it's running on an actual computer.","title":"Cloud Glossary"},{"location":"cloud_glossary/#glossary-of-cloud-terms","text":"","title":"Glossary of Cloud Terms"},{"location":"cloud_glossary/#why","text":"Researchers using the cloud must know a little about a lot of information technology to get computational work done in their domain specialty. Most cloud glossaries are for systems administrators, not the rest of us. This glossary is much more brief than Wikipedia and hopefully also provides the context a researcher needs to find what you need to use cloud services in your work. Do you have an item to add? Please contact us !","title":"Why?"},{"location":"cloud_glossary/#other-glossaries","text":"https://www.cloudbank.org/cloud-terms","title":"Other Glossaries"},{"location":"cloud_glossary/#the-glossary","text":"","title":"The Glossary"},{"location":"cloud_glossary/#arm-cpu","text":"CPU from \"Advanced RISC Machines, ltd. While historically most computers used Intel CPUs, ARM provides an alternative CPU that is becoming more popular and present as an option in HPC and Cloud Virtual Machine options. The vast majority of software written for Intel computers is compatible with ARM. Some computational work is sensitive to CPU choice, and CPU choice can affect cost and speed of excecution, so it may be important to understand the implications of this choice of CPU.","title":"Arm CPU"},{"location":"cloud_glossary/#arm-template","text":"A specification file listing all of the cloud resources and configuration settings tha that the Azure Resource Manager can use to create resources for you when you submit it a certain way. Templates are a great shortcut and automation feature but difficult to edit. For details see Azure Documentation: What are ARM templates?","title":"ARM Template"},{"location":"cloud_glossary/#azure-resource-manager-arm","text":"see Resource Manager =#### Blob Storage Azure calls there object cloud storage \"Blobs\". It is similar to Amazon Web Service 'S3' and Google cloud storage buckets. Azure Documentation: Introduction to Azure Blob storage While it's possible to 'mount' blob storage to linux VMs using 'blob fuse' or similar packages, it can not work as you may expect and so in practice Azure Files are a better solution for that. See File Storage","title":"Azure Resource Manager (ARM)"},{"location":"cloud_glossary/#client-server","text":"Client/Server model of computing is something we use everyday but perhaps dont' use this term. See https://techterms.com/definition/client-server_model You are used to using maybe a dozen clients everyday (phone apps, web browser, ssh to connect to a remote linux, Remote Desktop client to connect to remote desktop server, etc). Cloud computing provides all the infrastructure needed to create servers quickly and easily.","title":"Client-Server"},{"location":"cloud_glossary/#containers","text":"Or Docker Containers (not all containers need to be Docker the vast majority of container system use Docker). For R users, see https://colinfay.me/docker-r-reproducibility/ For Python users, there is https://www.netguru.com/blog/python-docker-tutorial although you could read either. Linux Containers is a term for a collection of methods and technologies that allows a multiple isolated systems to be run on one Linux computer. This is differnet from virtual machines in that a VM host provides abstract or virtualized hardware so each VM requires it's own portion of memory and CPU cores whereas containers share the main part of Linux (the kernel), memory and CPU more dynamically. The primary comercial company for containers is \"Docker\" so Docker is sometimes used synonymously with 'container' but it is just one form. In addition to being more efficient than VMs, most container systems have a system and scripting language for building containers. The means onecan provision an entire system from code. Containers are widely use to package and distribute complex research software systems for example Bioinformatics workflow system \"Cromwell.\" This way reseearches can download and use a pre-installed system without the trouble of getting all of the pre-requistes (dependencies) installed on their machine.","title":"Containers"},{"location":"cloud_glossary/#cpu","text":"Central Processing Unit, the main 'chip' of a computer, and a core component when specifying a Virtual Machine 'size'","title":"CPU"},{"location":"cloud_glossary/#devops","text":"This has many definitions but for researchers the shortcut is using code to make IT infrastructure. Helping developers (like you) do Ops (like sysadmins) with code. see IaC.","title":"DevOps"},{"location":"cloud_glossary/#docker","text":"Docker is the most prevalent form of \"Containers\", e.g Docker is to containers as google is to search. See containers above for details. Note that Docker is many things as once: a method and format for Linux containers, a program for working with container ( e.g. docker build... ), a Company, and that's company's hub or repository for storing and access free containers (or your own). Cloud companies also have \"hubs\" or repositories for storing your own Docker containers.","title":"Docker"},{"location":"cloud_glossary/#file-storage-azure","text":"Also called \"Azure Files.\" Azure cloud storage that is more traditional file sharing, and that can be connected (mounted) to computers and other services using the SMB protocal, making it similar experience to departmental shared fileservers. See https://azure.microsoft.com/en-us/services/storage/files/ and compare with Blob Storage","title":"File Storage (Azure)"},{"location":"cloud_glossary/#firewall","text":"A common concept in networking, firewall software on a computer's networking components limits which kind of traffic can come in or out, and restricts which computer internet addresses can connect. Best practices suggest closing all connections via the firewall, only opening those connections for services you need, and only to those users (e.g. your own computer) you need to. Azure additionally has an option to \"allow connections from Azure networks\" so that you can freely connect from the portal, 'cloud shell', or connect from on azure service to another. The implication is that you trust all Azure services.","title":"Firewall"},{"location":"cloud_glossary/#gpu","text":"From Wikipedia: https://en.wikipedia.org/wiki/Graphics_processing_unit GPUs can be very helpful for some code written to use them, especially many machine learning libraries, and Virtual Machines may be provisioned with GPUs.","title":"GPU"},{"location":"cloud_glossary/#infrastructure-as-code-iac","text":"In stead of using a GUI, or manual steps to create cloud computing, cloud resources may be created using scripts that interact with the cloud provider's api, and additional scripts can configure individual resources (such as to install software on a VM or configure a database). Doing this kind of \"provisioning\" with scripts makes it reproducible and debuggable which is at the heart of the Workflow or DevOps mentality.","title":"Infrastructure as Code (IaC)"},{"location":"cloud_glossary/#ip-address","text":"a unique string of characters that identifies each computer using the Internet Protocol to communicate over a network. Your computer will have a different IP address depending on where you are located (home, work, field). In addition, a home wifi router will assign a 'local' ip address for inside your home, but your 'public' internet IP address will be different. To find your own IP address, simply google \"what is my ip.\" All Azure services (VMs, data systems, etc) are assigned IP addresses via networking. see https://docs.microsoft.com/en-us/azure/virtual-network/public-ip-addresses","title":"IP Address"},{"location":"cloud_glossary/#object-storage","text":"From NetApp \"What is object storage? : \"...also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. These objects are kept in a single storehouse and are not ingrained in files inside other folders. Instead, object storage combines the pieces of data that make up a file, adds all its relevant metadata to that file, and attaches a custom identifier.\" Blob storage is object storage. Objects (e.g. files) are retrieved from a large system via their identifier, not their name. Amazon S3 and Google Cloud storage are also object stores.","title":"Object Storage"},{"location":"cloud_glossary/#on-prem","text":"\"On Premise\" refers to technology (computers, disks, networking, etc) that are on your institutions computer centers or in your own lab. Note that for some researchers, \"on-prem\" can still mean remove (e.g. our HPC is only accessible remotely, so it may not be obvious that it's on premise to users).","title":"On-prem"},{"location":"cloud_glossary/#resource","text":"For AWS and Azure, a resource is an entity that you can work with. The means something you can created, edit or delete via their cloud interface. Could be a computer (virtual machine), a whole cluster (azure batch pool), or some tiny network setting (IP address). Resoures almost always cost money. Resources are listed in your standard dashboard.","title":"Resource"},{"location":"cloud_glossary/#resource-group","text":"Organizational scheme unique to Azure. Nearly all resources must be part of a group and the resource group must be selected (or created ) when creating other resources. Resource groups could be used for specific projects, for 'personal' resources used for multiple projects (or for azure things like cloud shell).","title":"Resource Group"},{"location":"cloud_glossary/#resource-manager","text":"Azure calls the system they use to interface between you and cloud resources the \"Azure Resource Manager\" or ARM. There used to be a different way to interact with Azure resources, hence this has a specific name and is referred to in Microsoft documentation.","title":"Resource Manager"},{"location":"cloud_glossary/#serverless","text":"This buzz-word applies to many different cloud services, primarily those that the cloud company manages for you, usually referring to cloud functions (AWS Lamba) and sometimes others in the \"Platform As A Service\" service model . The origin is that, if you run virtual machines with operating systems and software install, your are maintaining servers to support that software. If the cloud service does not require you to provision and maintain a server, it is often marketed as \"serverless\" (e.g. recent marketing of Azure Files as \"Serverless file shares\" where on-premise File Sharing requires staff to manage and maintain Windows File Servers.","title":"Serverless"},{"location":"cloud_glossary/#service-models","text":"This is related to the \"... as a service\" (..aaS) phrases defined in the NIST document which included \"Infrastructure\", \"Platform\" and \"Softare\" as a service (IaaS, PaaS and SaaS). It's a conceptual organization of cloud services based on the stack model of computating with the infrastructure (network, hardware, CPU, etc) at the bottom and Software on the top. See The NIST Definition of Cloud Computing","title":"Service Models"},{"location":"cloud_glossary/#service-level-agreement-sla","text":"Level of service you expect from a vendor, laying out the metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved. In Cloud this is often spells out 'uptime,' which is percent of time the system is not down, e.g. 99.99%, and guarantees against data loss and availability. For most research, uptime is not important as we are our own customer and can tolerate some downtime.","title":"Service Level Agreement (SLA)"},{"location":"cloud_glossary/#services","text":"Cloud \"services\" are often bundles of resources pulled together for coordinate function. Cloud companies offer hundreds of often closely overlapping services.","title":"Services"},{"location":"cloud_glossary/#tags","text":"AWS and Azure allow you add meta data to resource in the form of tags (e.g. hashtags, etc) which are keys and values. When you create a resource you can add a tag indicating the project it is for e.g. \"project\" = \"dna-methylation\" To add more detail if your DNA methylation has multiple aspects or experiments, add more tags like \"experiment\" = \"Fall 2021\" For workgroups it's stronlgy suggested you add a \"created_by\" = your netid because it's often difficult in Azure to determine who created a resource if it needs to be turned off or deleted. Use tags to organize your Azure resources and management hierarchy","title":"Tags"},{"location":"cloud_glossary/#tensor-processing-unit-tpu","text":"Google Tensor Processing Unit is specialized computer chip similar to GPUs , used by deep learning libraries such as TensorFlow ( which leads to the question of \"what is a tensor\" and that depends on who you ask but similar to matrix.","title":"Tensor Processing Unit (TPU)"},{"location":"cloud_glossary/#virtual-machine","text":"(aka VM) Creating a simulated computer hardware using software, to be able run a guest operating system inside a host system, such that the guest thinks it's running on an actual computer.","title":"Virtual Machine"},{"location":"contact/","text":"Contacting Us If you are a cloud fellowship participant this year (or past participant!), please contact the instructors Pat Bills or Mahmoud Parvizi with any issues or questions related to the material or activities. The session meetings are designed to have plenty of time for questions, troubleshooting and discussion. We will also schedule office hours prior to meeting times to help with pre-meeting activities. If you have general questions about the MSU Cloud Fellowship, please contact Brian O'Shea or Danielle Barnes If you will be an MSU graduate student or post-doc in Fall 2022 and are interested in participating next year, please check back in the Summer of 2022 for announcements for invitation to participate, or request to join the MSU ICER mailing list If you are an MSU Researcher interested in using cloud for your research, please contact IT Services or MSU ICER via our ticketing systems and describe your needs.","title":"Contact"},{"location":"contact/#contacting-us","text":"If you are a cloud fellowship participant this year (or past participant!), please contact the instructors Pat Bills or Mahmoud Parvizi with any issues or questions related to the material or activities. The session meetings are designed to have plenty of time for questions, troubleshooting and discussion. We will also schedule office hours prior to meeting times to help with pre-meeting activities. If you have general questions about the MSU Cloud Fellowship, please contact Brian O'Shea or Danielle Barnes If you will be an MSU graduate student or post-doc in Fall 2022 and are interested in participating next year, please check back in the Summer of 2022 for announcements for invitation to participate, or request to join the MSU ICER mailing list If you are an MSU Researcher interested in using cloud for your research, please contact IT Services or MSU ICER via our ticketing systems and describe your needs.","title":"Contacting Us"},{"location":"projects/","text":"About The Fellowship Projects The fellowship is structured to first provide materials and help to learn core cloud concepts and activies, and to promote how to learn about cloud from existing documentation. This is to support a small, cloud-based research project that is the main object of the fellowship Video about the nature of the project, Mahmoud Parvizi Qs and Notes about projects Q. Do I have to use my own data for my project or can I use data from the web or other public data? A. you can bring any data that you may use for your research, or that demonstrates cloud processes you may use in your research Q. I don't know how to use the stuff I'm learning so far for my project. what do I do? A. We will cover several new topics that are adjancent to cloud computing that may be suited for you. Some of these do not require yo Databases for tabular or structured data Data systems in general Big data processing with Python notebooks Q. Are there constraints on the things I want do with my project? A. Our goal is to facilitate your education and advancing your research program. If you use the fellowship to develop only a small system to show what's possible or not possible, even on public data, that uses cloud computing, that is an acceptable project. Q. Do I have to use programming in my project? A. Most of the examples provided in the fellowship talk about processing data with scripts such as R or Python and many researchers are using these for data analysis, but it's not required for a successful project. You could install a program on a powerful virtual machine and show how to use that software along with cloud storage to tackle a large data set (for example). Secondly there are many forms of cloud computing that are not traditional such as data systems which may use a GUI or a language like SQL. One important aspect of a successful project is \"workflow thinking\" or how could you design your process so that you could do it 100 times or with some form of automation. That often requires programming but there are cloud systems that don't require programming (e.g. Azure Data Factory) but you may want learn about data base systems. Accumulating and organizing data is a huge part of successful research and there are cloud tools to help with that. Q. I have structured data and I want to process it and using a VM or storage don't seem quite right. You may want to investigate using a database. We don't have time to cover how to use to a database in this fellowship but can point you to starter documentation. Q. I want to make a web site or application for my project, can I use a VM? how do I do that? A. While the cloud was invented in part to run web applications, Web application design is a huge subject and the programming involved is almost as complex as any programming or data work you've done for your research. We will cover somethigns about using Azure services for hosting websites but don't attempt this for your project unless you have previous experience making websites or web applications, or if you are up for the big challenge of learning webdev along with cloud computing.","title":"About The Fellowship Projects"},{"location":"projects/#about-the-fellowship-projects","text":"The fellowship is structured to first provide materials and help to learn core cloud concepts and activies, and to promote how to learn about cloud from existing documentation. This is to support a small, cloud-based research project that is the main object of the fellowship Video about the nature of the project, Mahmoud Parvizi Qs and Notes about projects Q. Do I have to use my own data for my project or can I use data from the web or other public data? A. you can bring any data that you may use for your research, or that demonstrates cloud processes you may use in your research Q. I don't know how to use the stuff I'm learning so far for my project. what do I do? A. We will cover several new topics that are adjancent to cloud computing that may be suited for you. Some of these do not require yo Databases for tabular or structured data Data systems in general Big data processing with Python notebooks Q. Are there constraints on the things I want do with my project? A. Our goal is to facilitate your education and advancing your research program. If you use the fellowship to develop only a small system to show what's possible or not possible, even on public data, that uses cloud computing, that is an acceptable project. Q. Do I have to use programming in my project? A. Most of the examples provided in the fellowship talk about processing data with scripts such as R or Python and many researchers are using these for data analysis, but it's not required for a successful project. You could install a program on a powerful virtual machine and show how to use that software along with cloud storage to tackle a large data set (for example). Secondly there are many forms of cloud computing that are not traditional such as data systems which may use a GUI or a language like SQL. One important aspect of a successful project is \"workflow thinking\" or how could you design your process so that you could do it 100 times or with some form of automation. That often requires programming but there are cloud systems that don't require programming (e.g. Azure Data Factory) but you may want learn about data base systems. Accumulating and organizing data is a huge part of successful research and there are cloud tools to help with that. Q. I have structured data and I want to process it and using a VM or storage don't seem quite right. You may want to investigate using a database. We don't have time to cover how to use to a database in this fellowship but can point you to starter documentation. Q. I want to make a web site or application for my project, can I use a VM? how do I do that? A. While the cloud was invented in part to run web applications, Web application design is a huge subject and the programming involved is almost as complex as any programming or data work you've done for your research. We will cover somethigns about using Azure services for hosting websites but don't attempt this for your project unless you have previous experience making websites or web applications, or if you are up for the big challenge of learning webdev along with cloud computing.","title":"About The Fellowship Projects"},{"location":"references/","text":"Azure Resources General Resources Main Azue Documentation : https://docs.microsoft.com/en-us/azure/ List of All Azure Services : https://portal.azure.com/#allservices Azure Tips and Tricks : https://microsoft.github.io/AzureTipsAndTricks/ Azure Portal \"How to\" series - focused on using the Azure portal to do several different things. This is mostly about the services themselves, not the portal, and many topics do not apply to us (e.g. Azure Arc) but there are some very useful videos : https://youtube.com/playlist?list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR These look like really good intros to Azure, but requires a time investment. The examples are not really research computing examples but may be valuable learning examples. Most of these lessons were taken from other 'learning paths' and are still oriented towards IT professionals Microsoft Learn : - Azure for Researchers part 1: Introduction to Cloud Computing - Azure for Researchers part 2: Cloud Security and Cost Management Interface: Azure Portal Azure Portal Documentation : https://docs.microsoft.com/en-us/azure/azure-portal/ Microsoft Azure Hierarchy: Organize your Azure resources effectively Re-organize your portal view by creating a new dashboard (optional) : https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards Azure portal productivity Tips : https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html#azure-portal-productivity-tips https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html Interface: Command Line Command-line progamming of Cloud Services Azure PowerShell (Windows) https://docs.microsoft.com/en-us/powershell/azure/ Introduction to PowerShell : https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-3.0.0 Azure Command Line Interface (CLI) (MacOS, Linux): https://docs.microsoft.com/en-us/cli/azure Introduction to Azure CLI https://docs.microsoft.com/en-us/cli/azure/get-started-with-azure-cli?view=azure-cli-latest Hybrid inferface: using the CLI inside the Azure Portal You can install and use the az CLI program on your own computer, but Azure also has a way you can use the CLI without installing anything, with a cloud-based terminal interface called the \"cloud shell.\" For an overview see https://docs.microsoft.com/en-us/azure/cloud-shell/overview and for a great 'quickstart' see https://docs.microsoft.com/en-us/azure/cloud-shell/quickstart for a quick tutorial for how to use it. In the quickstart, the first example shows you how to create a resource group using the CLI in the cloudshell. If you don't have permissions to create a new resource group, skip to the next example (\"Create a Linux VM\") and put your own resource group in the command for the -g parameter and perhaps use a very unique name for the VM parameter. Storage Create a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Create and Manage a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Using the CLI with Storage Reference: https://docs.microsoft.com/en-us/cli/azure/storage/account Using PowerShell Storage Reference: https://docs.microsoft.com/en-us/powershell/module/azure.storage Create blob storage with CLI: https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli Create blob storage with PowerShell: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-powershell Compute Overview of Compute Options: https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-overview Choosing an Azure Compute Service (Decision Tree): https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree Interface: ARM templates Azure Resource Manager Templates are JSON-formatted configuration files that dictate which resources to create. Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview explore quick start ARM templates (web): https://azure.microsoft.com/en-us/resources/templates/ explore quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates many of these github repositories include a \"deploy to Azure\" button that will run the template via the portal and create resources. Programming with SDKs R and Azure https://blog.revolutionanalytics.com/2018/12/azurestor.html https://cloudblogs.microsoft.com/opensource/2019/07/01/azurer-available-create-manage-monitor-azure-services-r/ https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/r-packages-supported-by-azure-machine-learning https://github.com/Azure/AzureContainers https://github.com/Azure/AzureR https://github.com/Azure/AzureRMR Python and Azure https://azure.microsoft.com/en-us/develop/python/ https://docs.microsoft.com/en-us/azure/python/ https://github.com/Azure/azure-sdk-for-python https://github.com/Azure/azure-storage-python https://azure.github.io/azure-sdk/releases/latest/all/python.html (Note that pypi.org/project/azure/ is deprecated/obsolete if you find that via google) MATLAB and Azure https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/06/29/running-matlab-on-azure-provision-a-matlab-distributed-computing-server-using-azure-vms/ https://github.com/mathworks-ref-arch/matlab-on-azure https://www.itcentralstation.com/products/comparisons/mathworks-matlab_vs_microsoft-azure-machine-learning-studio https://www.mathworks.com/solutions/cloud.html Microsoft Azure Cosmos DB CosmosDB is a very large scale data system that can act like other database systems including SQL, MongoDB (a popular no-sql database), and others. It's advantage is that it can handle extremely large data sets (65tB) but is easy to get started. Google and AWS have similar offereings ( \"BigQuery\" and \"Aurora\" respectively). If your data is not large, consider using SQL data systems which are also very widely used (and can be used on your own computer) Intro: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction It can be free to use, but you have to turn that on when creating the service for your account: https://docs.microsoft.com/en-us/azure/cosmos-db/free-tier You can run a notebook inside the databaase to queery data with python : Notebook Description: https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks Service announcement: https://azure.microsoft.com/en-us/blog/analyze-and-visualize-your-data-with-azure-cosmos-db-notebooks/ Video: https://www.youtube.com/watch?v=OrnZMkP5Eq4&list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR&index=7 Cloud Architecture This section has resources for advanced to intermediate cloud users who are interested in much more details that most researchers will ever need, and are really geared for IT staff. However, sometimes to find insight into how to approach your problem (especially for cloud timing ooptimazation projects) these may have useful sections. Microsoft Azure Infrastructure Services for Architects by John Savill, Oct 2019, available from the MSU Library : http://catalog.lib.msu.edu/record=b13538669~S39 Azure has changed since 2019 but may still be relevant","title":"References"},{"location":"references/#azure-resources","text":"","title":"Azure Resources"},{"location":"references/#general-resources","text":"Main Azue Documentation : https://docs.microsoft.com/en-us/azure/ List of All Azure Services : https://portal.azure.com/#allservices Azure Tips and Tricks : https://microsoft.github.io/AzureTipsAndTricks/ Azure Portal \"How to\" series - focused on using the Azure portal to do several different things. This is mostly about the services themselves, not the portal, and many topics do not apply to us (e.g. Azure Arc) but there are some very useful videos : https://youtube.com/playlist?list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR These look like really good intros to Azure, but requires a time investment. The examples are not really research computing examples but may be valuable learning examples. Most of these lessons were taken from other 'learning paths' and are still oriented towards IT professionals Microsoft Learn : - Azure for Researchers part 1: Introduction to Cloud Computing - Azure for Researchers part 2: Cloud Security and Cost Management","title":"General Resources"},{"location":"references/#interface-azure-portal","text":"Azure Portal Documentation : https://docs.microsoft.com/en-us/azure/azure-portal/ Microsoft Azure Hierarchy: Organize your Azure resources effectively Re-organize your portal view by creating a new dashboard (optional) : https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards Azure portal productivity Tips : https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html#azure-portal-productivity-tips https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html","title":"Interface: Azure Portal"},{"location":"references/#interface-command-line","text":"Command-line progamming of Cloud Services Azure PowerShell (Windows) https://docs.microsoft.com/en-us/powershell/azure/ Introduction to PowerShell : https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-3.0.0 Azure Command Line Interface (CLI) (MacOS, Linux): https://docs.microsoft.com/en-us/cli/azure Introduction to Azure CLI https://docs.microsoft.com/en-us/cli/azure/get-started-with-azure-cli?view=azure-cli-latest Hybrid inferface: using the CLI inside the Azure Portal You can install and use the az CLI program on your own computer, but Azure also has a way you can use the CLI without installing anything, with a cloud-based terminal interface called the \"cloud shell.\" For an overview see https://docs.microsoft.com/en-us/azure/cloud-shell/overview and for a great 'quickstart' see https://docs.microsoft.com/en-us/azure/cloud-shell/quickstart for a quick tutorial for how to use it. In the quickstart, the first example shows you how to create a resource group using the CLI in the cloudshell. If you don't have permissions to create a new resource group, skip to the next example (\"Create a Linux VM\") and put your own resource group in the command for the -g parameter and perhaps use a very unique name for the VM parameter.","title":"Interface: Command Line"},{"location":"references/#storage","text":"Create a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ Create and Manage a Storage Account: https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account Using the CLI with Storage Reference: https://docs.microsoft.com/en-us/cli/azure/storage/account Using PowerShell Storage Reference: https://docs.microsoft.com/en-us/powershell/module/azure.storage Create blob storage with CLI: https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli Create blob storage with PowerShell: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-powershell","title":"Storage"},{"location":"references/#compute","text":"Overview of Compute Options: https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-overview Choosing an Azure Compute Service (Decision Tree): https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree","title":"Compute"},{"location":"references/#interface-arm-templates","text":"Azure Resource Manager Templates are JSON-formatted configuration files that dictate which resources to create. Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview explore quick start ARM templates (web): https://azure.microsoft.com/en-us/resources/templates/ explore quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates many of these github repositories include a \"deploy to Azure\" button that will run the template via the portal and create resources.","title":"Interface: ARM templates"},{"location":"references/#programming-with-sdks","text":"","title":"Programming with SDKs"},{"location":"references/#r-and-azure","text":"https://blog.revolutionanalytics.com/2018/12/azurestor.html https://cloudblogs.microsoft.com/opensource/2019/07/01/azurer-available-create-manage-monitor-azure-services-r/ https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/r-packages-supported-by-azure-machine-learning https://github.com/Azure/AzureContainers https://github.com/Azure/AzureR https://github.com/Azure/AzureRMR","title":"R and Azure"},{"location":"references/#python-and-azure","text":"https://azure.microsoft.com/en-us/develop/python/ https://docs.microsoft.com/en-us/azure/python/ https://github.com/Azure/azure-sdk-for-python https://github.com/Azure/azure-storage-python https://azure.github.io/azure-sdk/releases/latest/all/python.html (Note that pypi.org/project/azure/ is deprecated/obsolete if you find that via google)","title":"Python and Azure"},{"location":"references/#matlab-and-azure","text":"https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/06/29/running-matlab-on-azure-provision-a-matlab-distributed-computing-server-using-azure-vms/ https://github.com/mathworks-ref-arch/matlab-on-azure https://www.itcentralstation.com/products/comparisons/mathworks-matlab_vs_microsoft-azure-machine-learning-studio https://www.mathworks.com/solutions/cloud.html","title":"MATLAB and Azure"},{"location":"references/#microsoft-azure-cosmos-db","text":"CosmosDB is a very large scale data system that can act like other database systems including SQL, MongoDB (a popular no-sql database), and others. It's advantage is that it can handle extremely large data sets (65tB) but is easy to get started. Google and AWS have similar offereings ( \"BigQuery\" and \"Aurora\" respectively). If your data is not large, consider using SQL data systems which are also very widely used (and can be used on your own computer) Intro: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction It can be free to use, but you have to turn that on when creating the service for your account: https://docs.microsoft.com/en-us/azure/cosmos-db/free-tier You can run a notebook inside the databaase to queery data with python : Notebook Description: https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks Service announcement: https://azure.microsoft.com/en-us/blog/analyze-and-visualize-your-data-with-azure-cosmos-db-notebooks/ Video: https://www.youtube.com/watch?v=OrnZMkP5Eq4&list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR&index=7","title":"Microsoft Azure Cosmos DB"},{"location":"references/#cloud-architecture","text":"This section has resources for advanced to intermediate cloud users who are interested in much more details that most researchers will ever need, and are really geared for IT staff. However, sometimes to find insight into how to approach your problem (especially for cloud timing ooptimazation projects) these may have useful sections. Microsoft Azure Infrastructure Services for Architects by John Savill, Oct 2019, available from the MSU Library : http://catalog.lib.msu.edu/record=b13538669~S39 Azure has changed since 2019 but may still be relevant","title":"Cloud Architecture"},{"location":"session_bigdata/","text":"Session 5: Big Data on Azure Cloud Featuring Spark You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that build complex data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling. Meeting October 22 2:00-3:30pm Discussion and Questions of material from previous sessions Project related questions Lecture Overview of Big Data with Spark for Researchers Big Data Q & A Videos Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code Readings Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by cloud fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and readable introductions to \"big data\" I've ever seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial) For R users You can use R commands with Spark, and Databricks has the eoption of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark in their projects The book above describes how to use it in detail As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describee how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft. Activities There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"5. Big Data and the cloud"},{"location":"session_bigdata/#session-5-big-data-on-azure-cloud-featuring-spark","text":"You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004. \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data. Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes). However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer. To accomplish our data processing task we look for ways to split up the work with parallel methods. Modern big data tools offer this possibility without resorting to custom coding or manually processing. While big data technology doesn't require cloud computing, most cloud companies have a services that build complex data processing clusters with a few clicks. The goal of this single session is introduce you to basic concepts of 'big data' processing and peek at how it works and what it may do for you. Many applications can't take advantage of it of big data, or they have their own parallel systems. for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling.","title":"Session 5: Big Data on Azure Cloud Featuring Spark"},{"location":"session_bigdata/#meeting-october-22-200-330pm","text":"Discussion and Questions of material from previous sessions Project related questions Lecture Overview of Big Data with Spark for Researchers Big Data Q & A","title":"Meeting October 22 2:00-3:30pm"},{"location":"session_bigdata/#videos","text":"Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services. ( MSU log-in required for video) These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code","title":"Videos"},{"location":"session_bigdata/#readings","text":"Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave Voorhis Chapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0 Copyright \u00a9 2015 Elsevier Inc. All rights reserved. PDF copy, for use by cloud fellowship only (link is access restricted). The book is available as an electronic copy from the MSU Library While the book itself is really not of interest to us, this particular chapter is one of the better and readable introductions to \"big data\" I've ever seen, written for professionals like yourselves. Dr. Self studies ethics and big data for University of Derby in the UK. Textbook: Cloud Computing for Science and Engineering Chapter 7 \"Scaling Deployments\" , only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\" This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC). If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me). Chapter 8 \"Data Analytics in the Cloud\" This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\" We will only concentrate on spark for this session as it's much more approachable and more modern. There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series) Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure. Read the introduction only (see activities below for info on the tutorial)","title":"Readings"},{"location":"session_bigdata/#for-r-users","text":"You can use R commands with Spark, and Databricks has the eoption of creating an R-based notebook. Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue R commands. Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook. The easiest way to use R with Spark is with the package sparklyr from Rstudio. \"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. This is a full book, so only suggested reading for those who deecide to use Databricks/Spark in their projects The book above describes how to use it in detail As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks. The book has details for that. While it does not describee how to install databricks, all of the examples are useable in an R notebook in Azure databricks The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio. It requires some setup, see RStudio on Azure Databricks from Microsoft.","title":"For R users"},{"location":"session_bigdata/#activities","text":"There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list geared towards researchers Create an Azure Databricks workspace which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal . The quickstart tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL Introduction to Spark Data Frames with Python and SQL A job is a way to run non-interactive code in an Azure Databricks cluster. Doug Krum discusses using Jobs in the videos above. For details about Jobs and how they work, see Databricks Data Science & Engineering: Jobs or to simply try a quick example see Running Jobs in Databricks Quickstart (with Python)","title":"Activities"},{"location":"session_bigdata/principles_using_databricks/","text":"DRAFT Using Databricks and References Basic function Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .). How tos Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"DRAFT Using Databricks and References"},{"location":"session_bigdata/principles_using_databricks/#draft-using-databricks-and-references","text":"","title":"DRAFT Using Databricks and References"},{"location":"session_bigdata/principles_using_databricks/#basic-function","text":"Spark is a cluster technology that connects to special storage, performs parallel work and reports performance. It runs on Azure using a combination of VMs, Storage disks, blob storage and networking. Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer. AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the resource creation for spark clusters. When you create an \"Azure Databricks\" resource Azure creates the pieces necessary to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts. ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs. You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources. In fact the resources that ADB creates can't be changed by you manually. ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks. In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface. You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line. These data files are then available to your code that runs on the cluster. Becasue the Spark cluster uses special form of parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/ however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. ADB by itself can not run code. You use ADB to first create a spark cluster, then the cluster can run your code. Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere .).","title":"Basic function"},{"location":"session_bigdata/principles_using_databricks/#how-tos","text":"Create and use an ADB service: use azure portal (link), then go to the resource in the How to upload into databricks: 1) use the UI (link) 2) in a cluster, use the Can I upload files into the DB file system without creating a cluster? Is there a way to see the files on the DB file system easily from outside of the cluster? I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration why are there so many disks created in the auto-generated resource group I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs. That seems like it will be a problem when they go to try to build a DB and it creates a new RG. Job clusters much cheaper - interactive is default, but much more expensive old school RDD, had to do all your own Dataframes + Catalyst","title":"How tos"},{"location":"session_cloud_storage/","text":"Session 3: Cloud Storage Introduction Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size. The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud companies think of \"storage\" as anything that save files, or perhaps more importantly anything they can market to you as something to save files. Readings Storage as a Service from \"Cloud Computing for Science and Engineering\" Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) Table of Azure Storage Product Offerings Azure Documentation: Introduction to the core Azure Storage services Slides/Lecture: Azure Cloud Storage for Researchers with links for details on each slide optional Understanding block blobs, append blobs, and page blobs Activities Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Using Azure Cloud Storage to create and use storage Azure Storage Pricing Exercise Meeting September 24 2:00-3:30pm About Projects, Mahmoud Parvizi Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines What is cloud storage? concept review: cloud storage vs VM disks discuss exercises to be worked on next week Review of Broad Cloud Concepts: On-Demand, Compute, Storage, Identity Management Discussion : future activities and needs Optional Activity: Python And Cloud Storage For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: use the blob storage account you created in the exercise above familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line","title":"3. Cloud Storage"},{"location":"session_cloud_storage/#session-3-cloud-storage","text":"","title":"Session 3: Cloud Storage"},{"location":"session_cloud_storage/#introduction","text":"Central to using cloud for nearly all services is storing data. Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC. During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer. However there are disadvantages to this : 1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share 1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services 1. it is limited in size. The largest of virtual disks are around 1 TB. Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts. 1. You can only move data to/from a virtual or shared disk storage using a virtual machine 1. Most importantly virtual disks very expensive compared to cloud storage Cloud companies think of \"storage\" as anything that save files, or perhaps more importantly anything they can market to you as something to save files.","title":"Introduction"},{"location":"session_cloud_storage/#readings","text":"Storage as a Service from \"Cloud Computing for Science and Engineering\" Optional: this is long (27 minutes) but a good basic introduction to Azure storage: Azure Training: Explore Azure Storage services ( free training from Microsoft Learn) Table of Azure Storage Product Offerings Azure Documentation: Introduction to the core Azure Storage services Slides/Lecture: Azure Cloud Storage for Researchers with links for details on each slide optional Understanding block blobs, append blobs, and page blobs","title":"Readings"},{"location":"session_cloud_storage/#activities","text":"Download and install the Azure Cloud Storage Explorer See the \"Download now\" button at the top of that page. You may review the content of the page complete exercises in Using Azure Cloud Storage to create and use storage Azure Storage Pricing Exercise","title":"Activities"},{"location":"session_cloud_storage/#meeting-september-24-200-330pm","text":"About Projects, Mahmoud Parvizi Discussion and Review of previous sessions: Using the Portal Creating and Using Virtual Machines What is cloud storage? concept review: cloud storage vs VM disks discuss exercises to be worked on next week Review of Broad Cloud Concepts: On-Demand, Compute, Storage, Identity Management Discussion : future activities and needs","title":"Meeting September 24 2:00-3:30pm"},{"location":"session_cloud_storage/#optional-activity","text":"Python And Cloud Storage For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK Requirements: use the blob storage account you created in the exercise above familiarity with Azure portal Python installed on your computer (suggest python 3.6 minimal) familiarity with the terminal and command line","title":"Optional Activity:"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/","text":"Exercise: Using Azure Cloud Storage Pre-requisites Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item. Azure Quickstart Tutorials Storage Account We created a storage account in one of the first activities, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far. Blob Storage Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob File Storage In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"Exercise: Using Azure Cloud Storage"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#exercise-using-azure-cloud-storage","text":"","title":"Exercise: Using Azure Cloud Storage"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#pre-requisites","text":"Download the Storage Explorer Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers A valid subscription. A storage account is not always required for some tutorials, but if so, create a storage account with the first item.","title":"Pre-requisites"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#azure-quickstart-tutorials","text":"","title":"Azure Quickstart Tutorials"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#storage-account","text":"We created a storage account in one of the first activities, and you may use that storage account for many of the other activities below. However here is the Azure documentation for doing so if you want to review or practice creating a new one: Create a storage account *Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far.","title":"Storage Account"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#blob-storage","text":"Azure Quickstart: Upload, download, and list blobs with the Azure portal The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: Azure Quickstart: Use Azure Storage Explorer to create a blob","title":"Blob Storage"},{"location":"session_cloud_storage/exercise_using_azure_cloud_storage/#file-storage","text":"In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not ) Quickstart: Create and manage Azure file shares","title":"File Storage"},{"location":"session_cloud_storage/storage_pricing_exercise/","text":"Prior to doing this exercise, See the reading and lecture slides linked in this session for definitions of terms. How large, approximately, is your data? If you are unsure, estimate 100 gb. How much would it cost to keep it in the cloud? Compare the pricing for Blob, Files and Disk storage for 6 months Aspects Of Storage: Redunancy: Always slect \"LRS\" as that is almost always sufficient and for con Storage prices are not the same across regions, but the default (\"East US\") works for this exercise Consider only the \"Hot\" storage of the different tiers (\"Premium\", \"Hot\", \"Cool\", and \"Archive\") for some high performance applications, Premium is required, but look at the price difference! Operations, Transactions and data transfer costs charged per 10K operations really hard to estimate unless you know your workload very low costs, e.g. reading 10K Blobs costs 1/2 of one cent. I would not bother estimating this cost unless you know you will have very high disk operations Types of Storage to Compare: Azure Blob Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/blobs/ select \"Hierachcial namespace\" Azure Files Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/files/ Managed Disk Pricing : https://azure.microsoft.com/en-us/pricing/details/managed-disks/ note these are in different sizes and types, select 128gb size if you are estimating 100gb data, Standard SSD when you create a disk in the protal, it defaults to 1 TiB size, which is quite expensive / month Optional: compare with On-premise storage costs The MSU HPC offers 1TB storage with redundant backups and high-speed access for free, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?","title":"Storage pricing exercise"},{"location":"session_cloud_storage/storage_pricing_exercise/#optional-compare-with-on-premise-storage-costs","text":"The MSU HPC offers 1TB storage with redundant backups and high-speed access for free, with each additional 1TB for $125/year . Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage? If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?","title":"Optional: compare with On-premise storage costs"},{"location":"session_datasystems/","text":"Session 6: Data Servers on the Cloud Introduction Data servers like Relational Databases can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s but there are many other types. A central advantage of data servers is ability to have multiple econnections at once from many users, a busy web application, or parallel processing. Like Big Data tools, these data systems don't require cloud computing, but cloud companies offer database servers with a few clicks that require very littls management. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project. Meeting October 29 2:00-3:30pm Discussion of Previous Topics, Q&A Slide Presentation: Introduction to Data Servers on the Cloud Q & A, Discussion of Data Servers and Systems on the Cloud Readings From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" see the Chapter 4. Databases by Foster, Ghani, Jarmin, Kreuter and Lane which could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read Activities Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help provisioning and connecting to a SQL system. Optional : Data Analytics on the Google Platform Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"6. Cloud Data Systems"},{"location":"session_datasystems/#session-6-data-servers-on-the-cloud","text":"","title":"Session 6: Data Servers on the Cloud"},{"location":"session_datasystems/#introduction","text":"Data servers like Relational Databases can be a powerful tool for even small research projects. When we say \"Data Servers\" or \"Data Systems\" we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results. The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s but there are many other types. A central advantage of data servers is ability to have multiple econnections at once from many users, a busy web application, or parallel processing. Like Big Data tools, these data systems don't require cloud computing, but cloud companies offer database servers with a few clicks that require very littls management. A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project.","title":"Introduction"},{"location":"session_datasystems/#meeting-october-29-200-330pm","text":"Discussion of Previous Topics, Q&A Slide Presentation: Introduction to Data Servers on the Cloud Q & A, Discussion of Data Servers and Systems on the Cloud","title":"Meeting October 29 2:00-3:30pm"},{"location":"session_datasystems/#readings","text":"From the free textbook \" Big Data and Social Science: Data Science Methods and Tools for Research and Practice \" see the Chapter 4. Databases by Foster, Ghani, Jarmin, Kreuter and Lane which could be a valuable resource for learning about the data science methods that you may se on the cloud. Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database Difference between SQL and 'NoSQL' style databases Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read","title":"Readings"},{"location":"session_datasystems/#activities","text":"Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first. If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use record the admin user name and password you used when creating the database in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial Quickstart: Use Azure Data Studio to connect and query PostgreSQL Delete the database in your resource group when you have finished with the tutorial. If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal. SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks. Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help provisioning and connecting to a SQL system.","title":"Activities"},{"location":"session_datasystems/#optional-data-analytics-on-the-google-platform","text":"Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account. It can process huge amounts of data, and has several datasets available for free. It also has You may try BigQuery for free in their Sandbox, with only a Google Account. If you have a gmail account, use that to log in with an incognito/private browser window. You may try your msu.edu email but it may or may not work. In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google Using the BigQuery sandbox If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab. getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb Log-in to Colab using https://colab.research.google.com/ intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.","title":"Optional : Data Analytics on the Google Platform"},{"location":"session_datasystems/data_servers_intro_for_researchers_edited_with_typora/","text":"Overview of Data Servers and Databases on the Cloud for Researchers","title":"Data servers intro for researchers edited with typora"},{"location":"session_datasystems/table_of_responsibilties_by_service_level/","text":"Layer Responsibility On-Prem IAAS (VM) PAAS SAAS Network Connectivity & Security Campus IT Service Service Service Hardware Disk Failures You Service Service Service Operating System Updates, installation, security You You Service Service Security Software Install and maintain You You Service Service Server Software Install, maintain You You Service Service Server Configuration Tune, Speed, You You You (limited) Service User Configuration Who can access, user accounts You You You Service Code/Data You You You You","title":"Table of responsibilties by service level"},{"location":"session_how_to_cloud/","text":"Session 2: What is the cloud and how does it work? An introduction using Virtual Machines When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\" Readings Cloud background The NIST Definition of Cloud Computing The framework that most widely used to describe aspects of cloud computing, and categorize cloud sevices. Microsoft Reference Architecture: What is Infrastructure as a Service? Orientation Azure Portal Other References These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf) Fellowship Materials Top-down description of how Azure is organized Summary of Cloud Interfaces Virtual Machine Background What is a virtual machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company Activities Using the Azure Portal : tutorial and video This is a more detailed tutorial and video of the quick walk-through we did during our live session for Week 1 on September 3 Fellowship Meeting September 10, 2021. Zoom link sent via email Presentation (PDF) Review of Introduction to Cloud materials: discussion and questions Questions about the nature of cloud Activity: Creating (and deleting) a Virtual Machine with Azure updated 9/16; includes instructions for Linux Additional Post-session materials Determining Azure Costs","title":"2. How does the cloud work?"},{"location":"session_how_to_cloud/#session-2-what-is-the-cloud-and-how-does-it-work-an-introduction-using-virtual-machines","text":"When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines. Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start. This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program. At the end of the session you should have a good introduction of what it means to \"cloud compute.\"","title":"Session 2: What is the cloud and how does it work?  An introduction using Virtual Machines"},{"location":"session_how_to_cloud/#readings","text":"","title":"Readings"},{"location":"session_how_to_cloud/#cloud-background","text":"The NIST Definition of Cloud Computing The framework that most widely used to describe aspects of cloud computing, and categorize cloud sevices. Microsoft Reference Architecture: What is Infrastructure as a Service? Orientation Azure Portal","title":"Cloud background"},{"location":"session_how_to_cloud/#other-references","text":"These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective. However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites. Wikipedia article on cloud computing is actually pretty good [M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF]( https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf } Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing I. Porres, T. Mikkonen, A. Ashraf, eds. \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)","title":"Other References"},{"location":"session_how_to_cloud/#fellowship-materials","text":"Top-down description of how Azure is organized Summary of Cloud Interfaces","title":"Fellowship Materials"},{"location":"session_how_to_cloud/#virtual-machine-background","text":"What is a virtual machine (VM)? Introduction from Microsoft What is a Virtual Server? Youtube Video from IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company","title":"Virtual Machine Background"},{"location":"session_how_to_cloud/#activities","text":"Using the Azure Portal : tutorial and video This is a more detailed tutorial and video of the quick walk-through we did during our live session for Week 1 on September 3","title":"Activities"},{"location":"session_how_to_cloud/#fellowship-meeting","text":"September 10, 2021. Zoom link sent via email Presentation (PDF) Review of Introduction to Cloud materials: discussion and questions Questions about the nature of cloud Activity: Creating (and deleting) a Virtual Machine with Azure updated 9/16; includes instructions for Linux","title":"Fellowship Meeting"},{"location":"session_how_to_cloud/#additional-post-session-materials","text":"Determining Azure Costs","title":"Additional Post-session materials"},{"location":"session_how_to_cloud/azure_organization/","text":"Azure Organization This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"cloud fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful. Azure Locations or Regions Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Organization"},{"location":"session_how_to_cloud/azure_organization/#azure-organization","text":"This is a brief description of how Azure cloud services are organized for those just getting started with Azure. It's my own take on this topic written with researchers in mind. However it should not replace Azure official documentation. The link below has a great summary of how it's setup. However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization Microsoft Azure Documentation: Organize your Azure resources effectively Azure is organized by directories of user accounts and subscriptions. All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions. Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user. MSU created a \"cloud fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription. Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\" Anything you can create using a cloud interfaces is a \"resource.\" To help with more organization, in Azure, resources belong to a resource group. Resource groups can collect resources by project which could still have hundreds or just a few resources. There is no restriction and up to you to organize how it works for you. For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects. It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group. Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here. However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions. Applying this organization scheme requires practice and sometimes vigilance. For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers. When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ Summary of top-down Azure Organization: Directory : (MSU account). All account must come from a directory (but an account can be multiple directories) Management groups : we won't use these, for admins to manage multiple subscriptions) Subscription : tied to a billing account, and where all resources are created. Resource Group : organizational tool for resources. Think of it as a \"folder\" in your file system Resource : any cloud entity you may work with (e.g. create, configure, destroy) Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources. If you have never used Azure before, you may be asked to create a free trial. If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account. Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services. They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis. You can use any keys and any values you find useful.","title":"Azure Organization"},{"location":"session_how_to_cloud/azure_organization/#azure-locations-or-regions","text":"Subscriptions are for accounting only and don't represent concrete cloud resources. However cloud resource must reside in computer somewhere, and hence have a location. Locations for cloud providers for can be thought of inside one of their massive data centers. In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region') Resources and Resource groups must be assigned a location when you create them. considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin. Most of the time, simply choose the default which is East US which almost always has the latest features. For some advantage for data transfer, choose (US North Central US). However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers. It's also possible to have back-ups of resources in different region to protect against natural disasters.","title":"Azure Locations or Regions"},{"location":"session_how_to_cloud/azure_portal_walkthrough/","text":"Exercise: Azure Portal Walk-through and Storage account creation MSU Cloud Fellowship About This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure , but it can be a great place to start exploring and trying new services. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material. Orientation to the Azure Portal The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in) This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal: cloud shell: see (link TBD) directories: about your subscription notifications: alerts when things change (when they are created, deleted) settings : most will not be valuable unless you create many resources, but feel free to change these, although do not change your email address help/support feedback : to the Azure people A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere. Creating storage account with the Azure portal Note: It's ok if you would like to repeat this tutorial, there will be minimal costs and you may delete the resources you create (instructions for deleting at the end). You don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. You need a place to keep your stuff for a long time (persist your data) and cloud storage is a durable and inexpensive system for storage nearly unlimited files (or 'objects' in cloud terms). However as we will discover cloud storage is not the same as \"disk storage\" and works differently. Hence you need a storage \"account.\" Requirements: An Azure Account with valid subscription A Resource group All members of the current cloud fellowship cohort have these things Tutorial Steps. Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: This name must be unique for this region in azure, so Use your NetID for part of the name replace \"NETID\" with your MSU NetID here: \"cf21NETIDstorage\" e.g. cf21billspatstorage If you are repeating this tutorial, simply add a \"2\" or \"cf21billspatstorage2\" some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) Region (Location): You may leave US East, or click to select something closer to MSU (e.g. North Central US) Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS) although we won't see a different, LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. Networking: leave all of these settings as-is Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing Tags tags are optional but highly recommended. Tags are notes to yourself about the resource, use them for metadata. At MSU ADS we always have a tag with the key \"created by\" and value the netid of the creator. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa About Portal \"Resource\" Pages Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#exercise-azure-portal-walk-through-and-storage-account-creation","text":"MSU Cloud Fellowship","title":"Exercise: Azure Portal Walk-through and Storage account creation"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about","text":"This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services. Prior to doing this exercise, please read Azure Organization For more background on how azure is structured. For definition of terms used in this walkthrough , refer to our Cloud Glossary including \" resource \", \" azure resource manager \" and \" resource group \" or our list of cloud references for introduction to cloud computing. For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure , but it can be a great place to start exploring and trying new services. Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview Please refer to that as well as this material.","title":"About"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#orientation-to-the-azure-portal","text":"The link above is to a video that walks through the description and tutorial steps below, hosted on MSU MediaSpace ( requires MSU Log-in) This assumes you have an Azure account and a valid subscription. For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, Log-in to https://portal.azure.com with your MSU Netid. If you are a current member of the fellowship and you have difficulty logging in, please contact us right away. orientation: dashboard view. Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account. You may alter the panels on this dashboard to show you the services and aspects of azure that are most important to you. For information on how to create customize your dashboard, see \" Create a dashboard in the Azure portal .\" In the standard, default version of the dashboard the first panel is a list of resources. If you have not created any resources yet you won't see anything. We will explorer resources later in this introduction. The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you. We will focus on the \"All Resources Pane\" If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below) Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources. If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created. This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. Shortcut buttons: the next few icons are short cuts to other functionality in the portal: cloud shell: see (link TBD) directories: about your subscription notifications: alerts when things change (when they are created, deleted) settings : most will not be valuable unless you create many resources, but feel free to change these, although do not change your email address help/support feedback : to the Azure people A note about portal navigation: When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right. This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to Notice that like most things there are 4-5 ways to get to anywhere.","title":"Orientation to the Azure Portal"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#creating-storage-account-with-the-azure-portal","text":"Note: It's ok if you would like to repeat this tutorial, there will be minimal costs and you may delete the resources you create (instructions for deleting at the end). You don't need to know about Cloud storage to complete this tutorial. This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example. You need a place to keep your stuff for a long time (persist your data) and cloud storage is a durable and inexpensive system for storage nearly unlimited files (or 'objects' in cloud terms). However as we will discover cloud storage is not the same as \"disk storage\" and works differently. Hence you need a storage \"account.\" Requirements: An Azure Account with valid subscription A Resource group All members of the current cloud fellowship cohort have these things","title":"Creating storage account with the Azure portal"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#tutorial-steps","text":"Log-in to the Azure portal if you have not already: https://portal.azure.com Click the menu (top left, three horizontal bars) to open it Select \"home\" from the menu - this ensures we all have the same view In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\ Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen... This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft. When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step) Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar in the lower search bar, type \"Storage account\" Note that \"storage\" alone lists many other kinds of resources. You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a spreadsheet). The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. Click \"create\" The azure resource creation screens mostly work like this: there are so many settings Azure has split these up into groups which are listed horizontally across the top. You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form. At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it. We will go page-by-page for these settings Basics: Subscription: Cloud Fellowship Resource Group: Select your resource group (you may only have the one) \\ You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group Storage Account Name: This name must be unique for this region in azure, so Use your NetID for part of the name replace \"NETID\" with your MSU NetID here: \"cf21NETIDstorage\" e.g. cf21billspatstorage If you are repeating this tutorial, simply add a \"2\" or \"cf21billspatstorage2\" some resources have restrictions on naming. Next to storage account is an \"i\" in a circle that has more information. For storage accounts, they must be unique in region, and only numbers and lowercase letters are allowed. I don't know if Non-US letters are allowed (e.g.\u7bb1) Region (Location): You may leave US East, or click to select something closer to MSU (e.g. North Central US) Performance: Standard Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS) although we won't see a different, LRS is cheaper \\ beneath that, leave the \"make read access....\" box checked. Click \"next...Advanced\" Advanced: Leave all of these settings as-is. Networking: leave all of these settings as-is Data Protection: leave all as is. These settings allow you to recover files up to 7 days after deleting or over-writing Tags tags are optional but highly recommended. Tags are notes to yourself about the resource, use them for metadata. At MSU ADS we always have a tag with the key \"created by\" and value the netid of the creator. You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects. tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work Review and create review gives you a chance to double check your settings before committing click \"create\" Deployment Azure calls the process of creating cloud resources a \"deployment.\" This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available. On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment. Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. You may leave this page and the deployment will continue in the background. finish and review When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the \"Notification\" icon indicating the number of messages you have (probably just 1 ). Click on the Notifications icon to show this message. the message should be something like: Deployment succeeded Deployment 'resourcename_12345678901234' to resource group 'group name' was successful. \"Go to Resource\" button will open the Portal page with options for the resource \"Pin to Dashboard\" will create a new tile that is a shortcut to this resource on your dashboard for easy access. If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom) Examine Resource (storage ) We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized. If you didn't already click \"go to resource\", open the top menu and click \"home\" the Portal \"Home\" has a list of \"recent resources\" and this should be at the top. Click on this new cloud storage to view aa","title":"Tutorial Steps."},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about-portal-resource-pages","text":"Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center. The first page is the \"Overview\" which has the resource group, subscription, and other info important for that resource. this followed by the \"Activity Log\" showing how the resource has been used. Each of the following items on the left side is a new page of additional options to alter how the resource is configured. For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources. In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.","title":"About Portal \"Resource\" Pages"},{"location":"session_how_to_cloud/azure_vm_walkthrough/","text":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session. Requirements for both activities You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux) Creating a Windows Virtual Machine This section is based on Windows. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. Requirements for Windows VMs To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/ Optional: Creating a Linux Virtual Machine This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible). Requirements To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in but there are other programs Linux desktop/laptops come with an ssh client Creating a Linux Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-linuxdsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. 1. Authentication Type For the purpose of this exercise, select \"password\" If you are very familiar with ssh keys, this is the recommended method. You will be asked to download a key and use that key in your ssh command. The key is only available for download when you create this vm and if you lose it you can't connect. We can definitely cover how to use ssh keys as this is the preferred method for connecting. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.1000 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section Viewing VM Resources in your Resource group (Windows and Linux) While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) Connecting Connecting to a Windows VM using Remote Desktop Protocol (RDP) client You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines. Connecting to a Linux VM using SSH We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Starting and Stopping the VM (both Windows and Linux) There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal: Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. Deleting the Resources (both Windows and Linux) Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges. More Refereences Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#exercise-creating-and-connecting-to-a-virtual-machine-vm-for-both-windows-and-linux","text":"Link to Video for the Windows version of exercise. On mediaspace.msu.edu which requires a log-in","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. There are two nearly identical activities, and you only need complete one of them: creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer. We will use a pre-configured virtual machine with software already installed for both versions. When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session.","title":"About"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-both-activities","text":"You need an Azure account with an active subscription, and a resource group of your own to work in. Fellows have these things provided. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux)","title":"Requirements for both activities"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-windows-virtual-machine","text":"This section is based on Windows. For an equivalant exercise based on Linux, scroll down. If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-windows-vms","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements for Windows VMs"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows.","title":"Basics"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. You should kkip down the the Viewing VM Resources section below/","title":"Review and Create"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#optional-creating-a-linux-virtual-machine","text":"This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible).","title":"Optional:  Creating a Linux Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements","text":"To connect to Linux you need an terminal or command line interface with an ssh client software. If you have used the MSU HPC, this is the same method for connection. On Mac, the Terminal.app has ssh On Modern version of Windows, the cmd.exe command prompt has an ssh command built in but there are other programs Linux desktop/laptops come with an ssh client","title":"Requirements"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-linux-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Linux Virtual Machine"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template_1","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Ubuntu The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration_1","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal_1","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics_1","text":"The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-linuxdsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - Unbuntu..\" if this is changed you may have to select it again from the list. 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. 1. Authentication Type For the purpose of this exercise, select \"password\" If you are very familiar with ssh keys, this is the recommended method. You will be asked to download a key and use that key in your ssh command. The key is only available for download when you create this vm and if you lose it you can't connect. We can definitely cover how to use ssh keys as this is the preferred method for connecting. UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use","title":"Basics"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings_1","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags_1","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create_1","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this Linux VM. Mine says 0.1000 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. Linux Users continue to the next section","title":"Review and Create"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#viewing-vm-resources-in-your-resource-group-windows-and-linux","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"Viewing VM Resources in your Resource group (Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"The VM Resource Page"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting","text":"","title":"Connecting"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-windows-vm-using-remote-desktop-protocol-rdp-client","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines.","title":"Connecting to a Windows VM using Remote Desktop Protocol (RDP) client"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-linux-vm-using-ssh","text":"We will connect and use this remote VM running the Linux operating system with a command line connection. It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise. In addition this assumes you have some familiarity with using the command line and starting your terminal program. There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with SSH this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side. Copy this IP address to the clipboard, or make a note of it. Mine was 20.98.28.63. Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop. Use the Public IP address. not all VMs have a public IP address but this one will. also make a note of the User ID and password you used to create the VM above side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key, even though we did not create an ssh key when we created a VM. If you did not create an ssh key, you do not need to follow these instructions. on your desktop/laptop, start your terminal program on MacOS/Linux or cmd.exe if you using Windows. Enter the command as displayed, which is something like ssh vmusername@vmipaddress In my case, my command is ssh patbills@20.98.28.63 If this is the first time connection, you'll get the standard ssh warning \"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\" simply say \"yes\" and enter Enter the password you used when configuring the VM in the \"Basics\" section above. (note that ssh does not show any key movement or * when you type a password) it takes a while to connect for the fist time as the VM configures software and prepares your user account You may use the machine as you would any other linux computer. For more information about what software is installed, see We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt.","title":"Connecting to a Linux VM using SSH"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#starting-and-stopping-the-vm-both-windows-and-linux","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" In a Linux ssh session you may use a command like sudo shutdown -h now When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it.","title":"Starting and Stopping the VM (both Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#stopping-deallocating-the-vm-with-the-portal","text":"Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"Stopping (deallocating) the VM with the Portal:"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#deleting-the-resources-both-windows-and-linux","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . If you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\" Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges.","title":"Deleting the Resources (both Windows and Linux)"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#more-refereences","text":"Azure has very abbreviated versions of this exercise if you would like another perspective. They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship) https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps Data Science Use Case Tutorials from Azure: Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product. However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough If you follow these, just remember to delete the resources you create when you are done exploring","title":"More Refereences"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/","text":"Exercise: Creating a Windows Virtual Machine (VM) Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in) About This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/ Requirements You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided. Creating and Connecting to a Windows Virtual Machine Requirements To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection. Creating a Windows Virtual Machine If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below. 1. Selecting the Resource Template In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option. 2. select the pre-set configuration These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \" 3. Configure the VM using the Azure Portal The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. Basics The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked. Disks and Other Settings For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see. Tags Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\" Review and Create If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes. 4. The Resources While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above) 5. The VM Resource Page To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource) 6. Connecting You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt. 7. Starting and Stopping the VM There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security. 8. Deleting the Resources Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#exercise-creating-a-windows-virtual-machine-vm","text":"Please see our updated version that covers both Windows and Linux Link to Video for this exercise on mediaspace.msu.edu (requires log-in)","title":"Exercise: Creating a Windows Virtual Machine (VM)"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#about","text":"This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal. This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough . In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise. For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section We will use a pre-configured virtual machine with software already installed . When creating a VM you can use an Azure template and there are many of these. The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available. For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/","title":"About"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements","text":"You need an account in azure with an active subscription, and a resource group of your own to work in. Fellows have these things provided.","title":"Requirements "},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-and-connecting-to-a-windows-virtual-machine","text":"","title":"Creating and Connecting to a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements_1","text":"To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client. MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12 Linux users install http://xrdp.org/ Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.","title":"Requirements"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-a-windows-virtual-machine","text":"If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges. Go back to step 1 below.","title":"Creating a Windows Virtual Machine"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#1-selecting-the-resource-template","text":"In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option) In the create resource search box, type \"data science virtual machine\" In the options select Data Science Virtual Machine - Windows 2019 The \"Plans\" section has a description of the template if you would like to know more. Click the \" start with a pre-set configuration \" option.","title":"1. Selecting the Resource Template"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#2-select-the-pre-set-configuration","text":"These configurations help to select your VM size based on your activity. We will use the default options and click \"Continue to create a VM\" The options do not affect the outcome of the exercise so at this step explore each option Click \" Continue to create a VM \"","title":"2. select the pre-set configuration"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","text":"The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed.","title":"3. Configure the VM using the Azure Portal"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#basics","text":"The Subscription should be \"Cloud Fellowship\" and resource group should be your CF resource group (with your netid). As we create additional resource groups for this Virtual machine name Name: CF21-netid-dsvmtest One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing. In the name above, replace \"netid\" with your own MSU netid. Note that different resources have different naming restrictions. For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|<>+=;,?*@&, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix. We will delete this VM and create something more suitable in the future. 1. Region Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\" this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center). You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\" ). Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. 1. Image should be \"Data Science Virtual Machine - windows...\" if this is change you may 1. Azure Spot Instance leave unchecked. 1. Size You can leave the size that is currently selected. This is how you select the specifications for CPU and memory. The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting. If you click this drop-down menu you may see some other sizes and prices. The Monthly price assumes 24 hour/day operation. Your price to experiment will often be less than $1.00 1. Administrator Account Just like you need to log-in to your own computer, you must create a user account for the VM. Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. * username : use any user name you will easily remember, perhaps your netid * password : something you can remember, but is complex to be secure. Do not use your MSU password or any other passwords you use 1. Licensing Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure. Leave this box unchecked.","title":"Basics"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#disks-and-other-settings","text":"For this exercise we'll be using the default values for almost all the pages except for Basics page. However you are encouraged to look through these options to see what is involved in creating a virtual machine. The Azure VM documentation covers many of them. For example a VM requires several networking components. The good news is that Azure will name and create these for you, which will see.","title":"Disks and Other Settings"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#tags","text":"Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources. I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources. Click \"tags\" in the top row of options (just before 'review and create') In the first row, For Name , type activity and for the Value type session2 click \"review and create\"","title":"Tags"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#review-and-create","text":"If there are errors the form name will have a red dot next to it. Go back to that form and see what may be the issue. If the Validation passed, it will display the approximate hourly cost to use this VM. Mine says 0.1920 USD/hr Click \"Create\" and the deployment will start. It will take at most 15 minutes.","title":"Review and Create"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#4-the-resources","text":"While the deployment is in progress you may explore the operation details or click any of the resources that have been created. Open your resource group in the portal: click the portal menu on the top left, and select \"resource groups\" From the list, select your CF21 group. When the deployment is finished, you should see several new resources They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip The second column is the \"type\" which helps identify what they are click for a large view in a new tab/window Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)","title":"4. The Resources"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#5-the-vm-resource-page","text":"To see the details for your virtual machine, click the VM in your resource group if you haven't already. click for larger view There are many details here but some immediate things to notice: in the top row are buttons to connect, start, restart and stop the vvm. in the top, \"essentials\" section the \"status\" should be \"running.\" on the right side is the assigned IP address which you need to connect. Highlight and copy and paste this address. If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)","title":"5. The VM Resource Page"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#6-connecting","text":"You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both. The following Azure documentation describes how to connect to a Windows VM: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon Here are more detailed instructions: There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. Connect with RDP (remote desktop protocol) is a Microsoft method for connecting to the graphical desktop. For Mac/Linux requires additional software (mentioned at the beginning of this page). Click \"connect\" and select \"rdp\" if it isn't already. click \" download RDP file \" button and save the .rdp file anywhere on your computer that you find it again after it's download, and if you Mac users have installed the RDP client, then double click the .rdp file to open your remote desktop software. On windows, any security or error messages, click \"connect\" Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM When you connect, if the VM is not running, you will get an error message. Here is what the Windows screen looks like: This is because we are using a temporary certificate but it is secure. Click \"Yes\" Enter the Username and password you used when configuring the VM in the \"Basics\" section above. you may be able to simply enter the user name and password directly If not, in the Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK. If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. Once you connect, you may see Windows starting up and installing things. Feel free to close any windows. Once the installations are finished, you may use the machine as you would any other windows computer. If you type Rstudio in the search box, you may launch an Rstudio session on this remote computer. It also has Python, many python libs and Jupyter notebook. We will cover how to transfer code and files to a VM in a later session. When you finished with your remote session you may simply close the remote windows (leaving the VM running. See below for how to turn it off and delete it. Optional: Connect to the Windows DSVM with ssh This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH. If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter ssh <username>@<ipaddress> Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page. This is similar to how you connect to the MSU HPC, if you are HPC user. You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. When you log-in you will be connected to the Windows command prompt (e.g. C:\\Users\\username> To Exit, type exit at the command prompt.","title":"6. Connecting"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#7-starting-and-stopping-the-vm","text":"There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use Windows to turn it off. The VM is then \"stopped.\" The VM is not running, but it is still \"allocated.\" When you turn it back on, it will come on immediately. 1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM. Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up. This is cheaper then the first method in the long run 1. Delete it. Stopping (deallocating) the VM with the Portal : Go to the resource page for the VM, if you are not already. If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. The Status field near the top of this screen will indicate running or stopped. Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. There is a warning about losing your IP address, with a check box to reserve it. If you plan on deleting the VM now, click \"ok\" If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK The default is to use a \"dynamic\" address which is assigned every time you turn on the VM When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off. That is approx $2.70/month It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep. The main reason for this is for security.","title":"7. Starting and Stopping the VM"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#8-deleting-the-resources","text":"Open the Resource group as above When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify. Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button) If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\" For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views . IF you add filter on tag, then you may select all the items that are shown, and delete those. after selecting confirm the deletion by typing \"yes\"","title":"8. Deleting the Resources"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/","text":"Interfacing with Cloud Services Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad. Summary of Cloud Interfaces This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html Graphical Web Interface Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface. Desktop Applications Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure Command Line For those not familar wiht the command line, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell. SDK : Software Developer Kit A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to? Python SDK All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors. R Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages. Cloud company frameworks In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation . Azure: ARM templates Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates Third-party programming with Terraform There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The ad - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary Building Cloud from Cloud This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language. References See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"Interfacing with Cloud Services"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#interfacing-with-cloud-services","text":"Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources. This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC). Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it. All of the cloud companies as their base use a web interface, so-called REST API . Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces. Here is an example web api URL for weather forecast , with parameters for coordinates, units and format of output https://www.7timer.info/bin/astro.php?lon=113.2&lat=23.1&ac=0&unit=metric&output=json&tzshift=0 Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work. In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address. The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api. You may see references to resources in documentation and that means any web doo-dad.","title":"Interfacing with Cloud Services"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#summary-of-cloud-interfaces","text":"This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts. In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS. See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html","title":"Summary of Cloud Interfaces"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#graphical-web-interface","text":"Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com . For Google cloud it's the \"console\" and for AWS it's also called the console. See below for an introduction to using the portal. Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface.","title":"Graphical Web Interface"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#desktop-applications","text":"Azure provides some desktop applications for working with a few of the widely used cloud services : Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ Can create cloud storage and upload/download data. We will use that for our session on Storage Azure Data Studio: https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15 Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure","title":"Desktop Applications"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#command-line","text":"For those not familar wiht the command line, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command. With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line Azure has two command line interfaces: The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users. Since Powershell has been ported to Linux and Mac and the Linux Shell and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI. Your choice depends on the kinds of other systems you'll be working with. For example, the MSU HPC uses Linux command shell but Windows servers and other Windows services like SQLServer work well with Powershell.","title":"Command Line"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#sdk-software-developer-kit","text":"A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service. All the cloud vendors have SDKs, and they all have SDKs for Python. SDK simply means you can create, delete, interact with cloud services from your program. Why leave python or R if don't have to?","title":"SDK : Software Developer Kit"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#python-sdk","text":"All cloud vendors have SDKs to work with Python. After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others). Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK. These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. Both AWS and Google Cloud have Python SDKs, and probably other vendors.","title":"Python SDK"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#r","text":"Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio. See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages.","title":"R"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#cloud-company-frameworks","text":"In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure. For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation .","title":"Cloud company frameworks"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#azure-arm-templates","text":"Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created. For Azure these are JSON-formatted files that are \"declaritive\" (rather than procedural or imperative like Python). The best way to understand these is to explore the many that Microsoft posts on github, and to try them. If you do, be mindful to delete any resources you create so as not to be charged for them. - Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview - Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates","title":"Azure: ARM templates"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#third-party-programming-with-terraform","text":"There are other ways to 'program the cloud' from companies outside of the big three. One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company. The ad - Terraform: https://www.terraform.io - Can work with any vendor including Azure - Often more readable than ARM templates, Syntax remarkably simple - Focus on maintaining consistent systems ( declarative) - Does not cover all services, but can fall back to ARM templates when necessary","title":"Third-party programming with Terraform"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#building-cloud-from-cloud","text":"This may not be an 'interface' but is operationally similar. It's possible to use some of the above interfaces on existing cloud services, e.g. creating new cloud resources automaticaly from existing cloud resources. Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand). For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters). This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language.","title":"Building Cloud from Cloud"},{"location":"session_how_to_cloud/intro_to_cloud_interfaces/#references","text":"See our references page for curated Azure links. For AWS, see https://aws.amazon.com/tools/ about the AWS CLI: https://aws.amazon.com/cli/ Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html","title":"References"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/","text":"Workshop : Creating your own cloud computer Introduction This workshop walks you though , using Microsoft Azure, the creation of a cloud virtual machine and opens access to it. We will use command line access to use the remote machine to download data and run a calculation. this is a similar experience to using any remote Linux system, such as the MSU HPCC. Pre-requistites Microsoft Azure account (provisioned for participants) No previous experience with cloud virtual machines necessary Using the Azure portal to create a resource group (should this be creatd ahead of time?) Create a virtual machine using a template Create a data science virtual machine using a template. portal create... in search bar type \"data science virtual machine select \"d s v m Ubuntu\" select \"pre-configured\" click \"dev test\" and then below click \"general purpose\", and then 'next' \"Basics\" Section: in next screen select or entered the following options. Resource Group: select your resource group VM Name: please enter a name with the following pattern cf-dvsm-netid using your own netid Region : select the default Image : should say \"Data Science Virtual machine - Unbuntu 18.0.4 - Gen 1\" Azure Spot Instance : leave unchecked Size : Standard_D2s_v3 ($80/month) note: it will only cost pennies per hour Administrator account : select \"password\" note: ssh key is more secure but requires time consuming setup Username : enter your netid this is easy to remember Password : please enter a complex password don't use your actual netid password, also write it down as we will only use it once and it can't be recovered click \"next (disks)\" Note in this \"Create a Virtual Machine page, there are several sections across the top Basics Disks Networking Management Advanced Tags Review + create We can skip all sections now and go to \"Review + create\" Product details: note the costs (mine is 0.1100 USD/hr) click the \"Create\" button at the bottom of this screen wait. the screen should say \"Deployment in Progress\" report any errors or problems click \"Go to Resource\" when it's complete Exploring the Azure portal this portal page lists details about this virtual machine. Connect options to connect to remote linux computer: ssh , alwayws works, requires Mac terminal or windows or mobaxterm Rstudio Server (must be started) Jupyter Notebooks (must be started) Remote desktop (must be installed on VM, and a client must be installed on laptop) test connection: in the left hand menu of the VM resource, find the \"connect\" section click the \"ssh\" section if not already selected near the bottom click \"test your connection\" connect with ssh: open your terminal program in the portal, find the machine ip address issue command ssh azureuser@<ip> Download Data Using standard Linux tools we will download data onto this remote computer Log-in via ssh if you haven't already use the following command to download data set git clone https://github.com/fivethirtyeight/data/tree/master/college-majors review the files using linux commands cd college-majors; ls head grad-students.csv Start R studio Server","title":"Workshop : Creating your own cloud computer"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#workshop-creating-your-own-cloud-computer","text":"","title":"Workshop : Creating your own cloud computer"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#introduction","text":"This workshop walks you though , using Microsoft Azure, the creation of a cloud virtual machine and opens access to it. We will use command line access to use the remote machine to download data and run a calculation. this is a similar experience to using any remote Linux system, such as the MSU HPCC.","title":"Introduction"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#pre-requistites","text":"Microsoft Azure account (provisioned for participants) No previous experience with cloud virtual machines necessary","title":"Pre-requistites"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#using-the-azure-portal-to-create-a-resource-group","text":"(should this be creatd ahead of time?)","title":"Using the Azure portal to create a resource group"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#create-a-virtual-machine-using-a-template","text":"Create a data science virtual machine using a template. portal create... in search bar type \"data science virtual machine select \"d s v m Ubuntu\" select \"pre-configured\" click \"dev test\" and then below click \"general purpose\", and then 'next' \"Basics\" Section: in next screen select or entered the following options. Resource Group: select your resource group VM Name: please enter a name with the following pattern cf-dvsm-netid using your own netid Region : select the default Image : should say \"Data Science Virtual machine - Unbuntu 18.0.4 - Gen 1\" Azure Spot Instance : leave unchecked Size : Standard_D2s_v3 ($80/month) note: it will only cost pennies per hour Administrator account : select \"password\" note: ssh key is more secure but requires time consuming setup Username : enter your netid this is easy to remember Password : please enter a complex password don't use your actual netid password, also write it down as we will only use it once and it can't be recovered click \"next (disks)\" Note in this \"Create a Virtual Machine page, there are several sections across the top Basics Disks Networking Management Advanced Tags Review + create We can skip all sections now and go to \"Review + create\" Product details: note the costs (mine is 0.1100 USD/hr) click the \"Create\" button at the bottom of this screen wait. the screen should say \"Deployment in Progress\" report any errors or problems click \"Go to Resource\" when it's complete","title":"Create a virtual machine using a template"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#exploring-the-azure-portal","text":"this portal page lists details about this virtual machine.","title":"Exploring the Azure portal"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#connect","text":"options to connect to remote linux computer: ssh , alwayws works, requires Mac terminal or windows or mobaxterm Rstudio Server (must be started) Jupyter Notebooks (must be started) Remote desktop (must be installed on VM, and a client must be installed on laptop) test connection: in the left hand menu of the VM resource, find the \"connect\" section click the \"ssh\" section if not already selected near the bottom click \"test your connection\" connect with ssh: open your terminal program in the portal, find the machine ip address issue command ssh azureuser@<ip>","title":"Connect"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#download-data","text":"Using standard Linux tools we will download data onto this remote computer Log-in via ssh if you haven't already use the following command to download data set git clone https://github.com/fivethirtyeight/data/tree/master/college-majors review the files using linux commands cd college-majors; ls head grad-students.csv","title":"Download Data"},{"location":"session_how_to_cloud/workshop-creatingvm-saved/#start-r-studio-server","text":"","title":"Start R studio Server"},{"location":"session_how_to_cloud/workshop-creatingvm/","text":"Workshop : Creating your own cloud computer For Session 2 of the MSU Cloud Fellowship Details of the workshop and recording will be posted after our remote session on Sept 10","title":"Workshop : Creating your own cloud computer"},{"location":"session_how_to_cloud/workshop-creatingvm/#workshop-creating-your-own-cloud-computer","text":"For Session 2 of the MSU Cloud Fellowship Details of the workshop and recording will be posted after our remote session on Sept 10","title":"Workshop : Creating your own cloud computer"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/","text":"Intro to Cloud Costs on Azure You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background. 1. Pricing Pages. All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services. 2. Build something and check the cost The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view 3. Pricing Calculators All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/ Summary and other notes Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries). Azure Pricing Resources Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Intro to Cloud Costs on Azure"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#intro-to-cloud-costs-on-azure","text":"You've heard us say that nearly everything Azure has a cost, but how can you tell how much? Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required) The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background.","title":"Intro to Cloud Costs on Azure"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#1-pricing-pages","text":"All cloud vendors have pricing pages that describe how they meter and charge for services. For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing However I usually find the page I need quickly by simply googling azure <service name> pricing for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ Some of these pages are straightforward, but like the one above has addition knowledge. What does this mean in practice? For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand. I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices. This kind of background info is very common for services.","title":"1. Pricing Pages."},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#2-build-something-and-check-the-cost","text":"The other option is the empircal method: build something, use it, review the costs, and estimate. At the resource group in the protal ( see Azure Organization ), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\" - click that This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things. Near the middle are rouded buttons controlling the view you see. At the right side of this is a button \"Add Filter\" which you can click to show costs only for some resources. For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources. See the Cloud Glossary In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering. Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate. Use a custom date range for the time period that makes sense for the costs you want to observe. Example Azure Cost Analysis Screen, filtered by Tag. Click for larger view","title":"2. Build something and check the cost"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#3-pricing-calculators","text":"All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money. For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/","title":"3. Pricing Calculators"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#summary-and-other-notes","text":"Combining these three methods is how we can estimate costs. Notes: Pricing often depends on the location or region you select. Most regions in the US are the same price. Data transfer costs are really hard to estimate. Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge. This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers => more costs =>but more revenue). However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free. One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries).","title":"Summary and other notes"},{"location":"session_how_to_cloud/costs/azure_cloud_cost_basics/#azure-pricing-resources","text":"Quickstart: Explore and analyze costs with cost analysis Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021","title":"Azure Pricing Resources"},{"location":"session_introduction/","text":"Session 1: Introduction to the 2021-22 MSU Cloud Fellowship You don't have to face the clouds alone Welcome! The goals of this session are to orient you to this program, set up our technology, introduce ourselves, provide some background on cloud computing, and discuss what all of our expectations are. For this session, like the others, we have some pre-session activities for the week, followed by a meeting Friday, September 3, from 2:00-3:30pm. Activities: Please complete the following activities prior to our first synchronous meeting September 3. Complete a Brief Survey All 2021-22 participants were sent an introductory email that included a link to a brief survey. preferences and techmology exposure. Please complete this survey prior to our first meeting. Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting. If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us . Note there will be time for questions and dicussion during our first meeting. Readings Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version) Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review Meeting: Introductions and program overview. September 3rd, 2021 : Zoom meeting included in introductory email to participants Introductions Brian O'shea, ICER Danielle Barnes, MSU Analytics and Data Solutions Mahmoud Parvizi, Instructor Past experience & current role Cloud facilitator Participant in first Fellowship cohort Pat Bills, Main Instructor A video of our introductions is avaialble on the MSU MediaSpace (requires MSU log-in) Participant Introductions & Discussion Introductions Research synopsis, Research Methods skills (non-IT) Current research computing hurdles, roadblocks, challenges & triumphs How will (or has) cloud computing affected your research? Your goals for this fellowship What do you think the cloud is or is good for? Discussion on availability to complete class and projects Fellowship Program Overview Why and What: 15 minute lecture on broad topics and goals of the course Review our \" syllabus \" Pre-session materials and activities, \"textbook\" Session activity Expectations Projects: Mahmoud Parvizi Lecture: About Cloud Computing Introducing computing vs. research computing vs. HPC vs. cloud computing Learning how to learn about cloud Cloud perceptions vantage points Using workflow computational and computational thinking The interfaces to cloud computing About cloud security Costs and budget overview Acknowledging bias in access to cloud computing across research cultures References: The NIST definition of cloud computing Additional comments from program organizers Demonstration: Using the Azure Portal A quick, live demonstration orienting you to the Azure portal. Our next session activities will include a more thorough workshop on creating cloud computing resources A more complete tutorial and video of this walk-through is available in Session 2 activities. Questions and Discussion What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)?","title":"1. Introduction"},{"location":"session_introduction/#session-1-introduction-to-the-2021-22-msu-cloud-fellowship","text":"You don't have to face the clouds alone","title":"Session 1: Introduction to the 2021-22 MSU Cloud Fellowship"},{"location":"session_introduction/#welcome","text":"The goals of this session are to orient you to this program, set up our technology, introduce ourselves, provide some background on cloud computing, and discuss what all of our expectations are. For this session, like the others, we have some pre-session activities for the week, followed by a meeting Friday, September 3, from 2:00-3:30pm.","title":"Welcome!"},{"location":"session_introduction/#activities","text":"Please complete the following activities prior to our first synchronous meeting September 3. Complete a Brief Survey All 2021-22 participants were sent an introductory email that included a link to a brief survey. preferences and techmology exposure. Please complete this survey prior to our first meeting. Introduce yourself on Microsoft Teams You should have all been given access to a Team \"MSU ICER Cloud Fellowship\" via your NetID. Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client) Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed. If necessary MSU IT has documentation about MS Teams here: https://tech.msu.edu/technology/collaborative-tools/spartan365/ ( the link on that page requires yet another MSU log-in) Confirm Access to Azure Portal Go to https://portal.azure.com . Log in with your MSU netid and password. Ensure you can access the Azure main web \"portal.\" You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access. You may see a list of \"resources\" and will introduce Azure during our first meeting. If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us . Note there will be time for questions and dicussion during our first meeting.","title":"Activities:"},{"location":"session_introduction/#readings","text":"Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon ( Alternative link to publisher preview chapter ) Using Cloud Computing for Academic Research , Mahmoud Parvizi (draft version) Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review","title":"Readings"},{"location":"session_introduction/#meeting-introductions-and-program-overview","text":"September 3rd, 2021 : Zoom meeting included in introductory email to participants","title":"Meeting: Introductions and program overview."},{"location":"session_introduction/#introductions","text":"Brian O'shea, ICER Danielle Barnes, MSU Analytics and Data Solutions Mahmoud Parvizi, Instructor Past experience & current role Cloud facilitator Participant in first Fellowship cohort Pat Bills, Main Instructor A video of our introductions is avaialble on the MSU MediaSpace (requires MSU log-in)","title":"Introductions"},{"location":"session_introduction/#participant-introductions-discussion","text":"Introductions Research synopsis, Research Methods skills (non-IT) Current research computing hurdles, roadblocks, challenges & triumphs How will (or has) cloud computing affected your research? Your goals for this fellowship What do you think the cloud is or is good for? Discussion on availability to complete class and projects","title":"Participant Introductions &amp; Discussion"},{"location":"session_introduction/#fellowship-program-overview","text":"Why and What: 15 minute lecture on broad topics and goals of the course Review our \" syllabus \" Pre-session materials and activities, \"textbook\" Session activity Expectations Projects: Mahmoud Parvizi","title":"Fellowship Program Overview"},{"location":"session_introduction/#lecture-about-cloud-computing","text":"Introducing computing vs. research computing vs. HPC vs. cloud computing Learning how to learn about cloud Cloud perceptions vantage points Using workflow computational and computational thinking The interfaces to cloud computing About cloud security Costs and budget overview Acknowledging bias in access to cloud computing across research cultures References: The NIST definition of cloud computing","title":"Lecture: About Cloud Computing"},{"location":"session_introduction/#additional-comments-from-program-organizers","text":"","title":"Additional comments from program organizers"},{"location":"session_introduction/#demonstration-using-the-azure-portal","text":"A quick, live demonstration orienting you to the Azure portal. Our next session activities will include a more thorough workshop on creating cloud computing resources A more complete tutorial and video of this walk-through is available in Session 2 activities.","title":"Demonstration: Using the Azure Portal"},{"location":"session_introduction/#questions-and-discussion","text":"What things are at the top of your mind as you begin this program? Which of these topics resonates with your previous experience using computing or cloud computing (if any)?","title":"Questions and Discussion"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/","text":"Practical Introduction for Researchers on Azure Introducing cloud computing vs. research computing Learning how to learn about cloud You may have looked at the various websites and poked around the web, and found it's just not clear at all how cloud computing may be helpful to you, even though it all sounds great. The challenge for researchers learning about cloud is that most cloud documentation for isn't written for you. Cloud training and documentation are mostly written for IT professionals like system admins and architects, software developers, business people, and agency managers. Researchers tend to be a little of all of those things. Training materials ofen have an embedded conceptual models of computing, and this model depend on your approach. Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. That can make it difficult to decipher which kind of cloud service will work best for your use case. As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. The target audience for most cloud companies are IT professional building IT systems for public or institutational use. Let's call this the \"Systems\" perspective: built for someone else to use, e.g. a service must be available at scale and ultimately reliable documentation is in terms of historic IT systems house in on-premise corporate data centers \"production\" systems often very concerned with authentication and security The second audience are corporate software engineers, or dot-com or app software companies. We'll call this the \"developer perspective need to easily create systems to run their software for demonstration and testing complete interelate goal is a robust sytem that can handle many users, e.g. the performance of a \"production\" systems are often top of mind And finally most closely related to your work are data science, \"machine learning\" or an \"analytical\" perspective systems to achieve computation. May work like our local HPC systems built only for small work groups, not for public can still scale but must be reproducible to document methods even this documentation can quickly veer off in to building production systems for companies to re-run inference say many times a data or with a constant stream of corporate data What is are the goals from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others? What documentation is available for researchers? There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos NIST defintions of cloud: Service Levels and You The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researhces who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. Cloud \"Services\" and the Packaging of Open Source Systems Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ? Caveats and help As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing, even slightly, making technology-specific tutorials obsolete in months. For example last year Azure had a \"Notebook Service\" for running Python notebooks, and now there is this in place of the regular documentation: What happened to Azure Notebooks? There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. During the cloud fellowship we are here to provide some answers, context for what you are seeing, or possible directions to explore. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. The Interfaces to Cloud A defining aspect of cloud computing is that it's \"on-demand\" hence creation of resources must be automated or \"scriptable.\" All Cloud providers have various 'interfaces' to their services that include both programmatic and web-based. We will talk about about how these in detail next sesion, but at the end of this session we will do a walk through of using the Azure portal, which is also an exercise for next session. Using workflow and computational thinking Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research computing and one of much academic work. To enhance reproducibility in your own work, consider documenting all the steps needed for create the environment to run your computation. For many on-premise academic systems (e.g. the MSU HPCC), we depend upon the system administrators to create that environment, but we may install and configure all the software we need to run our code. Workflow thinking can apply to the scienfic domain itself (e.g. \"Principles for data analysis workflows\" https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008770 ) and to the provisioning of the cloud computing environment. That is, we may use a workflow system for creating all the cloud stuff we need, and then a different workflow system that runs on that cloud stuff. One example is we may create an HPC system on Azure using templates and then launch the Slurm scheduler on that HPC to run our jobs. ( note the complexity of running our own HPC is beyond the scope of this fellowship and used as an example only ) A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. This can dramatically save on costs . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need. About Cloud Security Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Attackers may use the services you create to launch attacks on other services, leaving you liable. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security: Microsoft Model of Shared Responsibility for Cloud Computing We will come back to this model as we gain deeper understanding of research computing on the cloud. Costs and Budget overview We will cover the details of pricing, examine costs, and controlling costs in future sessions. Each participant has a budget for their Azure resources that they should stay under. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Briefly: Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk HPCC vs Cloud Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers. Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never): Big Data systems (see magpie project) Long-running Data Systems like database servers Web-based applications (see on-demand project) Containers (see singularity project) Acknowledging bias in access to cloud computing across research cultures Additional comments from instructors and organizers Summary and additional comments","title":"Practical Introduction for Researchers on Azure"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-on-azure","text":"","title":"Practical Introduction for Researchers on Azure"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#introducing-cloud-computing-vs-research-computing","text":"","title":"Introducing cloud computing vs. research computing"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","text":"You may have looked at the various websites and poked around the web, and found it's just not clear at all how cloud computing may be helpful to you, even though it all sounds great. The challenge for researchers learning about cloud is that most cloud documentation for isn't written for you. Cloud training and documentation are mostly written for IT professionals like system admins and architects, software developers, business people, and agency managers. Researchers tend to be a little of all of those things. Training materials ofen have an embedded conceptual models of computing, and this model depend on your approach. Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes. That can make it difficult to decipher which kind of cloud service will work best for your use case. As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need. Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. The target audience for most cloud companies are IT professional building IT systems for public or institutational use. Let's call this the \"Systems\" perspective: built for someone else to use, e.g. a service must be available at scale and ultimately reliable documentation is in terms of historic IT systems house in on-premise corporate data centers \"production\" systems often very concerned with authentication and security The second audience are corporate software engineers, or dot-com or app software companies. We'll call this the \"developer perspective need to easily create systems to run their software for demonstration and testing complete interelate goal is a robust sytem that can handle many users, e.g. the performance of a \"production\" systems are often top of mind And finally most closely related to your work are data science, \"machine learning\" or an \"analytical\" perspective systems to achieve computation. May work like our local HPC systems built only for small work groups, not for public can still scale but must be reproducible to document methods even this documentation can quickly veer off in to building production systems for companies to re-run inference say many times a data or with a constant stream of corporate data What is are the goals from research perspective for cloud computing? Custom: can create customized resources only when you need it On-demand: can run ad-hoc computations on those on-demand resources Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. Cost effective: unlike commerical applications, more users does not mean more revenue. Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend. Others?","title":"Learning how to learn about cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","text":"There are general, conceptual introductions and dicussions for academics. https://cloud4scieng.org/ Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. https://cloudmaven.github.io/documentation/ from the eScience institute of the University of Washington. It doesn't appear to be maintained but may have some good resources. Original github repositories are https://github.com/cloudmaven https://cloudbank-project.github.io/cb-resources/ Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. Cloudbank training videos","title":"What documentation is available for researchers?"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#nist-defintions-of-cloud-service-levels-and-you","text":"The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn? Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum Infrastructure (aaS): Nuts and bolts, DIY, Lego. You need understanding of computing architecture as these services Everything in between: Platforms or pre-configured and managed infrastructure Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services. E.g. Office 365, Google Drive The sweet-spot for researhces who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms. These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls.","title":"NIST defintions of cloud: Service Levels and You"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems","text":"Case Study on Open Source system as Cloud service: MySQL Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data. Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app ) and millions of websites. project: https://www.mysql.com/products/community/ and https://mariadb.org/ DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved Azure MySQL Service (e.g PaaS): Azure Database for MySQL AWS MySQL Service: Amazon RDS for MySQL Google MySQL Service Cloud SQL other companies, such as Aiven for MySQL Spin-offs: Amazon also offers AWS Aurora which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper What would a \"SaaS\" offering for tabular data look like? A \"Google Docs\" for Databases? Perhaps https://www.airtable.com/ ?","title":"Cloud \"Services\" and the Packaging of Open Source Systems"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#caveats-and-help","text":"As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective. The cloud services themselves are always changing, even slightly, making technology-specific tutorials obsolete in months. For example last year Azure had a \"Notebook Service\" for running Python notebooks, and now there is this in place of the regular documentation: What happened to Azure Notebooks? There are new services and bundles created all the time that may be competing or superior choices for doing research If you are unsure, ask us. See the contact page or use our Teams channel. During the cloud fellowship we are here to provide some answers, context for what you are seeing, or possible directions to explore. Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those.","title":"Caveats and help"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#the-interfaces-to-cloud","text":"A defining aspect of cloud computing is that it's \"on-demand\" hence creation of resources must be automated or \"scriptable.\" All Cloud providers have various 'interfaces' to their services that include both programmatic and web-based. We will talk about about how these in detail next sesion, but at the end of this session we will do a walk through of using the Azure portal, which is also an exercise for next session.","title":"The Interfaces to Cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#using-workflow-and-computational-thinking","text":"Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66. ) and this is a significant issue for research computing and one of much academic work. To enhance reproducibility in your own work, consider documenting all the steps needed for create the environment to run your computation. For many on-premise academic systems (e.g. the MSU HPCC), we depend upon the system administrators to create that environment, but we may install and configure all the software we need to run our code. Workflow thinking can apply to the scienfic domain itself (e.g. \"Principles for data analysis workflows\" https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008770 ) and to the provisioning of the cloud computing environment. That is, we may use a workflow system for creating all the cloud stuff we need, and then a different workflow system that runs on that cloud stuff. One example is we may create an HPC system on Azure using templates and then launch the Slurm scheduler on that HPC to run our jobs. ( note the complexity of running our own HPC is beyond the scope of this fellowship and used as an example only ) A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed. This can dramatically save on costs . This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need.","title":"Using workflow and computational thinking"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#about-cloud-security","text":"Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source. Attackers may use the services you create to launch attacks on other services, leaving you liable. Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above. Our textbook has a nice chaper outlining cloud security The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security: Microsoft Model of Shared Responsibility for Cloud Computing We will come back to this model as we gain deeper understanding of research computing on the cloud.","title":"About Cloud Security"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#costs-and-budget-overview","text":"We will cover the details of pricing, examine costs, and controlling costs in future sessions. Each participant has a budget for their Azure resources that they should stay under. If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). Briefly: Costs are more than just dollars for services. Consider [Total Cost] = ( $ + Time + Risk ) [Total Time] = ( development time + wait time + compute time ) Risk is rarely non-significant. Never say \"I won't get hacked...\" In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk","title":"Costs and Budget overview"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#hpcc-vs-cloud","text":"Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing. The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers. Many systems not designed for HPC can be adjusted to run in that environment. However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never): Big Data systems (see magpie project) Long-running Data Systems like database servers Web-based applications (see on-demand project) Containers (see singularity project)","title":"HPCC vs Cloud"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","text":"","title":"Acknowledging bias in access to cloud computing across research cultures"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#additional-comments-from-instructors-and-organizers","text":"Summary and additional comments","title":"Additional comments from instructors and organizers"},{"location":"session_moving_data/","text":"Session 4: Moving Data in The Cloud There are many ways to move data around in the cloud. They are based on the limitations of data movement across complex and distant networks and the scale of cloud networks and storage, and the needs of companies to move and process huge amounts of data on a schedule. Reading Session Slides: Azure Techniques for Moving Data Optional Reading Adding a data disk to virtual machine: A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these. Overview of Azure Data Factory (ADF): See a description and more links in the session slides above If ADS seems interesting to you, read the following introductory material https://docs.microsoft.com/en-us/azure/data-factory/introduction Visual authoring in Azure Data Factory this is interesting as a case study for gui-based 'plaform as a service' cloud computing Activities For those who completed the storage pricing activity from session #3, post your estimated stoarge costs to teams. If they are very different, from others, or different than you expect, please explain or ask how folks got their numbers Select any one or more of these activities that seems relevant to you for your project, or minimally the first exercise Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. We want your feedback! We have some topics we plan to cover, but at this stage you've looked at cloud documentation and thought about your projects, via teams or email, contact us to let us know if there are topics you would like to hear about. These could be upcoming topics that you are particularly interested in. For example, we offered a specially session on \"command line techniques\" and we are prepping materials for that. Meeting October 8 2:00-3:30pm Questions from previous session on storage Presentation: Azure Techniques for Moving Data (slides linked in Reading section above) Note about future material and projects Discussion or questions about this or previous topic or projects","title":"4. Moving Data"},{"location":"session_moving_data/#session-4-moving-data-in-the-cloud","text":"There are many ways to move data around in the cloud. They are based on the limitations of data movement across complex and distant networks and the scale of cloud networks and storage, and the needs of companies to move and process huge amounts of data on a schedule.","title":"Session 4: Moving Data in The Cloud"},{"location":"session_moving_data/#reading","text":"Session Slides: Azure Techniques for Moving Data","title":"Reading"},{"location":"session_moving_data/#optional-reading","text":"Adding a data disk to virtual machine: A second disk may be faster to access than Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering Focus on the Introduction and Section 3.3 (Azure) This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS. If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these. Overview of Azure Data Factory (ADF): See a description and more links in the session slides above If ADS seems interesting to you, read the following introductory material https://docs.microsoft.com/en-us/azure/data-factory/introduction Visual authoring in Azure Data Factory this is interesting as a case study for gui-based 'plaform as a service' cloud computing","title":"Optional Reading"},{"location":"session_moving_data/#activities","text":"For those who completed the storage pricing activity from session #3, post your estimated stoarge costs to teams. If they are very different, from others, or different than you expect, please explain or ask how folks got their numbers Select any one or more of these activities that seems relevant to you for your project, or minimally the first exercise Exercise: moving data using storage URL Attaching Azure Files to a Virtual machine for reading and writing data Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal Linux VMs: command line option using 'scp' command Use SCP to move files to and from a Linux VM How to move data between the MSU HPC and Azure for an example using the azcopy utility, and other techniques Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. We want your feedback! We have some topics we plan to cover, but at this stage you've looked at cloud documentation and thought about your projects, via teams or email, contact us to let us know if there are topics you would like to hear about. These could be upcoming topics that you are particularly interested in. For example, we offered a specially session on \"command line techniques\" and we are prepping materials for that.","title":"Activities"},{"location":"session_moving_data/#meeting-october-8-200-330pm","text":"Questions from previous session on storage Presentation: Azure Techniques for Moving Data (slides linked in Reading section above) Note about future material and projects Discussion or questions about this or previous topic or projects","title":"Meeting October 8 2:00-3:30pm"},{"location":"session_moving_data/creating_a_container_sas_token_from_the_azure_portal/","text":"Creating a Storage Account SAS token for allowing access to storage from another service or person How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility References Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"Creating a Storage Account SAS token"},{"location":"session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#creating-a-storage-account-sas-token","text":"","title":"Creating a Storage Account SAS token"},{"location":"session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#for-allowing-access-to-storage-from-another-service-or-person","text":"How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account. Granting access to each different service one by one may not be feasible, Instead you can provide the service (or user) a special code that allows access. One such code in Azure is a \"shared access signature\" (SAS). You to the end of a storage URL To grant access to the storage acccount without having to log-in. This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the azcopy command. You need to create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from. There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS) To generate a SAS token using the Azure portal (service SAS): in the Portal, navigate to your storage account \u2192 containers \u2192 your container On the left side, click \"Shared access Tokens\" on the form for SAS token enter values as follows: Signing method : \"Account Key\" (this is the default and should be selected) Signing key : could be either Key 1 or Key 2 Permissions : click in the box that says \"read\" to see the list of permissions if you are copying from HPC to Azure, check all the boxes if you are copying from Azure to HPC, check Read and perhaps List Specify the signed key Start and Expiry times. The key is temporary, and defaults to 24hrs. You may want to change the \"expiry\" date to one a few days in the future, or for a month or so if you'll be using azcopy to transfer files for the semester. If you specify a long time, you should restrict the IP address access (see below) The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct. If you want to be extra secure and restrict to systems you are copying your data from. For example your own computer If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255 You could also use the MSU VPN address range and restrict to systems logged in via VPN. Find that from IT Services For your or a colleague computer, google \"what's my IP\" to get your IP address If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure) Click Generate SAS token and URL. The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window. Copy the Blob SAS URL (or token or both), and save in a secure location. They'll only be displayed once and cannot be retrieved once the window is closed. Treat the SAS token like a temporary password You can use the \"Blob SAS URL\" for most copy operations. It includes the container but not the file name. If you want to use a different file name from the original, you'll have to construct your own URL. To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows `https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend` If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however) See How to move data between the MSU HPC and Azure for an example using the azcopy utility","title":"for allowing access to storage from another service or person"},{"location":"session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#references","text":"Best practices when using SAS token Instructions these are based on (from Azure Cognitive Services) CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas","title":"References"},{"location":"session_moving_data/how_to_azure_files/","text":"How to Use Azure Files with Windows and Linux VMs The Azure cloud storage session materials describes \"Azure Files\" as one of several types of storage available. Here are some details about using Azure Files in practice to read and write data from a virtual machine Please review the Azure Documentation describing the \"Azure Files\" service Summary The \"Azure Files\" (or File Shares) service is Microsoft's attempt to provide storage with an interface that many IT people are familiar with, but at Cloud scale. They market it heavily as a replacement for File servers that an institution or company have to maintain. The alternative is blog storage, which works well when you alter your program code to read and write to blob storage, and for users of existing software (e.g. GUI software for your scientific application) you can't change the code. In practice, Azure File storage does work like cloud in that there are few limits on storage but you can also attach it as if it were network storage (\"network attach\") so you don't have to change your software. However it is more expensive than Blob storage and it is slower than network storage, especially much slower than storage in an HPC environment. So what to do? One method I've used to take advantage of the convenience of Azure Files storage but I need speed, I'll copy those files that need to have fast access onto the local disk of the VM (or service), but still use Azure files to save files (write output). There are several ways to use Network Attach Storage, and they are named for the file sharing protocol. A very common protocol invented by Microsoft in the 90s is Server Message Block or SMB. You don't have to know how it works, just that Windows, Mac and Linux have SMB file connection software built-in. Most on-premise network disk systems use SMB. Details using \"File Shares\" in a storage account A storage account is the entry point in Azure to any kind of storage service ( see materials in the Cloud Storage session ), so you need to first create a storage account. You can use an existing storage account for any tutorials or quickstarts linked below (though many of them have you create a resource group and storage account in the tutorial, can skip that although you'll have to adjust the names used). Note that storage account can have both blog storage containers and file shares in the same account. When you open a storage account resource in the portal, there is a \"File Shares\" option on the left-side menu which opens the form to add file shares to your storage account. Follow this quick start to create a file share, which also walks through creating a storage account if you need one : https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-portal?tabs=azure-portal Overview of process to use with a VM create a file share and upload your data using the Storage Explorer or other data movement method (e.g. Azure Data Factory, azcopy from your on-premise computer such as the HPC) create a Virtual Machine. since the data will stay on the File Share (but see below for performance) you may not need to provisions a VM disk much larger than 30gb after the VM is started and you are logged in, see methods below for attaching File share run your software but adjust the code or select folders on the connected file share (e.g. D:\\\\ on windows or the mount path in linux) save output the the cloud Storage File Share when finished, close and delete the VM and associated resources access output files using Storage Explorer, or another method See below for Azure instructions for each type of machine (Windows, Linux) Connecting File Share to Windows to read or save data If you are using Windows to run your software, you may want to read/write data to a file share, so you can delete the Windows VM when you are finished with a session, but keep your results. If you attach a file share to the windows VM, use that. After creating a file share, you can connect that to a windows VM. In session #2 we created a Windows VM based on the Data Science Virtual Machine image. The following uses a different image (Windows Server) but the process is the same: Mount SMB Azure file share on Windows Connecting File Share to Linux to read and/or save data These command-line based intructions show how to install the necesssary software and create a connection to a file share using SMB. Like the windows example, this would be a method for accessing data on in cloud storage so that you can remove [Mount SMB Azure file share on Linux] https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux?tabs=smb311 Performance issues with using File Shares and a work-around File shares are not as fast as a virtual machine disk, and those are not as fast as a disk on your physcial computer, or even as fast as on-premise Network Attached storage. If your process does a lot of reading/writing and needs to be faster, one solution is to 'stage' the data to the VM disk assuming you have file share storage and a new VM with a large enough disk to hold data connect/mount the file share storage as describe above to the VM before running your program, copy the input data from file share storage to the VM disk, (e.g. C:\\ for Windows or perhaps the homedir /mnt/home in linux ) Ensure you've created a large enough VM OS Disk to hold your data run your software, selecting this folder when the program/script is completed, copy the ooutput back to your file share shutdown and delete the VM access the output data from file share d","title":"How to Use Azure Files with Windows and Linux VMs"},{"location":"session_moving_data/how_to_azure_files/#how-to-use-azure-files-with-windows-and-linux-vms","text":"The Azure cloud storage session materials describes \"Azure Files\" as one of several types of storage available. Here are some details about using Azure Files in practice to read and write data from a virtual machine Please review the Azure Documentation describing the \"Azure Files\" service","title":"How to Use Azure Files with Windows and Linux VMs"},{"location":"session_moving_data/how_to_azure_files/#summary","text":"The \"Azure Files\" (or File Shares) service is Microsoft's attempt to provide storage with an interface that many IT people are familiar with, but at Cloud scale. They market it heavily as a replacement for File servers that an institution or company have to maintain. The alternative is blog storage, which works well when you alter your program code to read and write to blob storage, and for users of existing software (e.g. GUI software for your scientific application) you can't change the code. In practice, Azure File storage does work like cloud in that there are few limits on storage but you can also attach it as if it were network storage (\"network attach\") so you don't have to change your software. However it is more expensive than Blob storage and it is slower than network storage, especially much slower than storage in an HPC environment. So what to do? One method I've used to take advantage of the convenience of Azure Files storage but I need speed, I'll copy those files that need to have fast access onto the local disk of the VM (or service), but still use Azure files to save files (write output). There are several ways to use Network Attach Storage, and they are named for the file sharing protocol. A very common protocol invented by Microsoft in the 90s is Server Message Block or SMB. You don't have to know how it works, just that Windows, Mac and Linux have SMB file connection software built-in. Most on-premise network disk systems use SMB.","title":"Summary"},{"location":"session_moving_data/how_to_azure_files/#details","text":"","title":"Details"},{"location":"session_moving_data/how_to_azure_files/#using-file-shares-in-a-storage-account","text":"A storage account is the entry point in Azure to any kind of storage service ( see materials in the Cloud Storage session ), so you need to first create a storage account. You can use an existing storage account for any tutorials or quickstarts linked below (though many of them have you create a resource group and storage account in the tutorial, can skip that although you'll have to adjust the names used). Note that storage account can have both blog storage containers and file shares in the same account. When you open a storage account resource in the portal, there is a \"File Shares\" option on the left-side menu which opens the form to add file shares to your storage account. Follow this quick start to create a file share, which also walks through creating a storage account if you need one : https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-portal?tabs=azure-portal","title":"using  \"File Shares\" in a storage account"},{"location":"session_moving_data/how_to_azure_files/#overview-of-process-to-use-with-a-vm","text":"create a file share and upload your data using the Storage Explorer or other data movement method (e.g. Azure Data Factory, azcopy from your on-premise computer such as the HPC) create a Virtual Machine. since the data will stay on the File Share (but see below for performance) you may not need to provisions a VM disk much larger than 30gb after the VM is started and you are logged in, see methods below for attaching File share run your software but adjust the code or select folders on the connected file share (e.g. D:\\\\ on windows or the mount path in linux) save output the the cloud Storage File Share when finished, close and delete the VM and associated resources access output files using Storage Explorer, or another method See below for Azure instructions for each type of machine (Windows, Linux)","title":"Overview of process to use with a VM"},{"location":"session_moving_data/how_to_azure_files/#connecting-file-share-to-windows-to-read-or-save-data","text":"If you are using Windows to run your software, you may want to read/write data to a file share, so you can delete the Windows VM when you are finished with a session, but keep your results. If you attach a file share to the windows VM, use that. After creating a file share, you can connect that to a windows VM. In session #2 we created a Windows VM based on the Data Science Virtual Machine image. The following uses a different image (Windows Server) but the process is the same: Mount SMB Azure file share on Windows","title":"Connecting File Share to Windows to read or save data"},{"location":"session_moving_data/how_to_azure_files/#connecting-file-share-to-linux-to-read-andor-save-data","text":"These command-line based intructions show how to install the necesssary software and create a connection to a file share using SMB. Like the windows example, this would be a method for accessing data on in cloud storage so that you can remove [Mount SMB Azure file share on Linux] https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux?tabs=smb311","title":"Connecting File Share to Linux to read and/or save data"},{"location":"session_moving_data/how_to_azure_files/#performance-issues-with-using-file-shares-and-a-work-around","text":"File shares are not as fast as a virtual machine disk, and those are not as fast as a disk on your physcial computer, or even as fast as on-premise Network Attached storage. If your process does a lot of reading/writing and needs to be faster, one solution is to 'stage' the data to the VM disk assuming you have file share storage and a new VM with a large enough disk to hold data connect/mount the file share storage as describe above to the VM before running your program, copy the input data from file share storage to the VM disk, (e.g. C:\\ for Windows or perhaps the homedir /mnt/home in linux ) Ensure you've created a large enough VM OS Disk to hold your data run your software, selecting this folder when the program/script is completed, copy the ooutput back to your file share shutdown and delete the VM access the output data from file share d","title":"Performance issues with using File Shares and a work-around"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/","text":"How to move data between the MSU HPC and Azure Introduction A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory) Method 1. using scp with a virtual machine Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results. Requirements an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine A little about the scp utility The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk. Method 2. azcopy Requirements A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation) Alternative Methods Method 3. Azure data factory We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility. Method 4. Python We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda . Method 5. Python with URL Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"How to move data between the MSU HPC and Azure"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#how-to-move-data-between-the-msu-hpc-and-azure","text":"","title":"How to move data between the MSU HPC and Azure"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#introduction","text":"A common research cloud computing activity is moving data between cloud and on-premise (local) systems. Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage. The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work. I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory)","title":"Introduction"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#method-1-using-scp-with-a-virtual-machine","text":"Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation. This method is useful for one-time workflow of copy, process, save results.","title":"Method 1. using scp with a virtual machine"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#requirements","text":"an account on the MSU HPCC basic knowledge of Linux know how to create and use a Azure Virtual Machine","title":"Requirements"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#a-little-about-the-scp-utility","text":"The HPC runs Linux, and The cp utility copies files from one folder to another. The scp utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and ssh access. There are many programs to help with network file transfers but rsync and rclone are two command (and really great) programs to checkout. We will stick with scp for this example The basic format of the scp command is scp user@remote.system.com:path/to/remote/file path/to/copy_of_file For examples see http://www.hypexr.org/linux_scp_help.php Method 1a. simple method for a one-time copy to an Azure VM: Steps: 1. find the file on the MSU HPCC that you want to copy. Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already. - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this: - first, note the folder you are running this from (it defaults to the VM home directory) - scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp - enter your NetID password (it is not saved or visible on the command line) - consider using ssh keys instead of your password (which is a whole 'nother lesson) - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys Now you can access the file using the software from the I think of this as \"pulling\" data from HPC to the VM disk.","title":"A little about the scp utility"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#method-2-azcopy","text":"","title":"Method 2. azcopy"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#requirements_1","text":"A Storage account. We created one in the first session, but create a storage account in your resource group if you don't have one yet. Create a container in storage account to hold files. This can be a Blob or Azure Files container You must be owner of the storage account, and able to assign permissions ('roles'). Azure requires special persmissions grant that are NOT granted by default to use azcopy. Details in the instructions below OR you must be willing to go through the process of creating a \"SAS Token\" : see my instructions for creating SAS token Assuming you have a storage account with a blob container already created. In the portal, open the storage account container. Azure provides a command line tool azcopy which you can download for windows, mac and Linux. see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 How to install the azcopy utility Login to MSU HPCC ssh <netid>@hpcc.msu.edu download a copy of azcopy. This is the URL from Late september 2021: curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz untar and put in your home directory tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz How to use azcopy to upload to Azure using the \"AD Login\" Get a SAS URL from the Azure portal as described above Log-in to HPCC assuming your copy of azcopy is in your home directory, run a command like the following. Note that the URL must but enclosed in single quotes (not double quotes) `azcopy copy myfile.csv ' https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken ' For example, this copies a file and renames it when it's stored. The container \"from-hpcc\" in this case must already be created. azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st=2021-10-08T05:22:52Z&se=2021-10-08T13:22:52Z&sip=35.9.12.1-35.9.12.255&spr=https&sv=2020-08-04&sr=c&sig=abscus' References: - Getting Started with azcopy - azcopy login reference - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD) - Generate SAS tokens for your storage containers *(note I found this in the \"cognitive services\" documentation)","title":"Requirements"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#alternative-methods","text":"","title":"Alternative Methods"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#method-3-azure-data-factory","text":"We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility.","title":"Method 3. Azure data factory"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#method-4-python","text":"We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3 . To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python. See https://wiki.hpcc.msu.edu/display/ITH/Using+conda .","title":"Method 4. Python"},{"location":"session_moving_data/how_to_hpc_and_cloudstorage/#method-5-python-with-url","text":"Another approach that does not require the Azure SDK, is URL access, the same as for azcopy via the requests library. For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code import requests import csv import os azure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&st.... etc\" data = [] # see note below* with requests . get ( azure_url , stream = True ) as r : lines = ( line . decode ( 'utf-8' ) for line in r . iter_lines ()) for row in csv . reader ( lines ): data . append ( row ) len ( data ) don't put this code into github with the SAS url. Use a technique to read from command line or environment This would work anywhere, not just the HPC. This is the same example in the slides for this session","title":"Method 5. Python with URL"},{"location":"session_moving_data/moving_data_with_url_activity/","text":"Exercise: moving data using storage URL The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files) Upload file via portal Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise Get a URL to download this file back to your own laptop (or a different computer) determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard Test Download In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Exercise: moving data using storage URL"},{"location":"session_moving_data/moving_data_with_url_activity/#exercise-moving-data-using-storage-url","text":"The goal of the exercise is to show one of the many ways of get data out of your cloud storage account, especially as way to share a file using a URL Upload a file to cloud storage. get a file, any file and get it into cloud storage in any way you like. If you already have a file in Azure Blob storage container, you can skip this step. If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal. (I don't recommend this for large files for for many files)","title":"Exercise: moving data using storage URL"},{"location":"session_moving_data/moving_data_with_url_activity/#upload-file-via-portal","text":"Find a data file in any format on your computer. Let's called it mydata.txt Open the Azure portal and go to your storage account in your resource group In your storage account create container, if you don't want to use an existing container click \"containers\" on the left side menu above the list of containers is a \"+\" icon, click that to create a container For Name, call it \"democontainer\" For public access level, leave it as \"private\" Open the container in the portal click \"the upload\" link near the top select a file to upload- any file will work for this excercise","title":"Upload file via portal"},{"location":"session_moving_data/moving_data_with_url_activity/#get-a-url-to-download-this-file-back-to-your-own-laptop-or-a-different-computer","text":"determine your laptop's IP address Google \"what's my IP address\" copy it or save that IP address for later To share with a colleague you'd use their IP address for this step click on the file you just uploaded and a new form appears on the right on that form is a link near the top \"generate SAS\" - click that link for more details, see documentation Creating Container SAS Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got Click the \"Generate SAS ...URL\" button Copy the Blob SAS URL to the clipboard","title":"Get a URL to download this file back to your own laptop (or a different computer)"},{"location":"session_moving_data/moving_data_with_url_activity/#test-download","text":"In a web browser, paste the URL to see if you can re-download your own file. To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL","title":"Test Download"},{"location":"session_serverless/","text":"Session 7: The Cloud Computing Grab Bag That is Serverless example real-world cloud application Introductory Material by topic Overview of Serverless About Linux Containers with readings and activities Serverless and FaaS Readings As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349 Activities https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/ For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell Fellowship Meeting November 12, 2021 : Zoom Announcements, survey request Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction","title":"7. Serverless, Containers, and FaaS"},{"location":"session_serverless/#session-7-the-cloud-computing-grab-bag-that-is-serverless","text":"example real-world cloud application Introductory Material by topic Overview of Serverless About Linux Containers with readings and activities","title":"Session 7: The Cloud Computing Grab Bag That is Serverless"},{"location":"session_serverless/#serverless-and-faas-readings","text":"As you read these materials, do you think \"serverless\" resources are IaaS or PaaS? They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" Re-visit Chapter 4 Computing as a service An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon All About Azure Functions: https://www.serverless360.com/azure-functions Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/ Azure Functions triggers and bindings concepts tabs=csharp An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., & Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349","title":"Serverless and FaaS Readings"},{"location":"session_serverless/#activities","text":"https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/ For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line *This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell","title":"Activities"},{"location":"session_serverless/#fellowship-meeting","text":"November 12, 2021 : Zoom Announcements, survey request Discussion of Previous Weeks Introduction the Session materials Talk and demonstration: a cloud-based web application for gene function prediction","title":"Fellowship Meeting"},{"location":"session_serverless/about_web_applications_and_the_cloud/","text":"","title":"About web applications and the cloud"},{"location":"session_serverless/end_of_session_survey/","text":"","title":"End of session survey"},{"location":"session_serverless/linux_containers_and_the_cloud/","text":"Linux Containers & the Cloud For Session 7: Overview of Serverless The container metaphor relfects the nature of a standardized box can be carried on ships, trains, and trucks at different scales Introduction Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. However containers have several advantages to virtual machines which is why Google invested in their invention 15 yrs ago. you can use code to define exactly what will go into a container, making it reproducible. You can to this with VMs but it's more difficult and/or dependent on the cloud company (e.g an AWS linux VM is different from an Azure Linux VM)/ you can run a container on any vendor or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. In addition you can find container solutions from others, or from the software producers themselves. Notes Containers often are for running web applications, and great for running complex web systems, but they can be used for other types of servers, or for batch computing as well. Most of the examples may involve running a website. \"Docker\" is the company that popularized container technology and made it easy to share ideas, but they are only one of several systems that work with the Linux Container specification. Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the HPC we use Singularity . However to get started I suggest using Docker, installing docker desktop, and following docker tutorials. Azure is compatible with docker (that's what we use) You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. Azure has many docker-like features, and you can build and use containers with Azure without installing Docker on your computer, but I recommend working from your computer first to ensure it works The main code file that docker looks for is named \"Dockerfile\" with no extension, and so we say we are using a 'dockerfile' to build a container however this is just the default and the file name can be anything when using the command line You will hear alot about a technology platform called \"Kubernetes\" which was invented (at Google) to be able to manage dozens,hundreds or thousands of containers working together to support large web applications (like Google but also Walmart.com). This is called \"container orchestration.\" You don't need Kubernetes to run single or even a couple of containers. There are other solutions, or you can connect them yourself. Using Kubernetes can be an entire career but the promise is easy building an elastic cluster for HPC-style computing. The \"serverless\" infrastructure of Azure is built on containers. Containers are the heart of how the cloud works, and provide a way for developers of complex research software to provide a mechanism for users to launch their software quickly. Many bioinformatics or genomics packages now include Containers are complex and especially how they work but if you can use them in practice you don't need to know the details. Reading An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Docker Overview Azure Container Service Overview Activity Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance","title":"Linux Containers & the Cloud"},{"location":"session_serverless/linux_containers_and_the_cloud/#linux-containers-the-cloud","text":"","title":"Linux Containers &amp; the Cloud"},{"location":"session_serverless/linux_containers_and_the_cloud/#for-session-7-overview-of-serverless","text":"The container metaphor relfects the nature of a standardized box can be carried on ships, trains, and trucks at different scales","title":"For Session 7: Overview of Serverless"},{"location":"session_serverless/linux_containers_and_the_cloud/#introduction","text":"Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment. However containers have several advantages to virtual machines which is why Google invested in their invention 15 yrs ago. you can use code to define exactly what will go into a container, making it reproducible. You can to this with VMs but it's more difficult and/or dependent on the cloud company (e.g an AWS linux VM is different from an Azure Linux VM)/ you can run a container on any vendor or your laptop or even the HPC because you define what is installed in a container, the configuration of complex software is easier and portable. In addition you can find container solutions from others, or from the software producers themselves. Notes Containers often are for running web applications, and great for running complex web systems, but they can be used for other types of servers, or for batch computing as well. Most of the examples may involve running a website. \"Docker\" is the company that popularized container technology and made it easy to share ideas, but they are only one of several systems that work with the Linux Container specification. Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub) So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\"). On the HPC we use Singularity . However to get started I suggest using Docker, installing docker desktop, and following docker tutorials. Azure is compatible with docker (that's what we use) You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop. Most likely no one else can access it, but it's great for development and testing. Azure has many docker-like features, and you can build and use containers with Azure without installing Docker on your computer, but I recommend working from your computer first to ensure it works The main code file that docker looks for is named \"Dockerfile\" with no extension, and so we say we are using a 'dockerfile' to build a container however this is just the default and the file name can be anything when using the command line You will hear alot about a technology platform called \"Kubernetes\" which was invented (at Google) to be able to manage dozens,hundreds or thousands of containers working together to support large web applications (like Google but also Walmart.com). This is called \"container orchestration.\" You don't need Kubernetes to run single or even a couple of containers. There are other solutions, or you can connect them yourself. Using Kubernetes can be an entire career but the promise is easy building an elastic cluster for HPC-style computing. The \"serverless\" infrastructure of Azure is built on containers. Containers are the heart of how the cloud works, and provide a way for developers of complex research software to provide a mechanism for users to launch their software quickly. Many bioinformatics or genomics packages now include Containers are complex and especially how they work but if you can use them in practice you don't need to know the details.","title":"Introduction"},{"location":"session_serverless/linux_containers_and_the_cloud/#reading","text":"An Introduction to Containers from a company called \"Rancher\" which sells software manage containers Chapter 6: Using and Managing Containers from our textbook \" Cloud Computing for Science and Engineering \" Docker Overview Azure Container Service Overview","title":"Reading"},{"location":"session_serverless/linux_containers_and_the_cloud/#activity","text":"Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure Docker Orientation and setup For Python Users: How to Run Jupyter Notebook on Docker optional for shell scripters and command line users : complete this shell script that launches an Rstudio session on azure container instance","title":"Activity"},{"location":"session_serverless/serverless_overview/","text":"Introduction to Serverless and Azure For Session 7: Overview of Serverless *Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that. Many problems that \"serverless\" can be applied to short and 'stateless' function execution, where functions can scale at will (Python, Java, C, C# etc) event processing, handling huge streams of data in small chunks components of a cloud-based workflow web application engines Main distinction for 'serverless' is that even though in the end of course your website or function run on a server somewhere that has an operating system installed on it, you don't have to know. Server Process : provission machine --> install OS --> install software --> add your code, read your data and run --> delete and/or keep it maintained Serverlesss Process : provision resource --> add code --> and run Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed? Key points about serverless goal is to have aa workflow of components that communicate with each other, but can be indepedently managed a primary communication method is using web api's, aka REST aka","title":"Introduction to Serverless and Azure"},{"location":"session_serverless/serverless_overview/#introduction-to-serverless-and-azure","text":"","title":"Introduction to Serverless and Azure"},{"location":"session_serverless/serverless_overview/#for-session-7-overview-of-serverless","text":"*Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance. Traditional IT is a collection of massive servers with many purposes and features that do it all. Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud. We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS) \"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that. Many problems that \"serverless\" can be applied to short and 'stateless' function execution, where functions can scale at will (Python, Java, C, C# etc) event processing, handling huge streams of data in small chunks components of a cloud-based workflow web application engines Main distinction for 'serverless' is that even though in the end of course your website or function run on a server somewhere that has an operating system installed on it, you don't have to know. Server Process : provission machine --> install OS --> install software --> add your code, read your data and run --> delete and/or keep it maintained Serverlesss Process : provision resource --> add code --> and run Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues. But what if you just wanted to have one step in your work be isolated, and also run only when needed? Key points about serverless goal is to have aa workflow of components that communicate with each other, but can be indepedently managed a primary communication method is using web api's, aka REST aka","title":"For Session 7: Overview of Serverless"},{"location":"session_serverless/container_scripts/rstudio_container_script/","text":"Containers on Azure: example Script echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf21-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"},{"location":"session_serverless/container_scripts/rstudio_container_script/#containers-on-azure-example-script","text":"echo \"Starting the setup for running Rstudio Server on Azure\" AZUSER = # add your account name here, no space between the = sign AZGROUP = # enter your resource gropu here, no space between the = sign echo \"Enter Rstudio pw (for user rstudio):\" read CONTAINERPW DOCKERIMAGE = rocker/geospatial # or rocker/tidyverse AZCONTAINERNAME = cf21-demo-container- $AZUSER # you must enter the values here for your storage account by finding the key in the Azure portal AZFILESACCOUNT = y AZFILESSHARE = z AZFILESKEY = x # docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create # create the container instance, which starts if the Dockerfile has an entry point # by assigning a '--dns-name-label' we give it a public IP address echo \"please wait while the container instance is created\" az container create -g $AZGROUP --name $AZCONTAINERNAME \\ --os-type Linux --location eastus \\ --cpu 4 \\ --memory 16 \\ --image $DOCKERIMAGE --ports 8787 \\ --dns-name-label ${ AZUSER } rstudio \\ --secure-environment-variables PASSWORD = $CONTAINERPW # --assign-identity x \\ # --azure-file-volume-account-key $AZFILESKEY \\ # --azure-file-volume-account-name $AZFILESACCOUNT \\ # --azure-file-volume-share-name $AZFILESSHARE \\ # --azure-file-volume-mount-path /mnt/azfiles # NOTE this is not an https connection and hence is insecure and not recommended # see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl # for a method for using https # show the way to log in FQDN = ` az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv ` echo \"your RStudio is running on \" echo \"https:// ${ FQDN } :8787\" # how to stop and/or delete the container. # stop it if you are taking a break from using it # az container stop --name $AZCONTAINERNAME -g $AZGROUP # delete if you can # az container delete --name $AZCONTAINERNAME -g $AZGROUP","title":"Containers on Azure: example Script"}]}