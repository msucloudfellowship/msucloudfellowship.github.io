{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MSU Cloud Computing Fellowship","text":"<p>Welcome to the website for the MSU Cloud Computing Fellowship for 2022-2022.  See our \"about\" page for more information about the program.   </p>"},{"location":"#syllabus-fall-2022-spring-2023","title":"Syllabus Fall 2022 - Spring 2023","text":"<p>The program runs Fall semester through Winder/Spring semester.  </p> <p>Fall Sessions are approximately bi-weekly with breaks for holidays.  A session includes preparatory readings and activities to orient you to the topic, followed by an in-person meeting on a Friday to review the materials, seminar, provide a venue for discussion,  hands-on collaborative activities, or presentations by the fellows. </p> <p>Winter/Spring sessions are for discussion and to provide updates to your project.   </p>"},{"location":"#symposium-and-project-presentations","title":"Symposium and Project Presentations","text":"<p>The culmination of the fellowship is a project resulting in a write-up and presentation during the spring symposium, typically held late-April or early-May.   </p> <p>Project details and due dates</p>"},{"location":"#meeting-location","title":"Meeting location","text":"<p>At this time all meetings are in-person in the training room of the Institute for Cyber-Enabled Research, located on the first floor of the MSU Biomedical &amp; Physical Sciences Building</p> <p>Biomedical and Physical Science (BPS) Building, Room 1445 567 Wilson Road Michigan State University. East Lansing, MI 48824</p> <ul> <li>enter the doors marked 1440, in the center of the BPS atrium </li> </ul>"},{"location":"#schedule-for-fall-2022","title":"Schedule for Fall 2022","text":"<p>Note since our meeting for September 2 was cancalled The schedule has been revised</p> <ol> <li>Introduction to the 22-23 Fellowship<ul> <li>Meeting September 16: Introductions, Cloud background and hands-on with Azure portal</li> </ul> </li> <li>Hands-on Introduction to Cloud computing Using Virtual Machines<ul> <li>self-paced readings and activies: <ul> <li>Using the Azure portal</li> <li>creating an connecting to a  virtual machine</li> </ul> </li> <li>Optional help/office hours September 23 2pm</li> </ul> </li> <li>Cloud Storage<ul> <li>Meeting September 30: Discussion &amp; Cloud Storage Workshop.  </li> </ul> </li> <li>Databases and Data Analytics Systems on the Cloud for research<ul> <li>Meeting October 14: Seminar on Database and data systems.  Hands-on: Using Cosmos DB</li> </ul> </li> <li>Big Data Systems and the cloud<ul> <li>Meeting October 28: Overview of Big Data on Azure with DataBricks</li> </ul> </li> <li>Serverless Cloud Computing<ul> <li>Meeting November 4: Overview of Serverless and FaaS, Demonstration of Real-world project</li> </ul> </li> <li> <p>Cloud Services Organization </p> <ul> <li>Meeting November 18: Details about the Project</li> </ul> </li> <li> <p>Synthesis: projects and development of project proposal</p> <ul> <li>Mini-project assignment</li> <li>About Project</li> <li>December 2: optional office hours, time to work on mini-project, 1-1 help, project discussion</li> <li>December 9: Synthesis Session<ul> <li>send by email 1-2 sentences describing your current thinking on your project by this time</li> <li>discussion of Fellowship Projects  </li> <li>additional 1-1 help with mini project</li> </ul> </li> <li>December 5 - 16 : On going help available as needed, please contact us</li> <li>December 16: <ul> <li>optional office hours, mini-project, project proposal or other help. </li> <li>submit write-up for mini-project via email</li> </ul> </li> </ul> </li> </ol>"},{"location":"#schedule-for-winterspring-2023","title":"Schedule for Winter/Spring 2023","text":"<p>The second semester of the fellowship is focused on completing a project based on fellow research interests.   We will meet approximately bi-weekly for fellows to present, get feedback, ask questions, and group discussions.  For some of these dates/times, fellows will deliver a short presentation about their projects as follows:</p> <p>For details, please see the timeline and details about what's expected:  Cloud Computing Fellowship Deliverables Timeline Spring 2023 pdf *this was sent via email in January, but also posted here in February and is the same schedule on the projects page. *</p> <p>** Schedule Synopsis** (Updated March 21)</p> <p>All meetings are in the ICER training room, 1455A BPS, from 2:00 to 3:30 pm </p> <ul> <li>January 9th Post Written Project Proposal to this MS Teams folder prior to 5:00pm January 9th</li> <li>January 12th Post Project Proposal Slides to this MS Teams folder prior to 5:00pm </li> <li>January 13 Present \u2018in-person\u2019 your Project Proposal Slides at 2:00pm </li> <li>March 24th: In-person discussion of projects and fellowship goals, 2:00pm </li> <li>May 5 Tenative date for in-person presentation of project summary at the CCF Annual Symposium</li> </ul>"},{"location":"#on-going-help","title":"On-going help","text":"<p>We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general.  </p>"},{"location":"#textbook","title":"Textbook","text":"<p>We will occasionally link to the following book: </p> <p>\"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 </p> <ul> <li>MIT Press website </li> <li>Book Website : Cloud4SciEng.org</li> </ul> <p>The book website does provide open access to individual chapters. </p>"},{"location":"#communications","title":"Communications","text":"<p>Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned.  In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email).   Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program.  Mentioning one of us e.g. @billspat or @parvizm will help get our attention.  Additionally you may email us at any time.   If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us.   </p> <p>If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue.    </p> <p>If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support.   This may be especially effective when fellows are developing their projects.  </p> <p>We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License</p>"},{"location":"about/","title":"About The MSU Cloud Computing Fellowship","text":"<p>The MSU Cloud Computing Fellowship is a cross-disciplinary program produced by MSU\u2019s Institute of Cyber-Enabled Research (ICER) and the IT Services Analytics and Data Solutions (ADS) group for invited MSU doctoral students and postdoctoral researchers. As a part of this program, fellows will participate in a series of workshops during the fall semester to:</p> <ul> <li>Determine the aspects of your research that can be accomplished with cloud computing;</li> <li>Incorporate cloud-based systems into your research application or workflow; and</li> <li>Understand the strengths and limitations of commercial cloud computing with the goal of improving research yield and minimizing cost, and to develop a workflow that utilizes that knowledge.</li> </ul>"},{"location":"about/#background","title":"Background","text":"<p>MSU doctoral students and postdoctoral researchers are invited to apply in the summer and approximately 18 are selected each year.  The program started in 2019.   If you are an MSU graduate student or post-doc and interested in participating next year, please check back in the Summer of 2022 for announcements on the invitation to participate, or request to join the MSU ICER mailing list</p>"},{"location":"about/#citing-the-msu-icer-cloud-computing-fellowship-in-research-publications","title":"Citing the MSU ICER Cloud Computing Fellowship in Research Publications","text":"<p>We encourage cloud fellows to acknowledge the fellowship in publications arising from computational work performed during your fellowship project. Please let us know that you have referenced the fellowship, and we will link to your publication on the ICER publication site, which will further increase the visibility of your work. A sample statement can be:  </p> <p>\"This work was supported in part through Michigan State University\u2019s Institute for Cyber-Enabled Research Cloud Computing Fellowship, with computational resources and services provided by Information Technology Services and the Office of Research and Innovation at Michigan State University.\u201d  </p>"},{"location":"about/#cloud-computing-fellowship-organizers","title":"Cloud Computing Fellowship Organizers","text":"<p>Dr. Brian O'Shea Professor and Director, MSU ICER</p> <p>Role: Program Lead, ICER</p> <p> Dr. Brian O'Shea is a computational and theoretical astrophysicist studying cosmological structure formation, including galaxy formation and the behavior of the hot, diffuse plasma in the intergalactic medium and within galaxy clusters. He is also a co-author of the Enzo AMR code, an expert in high performance computing, and an advocate for open-source computing and open-source science. He received his B.S. in Engineering Physics at the University of Illinois in Urbana-Champaign (UIUC) in 2000, and his PhD in physics from UIUC in 2005 (with 2002-2005 being spent as a graduate student in residence at the Laboratory for Computational Astrophysics at UC San Diego and in the Theoretical Astrophysics Group at Los Alamos National Laboratory). Following that, he was a Director's Postdoctoral Fellow at Los Alamos National Laboratory, with a joint appointment between the Theoretical Astrophysics Group and the Applied Physics Division. Since 2008, he has been a member of the faculty at Michigan State University, with a joint appointment between the Department of Computational Mathematics, Science and Engineering (2015-present), the Department of Physics and Astronomy (2008-present), and the National Superconducting Cyclotron Laboratory (2014-present). From 2008-2015, Dr. O'Shea was a member of Lyman Briggs College. He has authored or co-authored over 75 peer-reviewed journal articles in astrophysics, computer science, and education research journals, and has received a variety of awards for his teaching and public outreach efforts. In 2016, he became a Fellow of the American Physical Society, and in 2019 he became the director of MSU's Institute for Cyber-Enabled Research.</p> <p> Danielle Barnes Assistant Director, ADS, MSU IT Services Role: Program Lead, IT Services</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p>Patrick Bills  Data Science Technical Lead, MSU IT Services Role: Lead Instructor </p> <p>  Pat Bills research background is in data systems for ecology (MS Entomology, MSU).  He has experience in database design, R, Python, and web application programming.  Pat has worked in research IT for over 25 yrs for departments and labs across MSU, including for MSU ICER as a research consultant and trainer.   He is currently the technical lead for the data science team within ADS.  </p> <p>Like many, he has built and worked with on-campus linux systems for many years including the MSU HPC.  Pat started my cloud journey in 2017 during a workshop at the HPC conference where he saw Ian Foster (our textbook author) present his vision of research on the cloud. Since then he has used cloud services from Google, Amazon, and Azure - currently focusing on Microsoft Azure.  ADS uses cloud services where appropriate for their data systems or applications, and he will use examples directly from that work in this class.  </p> <p>Dr. Mahmoud Parvizi  Research Consultant, MSU ICER Role: Assistant Instructor </p> <p> Mahmoud earned his PhD in physics from Vanderbilt University with research in high-energy theory in the context of early universe cosmology as well as computational astrophysics. In addition, Mahmoud earned an MBA with a concentration in finance from the University of Michigan - Flint.  Mahmoud was formerly a postdoctoral research associate in the Department of Physics and Astronomy at Michigan State University with a focus on machine learning applications of cloud-computing workflows and currently a research consultant for the MSU Institute for Cyber-Enabled Research (ICER).   He participated as a cloud fellow in 2019 and co-instructor of the Cloud Computing Fellowship in 2020. </p> <p>Mahmoud\u2019s diverse research interests include mathematical and theoretical physics, data-intensive astrophysics, machine learning for precision health, and cloud-computing platforms for academic research. His expertise includes 1) quantum field theory in curved/non-stationary spacetimes; 2) finite temperature quantum field theory and open quantum systems; 3) automated and end-to-end intelligent data pipelines for signal processing using compressed sensing and applied harmonic analysis; 4) machine learning and cloud-computing applications for precision health.</p> <p>Chelsea Beck Data Warehouse Lead, ADS, MSU IT Services Role: Logistics and Organizational expertise</p>"},{"location":"about/#previous-cloud-fellows","title":"Previous Cloud Fellows","text":"<p>2019-2020</p> <ul> <li>MSU Cloud Computing Fellows</li> <li>Summary of the first cohort of MSU Cloud Computing Fellows</li> </ul> <p>2020-2021</p> <ul> <li>Introducing the 2020 Cloud Fellows</li> <li>20-21 Cloud Computing Fellowship Culminates in Impressive Symposium</li> </ul>"},{"location":"cloud_glossary/","title":"Glossary of Cloud Terms","text":""},{"location":"cloud_glossary/#why","title":"Why?","text":"<p>Researchers using the cloud must know a little about a lot of information technology to get computational work done in their domain specialty.   Most cloud glossaries are for systems administrators, not the rest of us.  This glossary is much more brief than Wikipedia and hopefully also provides the context a researcher needs to find what you need to use cloud services in your work.    Do you have an item to add? Please contact us! </p>"},{"location":"cloud_glossary/#other-glossaries","title":"Other Glossaries","text":"<p>https://www.cloudbank.org/cloud-terms</p>"},{"location":"cloud_glossary/#the-glossary","title":"The Glossary","text":""},{"location":"cloud_glossary/#arm-cpu","title":"Arm CPU","text":"<p>CPU from \"Advanced RISC Machines, ltd.  While historically most computers used Intel CPUs, ARM provides an alternative CPU that is becoming more popular and present as an option in HPC and Cloud Virtual Machine options.  The vast majority of software written for Intel computers is compatible with ARM.  Some computational work is sensitive to CPU choice, and CPU choice can affect cost and speed of excecution, so it may be important to understand the implications of this choice of CPU.  </p>"},{"location":"cloud_glossary/#arm-template","title":"ARM Template","text":"<p>A specification file listing all of the cloud resources and configuration settings tha that the Azure Resource Manager can use to create resources for you when you submit it a certain way.   Templates are a great shortcut and automation feature but difficult to edit.  For details see Azure Documentation: What are ARM templates?</p>"},{"location":"cloud_glossary/#azure-resource-manager-arm","title":"Azure Resource Manager (ARM)","text":"<p>see Resource Manager</p> <p>=#### Blob Storage Azure calls there object cloud storage \"Blobs\".  It is similar to Amazon Web Service 'S3' and Google cloud storage buckets.   Azure Documentation: Introduction to Azure Blob storage  While it's possible to 'mount' blob storage to linux VMs using 'blob fuse' or similar packages, it can not work as you may expect and so in practice Azure Files are a better solution for that. See File Storage</p>"},{"location":"cloud_glossary/#client-server","title":"Client-Server","text":"<p>Client/Server model of computing is something we use everyday but perhaps dont' use this term.   See https://techterms.com/definition/client-server_model   You are used to using maybe a dozen clients everyday (phone apps, web browser, ssh to connect to a remote linux, Remote Desktop client to connect to remote desktop server, etc).  Cloud computing provides all the infrastructure needed to create servers quickly and easily. </p>"},{"location":"cloud_glossary/#containers","title":"Containers","text":"<p>Or Docker Containers (not all containers need to be Docker the vast majority of container system use Docker).  For R users, see https://colinfay.me/docker-r-reproducibility/   For Python users, there is https://www.netguru.com/blog/python-docker-tutorial  although you could read either. </p> <p>Linux Containers is a term for a collection of methods and technologies that allows a multiple isolated systems to be run on one Linux computer.   This is differnet from virtual machines in that a VM host provides abstract or virtualized hardware so each VM requires it's own portion of memory and CPU cores whereas containers share the main part of Linux (the kernel), memory and CPU more dynamically.   The primary comercial company for containers is \"Docker\" so Docker is sometimes used synonymously with 'container' but it is just one form. </p> <p>In addition to being more efficient than VMs, most container systems have a system and scripting language for building containers.  The means onecan provision an entire system from code.   Containers are widely use to package and distribute complex research software systems for example Bioinformatics workflow system \"Cromwell.\"  This way reseearches can download and use a pre-installed system without the trouble of getting all of the pre-requistes (dependencies) installed on their machine.   </p>"},{"location":"cloud_glossary/#cpu","title":"CPU","text":"<p>Central Processing Unit, the main 'chip' of a computer, and a core component when specifying a Virtual Machine 'size'</p>"},{"location":"cloud_glossary/#devops","title":"DevOps","text":"<p>This has many definitions but for researchers the shortcut is using code to make IT infrastructure.  Helping developers (like you) do Ops (like sysadmins) with code.   see IaC.</p>"},{"location":"cloud_glossary/#docker","title":"Docker","text":"<p>Docker is the most prevalent form of \"Containers\", e.g Docker is to containers as google is to search.   See containers above for details.  Note that Docker is many things as once:  a method and format for Linux containers, a program for working with container ( e.g. <code>docker build...</code>), a Company, and that's company's hub or repository for storing and access free containers (or your own).    Cloud companies also have \"hubs\" or repositories for storing your own Docker containers.    </p>"},{"location":"cloud_glossary/#file-storage-azure","title":"File Storage (Azure)","text":"<p>Also called \"Azure Files.\" Azure cloud storage that is more traditional file sharing, and that can be connected (mounted) to computers and other services using the SMB protocal, making it similar experience to departmental shared fileservers.   See https://azure.microsoft.com/en-us/services/storage/files/  and compare with Blob Storage</p>"},{"location":"cloud_glossary/#firewall","title":"Firewall","text":"<p>A common concept in networking, firewall software on a computer's networking components limits which kind of traffic can come in or out, and restricts which computer internet addresses can connect. Best practices suggest closing all connections via the firewall, only opening those connections for services you need, and only to those users (e.g. your own computer) you need to. Azure additionally has an option to \"allow connections from Azure networks\" so that you can freely connect from the portal, 'cloud shell', or connect from on azure service to another.   The implication is that you trust all Azure services. </p>"},{"location":"cloud_glossary/#gpu","title":"GPU","text":"<p>From Wikipedia: https://en.wikipedia.org/wiki/Graphics_processing_unit  GPUs can be very helpful for some code written to use them, especially many machine learning libraries, and Virtual Machines may be provisioned with GPUs.  </p>"},{"location":"cloud_glossary/#infrastructure-as-code-iac","title":"Infrastructure as Code (IaC)","text":"<p>In stead of using a GUI, or manual steps to create cloud computing, cloud resources may be created using scripts that interact with the cloud provider's api, and additional scripts can configure individual resources (such as to install software on a VM or configure a database).   Doing this kind of \"provisioning\" with scripts makes it reproducible and debuggable which is at the heart of the Workflow or DevOps mentality. </p>"},{"location":"cloud_glossary/#ip-address","title":"IP Address","text":"<p>a unique string of characters that identifies each computer using the Internet Protocol to communicate over a network.   Your computer will have a different IP address depending on where you are located (home, work, field).   In addition, a home wifi router will assign a 'local' ip address for inside your home, but your 'public' internet IP address will be different.  To find your own IP address, simply google \"what is my ip.\"   All Azure services (VMs, data systems, etc) are assigned IP addresses via networking.  see https://docs.microsoft.com/en-us/azure/virtual-network/public-ip-addresses</p>"},{"location":"cloud_glossary/#object-storage","title":"Object Storage","text":"<p>From NetApp \"What is object storage?:  \"...also known as object-based storage, is a strategy that manages and manipulates data storage as distinct units, called objects. These objects are kept in a single storehouse and are not ingrained in files inside other folders. Instead, object storage combines the pieces of data that make up a file, adds all its relevant metadata to that file, and attaches a custom identifier.\" Blob storage is object storage.   Objects (e.g. files) are retrieved from a large system via their identifier, not their name.   Amazon S3 and Google Cloud storage are also object stores.  </p>"},{"location":"cloud_glossary/#on-prem","title":"On-prem","text":"<p>\"On Premise\" refers to technology (computers, disks, networking, etc) that are on your institutions computer centers or in your own lab.   Note that for some researchers, \"on-prem\" can still mean remove (e.g. our HPC is only accessible remotely, so it may not be obvious that it's on premise to users).  </p>"},{"location":"cloud_glossary/#resource","title":"Resource","text":"<p>For AWS and Azure, a resource is an entity that you can work with.  The means something you can created, edit or delete via their cloud interface.  Could be a computer (virtual machine), a whole cluster (azure batch pool), or some tiny network setting (IP address). Resoures almost always cost money.  Resources are listed in your standard dashboard.  </p>"},{"location":"cloud_glossary/#resource-group","title":"Resource Group","text":"<p>Organizational scheme unique to Azure.  Nearly all resources must be part of a group and the resource group must be selected (or created ) when creating other resources.   Resource groups could be used for specific projects, for 'personal' resources used for multiple projects (or for azure things like cloud shell).  </p>"},{"location":"cloud_glossary/#resource-manager","title":"Resource Manager","text":"<p>Azure calls the system they use to interface between you and cloud resources the \"Azure Resource Manager\" or ARM.   There used to be a different way to interact with Azure resources, hence this has a specific name and is referred to in Microsoft documentation.  </p>"},{"location":"cloud_glossary/#serverless","title":"Serverless","text":"<p>This buzz-word applies to many different cloud services, primarily those that the cloud company manages for you, usually referring to cloud functions (AWS Lamba) and sometimes others in the  \"Platform As A Service\" service model.    The origin is that, if you run virtual machines with operating systems and software install, your are maintaining servers to support that software.  If the cloud service does not require you to provision and maintain a server, it is often marketed as \"serverless\" (e.g. recent marketing of Azure Files as \"Serverless file shares\" where on-premise File Sharing requires staff to manage and maintain Windows File Servers.  </p>"},{"location":"cloud_glossary/#service-models","title":"Service Models","text":"<p>This is related to the \"... as a service\" (..aaS) phrases defined in the NIST document which included  \"Infrastructure\", \"Platform\" and \"Softare\" as a service  (IaaS, PaaS and SaaS).  It's a conceptual organization of cloud services based on the stack model of computating with the infrastructure (network, hardware, CPU, etc) at the bottom and Software on the top.  See The NIST Definition of Cloud Computing</p>"},{"location":"cloud_glossary/#service-level-agreement-sla","title":"Service Level Agreement (SLA)","text":"<p>Level of service you expect from a vendor, laying out the metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved.  In Cloud this is often spells out 'uptime,' which is percent of time the system is not down, e.g. 99.99%, and guarantees against data loss and availability.   For most research, uptime is not important as we are our own customer and can tolerate some downtime.</p>"},{"location":"cloud_glossary/#services","title":"Services","text":"<p>Cloud \"services\" are often bundles of resources pulled together for coordinate function.   Cloud companies offer hundreds of often closely overlapping services.   </p>"},{"location":"cloud_glossary/#tags","title":"Tags","text":"<p>AWS and Azure allow you add meta data to resource in the form of tags (e.g. hashtags, etc) which are keys and values.     When you create a resource you can add a tag indicating the project it is for e.g. \"project\" = \"dna-methylation\"   To add more detail if your DNA methylation has multiple aspects or experiments, add more tags like \"experiment\" = \"Fall 2021\"</p> <p>For workgroups it's stronlgy suggested you add a \"created_by\" = your netid because it's often difficult in Azure to determine who created a resource if it needs to be turned off or deleted.  </p> <p>Use tags to organize your Azure resources and management hierarchy</p>"},{"location":"cloud_glossary/#tensor-processing-unit-tpu","title":"Tensor Processing Unit (TPU)","text":"<p>Google Tensor Processing Unit is specialized computer chip similar to GPUs, used by deep learning libraries such as TensorFlow ( which leads to the question of \"what is a tensor\" and that depends on who you ask but similar to matrix.  </p>"},{"location":"cloud_glossary/#virtual-machine","title":"Virtual Machine","text":"<p>(aka VM) Creating a simulated computer hardware using software, to be able run a guest operating system inside a host system, such that the guest thinks it's  running on an actual computer.</p>"},{"location":"contact/","title":"Contacting Us","text":"<p>If you are a Cloud Computing Fellowship participant this year (or past participant!), please contact the instructors Pat Bills or Mahmoud Parvizi with any issues or questions related to the material or activities.  </p> <p>The session meetings are designed to have plenty of time for questions, troubleshooting and discussion.   We will also schedule office hours prior to meeting times to help with pre-meeting activities. </p> <p>If you have general questions about the MSU Cloud Computing Fellowship, please contact Brian O'Shea or Danielle Barnes</p> <p>If you will be an MSU graduate student or post-doc in Fall 2022 and are interested in participating next year, please check back in the Summer of 2022 for announcements for invitation to participate, or request to join the MSU ICER mailing list</p> <p>If you are an MSU Researcher interested in using cloud for your research, please contact IT Services or MSU ICER via our ticketing systems and describe your needs.   </p>"},{"location":"index2021/","title":"Previous MSU Cloud Computing Fellowship Schedule","text":"<p>This is the schedule for a previous year provided as an example.  Please see our home page for the current year</p>"},{"location":"index2021/#msu-cloud-computing-fellowship-2021-2022","title":"MSU Cloud Computing Fellowship 2021-2022","text":"<p>Welcome to the website for the MSU Cloud fellowship for 2021-2022.  See our \"about\" page for more information about the program.   </p>"},{"location":"index2021/#syllabus","title":"Syllabus","text":"<p>The program runs from Fall 2021 to Spring 2022 semester.  Sessions are organized with pre-meeting materials (readings and videos), pre-requisites, and activities, which allow fellows to prepare for our Friday meetings where we will have hands-on activities and discussion.  </p>"},{"location":"index2021/#schedule-for-fall-2021","title":"Schedule for Fall 2021","text":"<ul> <li>Session 1: Introduction to the 21-22 Fellowship<ul> <li>Sept 3: Meeting : program introductions and program overview (via zoom)</li> </ul> </li> <li>Session 2: Using the cloud for computing<ul> <li>Sept 10: Using Virtual Machines workshop </li> </ul> </li> <li>Session 3: Cloud Storage<ul> <li>Sept 24: Cloud Storage Workshop </li> </ul> </li> <li>Session 4: Moving data to the cloud<ul> <li>October 8: Data utilities and services workshop (Azure Data Factory)</li> </ul> </li> <li>Session 5: Big Data Systems and the cloud<ul> <li>Oct 22: Overview of Big Data on Azure with DataBricks</li> </ul> </li> <li>Session 6: Databases and Data Analytics Systems on the Cloud<ul> <li>Oct 29: Overview of Databases on the cloud, SQL demonstration</li> </ul> </li> <li>Session 7: Serverless and Application Development <ul> <li>Nov 12: Overview of Serverless and FaaS, Demonstration of Real-world project</li> </ul> </li> <li>Session 8: Wrap up and project proposals<ul> <li>Dec 3: Meeting : review and feedback on project proposals &amp; general discussion</li> <li>Dec 17: Final Cloud Computing Fellowship project proposal submission date</li> </ul> </li> </ul>"},{"location":"index2021/#schedule-for-winterspring-2022","title":"Schedule for Winter/Spring 2022","text":""},{"location":"index2021/#meetings","title":"Meetings","text":"<p>We will meet virtually according to the schedule below for 'project update' presentations and group discussions. If you have a scheduling conflict, please let us know as soon as possible. </p> <ul> <li>February 4th : Presentation of Revised Project and current status</li> <li>March 4th : TBD</li> <li> <p>April 8th : TBD</p> </li> <li> <p>All sessions 2:00-4:00pm EST</p> </li> <li>Zoom links and password will be sent over email. </li> </ul>"},{"location":"index2021/#virtual-office-hours-sessions","title":"Virtual Office Hours Sessions","text":"<p>We will also hold two Friday virtual helpdesk sessions per month.  Feel free to take advantage of these voluntary sessions for help with specifics on your project, presentations, and/or general research computing topics. </p> <p>January 14th and 28th  February 11th and 25th  March 18th and 25th  April 1st and 15th</p> <ul> <li>all office hours sessions 2:00-3:30pm EST</li> <li>Zoom links and password will be sent over email but will be the same as for the meetings above. </li> </ul> <p>We encourage you, especially during Winter/spring, to contact us at any time with any questions related to your projects, the fellowship, or cloud computing in general.  We will get back with you when we can and schedule a time for a virtual 1-1 meeting.  </p>"},{"location":"index2021/#symposium-and-project-presentations","title":"Symposium and Project Presentations","text":"<p>Participants will present projects in late April at a symposium for the Cloud Computing Fellowship.  The exact date and time to be determined, and virtual vs in-person also to be determined.   </p>"},{"location":"index2021/#textbook","title":"Textbook","text":"<p>We will occasionally link to the following book: </p> <p>\"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017 </p> <ul> <li>MIT Press website </li> <li>Book Website : Cloud4SciEng.org</li> </ul> <p>The book website does provide open access to individual chapters. </p>"},{"location":"index2021/#communications","title":"Communications","text":"<p>Fellows are encouraged to contact us with questions or if they are ever stuck on an activity we've assigned.  In addition to email, we are utilizing Microsoft Teams at MSU (Fellows receive a link in the welcome email).   Please feel free to reach on out the MS Teams channel sent to participants at the beginning of the program.  Mentioning one of us e.g. @billspat or @parvizm will help get our attention.  Additionally you may email us at any time.   If you are not a participant but have questions about the program, see the Contact page for how to get in touch with us.   </p> <p>If you see a question or discussion on Teams please feel free to add any info or advice you may have, or even let us know that you have a similar question or issue.    </p> <p>If you need interactive, on-going help it may be better to schedule a help session with a fellowship coordinator; and we are happy to meet individually for additional support.   This may be especially effective when fellows are developing their projects.  </p> <p>We also save time during our synchronous meetings for group discussions, so please bring any concerns, difficulties, or successes to our sessions! </p>"},{"location":"index2021/#meeting-location","title":"Meeting location","text":"<p>Given the state of the pandemic in late summer 2021, we are hosting our first meeting (September 3) via zoom.  Participants will be sent a link via email.   Locations for future meetings are to be determined and based on participant feedback.  </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License</p>"},{"location":"miniproject/","title":"end-of-semeseter mini-project","text":"<p>We ask the fellows to complete a small project using the cloud to summarize and visualize data. </p>"},{"location":"miniproject/#overview","title":"Overview","text":"<p>The basic task of this project is analyze data in the cloud: copying data and code to the cloud, and using cloud computing to run a basic script, and save the output to cloud storage.  We provide the data and the code (in R and Python ) with clear description of how to run it.</p> <p>The goal is to assess whether the structure of this material was sufficient (did we do our jobs?), that you were able to synthesize it, and hence you as a fellow are ready to take on a cloud project.  </p> <p>The goal is not to determine your ability to run code (which you most like can already do!), use git, use the command line, or to be a systems admin but just to assess what piiece of this small puzzle we may need to reinforce.   All steps should be able to be completed without having to write any code at all, except tp run the program.  We hope this unified exercise helps fill any gaps in practical and potentially practical understanding of how computing in the cloud works.   Or, even better, that it's so easy that it seems like busy work. </p>"},{"location":"miniproject/#process","title":"Process","text":"<p>We are here to help along the way, and happy to answer any an all questions.   The goal is to not present a step by step tutorial but to provide guidelines for how you should approach the problem.   If you have issues it would be very help to us for you to review the course materials to determine if we've provided the information or links to the information to know if we need to augment these materials.  However we will aways answer your questions as they come up. </p> <p>If you review this and find it very easy, you want to use something other than a VM to do calculations, or have code and data of your own you'd like to run, that is great!    The goal is to help you accomplish a computation in a way that you may use in your project.   </p>"},{"location":"miniproject/#output","title":"Output","text":"<p>We ask that you prepare a short, informal description of the resources you used, how you used them to move data and execute code, and the costs associated with those resources.   In addition any technical challenges, lack of clear documentation,  or any other issues that needed to be overcome to complete this will be helpful to us. </p>"},{"location":"miniproject/#data","title":"Data","text":"<p>The data is a simple CSV file of approximately 450,000 weather observations near the MSU campus.   Details about the data file and it's origin are documented in the code site linked below.   In addition a direct link for downloading the suggested data set will be sent to the fellows in email.   While the data is in the public domain, for each download there is a small cost.  Hence we are not posting the URL on this  public site to prevent bots from repeatedly downloading the file. </p>"},{"location":"miniproject/#code","title":"Code","text":"<p>The code we suggest you run is available on Github: https://github.com/msucloudfellowship/msu_ccf_miniproject There is a Python and an R version.  The data is not in the github repository, but you should have recieved a link to download it, and there are instructions and code for downloading the data from the source for Lansing or other weather stations. </p>"},{"location":"miniproject/#task-details","title":"Task Details","text":"<p>We expect you to create the following elements. If you already have some of these cloud resources, of course it's more efficient to re-use those but we want to get a cost element for all aspects, so we recommend creating a new resources (e..g. a new storage account) for this mini project.  </p> <p>You can use the Azure portal to accomplish many if not not all of these tasks, excpet to run your actual program,</p> <ul> <li>create cloud storage (account, etc)</li> <li>copy data into storage</li> <li>create and start a Virtual Machine (VM) that can run this code.   The instructions refer to the Azure data science virtual machine, which we discussed in the session \"how to cloud\" . You may also use container services (e.g. Azure Container Instance) to run this code if you like. </li> <li>hint: consider using tags to uniquely identify resources you are creating for this project to easily identify all resources used for 1) cost analysis 2) deleting</li> <li>connect and log-in to the VM, and get the scripts into the machine, install software as needed</li> <li>copy the data from storage to the virtual machine disk, </li> <li>by attaching the storage to the compute service and access via that connect</li> <li>or otherwise copy the data (hint: the DSVM comes with the Azure storage explorer installed)</li> <li>run script while pointing to the data file location<ul> <li>this will output images of plots (PDF or PNG formatted)</li> </ul> </li> <li>save output files to cloud storage</li> <li>turn off delete resources related to the VM</li> <li>determine total costs. See the section on costs in the cloud organization session. <ul> <li>if you commplete this in less than a day, the costs for these resources will not be immediately visible in the Azure cost analysis tool.  Potentially wait until next day to view the costs in the Azure portal. </li> <li>This analysis was very small, so the costs will be very very small. </li> <li>uses the outputs from the costs analysis to add a list of resources and costs to your report.</li> <li>As mentioned above, if you use unique tags when creating the virtual machine it will be easier to identify costs specific to this activity</li> </ul> </li> </ul>"},{"location":"miniproject/#due-dates","title":"Due dates","text":"<p>The due date will be discussed in the email but they are flexible.   </p>"},{"location":"projects/","title":"Cloud Computing Fellowship Projects 2022-2023","text":"<p>The primary activity of the Cloud Computing Fellowship is to support the fellows to create and present a cloud-computing-based project working with research data.  During Fall semseter the fellowship provides materials and help to learn core cloud concepts and activies, and Winter/Spring semester is devoted to project development.  </p>"},{"location":"projects/#time-line-and-due-dates","title":"Time-line and Due dates","text":"<p>March 24, 2pm: In-person meeting to discuss fellowship participation</p> <p>April 28:  Final Project Writeup due by 5:00pm EDT</p> <p>May 5 : Presentation of project experience at the Cloud Computing Fellowship Symposium (time and location TBD)</p> <p>Note the Previous Timeline due date sare no longer relevant due to events on campus this semester </p>"},{"location":"projects/#questions-answers-and-other-notes","title":"Questions, Answers and other Notes","text":"<p>Q. Do I have to use my own data for my project or can I use data from the web or other public data?</p> <p>A. you can bring any data that you may use for your research, or that demonstrates cloud processes you may use in your research.   </p> <p>Q.  Do I have to use programming in my project?</p> <p>A.  Most of the examples provided in the fellowship talk about processing data with scripts such as R or Python and many researchers are using these for data analysis, but it's not required for a successful project.   You could install a program on a powerful virtual machine and show how to use that software along with cloud storage to tackle a large data set (for example).   Secondly there are many forms of cloud computing that are not traditional such as data systems which may use a GUI or a language like SQL. </p> <p>One important aspect of a successful project is \"workflow thinking\" or how could you design your process so that you could do it 100 times or with some form of automation.   That often requires programming but there are cloud systems that don't require programming (e.g. Azure Data Factory).    Accumulating and organizing data is a huge part of successful research and using cloud tools to facilitate that and documenting the process, advantages and costs would be a successful project.  </p> <p>Q. Do I have to use Virtual Machine as part of my project?</p> <p>No you don't, and in fact we encourage you to look for other services in the cloud to work with your data or your research processes. </p> <p>Q. Do I have to use services that we've covered in the sessions?</p> <p>A. Cloud companies provide many amazing services, and you are not limited to what we've talked about in the sessions.  In addition we don't require you to use \"computation\" based services alone .   If you are interested in using some other service, please contact us and we may find useful resources or connect you with a colleague who has used the service in mind.  </p> <p>Q. Are there constraints on the things I want do with my project?  Can I do whatever I want?</p> <p>A.  Our goal is to facilitate your education and advancing your research program as it relates to cloud computing, and that is a very broad goal.  If you use the fellowship to develop only a small system to show what's possible or not possible, even on public data, that uses cloud computing, that is an acceptable project. </p> <p>Q. I want to make a web site or application for my project, can I use a VM?  how do I do that?</p> <p>A.  This is a common request and the cloud was invented in part to run web applications.  However web application design is a huge subject and the programming involved is almost as complex as any programming or data work you've done for your research.  We tend to discourage projects focused on web applications because of the work involved to both 1) create the infrastructure for a website (web server, storage, databases, possibly docker containers, etc) and 2) the web application itself (Python/PHP other language, HTML, Javascript, Style Sheets, etc). </p> <p>Azure has services for hosting websites but don't attempt this for your project unless you have previous experience making websites or web applications, or if you are up for the big challenge of learning webdev along with cloud computing because the research you are showing off is mostly complete.    Secondly web services must be on-line 24/7 and the cost may accumulate quickly.   </p> <p>Finally cybsecurity is a major issues for websites which present an open door to anyone on the Internet.   keeping your site secure is a major challenge so during development please turn it off when you are not using it, and consider that web applications are hacked routinely.  </p> <p>However if you are ready to devote the time and this is a goal for your and your advisor please come speak with us as we have experience creating research web applications and we will support you.   </p>"},{"location":"index2021/session_bigdata/","title":"Session 5: Big Data on Azure Cloud Featuring Spark","text":"<p>You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004.   \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data.  </p> <p>Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes).   However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer.  To accomplish our data  processing task we look for ways to split up the work with parallel methods.  Modern big data tools offer this possibility without resorting to custom coding or manually processing.   </p> <p>While big data technology doesn't require cloud computing, most cloud companies have a services that build complex data processing  clusters with a few clicks.  The goal of this single session is introduce you to basic concepts of  'big data' processing and peek at how it works and what it may do for you.   Many applications can't take advantage  of it of big data, or they have their own parallel systems.  for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling. </p>"},{"location":"index2021/session_bigdata/#meeting-october-22-200-330pm","title":"Meeting October 22 2:00-3:30pm","text":"<ul> <li>Discussion and Questions of material from previous sessions</li> <li>Project related questions </li> <li>Lecture Overview of Big Data with Spark for Researchers</li> <li>Big Data Q &amp; A</li> </ul>"},{"location":"index2021/session_bigdata/#videos","title":"Videos","text":"<ol> <li>Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services.    ( MSU log-in required for video)</li> <li>Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services.    ( MSU log-in required for video)</li> </ol> <p>These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code</p>"},{"location":"index2021/session_bigdata/#readings","title":"Readings","text":"<p>Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave VoorhisChapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0  Copyright \u00a9 2015 Elsevier Inc. All rights reserved.</p> <p>PDF copy, for use by Cloud Computing Fellowship only (link is access restricted).  The book is available as an electronic copy from the MSU Library</p> <p>While the book itself is really not of interest to us, this particular chapter is one of the better and readable introductions to \"big data\" I've ever seen, written for professionals like yourselves.    Dr. Self studies ethics and big data for University of Derby in the UK. </p> <p>Textbook: Cloud Computing for Science and Engineering</p> <ul> <li> <p>Chapter 7 \"Scaling Deployments\", only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\"    This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC).  If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me).   </p> </li> <li> <p>Chapter 8 \"Data Analytics in the Cloud\"     This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\"  We will only concentrate on spark for this session as it's much more approachable and more modern.   There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series)</p> </li> </ul> <p>Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure.  Read the introduction only (see activities below for info on the tutorial)</p>"},{"location":"index2021/session_bigdata/#for-r-users","title":"For R users","text":"<p>You can use R commands with Spark, and Databricks has the eoption of creating an R-based notebook.   Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue  R commands.    Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook.  </p> <p>The easiest way to use R with Spark is with the package sparklyr from Rstudio.  </p> <p>\"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. </p> <ul> <li>This is a full book, so only suggested reading for those who deecide to use Databricks/Spark in their projects The book above describes how to use it in detail</li> <li>As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks.  The book has details for that. </li> <li>While it does not describee how to install databricks, all of the examples are useable in an R notebook in Azure databricks</li> <li>The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. </li> </ul> <p>In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio.  It requires some setup, see RStudio on Azure Databricks from Microsoft.  </p>"},{"location":"index2021/session_bigdata/#activities","title":"Activities","text":"<p>There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list  geared towards researchers</p> <p>Create an Azure Databricks workspace  which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal.   The quickstart  tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL</p> <p>Introduction to Spark Data Frames with Python and SQL</p> <p>A job is a way to run non-interactive code in an Azure Databricks cluster.   Doug Krum discusses using Jobs in the videos above.  For details about Jobs and how they work, see Databricks Data Science &amp; Engineering: Jobs  or to simply try a quick example see  Running Jobs in Databricks Quickstart (with Python)</p>"},{"location":"index2021/session_bigdata/principles_using_databricks/","title":"DRAFT Using Databricks and References","text":""},{"location":"index2021/session_bigdata/principles_using_databricks/#basic-function","title":"Basic function","text":"<p>Spark is a cluster technology that connects to special storage, performs parallel work and reports performance.  It runs on Azure using a combination of VMs, Storage disks, blob storage and networking.   Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer.  </p> <p>AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the  resource creation for spark clusters.   When you create an \"Azure Databricks\" resource Azure creates the pieces necessary  to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts.   ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs.  </p> <p>You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources.  In fact the resources that ADB creates can't be changed by you manually.  </p> <p>ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks.     In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface.  </p> <p>You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line.  These data files are then available to your code that runs on the cluster.  Becasue the Spark cluster uses special form of  parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/  however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. </p> <p>ADB by itself can not run code.  You use ADB to first create a spark cluster, then the cluster can run your code.  Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere.). </p>"},{"location":"index2021/session_bigdata/principles_using_databricks/#how-tos","title":"How tos","text":"<p>Create and use an ADB service: use azure portal (link), then go to the resource in the  How to upload into databricks: </p> <p>1) use the UI (link) 2) in a cluster, use the </p> <p>Can I upload files into the DB file system without creating a cluster?  Is there a way to see the files  on the DB file system easily from outside of the cluster?</p> <p>I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration</p> <p>why are there so many disks created in the auto-generated resource group</p> <p>I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs.    That seems like it will be a problem when they go to try to build a DB and it creates a new RG. </p> <p>Job clusters much cheaper - interactive is default, but much more expensive</p> <p>old school RDD, had to do all your own </p> <p>Dataframes + Catalyst</p>"},{"location":"index2021/session_cloud_storage/","title":"Session 3: Cloud Storage","text":""},{"location":"index2021/session_cloud_storage/#introduction","title":"Introduction","text":"<p>Central to using cloud for nearly all services is storing data.   Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC.   During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer.   However there are disadvantages to this :    1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share   1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services    1. it is limited in size.  The largest of virtual disks are around 1 TB.  Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts.    1. You can only move data to/from a virtual or shared disk storage using a virtual machine   1. Most importantly virtual disks very expensive compared to cloud storage </p> <p>Cloud companies think of \"storage\" as anything that save files, or perhaps more importantly anything they can market to you as something to save files.   </p>"},{"location":"index2021/session_cloud_storage/#readings","title":"Readings","text":"<ul> <li>Storage as a Service from \"Cloud Computing for Science and Engineering\"  </li> <li>Optional: this is long (27 minutes) but a good basic introduction to Azure storage:  Azure Training: Explore Azure Storage services ( free training from Microsoft Learn)</li> <li>Table of Azure Storage Product Offerings</li> <li>Azure Documentation: Introduction to the core Azure Storage services </li> <li> <p>Slides/Lecture: Azure Cloud Storage for Researchers with links for details on each slide</p> </li> <li> <p>optional Understanding block blobs, append blobs, and page blobs</p> </li> </ul>"},{"location":"index2021/session_cloud_storage/#activities","title":"Activities","text":"<ul> <li>Download and install the Azure Cloud Storage Explorer  See the \"Download now\" button at the top of that page.  You may review the content of the page</li> <li>complete exercises in Using Azure Cloud Storage to create and use storage</li> <li>Azure Storage Pricing Exercise </li> </ul>"},{"location":"index2021/session_cloud_storage/#meeting-september-24-200-330pm","title":"Meeting September 24 2:00-3:30pm","text":"<ul> <li>About Projects, Mahmoud Parvizi</li> <li>Discussion and Review of previous sessions: <ul> <li>Using the Portal</li> <li>Creating and Using Virtual Machines</li> </ul> </li> <li>What is cloud storage? <ul> <li>concept review: cloud storage vs VM disks</li> <li>discuss exercises to be worked on next week</li> </ul> </li> <li>Review of Broad Cloud Concepts: <ul> <li>On-Demand, Compute, Storage, Identity Management</li> </ul> </li> <li>Discussion : future activities and needs</li> </ul>"},{"location":"index2021/session_cloud_storage/#optional-activity","title":"Optional Activity:","text":"<p>Python And Cloud Storage</p> <p>For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure:    Quickstart: Manage blobs with Python v12 SDK</p> <ul> <li>Requirements:</li> <li>use the blob storage account you created in the exercise above</li> <li>familiarity with Azure portal </li> <li>Python installed on your computer (suggest python 3.6 minimal)</li> <li>familiarity with the terminal and command line</li> </ul>"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/","title":"Exercise: Using Azure Cloud Storage","text":""},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Download the Storage Explorer</li> <li>Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers </li> <li>A valid subscription. </li> <li>A storage account is not always required for some tutorials, but if so, create a storage account with the first item.  </li> </ol>"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#azure-quickstart-tutorials","title":"Azure Quickstart Tutorials","text":""},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#storage-account","title":"Storage Account","text":"<p>We created a storage account in one of the first activities, and you may use that storage account for many of the other activities below.  However  here is the Azure documentation for doing so if you want to review or practice creating a new one: </p> <p>Create a storage account</p> <p>*Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far. </p>"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#blob-storage","title":"Blob Storage","text":"<p>Azure Quickstart: Upload, download, and list blobs with the Azure portal</p> <p>The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: </p> <p>Azure Quickstart: Use Azure Storage Explorer to create a blob</p>"},{"location":"index2021/session_cloud_storage/exercise_using_azure_cloud_storage/#file-storage","title":"File Storage","text":"<p>In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not )</p> <p>Quickstart: Create and manage Azure file shares</p>"},{"location":"index2021/session_cloud_storage/storage_pricing_exercise/","title":"Storage pricing exercise","text":"<p>Prior to doing this exercise, See the reading and lecture slides linked in this session for definitions of terms. </p> <p>How large, approximately, is your data?  If you are unsure, estimate 100 gb.   How much would it cost to keep it in the cloud?</p> <p>Compare the pricing for Blob, Files and Disk storage for 6 months</p> <p>Aspects Of Storage:</p> <ul> <li>Redunancy: Always slect \"LRS\" as that is almost always sufficient and for con</li> <li>Storage prices are not the same across regions, but the default (\"East US\") works for this exercise</li> <li>Consider only the \"Hot\" storage of the different tiers (\"Premium\", \"Hot\", \"Cool\", and \"Archive\")<ul> <li>for some high performance applications, Premium is required, but look at the price difference! </li> </ul> </li> <li>Operations, Transactions and data transfer costs<ul> <li>charged per 10K operations </li> <li>really hard to estimate unless you know your workload</li> <li>very low costs, e.g. reading 10K Blobs costs 1/2 of one cent.  </li> <li>I would not bother estimating this cost unless you know you will have very high disk operations</li> </ul> </li> </ul> <p>Types of Storage to Compare: </p> <ul> <li> <p>Azure Blob Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/blobs/  select \"Hierachcial namespace\"    </p> </li> <li> <p>Azure Files Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/files/ </p> </li> <li> <p>Managed Disk Pricing : https://azure.microsoft.com/en-us/pricing/details/managed-disks/ </p> <ul> <li>note these are in different sizes and types, select 128gb size if you are estimating 100gb data, Standard SSD</li> <li>when you create a disk in the protal, it defaults to 1 TiB size, which is quite expensive / month     </li> </ul> </li> </ul>"},{"location":"index2021/session_cloud_storage/storage_pricing_exercise/#optional-compare-with-on-premise-storage-costs","title":"Optional: compare with On-premise storage costs","text":"<p>The MSU HPC offers 1TB storage with redundant backups and high-speed access for free, with each additional 1TB for $125/year.  Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage?</p> <p>If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?  </p>"},{"location":"index2021/session_datasystems/","title":"Session 6: Data Servers on the Cloud","text":""},{"location":"index2021/session_datasystems/#introduction","title":"Introduction","text":"<p>Data servers like Relational Databases can be a powerful tool for even small research projects.   When we say \"Data Servers\" or \"Data Systems\"  we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results.  The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s but there are many other types.  A central advantage of data servers is ability to have multiple econnections at once from many users, a busy web application, or parallel processing.    Like Big Data tools, these data systems don't require cloud computing, but cloud companies offer database servers with a few clicks that require very littls management.  A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project.  </p>"},{"location":"index2021/session_datasystems/#meeting-october-29-200-330pm","title":"Meeting October 29 2:00-3:30pm","text":"<ul> <li>Discussion of Previous Topics, Q&amp;A</li> <li>Slide Presentation: Introduction to Data Servers on the Cloud</li> <li>Q &amp; A, Discussion of Data Servers and Systems on the Cloud</li> </ul>"},{"location":"index2021/session_datasystems/#readings","title":"Readings","text":"<p>From the free textbook \"Big Data and Social Science: Data Science Methods and Tools for Research and Practice\" see the Chapter 4. Databases   by Foster, Ghani, Jarmin, Kreuter and Lane which could be a valuable resource for learning about the data science methods that you may se on the cloud.  </p> <p>Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database</p> <p>Difference between SQL and 'NoSQL' style databases</p> <p>Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me</p> <p>A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read</p>"},{"location":"index2021/session_datasystems/#activities","title":"Activities","text":"<p>Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first.   </p> <p>If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql</p> <ol> <li>Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal<ul> <li>I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use</li> <li>record the admin user name and password you used when creating the database</li> <li>in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial</li> </ul> </li> <li>Quickstart: Use Azure Data Studio to connect and query PostgreSQL</li> <li>Delete the database in your resource group when you have finished with the tutorial.  If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal.  SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks.  </li> </ol> <p>Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help provisioning and  connecting to a SQL system.   </p>"},{"location":"index2021/session_datasystems/#optional-data-analytics-on-the-google-platform","title":"Optional : Data Analytics on the Google Platform","text":"<p>Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account.  It can process huge amounts of data, and has several datasets available for free.  It also has </p> <p>You may try BigQuery for free in their Sandbox, with only a Google Account.  If you have a gmail account, use that to log in with an incognito/private browser window.   You may try your msu.edu email but it may or may not work. </p> <p>In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google</p> <p>Using the BigQuery sandbox </p> <p>If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab.  </p> <ul> <li>getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb   Log-in to Colab using https://colab.research.google.com/ </li> <li>intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb</li> <li>Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery</li> </ul> <p>Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.  </p>"},{"location":"index2021/session_datasystems/data_servers_intro_for_researchers_edited_with_typora/","title":"Data servers intro for researchers edited with typora","text":"Overview of Data Servers and Databases on the Cloud for Researchers    class: cloudtitle,center, middle  # Data Servers on the Cloud for Researchers  ### Pat Bills, IT Services ADS  for the [MSU Cloud Computing Fellowship](../session_datasystems)  ---  # Again, Why are we talking about Data?    **Session Goal:** understand the principles, how and why to use data servers in your research - we all have data to deal with - a common research struggle is working with complex data, or collaborating with others - Databases can offer a solution for collaboration among researchers and parallel processes - cloud computing offers Data servers  \"as a service\" (PAAS)   - without cloud these systems require a collection of hards, a month of installation, infrastructure expertise - Databases are common place in industry and have been used by researchers for decades - Potential gateway to whole new realm of solutions for data workflows  ---  # Client/Server architecture  - designed in the 1970s, common-place now - client does very little processing, used to send/receive messages - server houses all the data and processing power - now clients are apps and many have significant prrocessing power (chrome) - Most Research workflow:  download data and process it on our machine  ![server](https://assets-global.website-files.com/5debb9b4f88fbc3f702d579e/5ea0baf0b2840153a46b9128_Client-Server-Achitecture.png)  ---  # What is a server?   - Running Program  - listens on specific port  - accepts messagess that match it's protocol/format  - optionally include mechanism for secure authetication   - sends messages and data back using same protocol/format  ---  # What is a server? web server example  - listens for and accepts messages using the 'http' protocol (on port 80)  - the http protocol tells  the web server which content to fetch (via the URL), and what formats the client can use (html)  - the server returns a message indicating the format of the content (html, PDF, etc), other info, and the content itself  -  the browser client determines what to do convert the content to something you can  read     ---  # Clients and Servers  each server requires a specific protocol, so typically you can't mix clients and servers BUT   - some clientss are smart and can alter protocol to work with multipel server  - some sereves are smart and can respond to differnet protocols.   A data serever rmay have a webs interface  For example, many database clients can communicate with many flavorrs of SQL dataabases  - communication protocols are text and binarry, and client apps provide GUIs of those  - servers accept commands, programs, or data, formatted in propeer protocol - clients let you type to thee commands and format into th eprotocol for you  ---  # Client/Server Connections  - `user -&gt; connects to server host -&gt; enters commands -&gt;  client formats and sends  ---&gt; server accepts commands --&gt; run process and returns value`  - `user &lt;-- client displays results &lt;- client accepts results and displays`  - communication can be about data, but also about server configuration, client output format, etc   ---  # Client/Server : essential for data systems  This session is focused on data systems that use a client/server model but we use services every day - email - remote desktop : the 'server' is a windows programs that returns views of the screen - most apps ( I have to use on to remote start my car ) - others?    ![db server architecture](img/db_server_topology.png)  ---  # Cloud was made to  serve  The cloud was invented to host servers  Large institutions have to run servers for many aspects of their work  in addition to data      # Steps for Client-Server-ing  1. install a server    - physical machine or a VM that is running server software 2. configure server    - network, securrity, user aaccounts, storagee, server prefs/config    - use managed cloud service (restuarant)  3. install client    - download any number of compatible programs  ---    ---  # Server Connection Terms  - *host*: computer that runs the server software \"host\" and id by it's internet address - *port*: too allow muliple servers linux has 65K ports - *user vs admin*  : accounts on the server , admin has full power, user limited.  For DIY server, you are the admin - *database vs server* : a \"database server\" can have multiple \"databases\" becuase servers are typicaly shared - *SSL* : secure sockets layer required to encrypt the communication for security, Azure takes care of this - *Connection string* : the combination of these parameters used to connect to a database, formated for the Client - *Client* : can be a package or library used inside a programming language  ---  # Server Locality  *Servers can run anywhere*   - on your laptop, running alongside your other  programs.  The *host* is called `localhost`     - on a computer on campus (on-premise) the host is something like myservername.mydepartment.msu.edu   - on a VM that you create in the cloud :  myvmname.east.azure.net (IAAS)  - as part of a service offerring, provisioned for you (PAAS)  - the service itself, you don't control the server, only access data serevices (SAAS)  #   # Example session : terminal client  #### Demo of Terminal session to Postgresql Server   - Create a Azure Postgresql Database Server  - Connect to the server with a command line interface  ![Example PSQL Terminal Session](img/psql_terminal_session.png)  ---  # Example Session : GUI client    #### Demonstration using a free Graphical Client to connect to a Postgresql Database hosted on Azure    ![Example DB gui](img/database_gui_example.png)  ---  # Example Session : Scripting Client    # Example Data Command Language: SQL  - Structured Query Language for Relational Databases - by far most common data processsing language since 1970s - declarative not procedural   - like ordering from a restaurant - you state what you want, with no direction for how to prepare - easy to learn and use and use the basics - like other Data Command languages, based the data model  = tabular data, linked on common ID values.    ---  # Example Data Command Language: SQL  This is not a course on SQL but for Example to return rows of a table  - *SELECT* the columns to show  - *FROM* the table  - **WHERE** a logical condition to match data in the rows - ordering   list some data for all flights for today in the US:    <pre><code>SELECT flight_num, airport_code, airline, takeoff_time, aircraft_id \nFROM flights WHERE fight_date = '2021-10-28' and country='US'\n</code></pre>  1. -   ---    --- # Cloud-scale Database Services  We covered a \"Big Data\" system last seesion (Spark) but cloud companies provide a data service for really big data.  These are proprietary, on-of-a-kind systems that can work on truly huge amouts of data  - Google BigQuery (google invented the concept and unbelievable huge) - AWS Redshift - Azure ComosDB - Azure DataExplorer aka Kusto  do not need to provision any resources, only an \"account\" in which you can store your data, queries/scripts, and the output.   Data storage is inside the db and  output can be exported to cloud storage in various formats  - SAAS for large database  ---  # Cloud-scale Database Services: Azure Cosmos DB  - Primarily a NoSQL database, but has a SQL API to make it easy - Compatible with other common open source NoSQL database \"MongoDB\" - Getting data ingested requires using a windows program, or using Azure DataFactory to move data from Cloud storage into Cosmos DB - Could be useful if you are analyzing a very large amount of semi-structured data that may already be in JSON format and don't want to manage a big data system like Databricks.  - Resource [Introduction to Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction) and the Azure [Quick Start using Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/sql/create-cosmosdb-resources-portal)  ---  # Azure Data Explorer : Analytics as a Service    [Data Analytics Service on Cluster Computing  aka *\"Kusto\"*](https://docs.microsoft.com/en-us/azure/data-explorer/data-explorer-overview)  - Useful for fast analytics of large data without provisioning a server - Data is read-only and  can't be changed.  - SQL-like query language called KQL unique to Kusto: [Overview with link to free example](https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/) - Create a cluster: https://portal.azure.com/#create/Microsoft.AzureKusto then use https://dataexplorer.azure.com/   ![Kusto Example](img/azure_kusto_example.png) ---  # Google Detour    #### We could use a collection of Google services to accomplish data analytics on the cloud:   - Google Drive: Files as a Service - Google Colab: Python/R/SQL as a Service : free notebooks hosted in Google Drive` - Google BigQuery : Data query as a service    - [CoLab Example (PSB's drive)](https://colab.research.google.com/drive/1e_nObJODQ61-0NtaMI-jlEvT9eHgvkmd) - [Weather Tutorial using Google Services](https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery)     that access huge public dataset demonstrates the power of this approach  #### *Google Colab + Google BigQuery + GoogleDrive*  - definitely cloud computing   - is it cloud computing in the way we think about it?  ---  # Cloud Serivce Levels and Responsibility  - any server connected to the internet has security  - many ways to mitigate the risk including cloud private networking, firewalls, encryption - When chosing data services, consider responsibilities for security and configuration    - Infrastructure = IAAS : cheaper, more work, more responsibility, more risk    - Services = PAAS/SAAS:  more expensive, faster provisioning, less risk  ![Service levels](../img/service_levels_and_user_responsibility_stack.svg)   ---  # Questions?  ![Example database diagram from US BLM](img/exampledatabase-FGDC-Cadastral-Standard-ERD-The-National-Integrated-Land-System-NILS-is-a-joint.png)  *example Database Diagram from [Towards a Standard for the Cadastral Domain: Proposal to establish a Core Cadastral Data Model, 2002 Van Oosterom &amp; Lemmen](https://www.researchgate.net/publication/27349321_Towards_a_Standard_for_the_Cadastral_Domain_Proposal_to_establish_a_Core_Cadastral_Data_Model)*"},{"location":"index2021/session_datasystems/table_of_responsibilties_by_service_level/","title":"Table of responsibilties by service level","text":"Layer Responsibility On-Prem IAAS (VM) PAAS SAAS Network Connectivity &amp; Security Campus IT Service Service Service Hardware Disk Failures You Service Service Service Operating System Updates, installation, security You You Service Service Security Software Install and maintain You You Service Service Server Software Install, maintain You You Service Service Server Configuration Tune, Speed, You You You (limited) Service User Configuration Who can access, user accounts You You You Service Code/Data You You You You"},{"location":"index2021/session_how_to_cloud/","title":"Session 2: What is the cloud and how does it work?  An introduction using Virtual Machines","text":"<p> When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines.   Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start.   This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program.    At the end of the session you should have a good introduction of what it means to \"cloud compute.\"</p>"},{"location":"index2021/session_how_to_cloud/#readings","title":"Readings","text":""},{"location":"index2021/session_how_to_cloud/#cloud-background","title":"Cloud background","text":"<ul> <li>The NIST Definition of Cloud Computing  The framework that most widely used to describe aspects of cloud computing, and categorize cloud sevices. </li> <li>Microsoft Reference Architecture: What is Infrastructure as a Service?</li> <li>Orientation Azure Portal</li> </ul>"},{"location":"index2021/session_how_to_cloud/#other-references","title":"Other References","text":"<p>These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective.  However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites.   </p> <ul> <li> <p>Wikipedia article on cloud computing is actually pretty good</p> </li> <li> <p>[M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf}     Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing</p> </li> <li> <p>I. Porres, T. Mikkonen, A. Ashraf, eds.  \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)</p> </li> </ul>"},{"location":"index2021/session_how_to_cloud/#fellowship-materials","title":"Fellowship Materials","text":"<ul> <li>Top-down description of how Azure is organized</li> <li>Summary of Cloud Interfaces</li> </ul>"},{"location":"index2021/session_how_to_cloud/#virtual-machine-background","title":"Virtual Machine Background","text":"<ul> <li>What is a virtual machine (VM)?  Introduction from Microsoft</li> <li>What is a Virtual Server? Youtube Video from  IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. </li> <li>What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company</li> </ul>"},{"location":"index2021/session_how_to_cloud/#activities","title":"Activities","text":"<ul> <li>Using the Azure Portal : tutorial and video This is a more detailed tutorial and video of the quick walk-through we did during our live session for Week 1 on September 3</li> </ul>"},{"location":"index2021/session_how_to_cloud/#fellowship-meeting","title":"Fellowship Meeting","text":"<p>September 10, 2021.  Zoom link sent via email</p> <ul> <li>Presentation (PDF)</li> <li>Review of Introduction to Cloud materials: discussion and questions</li> <li>Questions about the nature of cloud</li> <li>Activity: Creating (and deleting) a Virtual Machine with Azure updated 9/16; includes instructions for Linux</li> </ul>"},{"location":"index2021/session_how_to_cloud/#additional-post-session-materials","title":"Additional Post-session materials","text":"<ul> <li>Determining Azure Costs</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_organization/","title":"Azure Organization","text":"<p>This is a brief description of how Azure cloud services are organized for those just getting started with Azure.  It's my own take on this topic written with researchers in mind.  However it should not replace Azure official documentation.  The link below has a great summary of how it's setup.  However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization</p> <p>Microsoft Azure Documentation: Organize your Azure resources effectively</p> <p></p> <p>Azure is organized by directories of user accounts and subscriptions.  All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions.  Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user.  MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription.   </p> <p>Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\"   Anything you can create using a cloud interfaces is a \"resource.\"   </p> <p>To help with more organization, in Azure, resources belong to a resource group.   Resource groups can collect resources by project which could still have hundreds or just a few resources.  There is no restriction and up to you to organize how it works for you.  For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects.   </p> <p>It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group.  Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here.  </p> <p>However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions.   Applying this organization scheme requires practice and sometimes vigilance.   </p> <p>For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers.   When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ </p> <p>Summary of top-down Azure Organization: </p> <ul> <li>Directory : (MSU account). All account must come from a directory (but an account can be multiple directories)<ul> <li>Management groups : we won't use these, for admins to manage multiple subscriptions)<ul> <li>Subscription : tied to a billing account, and where all resources are created.  <ul> <li>Resource Group : organizational tool for resources.  Think of it as a \"folder\" in your file system<ul> <li>Resource : any cloud entity you may work with (e.g. create, configure, destroy)</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources.  If you have never used Azure before, you may be asked to create a free trial.   If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account.  </p> <p>Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services.   They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis.   You can use any keys and any values you find useful.  </p>"},{"location":"index2021/session_how_to_cloud/azure_organization/#azure-locations-or-regions","title":"Azure Locations or Regions","text":"<p>Subscriptions are for accounting only and don't represent concrete cloud resources.  However cloud resource must reside in computer somewhere, and hence have a location.   Locations for cloud providers for can be thought of inside one of their massive data centers.  In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region')</p> <p>Resources and Resource groups must be assigned a location when you create them.   considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin.   </p> <p>Most of the time, simply choose the default which is East US which almost always has the latest features.  For some advantage for data transfer, choose (US North Central US).   However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. </p> <p>Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers.  It's also possible to have back-ups of resources in different region to protect against natural disasters.  </p>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/","title":"Exercise: Azure Portal Walk-through and Storage account creation","text":"<p>MSU Cloud Computing Fellowship </p>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services.   Prior to doing this exercise, please read  Azure Organization For more background on how azure is structured.   </p> <p>For definition of terms used in this walkthrough , refer to our Cloud Glossary  including \"resource\", \"azure resource manager\" and \"resource group\"  or our list of cloud references for introduction to cloud computing. </p> <p>For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure, but it can be a great place to start exploring and trying new services.    Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. </p> <p>Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview  Please refer to that as well as this material.   </p>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#orientation-to-the-azure-portal","title":"Orientation to the Azure Portal","text":"<p>The link above is to a video that walks through the description and tutorial steps below, hosted on  MSU MediaSpace ( requires MSU Log-in)</p> <p> This assumes you have an Azure account and a valid subscription.   For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, </p> <ol> <li>Log-in to https://portal.azure.com with your MSU Netid.   <ol> <li>If you  are a current member of the fellowship and you have difficulty logging in, please contact us right away. </li> </ol> </li> <li>orientation: dashboard view.     Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account.  You may alter the panels on this dashboard  to show you the services and aspects of azure that are most important to you.   For information on how to create customize your dashboard, see \"Create a dashboard in the Azure portal.\"    In the standard, default version of the dashboard the first panel is a list of resources.  If you have not created any resources yet you won't see anything.  We will explorer resources later in this introduction.     The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you.   We will focus on the \"All Resources Pane\"    If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below)</li> <li>Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources.   If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. </li> <li>Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created.    This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. </li> <li> <p>Shortcut buttons: the next few icons are short cuts to other functionality in the portal: </p> <ul> <li>cloud shell: see (link TBD)</li> <li>directories: about your subscription</li> <li>notifications: alerts when things change (when they are created, deleted)</li> <li>settings : most will not be valuable unless you create many resources, but feel free to change these, although do not change your email address</li> <li>help/support</li> <li>feedback : to the Azure people</li> </ul> </li> <li> <p>A note about portal navigation:  When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right.  This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to  </p> </li> </ol> <p>Notice that like most things there are 4-5 ways to get to anywhere.  </p>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#creating-storage-account-with-the-azure-portal","title":"Creating storage account with the Azure portal","text":"<p>Note: It's ok if you would like to repeat this tutorial, there will be minimal costs and you may delete the resources you create (instructions for deleting at the end). </p> <p>You don't need to know about Cloud storage to complete this tutorial.  This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example.  You need a place to keep your stuff for a long time (persist your data) and cloud storage is a durable and inexpensive system for storage nearly unlimited files (or 'objects' in cloud terms).    However as we will discover cloud storage is not the same as \"disk storage\" and works differently.  Hence you need a storage \"account.\"</p> <p>Requirements:</p> <ul> <li>An Azure Account with valid subscription</li> <li>A Resource group</li> </ul> <p>All members of the current Cloud Computing Fellowship cohort have these things</p>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#tutorial-steps","title":"Tutorial Steps.","text":"<ol> <li>Log-in to the Azure portal if you have not already:  https://portal.azure.com</li> <li>Click the menu (top left, three horizontal bars) to open it</li> <li>Select \"home\" from the menu - this ensures we all have the same view</li> <li>In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\    Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen...</li> <li>This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft.   When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step)</li> <li>Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar</li> <li>in the lower search bar, type \"Storage account\"   Note that \"storage\" alone lists many other kinds of resources. </li> <li>You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a spreadsheet).   </li> <li>The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. </li> <li>Click \"create\"</li> <li>The azure resource creation screens mostly work like this:   there are so many settings Azure has split these up into groups which are listed horizontally across the top.   You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form.   At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it.  We will go page-by-page for these settings</li> <li>Basics: <ol> <li>Subscription: Cloud Computing Fellowship</li> <li>Resource Group: Select your resource group (you may only have the one) \\     You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group</li> <li>Storage Account Name:   This name must be unique for this region in azure, so Use your NetID for part of the name<ul> <li>replace \"NETID\" with your MSU NetID here:  \"cf21NETIDstorage\"   e.g. cf21billspatstorage</li> <li>If you are repeating this tutorial, simply add a \"2\" or \"cf21billspatstorage2\"</li> <li>some resources have restrictions on naming.  Next to storage account is an \"i\" in a circle that has more information.  For storage accounts, they must be unique in region, and only numbers and  lowercase letters are allowed.  I don't know if Non-US letters are allowed (e.g.\u7bb1)</li> </ul> </li> <li>Region (Location):  You may leave US East, or click to select something closer to MSU (e.g. North Central US)</li> <li>Performance: Standard</li> <li>Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS) although we won't see a different, LRS is cheaper \\</li> <li>beneath that, leave the \"make read access....\" box checked. </li> <li>Click \"next...Advanced\"</li> </ol> </li> <li>Advanced: Leave all of these settings as-is.   </li> <li>Networking: leave all of these settings as-is</li> <li>Data Protection: leave all as is.  These settings allow you to recover files up to 7 days after deleting or over-writing</li> <li>Tags</li> <li>tags are optional but highly recommended.  Tags are notes to yourself about the resource, use them for metadata.  </li> <li>At MSU ADS we always have a tag with the key \"created by\" and value the netid of the creator.   </li> <li>You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects.     </li> <li>tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work</li> <li>Review and create<ul> <li>review gives you a chance to double check your settings before committing</li> <li>click \"create\"</li> </ul> </li> <li>Deployment<ul> <li>Azure calls the process of creating cloud resources a \"deployment.\"   This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available.  On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment.   </li> <li>Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. </li> <li>You may leave this page and the deployment will continue in the background.   </li> </ul> </li> <li> <p>finish and review</p> <ul> <li>When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the  \"Notification\" icon indicating the number of messages you have (probably just 1 ).   Click on the Notifications icon to show this message.   </li> <li>the message should be something like:          Deployment succeeded         Deployment 'resourcename_12345678901234' to resource group 'group name' was successful.</li> <li>\"Go to Resource\" button will open the Portal page with options for the resource</li> <li>\"Pin to Dashboard\" will create a  new tile that is a shortcut to this resource on your dashboard for easy access.   If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom)</li> </ul> </li> <li> <p>Examine Resource (storage )     We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized.  </p> <ol> <li>If you didn't already click \"go to resource\", open the top menu and click \"home\"</li> <li>the Portal \"Home\" has a list of \"recent resources\" and this should be at the top.  </li> <li>Click on this new cloud storage to view aa</li> </ol> </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_portal_walkthrough/#about-portal-resource-pages","title":"About Portal \"Resource\" Pages","text":"<p>Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center.  The first page is the \"Overview\"  which has the resource group, subscription, and other info important for that resource.   this followed by the \"Activity Log\" showing how the resource has been used.   Each of the following items on the left side is a new page of additional options to alter how the resource is configured.  For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. </p> <p>Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources.   In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface</p> <p>Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.  </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux","text":"<p>Link to Video for the Windows version of exercise.  On mediaspace.msu.edu which requires a log-in</p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal.  </p> <p>There are two nearly identical activities, and you only need complete one of them:  </p> <ol> <li>creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer</li> <li>creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer.   </li> </ol> <p>We will use a pre-configured virtual machine with software already installed for both versions.  When creating a VM you can use an Azure template and there are many of these.  The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available.   For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/   and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included  Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements-for-both-activities","title":"Requirements for both activities","text":"<p>You need an Azure account with an active subscription, and a resource group of your own to work in.   Fellows have these things provided.  </p> <p>This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough.  In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise.  For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section</p> <p>It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux)</p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#creating-a-windows-virtual-machine","title":"Creating a Windows Virtual Machine","text":"<p>This section is based on Windows.  For an equivalant exercise based on Linux, scroll down.  If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements-for-windows-vms","title":"Requirements for Windows VMs","text":"<p>To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client.  </p> <ul> <li>MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12</li> <li>Linux users install http://xrdp.org/</li> <li>Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select **Data Science Virtual Machine - Windows 2019 **</p> <p>The \"Plans\" section has a description of the template if you would like to know more. </p> <p>Click the \"start with a pre-set configuration\" option. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration","title":"2. select the pre-set configuration","text":"<p>These configurations help to select your VM size based on your activity.  We will use the default options and click \"Continue to create a VM\" </p> <p>The options do not affect the outcome of the exercise so at this step explore each option</p> <p>Click \"Continue to create a VM\"</p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","title":"3. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#basics","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid).  As we create additional resource groups for this </p> </li> <li> <p>Virtual machine name  Name: CF21-netid-dsvmtest    One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing.   In the name above, replace \"netid\" with your own MSU netid.   </p> </li> </ol> <p>Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \"</p> <p>Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future.  1. Region  Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message.  1. Image should be \"Data Science Virtual Machine - windows...\"   if this is change you may  1. Azure Spot Instance  leave unchecked.  1. Size   You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step.     This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00 1. Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.   Select a User name and account that you will easily remember, because you will need it to log-in to the new VM.      * username : use any user name you will easily remember, perhaps your netid     * password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use 1. Licensing  Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure.   Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows.    </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages except for Basics page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#tags","title":"Tags","text":"<p>Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources.  I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources.   </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2</code></li> <li>click \"review and create\" </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#review-and-create","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this VM.  Mine says <code>0.1920 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p> <p>You should kkip down the the Viewing VM Resources section below/ </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#optional-creating-a-linux-virtual-machine","title":"Optional:  Creating a Linux Virtual Machine","text":"<p>This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible). </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#requirements","title":"Requirements","text":"<p>To connect to Linux you need an terminal or command line interface with an <code>ssh</code> client software.  If you have used the MSU HPC, this is the same method for connection.  </p> <ul> <li>On Mac, the Terminal.app has ssh</li> <li>On Modern version of Windows, the cmd.exe command prompt has an <code>ssh</code> command built in but there are other programs </li> <li>Linux desktop/laptops come with an ssh client</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#creating-a-linux-virtual-machine","title":"Creating a Linux Virtual Machine","text":"<p>If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template_1","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select **Data Science Virtual Machine - Ubuntu **</p> <p>The \"Plans\" section has a description of the template if you would like to know more. </p> <p>Click the \"start with a pre-set configuration\" option. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration_1","title":"2. select the pre-set configuration","text":"<p>These configurations help to select your VM size based on your activity.  We will use the default options and click \"Continue to create a VM\" </p> <p>The options do not affect the outcome of the exercise so at this step explore each option</p> <p>Click \"Continue to create a VM\"</p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal_1","title":"3. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#basics_1","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid).  As we create additional resource groups for this </p> </li> <li> <p>Virtual machine name  Name: CF21-netid-linuxdsvmtest    One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing.   In the name above, replace \"netid\" with your own MSU netid.   </p> </li> </ol> <p>Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \"</p> <p>Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future.  1. Region  Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message.  1. Image should be \"Data Science Virtual Machine - Unbuntu..\"   if this is changed you may have to select it again from the list.  1. Azure Spot Instance  leave unchecked.  1. Size   You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step.       This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00 1. Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.     1. Authentication Type  For the purpose of this exercise, select \"password\"    If you are very familiar with ssh keys, this is the recommended method.  You will be asked to download a key and use that key in your ssh command.  The key is only available for download when you create this vm and if you lose it you can't connect.   We can definitely cover how to use ssh keys as this is the preferred method for connecting. </p> <ol> <li> <p>UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. </p> </li> <li> <p>password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use</p> </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings_1","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages except for Basics page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#tags_1","title":"Tags","text":"<p>Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources.  I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources.   </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2</code></li> <li>click \"review and create\" </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#review-and-create_1","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this Linux VM.  Mine says <code>0.1000 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p> <p>Linux Users continue to the next section</p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#viewing-vm-resources-in-your-resource-group-windows-and-linux","title":"Viewing VM Resources in your Resource group (Windows and Linux)","text":"<p>While the deployment is in progress you may explore the operation details or click any of the resources that have been created. </p> <ol> <li>Open your resource group in the portal:  <ol> <li>click the portal menu on the top left, and select \"resource groups\"</li> </ol> </li> <li>From the list, select your CF21 group. </li> <li>When the deployment is finished, you should see several new resources <ul> <li>They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip </li> <li>The second column is the \"type\" which helps identify what they are</li> </ul> </li> </ol> <p> click for a large view in a new tab/window</p> <ol> <li>Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)</li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#the-vm-resource-page","title":"The VM Resource Page","text":"<p>To see the details for your virtual machine, click the VM in your resource group if you haven't already. </p> <p> click for larger view</p> <p>There are many details here but some immediate things to notice: </p> <ul> <li>in the top row are buttons to connect, start, restart and stop the vvm.   </li> <li>in the top, \"essentials\" section the  \"status\" should be \"running.\"</li> <li>on the right side is the assigned IP address which you need to connect.   Highlight and copy and paste this address.   If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting","title":"Connecting","text":""},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-windows-vm-using-remote-desktop-protocol-rdp-client","title":"Connecting to a Windows VM using Remote Desktop Protocol (RDP) client","text":"<p>You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both.  </p> <p>The following Azure documentation describes how to connect to a Windows VM:  https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon</p> <p>Here are more detailed instructions: </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with RDP  (remote desktop protocol)  is a Microsoft method for connecting to the graphical desktop.  For Mac/Linux requires additional software (mentioned at the beginning of this page).  </p> <ul> <li>Click \"connect\" and select \"rdp\" if it isn't already.  </li> <li>click \"download RDP file\" button and save the <code>.rdp</code> file anywhere on your computer that you find it again</li> <li> <p>after it's download, and if you Mac users have installed the RDP client, then double click the <code>.rdp</code> file to open your remote desktop software. </p> </li> <li> <p>On windows, any security or error messages, click \"connect\"</p> </li> <li> <p>Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM</p> </li> </ul> <p></p> <ul> <li>When you connect, if the VM is not running, you will get an error message.  Here is what the Windows screen looks like: </li> </ul> <p></p> <p>This is because we are using a temporary certificate but it is secure.  Click \"Yes\" </p> <ul> <li>Enter the Username and password you used when  configuring the VM in the \"Basics\" section above.  <ul> <li>you may be able to simply enter the user name and password directly</li> <li>If not, in the  Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK.  If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. </li> </ul> </li> </ul> <p>Once you connect, you may see Windows starting up and installing things.  Feel free to close any windows.  Once the installations are finished, you may use the machine as you would any other windows computer.  If you type Rstudio in the search box, you may launch an  Rstudio session on this remote computer.    It also has Python, many python libs and Jupyter notebook.  </p> <p>We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p> <p>Optional: Connect to the Windows DSVM with ssh </p> <p>This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH.   If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter <code>ssh &lt;username&gt;@&lt;ipaddress&gt;</code></p> <p>Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page.   </p> <p>This is similar to how you connect to the MSU HPC, if you are HPC user. </p> <p>You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. </p> <p>When you log-in you will be connected to the Windows command prompt (e.g. <code>C:\\Users\\username&gt;</code> </p> <p>To Exit, type <code>exit</code> at the command prompt. </p> <p>Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines.  </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-linux-vm-using-ssh","title":"Connecting to a Linux VM using SSH","text":"<p>We will connect and use this remote VM running the Linux operating system with a command line connection.  It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise.  </p> <p>In addition this assumes you have some familiarity with using the command line and starting your terminal program.  </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with SSH </p> <p>this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. </p> <ul> <li>On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side.   Copy this IP address to the clipboard, or make a note of it.   Mine was 20.98.28.63.   Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop.  Use the Public IP address.  not all VMs have a public IP address but this one will.  </li> <li>also make a note of the User ID and password you used to create the VM above</li> <li> <p>side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key,  even though we did not create an ssh key when we created a VM.  If you did not create an ssh key, you do not need to follow these instructions. </p> </li> <li> <p>on your desktop/laptop, start your terminal program on MacOS/Linux or <code>cmd.exe</code> if you using Windows. </p> </li> <li>Enter the command as displayed, which is something like <code>ssh vmusername@vmipaddress</code>   In my case, my command is <code>ssh patbills@20.98.28.63</code></li> <li>If this is the first time connection, you'll get the standard ssh warning <code>\"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\"</code> simply say \"yes\" and enter</li> <li>Enter the password you used when  configuring the VM in the \"Basics\" section above.  (note that ssh does not show any key movement or * when you type a password)</li> <li>it takes a while to connect for the fist time as the VM configures software and prepares your user account</li> </ul> <p>You may use the machine as you would any other linux computer. For more information about what software is installed, see  We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p> <p>Optional: Connect to the Windows DSVM with ssh </p> <p>This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH.   If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter <code>ssh &lt;username&gt;@&lt;ipaddress&gt;</code></p> <p>Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page.   </p> <p>This is similar to how you connect to the MSU HPC, if you are HPC user. </p> <p>You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. </p> <p>When you log-in you will be connected to the Windows command prompt (e.g. <code>C:\\Users\\username&gt;</code> </p> <p>To Exit, type <code>exit</code> at the command prompt. </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#starting-and-stopping-the-vm-both-windows-and-linux","title":"Starting and Stopping the VM (both Windows and Linux)","text":"<p>There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use  Windows to turn it off.  The VM is then \"stopped.\"   In a Linux ssh session you may use a command like <code>sudo shutdown -h now</code>   When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\"  When you turn it back on, it will come on immediately.  1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM.  Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up.  This is cheaper then the first method in the long run 1. Delete it.   </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#stopping-deallocating-the-vm-with-the-portal","title":"Stopping (deallocating) the VM with the Portal:","text":"<ol> <li>Go to the resource page for the VM, if you are not already. </li> <li>If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. </li> <li>The Status field near the top of this screen will indicate running or stopped.  </li> <li>Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. </li> <li>There is a warning about losing your IP address, with a check box to reserve it.<ul> <li>If you plan on deleting the VM now, click \"ok\"</li> <li>If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK</li> <li>The default is to use a \"dynamic\" address which is assigned every time you turn on the VM</li> <li>When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine</li> <li>the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. </li> <li>you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal</li> <li>Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off.  That is approx $2.70/month</li> </ul> </li> <li>It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep.   The main reason for this is for security.  </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#deleting-the-resources-both-windows-and-linux","title":"Deleting the Resources (both Windows and Linux)","text":"<ol> <li>Open the Resource group as above</li> <li>When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify.   Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button)</li> <li>If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\"  For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views .  If you add filter on tag, then you may select all the items that are shown, and delete those. </li> <li>after selecting confirm the deletion by typing \"yes\"</li> </ol> <p>Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges.  </p>"},{"location":"index2021/session_how_to_cloud/azure_vm_walkthrough/#more-refereences","title":"More Refereences","text":"<p>Azure has very abbreviated versions of this exercise if you would like another perspective.  They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship)  </p> <p>https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps </p> <p>**Data Science Use Case Tutorials from Azure: **</p> <ul> <li> <p>Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product.   However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface  https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things </p> </li> <li> <p>Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough</p> </li> </ul> <p>If you follow these, just remember to delete the resources you create when you are done exploring</p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/","title":"Exercise: Creating a Windows Virtual Machine (VM)","text":"<p>Please see our updated version that covers both Windows and Linux</p> <p></p> <p>Link to Video for this exercise on mediaspace.msu.edu (requires log-in)</p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal.  This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough.  In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise.  For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section</p> <p>We will use a pre-configured virtual machine with software already installed.  When creating a VM you can use an Azure template and there are many of these.  The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available.   For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/</p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#requirements","title":"Requirements","text":"<p>You need an account in azure with an active subscription, and a resource group of your own to work in.   Fellows have these things provided.  </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#creating-and-connecting-to-a-windows-virtual-machine","title":"Creating and Connecting to a Windows Virtual Machine","text":""},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#requirements_1","title":"Requirements","text":"<p>To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client.  </p> <ul> <li>MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12</li> <li>Linux users install http://xrdp.org/</li> <li>Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#creating-a-windows-virtual-machine","title":"Creating a Windows Virtual Machine","text":"<p>If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#1-selecting-the-resource-template","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select **Data Science Virtual Machine - Windows 2019 **</p> <p>The \"Plans\" section has a description of the template if you would like to know more. </p> <p>Click the \"start with a pre-set configuration\" option. </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#2-select-the-pre-set-configuration","title":"2. select the pre-set configuration","text":"<p>These configurations help to select your VM size based on your activity.  We will use the default options and click \"Continue to create a VM\" </p> <p>The options do not affect the outcome of the exercise so at this step explore each option</p> <p>Click \"Continue to create a VM\"</p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","title":"3. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#basics","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid).  As we create additional resource groups for this </p> </li> <li> <p>Virtual machine name  Name: CF21-netid-dsvmtest    One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing.   In the name above, replace \"netid\" with your own MSU netid.   </p> </li> </ol> <p>Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \"</p> <p>Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future.  1. Region  Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message.  1. Image should be \"Data Science Virtual Machine - windows...\"   if this is change you may  1. Azure Spot Instance  leave unchecked.  1. Size   You can leave the size that is currently selected.     This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00 1. Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.   Select a User name and account that you will easily remember, because you will need it to log-in to the new VM.      * username : use any user name you will easily remember, perhaps your netid     * password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use 1. Licensing  Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure.   Leave this box unchecked.  </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#disks-and-other-settings","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages except for Basics page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#tags","title":"Tags","text":"<p>Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources.  I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources.   </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2</code></li> <li>click \"review and create\" </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#review-and-create","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this VM.  Mine says <code>0.1920 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#4-the-resources","title":"4. The Resources","text":"<p>While the deployment is in progress you may explore the operation details or click any of the resources that have been created. </p> <ol> <li>Open your resource group in the portal:  <ol> <li>click the portal menu on the top left, and select \"resource groups\"</li> </ol> </li> <li>From the list, select your CF21 group. </li> <li>When the deployment is finished, you should see several new resources <ul> <li>They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip </li> <li>The second column is the \"type\" which helps identify what they are</li> </ul> </li> </ol> <p> click for a large view in a new tab/window</p> <ol> <li>Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)</li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#5-the-vm-resource-page","title":"5. The VM Resource Page","text":"<p>To see the details for your virtual machine, click the VM in your resource group if you haven't already. </p> <p> click for larger view</p> <p>There are many details here but some immediate things to notice: </p> <ul> <li>in the top row are buttons to connect, start, restart and stop the vvm.   </li> <li>in the top, \"essentials\" section the  \"status\" should be \"running.\"</li> <li>on the right side is the assigned IP address which you need to connect.   Highlight and copy and paste this address.   If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)</li> </ul>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#6-connecting","title":"6. Connecting","text":"<p>You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both.  </p> <p>The following Azure documentation describes how to connect to a Windows VM:  https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon</p> <p>Here are more detailed instructions: </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with RDP  (remote desktop protocol)  is a Microsoft method for connecting to the graphical desktop.  For Mac/Linux requires additional software (mentioned at the beginning of this page).  </p> <ul> <li>Click \"connect\" and select \"rdp\" if it isn't already.  </li> <li>click \"download RDP file\" button and save the <code>.rdp</code> file anywhere on your computer that you find it again</li> <li> <p>after it's download, and if you Mac users have installed the RDP client, then double click the <code>.rdp</code> file to open your remote desktop software. </p> </li> <li> <p>On windows, any security or error messages, click \"connect\"</p> </li> <li> <p>Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM</p> </li> </ul> <p></p> <ul> <li>When you connect, if the VM is not running, you will get an error message.  Here is what the Windows screen looks like: </li> </ul> <p></p> <p>This is because we are using a temporary certificate but it is secure.  Click \"Yes\" </p> <ul> <li>Enter the Username and password you used when  configuring the VM in the \"Basics\" section above.  <ul> <li>you may be able to simply enter the user name and password directly</li> <li>If not, in the  Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK.  If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. </li> </ul> </li> </ul> <p>Once you connect, you may see Windows starting up and installing things.  Feel free to close any windows.  Once the installations are finished, you may use the machine as you would any other windows computer.  If you type Rstudio in the search box, you may launch an  Rstudio session on this remote computer.    It also has Python, many python libs and Jupyter notebook.  </p> <p>We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p> <p>Optional: Connect to the Windows DSVM with ssh </p> <p>This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH.   If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter <code>ssh &lt;username&gt;@&lt;ipaddress&gt;</code></p> <p>Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page.   </p> <p>This is similar to how you connect to the MSU HPC, if you are HPC user. </p> <p>You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. </p> <p>When you log-in you will be connected to the Windows command prompt (e.g. <code>C:\\Users\\username&gt;</code> </p> <p>To Exit, type <code>exit</code> at the command prompt. </p>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#7-starting-and-stopping-the-vm","title":"7. Starting and Stopping the VM","text":"<p>There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use  Windows to turn it off.  The VM is then \"stopped.\"  The VM is not running, but it is still \"allocated.\"  When you turn it back on, it will come on immediately.  1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM.  Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up.  This is cheaper then the first method in the long run 1. Delete it.   </p> <p>Stopping (deallocating) the VM with the Portal: </p> <ol> <li>Go to the resource page for the VM, if you are not already. </li> <li>If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. </li> <li>The Status field near the top of this screen will indicate running or stopped.  </li> <li>Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. </li> <li>There is a warning about losing your IP address, with a check box to reserve it.<ul> <li>If you plan on deleting the VM now, click \"ok\"</li> <li>If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK</li> <li>The default is to use a \"dynamic\" address which is assigned every time you turn on the VM</li> <li>When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine</li> <li>the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. </li> <li>you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal</li> <li>Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off.  That is approx $2.70/month</li> </ul> </li> <li>It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep.   The main reason for this is for security.  </li> </ol>"},{"location":"index2021/session_how_to_cloud/azure_windows_vm_walkthrough/#8-deleting-the-resources","title":"8. Deleting the Resources","text":"<ol> <li>Open the Resource group as above</li> <li>When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify.   Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button)</li> <li>If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\"   For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views .  IF you add filter on tag, then you may select all the items that are shown, and delete those. </li> <li>after selecting confirm the deletion by typing \"yes\"</li> </ol>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/","title":"Interfacing with Cloud Services","text":"<p>Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources.  This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC).  Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it.  </p> <p>All of the cloud companies as their base use a web interface, so-called REST API.   Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces.  </p> <p>Here is an example web api URL for weather forecast, with parameters for coordinates, units and format of output</p> <p><code>https://www.7timer.info/bin/astro.php?lon=113.2&amp;lat=23.1&amp;ac=0&amp;unit=metric&amp;output=json&amp;tzshift=0</code> </p> <p>Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work.  </p> <p>In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address.   The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api.    You may see references to resources in documentation and that means any web doo-dad. </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#summary-of-cloud-interfaces","title":"Summary of Cloud Interfaces","text":"<p>This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts.   In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS.  See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html</p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#graphical-web-interface","title":"Graphical Web Interface","text":"<p>Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com.  For Google cloud it's the \"console\" and for AWS it's also called the console.  See below for an introduction to using the portal.   Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface.    </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#desktop-applications","title":"Desktop Applications","text":"<p>Azure provides some desktop applications for working with a few of the widely used cloud services : </p> <ul> <li>Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/     Can create cloud storage and upload/download data.  We will use that for our session on Storage</li> <li>Azure Data Studio:  https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15      Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure</li> </ul>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#command-line","title":"Command Line","text":"<p>For those not familar wiht the command line, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell</p> <p>The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command.   With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line </p> <p>Azure has two command line interfaces:  The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users.   Since Powershell has been ported to Linux and Mac and the Linux Shell  and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI.   Your choice depends on the kinds of other systems you'll be working with.  For example, the MSU HPC uses Linux command shell  but Windows servers and other Windows services like SQLServer work well with Powershell. </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#sdk-software-developer-kit","title":"SDK : Software Developer Kit","text":"<p>A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service.  All the cloud vendors have SDKs, and they all have SDKs for Python.    SDK simply means you can create, delete, interact with cloud services from your program.</p> <p>Why leave python or R if don't have to?</p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#python-sdk","title":"Python SDK","text":"<p>All cloud vendors have SDKs to work with Python.   After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others).   Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python</p> <p>Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd</p> <p>Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK.  These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. </p> <p>Both AWS and Google Cloud have Python SDKs, and probably other vendors.  </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#r","title":"R","text":"<p>Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio.  See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages.  </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#cloud-company-frameworks","title":"Cloud company frameworks","text":"<p>In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure.  For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation. </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#azure-arm-templates","title":"Azure: ARM templates","text":"<p>Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created.   For Azure these are JSON-formatted files  that are \"declaritive\" (rather than procedural or imperative like Python).   The best way to understand these is to explore the many that Microsoft posts on github, and to try them.   If you do, be mindful to delete any resources you create so as not to be charged for them. </p> <pre><code>- Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview\n- Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates\n</code></pre>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#third-party-programming-with-terraform","title":"Third-party programming with Terraform","text":"<p>There are other ways to 'program the cloud' from companies outside of the big three.  One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company.   The ad</p> <pre><code>- Terraform: https://www.terraform.io\n- Can work with any vendor including Azure\n- Often more readable than ARM templates, Syntax remarkably simple \n- Focus on maintaining consistent systems ( declarative) \n- Does not cover all services, but can fall back to ARM templates when necessary\n</code></pre>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#building-cloud-from-cloud","title":"Building Cloud from Cloud","text":"<p>This may not be an 'interface' but is operationally similar.  It's possible to use some of the above interfaces on existing cloud services, e.g.   creating new cloud resources automaticaly from existing cloud resources.   Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand).    </p> <p>For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters).   This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language. </p>"},{"location":"index2021/session_how_to_cloud/intro_to_cloud_interfaces/#references","title":"References","text":"<p>See our references page for curated Azure links.   For AWS, see </p> <ul> <li>https://aws.amazon.com/tools/ </li> <li>about the AWS CLI: https://aws.amazon.com/cli/</li> <li>Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html</li> </ul>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/","title":"Workshop : Creating your own cloud computer","text":""},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#introduction","title":"Introduction","text":"<p>This workshop walks you though , using Microsoft Azure, the creation of a cloud virtual machine and opens access to it.  We will use command line access to use the remote machine to download data and run a calculation.   this is a similar experience to using any remote Linux system, such as the MSU HPCC.   </p>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#pre-requistites","title":"Pre-requistites","text":"<ul> <li>Microsoft Azure account (provisioned for participants)</li> </ul> <ul> <li>No previous experience with cloud virtual machines necessary</li> </ul>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#using-the-azure-portal-to-create-a-resource-group","title":"Using the Azure portal to create a resource group","text":"<p>(should this be creatd ahead of time?)</p>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#create-a-virtual-machine-using-a-template","title":"Create a virtual machine using a template","text":"<p>Create a data science virtual machine using a template.  </p> <ol> <li>portal create...</li> <li>in search bar type \"data science virtual machine</li> <li>select \"d s v m Ubuntu\"</li> <li>select \"pre-configured\"</li> <li>click \"dev test\" and then below click \"general purpose\", and then 'next'</li> <li>\"Basics\" Section: in next screen select or entered the following options. <ul> <li>Resource Group: select your resource group</li> <li>VM Name: please enter a name with the following pattern cf-dvsm-netid using your own netid</li> <li>Region : select the default</li> <li>Image : should say \"Data Science Virtual machine - Unbuntu 18.0.4 - Gen 1\"</li> <li>Azure Spot Instance : leave unchecked</li> <li>Size :  Standard_D2s_v3 ($80/month) note: it will only cost pennies per hour</li> <li>Administrator account : select \"password\"  note: ssh key is more secure but requires time consuming setup</li> <li>Username : enter your netid this is easy to remember</li> <li>Password : please enter a complex password don't use your actual netid password, also write it down as we will only use it once and it can't be recovered</li> <li>click \"next (disks)\"</li> </ul> </li> </ol> <ol> <li>Note in this \"Create a Virtual Machine page, there are several sections across the top     <code>Basics  Disks  Networking  Management  Advanced  Tags  Review + create</code>     We can skip all sections now and go to \"Review + create\"</li> <li> <p>Product details: </p> <ul> <li>note the costs (mine is 0.1100 USD/hr)</li> <li>click the \"Create\" button at the bottom of this screen</li> </ul> </li> <li> <p>wait. </p> <ul> <li>the screen should say \"Deployment in Progress\" report any errors or problems </li> <li>click \"Go to Resource\" when it's complete</li> </ul> </li> </ol>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#exploring-the-azure-portal","title":"Exploring the Azure portal","text":"<p>this portal page lists details about this virtual machine.   </p>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#connect","title":"Connect","text":"<p>options to connect to remote linux computer: </p> <ul> <li>ssh , alwayws works, requires Mac terminal or windows or mobaxterm</li> <li>Rstudio Server (must be started)</li> <li>Jupyter Notebooks (must be started)</li> <li>Remote desktop (must be installed on VM, and a client must be installed on laptop)</li> </ul> <p>test connection: </p> <ul> <li>in the left hand menu of the VM resource, find the \"connect\" section</li> <li>click the \"ssh\" section if not already selected</li> <li>near the bottom click \"test your connection\"</li> <li></li> </ul> <p>connect with ssh:</p> <ol> <li>open your terminal program</li> <li>in the portal, find the machine ip address</li> <li>issue command <code>ssh azureuser@&lt;ip&gt;</code></li> </ol>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#download-data","title":"Download Data","text":"<p>Using standard Linux tools we will download data onto this remote computer</p> <ol> <li>Log-in via ssh if you haven't already</li> <li>use the following command to download data set         <code>git clone https://github.com/fivethirtyeight/data/tree/master/college-majors</code></li> <li>review the files using linux commands<ol> <li><code>cd college-majors; ls</code></li> <li><code>head grad-students.csv</code></li> </ol> </li> </ol>"},{"location":"index2021/session_how_to_cloud/workshop-creatingvm-saved/#start-r-studio-server","title":"Start R studio Server","text":""},{"location":"index2021/session_how_to_cloud/workshop-creatingvm/","title":"Workshop : Creating your own cloud computer","text":"<p>For Session 2 of the MSU Cloud Computing Fellowship</p> <p>Details of the workshop and recording will be posted after our remote session on Sept 10</p>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/","title":"Intro to Cloud Costs on Azure","text":"<p>You've heard us say that nearly everything Azure has a cost, but how can you tell how much?</p> <p> </p> <p>Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required)</p> <p>The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background. </p>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#1-pricing-pages","title":"1. Pricing Pages.","text":"<p>All cloud vendors have pricing pages that describe how they meter and charge for services.  For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing</p> <p>However I usually find the page I need quickly by simply googling <code>azure &lt;service name&gt; pricing</code> for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/</p> <p>Some of these pages are  straightforward, but like the one above has addition knowledge.  What does this mean in practice?  For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand.  I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices.</p> <p>This kind of background info is very common for services.  </p>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#2-build-something-and-check-the-cost","title":"2. Build something and check the cost","text":"<p>The other option is the empircal method: build something, use it, review the costs, and estimate.  </p> <p>At the resource group in the protal ( see  Azure Organization), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\"   - click that</p> <p>This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things.   </p> <p>Near the middle are rouded buttons controlling the view you see.   At the right side of this is a button \"Add Filter\"  which you can click to show costs only for some resources.  For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. </p> <p>A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources.   See the Cloud Glossary </p> <p>In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering.    </p> <p>Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate.  Use a custom date range for the time period that makes sense for the costs you want to observe. </p> <p></p> <p>Example Azure Cost Analysis Screen, filtered by Tag.  Click for larger view</p>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#3-pricing-calculators","title":"3. Pricing Calculators","text":"<p>All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money.  </p> <p>For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/</p>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#summary-and-other-notes","title":"Summary and other notes","text":"<p>Combining these three methods is how we can estimate costs. </p> <p>Notes: </p> <ul> <li> <p>Pricing often depends on the location or region you select.  Most regions in the US are the same price.   </p> </li> <li> <p>Data transfer costs are really hard to estimate.   Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge.  This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers =&gt; more costs =&gt;but more revenue).  However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free.   One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries).  </p> </li> </ul>"},{"location":"index2021/session_how_to_cloud/costs/azure_cloud_cost_basics/#azure-pricing-resources","title":"Azure Pricing Resources","text":"<p>Quickstart: Explore and analyze costs with cost analysis</p> <p>Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021</p>"},{"location":"index2021/session_introduction/","title":"Session 1: Introduction to the 2021-22 MSU Cloud Computing Fellowship","text":"You don't have to face the clouds alone"},{"location":"index2021/session_introduction/#welcome","title":"Welcome!","text":"<p>The goals of this session are to orient you to this program, set up our technology, introduce ourselves, provide some background on cloud computing, and discuss what all of our expectations are.    For this session, like the others, we have some pre-session activities for the week, followed by a meeting Friday, September 3, from 2:00-3:30pm.  </p>"},{"location":"index2021/session_introduction/#activities","title":"Activities:","text":"<p>Please complete the following activities prior to our first synchronous meeting September 3. </p> <p>Complete a Brief Survey</p> <p>All 2021-22 participants were sent an introductory email that included a link to a brief survey.  preferences and techmology exposure.   Please complete this survey prior to our first meeting. </p> <p>Introduce yourself on Microsoft Teams</p> <p>You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID.  </p> <ul> <li>Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client)</li> <li>Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed.   </li> <li>If necessary MSU IT has documentation about MS Teams here:  https://tech.msu.edu/technology/collaborative-tools/spartan365/  ( the link on that page requires yet another MSU log-in)</li> </ul> <p>Confirm Access to Azure Portal</p> <ul> <li>Go to https://portal.azure.com.</li> <li>Log in with your MSU netid and password.</li> <li>Ensure you can access the Azure main web \"portal.\"  </li> <li>You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access.   You may see a list of \"resources\" and will introduce Azure during our first meeting. </li> </ul> <p>If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us.  Note there will be time for questions and dicussion during our first meeting. </p>"},{"location":"index2021/session_introduction/#readings","title":"Readings","text":"<ul> <li>Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon      ( Alternative link to publisher preview chapter  )</li> <li>Using Cloud Computing for Academic Research, Mahmoud Parvizi (draft version)</li> <li>Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review</li> </ul>"},{"location":"index2021/session_introduction/#meeting-introductions-and-program-overview","title":"Meeting: Introductions and program overview.","text":"<p>September 3rd, 2021:   Zoom meeting included in introductory email to participants </p>"},{"location":"index2021/session_introduction/#introductions","title":"Introductions","text":"<ul> <li>Brian O'shea, ICER</li> <li>Danielle Barnes, MSU Analytics and Data Solutions</li> <li>Mahmoud Parvizi, Instructor<ul> <li>Past experience &amp; current role</li> <li>Cloud facilitator</li> <li>Participant in first Fellowship cohort</li> </ul> </li> <li>Pat Bills, Main Instructor</li> </ul> <p>A video of our introductions  is avaialble on the MSU MediaSpace (requires MSU log-in)</p>"},{"location":"index2021/session_introduction/#participant-introductions-discussion","title":"Participant Introductions &amp; Discussion","text":"<ul> <li>Introductions</li> <li>Research synopsis, Research Methods skills (non-IT)</li> <li>Current research computing hurdles, roadblocks, challenges &amp; triumphs</li> <li>How will (or has) cloud computing affected your research?</li> <li>Your goals for this fellowship<ul> <li>What do you think the cloud is or is good for?</li> </ul> </li> <li>Discussion on availability to complete class and projects</li> </ul>"},{"location":"index2021/session_introduction/#fellowship-program-overview","title":"Fellowship Program Overview","text":"<ul> <li>Why and What: 15 minute lecture on broad topics and goals of the course </li> <li>Review our \"syllabus\"<ul> <li>Pre-session materials and activities, \"textbook\"</li> <li>Session activity</li> <li>Expectations</li> </ul> </li> <li>Projects: Mahmoud Parvizi</li> </ul>"},{"location":"index2021/session_introduction/#lecture-about-cloud-computing","title":"Lecture: About Cloud Computing","text":"<ul> <li>Introducing computing vs. research computing vs. HPC vs. cloud computing<ul> <li>Learning how to learn about cloud</li> <li>Cloud perceptions vantage points</li> <li>Using workflow computational and computational thinking </li> </ul> </li> <li>The interfaces to cloud computing </li> <li>About cloud security</li> <li>Costs and budget overview</li> <li>Acknowledging bias in access to cloud computing across research cultures</li> <li>References: <ul> <li>The NIST definition of cloud computing </li> </ul> </li> </ul>"},{"location":"index2021/session_introduction/#additional-comments-from-program-organizers","title":"Additional comments from program organizers","text":""},{"location":"index2021/session_introduction/#demonstration-using-the-azure-portal","title":"Demonstration: Using the Azure Portal","text":"<p>A quick, live demonstration orienting you to the Azure portal.  Our next session activities will include a more thorough workshop on creating cloud computing resources</p> <p>A more complete tutorial and video of this walk-through is available in Session 2 activities. </p>"},{"location":"index2021/session_introduction/#questions-and-discussion","title":"Questions and Discussion","text":"<ul> <li>What things are at the top of your mind as you begin this program?  </li> <li>Which of these topics resonates with your previous experience using computing or cloud computing (if any)?</li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/","title":"Practical Introduction for Researchers on Azure","text":""},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#introducing-cloud-computing-vs-research-computing","title":"Introducing cloud computing vs. research computing","text":""},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","title":"Learning how to learn about cloud","text":"<p>You may have looked at the various websites and poked around the web, and found it's just not clear at all how cloud computing may be helpful to you, even though it all sounds great.  The challenge for researchers learning about cloud is that most cloud documentation for isn't written for you.  </p> <p>Cloud training and documentation are mostly written for IT professionals like system admins and architects, software developers, business people, and agency managers.  Researchers tend to be a little of all of those things.   </p> <p>Training materials ofen have an embedded  conceptual models of computing, and this model depend on your approach.  Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes.   That can make it difficult to decipher which kind of cloud service will work best for your use case.   As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC.   There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need.   Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. </p> <p>The target audience for most cloud companies are IT professional building IT systems for public or institutational use.  Let's call this the \"Systems\" perspective:</p> <ul> <li>built for someone else to use, e.g. a service</li> <li>must be available at scale and ultimately reliable</li> <li>documentation is in terms of historic IT systems house in on-premise corporate data centers </li> <li>\"production\" systems</li> <li>often very concerned with authentication and security</li> </ul> <p>The second audience are corporate software engineers, or dot-com or app software companies. We'll call this the \"developer  perspective</p> <ul> <li>need to easily create systems to run their software for demonstration and testing </li> <li>complete interelate</li> <li>goal is a robust sytem that can handle many users, e.g. the performance of a \"production\" systems are often top of mind</li> </ul> <p>And finally most closely related to your work are data science, \"machine learning\" or an \"analytical\" perspective</p> <ul> <li>systems to achieve computation.  </li> <li>May work like our local HPC</li> <li>systems built only for small work groups, not for public </li> <li>can still scale </li> <li>but must be reproducible to document methods</li> <li>even this documentation can quickly veer off in to building production systems for companies to re-run inference say many times a data or with a constant stream of corporate data</li> </ul> <p>What is are the goals from research perspective for cloud computing?</p> <ul> <li>Custom: can create customized resources only when you need it</li> <li>On-demand: can run ad-hoc computations on those on-demand resources</li> <li>Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. </li> <li>Cost effective: unlike commerical applications, more users does not mean more revenue.   Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend.   </li> <li>Others? </li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","title":"What documentation is available for researchers?","text":"<p>There are general, conceptual introductions and dicussions for academics.   </p> <ul> <li>https://cloud4scieng.org/  Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. </li> <li>https://cloudmaven.github.io/documentation/  from the eScience institute of the University of Washington.   It doesn't appear to be maintained but may have some good resources.  Original github repositories are https://github.com/cloudmaven</li> <li>https://cloudbank-project.github.io/cb-resources/  Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. <ul> <li>Cloudbank training videos</li> </ul> </li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#nist-defintions-of-cloud-service-levels-and-you","title":"NIST defintions of cloud: Service Levels and You","text":"<p>The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn?   Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum</p> <ul> <li>Infrastructure (aaS):  Nuts and bolts, DIY, Lego.  You need understanding of computing architecture as these services </li> <li>Everything in between:  Platforms or pre-configured and managed infrastructure</li> <li>Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services.  E.g. Office 365, Google Drive</li> </ul> <p>The sweet-spot for researhces who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms.  These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. </p>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>Case Study on Open Source system as Cloud service: **MySQL **</p> <p>Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data.   Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app) and millions of websites. </p> <ul> <li>project: https://www.mysql.com/products/community/ and  https://mariadb.org/</li> <li>DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved</li> <li>Azure MySQL Service (e.g PaaS): Azure Database for MySQL <ul> <li>AWS MySQL Service: Amazon RDS for MySQL</li> <li>Google MySQL Service Cloud SQL </li> </ul> </li> <li> <p>other companies, such as Aiven for MySQL</p> </li> <li> <p>Spin-offs: Amazon also offers AWS Aurora  which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper </p> </li> </ul> <p>What would a \"SaaS\" offering for tabular data look like?  A \"Google Docs\" for Databases?  Perhaps https://www.airtable.com/ ?</p>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#caveats-and-help","title":"Caveats and help","text":"<p>As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective.  </p> <ul> <li>The cloud services themselves are always changing, even slightly, making technology-specific tutorials obsolete in months.  For example last year Azure had a \"Notebook Service\" for running Python notebooks, and now there is this  in place of the regular documentation: What happened to Azure Notebooks?</li> <li>There are new services and bundles created all the time that may be competing or superior choices for doing research</li> <li>If you are unsure, ask us.  See the contact page or use our Teams channel.   During the Cloud Computing Fellowship we are here to provide some answers, context for what you are seeing, or possible directions to explore.  </li> <li>Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. </li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#the-interfaces-to-cloud","title":"The Interfaces to Cloud","text":"<p>A defining aspect of cloud computing is that it's \"on-demand\" hence creation of resources must be automated or \"scriptable.\"  All Cloud providers have various 'interfaces' to their services that include both programmatic and web-based.   We will talk about about how these in detail next sesion, but at the end of this session we will do a walk through of using the Azure portal, which is also an exercise for next session.  </p>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#using-workflow-and-computational-thinking","title":"Using workflow and computational thinking","text":"<p>Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66.) and this is a significant issue for research computing and one of much academic work. </p> <p>To enhance reproducibility in your own work, consider documenting all the steps needed for create the environment to run your computation.   For many on-premise academic systems (e.g. the MSU HPCC), we depend upon the system administrators to create that environment, but we may install and configure all the software we need to run our code.   Workflow thinking can apply to the scienfic domain itself (e.g. \"Principles for data analysis workflows\" https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008770 )  and to the provisioning of the cloud computing environment.   That is, we may use a workflow system for creating all the cloud stuff we need, and then a different workflow system that runs on that cloud stuff.   One example is we may create an HPC system on Azure using templates and then launch the Slurm scheduler on that HPC to run our jobs.  (note the complexity of running our own HPC is beyond the scope of this fellowship and used as an example only)</p> <p>A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed.   This can dramatically save on costs  .   This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need.  </p>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#about-cloud-security","title":"About Cloud Security","text":"<p>Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source.   Attackers  may use the services you create to launch attacks on other services, leaving you liable.  </p> <p>Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above.  Our textbook has a nice chaper outlining cloud security</p> <p>The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security:</p> <p> Microsoft Model of Shared Responsibility for Cloud Computing</p> <p>We will come back to this model as we gain deeper understanding of research computing on the cloud.  </p>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#costs-and-budget-overview","title":"Costs and Budget overview","text":"<p>We will cover the details of pricing, examine costs, and controlling costs in future sessions.   Each participant has a budget for their Azure resources that they should stay under.   If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). </p> <p>Briefly: </p> <ul> <li>Costs are more than just dollars for services.  Consider <code>[Total Cost] = ( $ + Time + Risk )</code></li> <li><code>[Total Time] = ( development time + wait time + compute time )</code></li> <li>Risk is rarely non-significant.  Never say \"I won't get hacked...\"</li> <li>In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk</li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#hpcc-vs-cloud","title":"HPCC vs Cloud","text":"<p>Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing.  </p> <p>The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers.  Many systems not designed for HPC can be adjusted to run in that environment.  However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never):</p> <ul> <li>Big Data systems (see magpie project)</li> <li>Long-running Data Systems like database servers</li> <li>Web-based applications (see on-demand project)</li> <li>Containers (see singularity project)</li> </ul>"},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","title":"Acknowledging bias in access to cloud computing across research cultures","text":""},{"location":"index2021/session_introduction/lecture_introduction_to_cloud_computing_research/#additional-comments-from-instructors-and-organizers","title":"Additional comments from instructors and organizers","text":"<p>Summary and additional comments</p>"},{"location":"index2021/session_moving_data/","title":"Session 4: Moving Data in The Cloud","text":"<p>There are many ways to move data around in the cloud.  They are based on the limitations of data movement across complex and distant networks and the scale of cloud networks and storage, and the needs of companies to move and process huge amounts of data on a schedule.   </p>"},{"location":"index2021/session_moving_data/#reading","title":"Reading","text":"<ul> <li>Session Slides: Azure Techniques for Moving Data</li> </ul>"},{"location":"index2021/session_moving_data/#optional-reading","title":"Optional Reading","text":"<ul> <li> <p>Adding a data disk to virtual machine:    A second disk may be faster to access than </p> <ul> <li>Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal</li> <li>Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal</li> </ul> </li> <li> <p>Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering </p> <ul> <li> <p>Focus on the Introduction and Section 3.3 (Azure)</p> </li> <li> <p>This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS.   If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these.   </p> </li> </ul> </li> </ul> <p>Overview of Azure Data Factory (ADF): </p> <ul> <li>See a description and more links in the session slides above</li> <li>If ADS seems interesting to you, read the following introductory material</li> <li>https://docs.microsoft.com/en-us/azure/data-factory/introduction</li> <li>Visual authoring in Azure Data Factory this is interesting as a case study for gui-based 'plaform as a service' cloud computing</li> </ul>"},{"location":"index2021/session_moving_data/#activities","title":"Activities","text":"<p>For those who completed the storage pricing activity from session #3, post your estimated stoarge costs to teams.  If they are very different, from others, or different than you expect, please explain or ask how folks got their numbers</p> <p>Select any one or more of these activities that seems relevant to you for your project, or minimally the first exercise</p> <ul> <li>Exercise: moving data using storage URL</li> <li>Attaching Azure Files to a Virtual machine for reading and writing data</li> <li>Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal</li> <li>Linux VMs: command line option using 'scp' command  Use SCP to move files to and from a Linux VM</li> <li> <p>How to move data between the MSU HPC and Azure for an example using the <code>azcopy</code> utility, and other techniques   Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to.  </p> </li> <li> <p>We want your feedback!     We have some topics we plan to cover, but at this stage you've looked at cloud documentation and thought about your projects, via teams or email, contact us to let us know if there are topics you would like to hear about.  These could be upcoming     topics that you are particularly interested in.  For example, we offered a specially session on \"command line techniques\" and we are prepping materials for that.  </p> </li> </ul>"},{"location":"index2021/session_moving_data/#meeting-october-8-200-330pm","title":"Meeting October 8 2:00-3:30pm","text":"<ul> <li>Questions from previous session on storage</li> <li>Presentation: Azure Techniques for Moving Data (slides linked in Reading section above)</li> <li>Note about future material and projects</li> <li>Discussion or questions about this or previous topic or projects</li> </ul>"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/","title":"Creating a Storage Account SAS token","text":""},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#for-allowing-access-to-storage-from-another-service-or-person","title":"for allowing access to storage from another service or person","text":"<p>How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account.   Granting access to each different service one by one may not be feasible,  Instead you can provide the service (or user) a special code that allows access.  One such code in Azure is a \"shared access signature\" (SAS).  You to the end of a storage URL To grant access to the storage acccount without having to log-in.  This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the <code>azcopy</code> command.   </p> <p>You need to  create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from.  There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS)</p> <p>To generate a SAS token using the Azure portal (service SAS): </p> <ul> <li> <p>in the Portal, navigate to your storage account \u2192 containers \u2192 your container</p> </li> <li> <p>On the left side, click \"Shared access Tokens\"</p> </li> <li> <p>on the form for SAS token enter values as follows: </p> </li> <li> <p>Signing method : \"Account Key\" (this is the default and should be selected)</p> </li> <li> <p>Signing key : could be either Key 1 or Key 2</p> </li> <li> <p>Permissions : </p> </li> <li>click in the box that says \"read\" to see the list of permissions</li> <li>if you are copying from HPC to Azure, check all the boxes</li> <li> <p>if you are copying from Azure to HPC, check Read and perhaps List</p> </li> <li> <p>Specify the signed key Start and Expiry times.  </p> </li> <li>The key is temporary, and defaults to 24hrs.  </li> <li>You may want to change the \"expiry\" date to one a few days in the future, or </li> <li> <p>for a month or so if you'll be using azcopy to transfer files for the semester.   If you specify a long time, you should restrict the IP address access (see below)</p> </li> <li> <p>The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct.   </p> </li> <li>If you want to be extra secure and restrict to systems you are copying your data from.  For example your own computer</li> <li>If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255</li> <li>You could also use the MSU VPN address range and restrict to systems logged in via VPN.  Find that from IT Services</li> <li>For your or a colleague computer, google \"what's my IP\" to get your IP address</li> <li> <p>If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it</p> </li> <li> <p>Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure)</p> </li> <li> <p>Click Generate SAS token and URL.</p> </li> </ul> <p>The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window.</p> <p>Copy the Blob SAS URL (or token or both), and save in a secure location.  They'll only be displayed once and cannot be retrieved once the window is closed.  Treat the SAS token like a temporary password</p> <p>You can use the \"Blob SAS URL\" for most copy operations.  It includes the container but not the file name.  If you want to use a different file name from the original, you'll have to construct your own URL. </p> <p>To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows</p> <pre><code>`https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend`\n</code></pre> <p>If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however)</p> <p>See How to move data between the MSU HPC and Azure for an example using the <code>azcopy</code> utility</p>"},{"location":"index2021/session_moving_data/creating_a_container_sas_token_from_the_azure_portal/#references","title":"References","text":"<ul> <li>Best practices when using SAS token</li> <li>Instructions these are based on (from Azure Cognitive Services)</li> <li>CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas</li> </ul>"},{"location":"index2021/session_moving_data/how_to_azure_files/","title":"How to Use Azure Files with Windows and Linux VMs","text":"<p>The Azure cloud storage session materials describes \"Azure Files\" as one of several types of storage available.   Here are some details about using Azure Files in practice to read and write data from a virtual machine </p> <p>Please review the Azure Documentation describing the \"Azure Files\" service </p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#summary","title":"Summary","text":"<p>The \"Azure Files\" (or File Shares) service is Microsoft's attempt to provide storage with an interface that many IT people are familiar with, but at Cloud scale.  They market it heavily as a replacement for File servers that an institution or company have to maintain.   The alternative is blog storage, which works well when you alter your program code to read and write to blob storage, and for users of existing software (e.g. GUI software for your scientific application) you can't change the code. </p> <p>In practice, Azure File storage does work like cloud in that there are few limits on storage but you can also attach it as if it were network storage (\"network attach\") so you don't have to change your software.    However it is more expensive than Blob storage and it is slower than network storage, especially much slower than storage in an HPC environment. </p> <p>So what to do?  One method I've used to take advantage of the convenience of Azure Files storage but I need speed, I'll copy those files that need to have fast access onto the local disk of the VM (or service), but still use Azure files to save files (write output).  </p> <p>There are several ways to use Network Attach Storage, and they are named for the file sharing protocol.  A very common protocol invented by Microsoft in the 90s is Server Message Block or SMB.  You don't have to know how it works, just that Windows, Mac and Linux have SMB file connection software built-in.   Most on-premise network disk systems use SMB.  </p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#details","title":"Details","text":""},{"location":"index2021/session_moving_data/how_to_azure_files/#using-file-shares-in-a-storage-account","title":"using  \"File Shares\" in a storage account","text":"<p>A storage account is the entry point in Azure to any kind of storage service ( see materials in the Cloud Storage session ), so you need to first create a storage account.  You can use an existing storage account for any tutorials or quickstarts linked below (though many of them have you create a resource group and storage account in the tutorial, can skip that although you'll have to adjust the names used). </p> <p>Note that storage account can have both blog storage containers and file shares in the same account.  </p> <p>When you open a storage account resource in the portal, there is a \"File Shares\" option on the left-side menu which opens the form to add file shares to your storage account. </p> <p>Follow this quick start to create a file share, which also walks through creating a storage account if you need one : </p> <p>https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-portal?tabs=azure-portal</p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#overview-of-process-to-use-with-a-vm","title":"Overview of process to use with a VM","text":"<ol> <li>create a file share and upload your data using the Storage Explorer or other data movement method (e.g. Azure Data Factory, <code>azcopy</code> from your on-premise computer such as the HPC)</li> <li>create a Virtual Machine.  since the data will stay on the File Share (but see below for performance) you may not need to provisions a VM disk much larger than 30gb</li> <li>after the VM is started and you are logged in, see methods below for attaching File share</li> <li>run your software but adjust the code or select folders on the connected file share (e.g. <code>D:\\\\</code> on windows or the mount path in linux)</li> <li>save output the the cloud Storage File Share</li> <li>when finished, close and delete the VM and associated resources</li> <li>access output files using Storage Explorer, or another method</li> </ol> <p>See below for Azure instructions for each type of machine (Windows, Linux)</p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#connecting-file-share-to-windows-to-read-or-save-data","title":"Connecting File Share to Windows to read or save data","text":"<p>If you are using Windows to run your software, you may want to read/write data to a file share, so you can delete the Windows VM when you are finished with a session, but keep your results.    If you attach a file share to the windows VM, use that. </p> <p>After creating a file share, you can connect that to a windows VM.  In session #2 we created a Windows VM based on the Data Science Virtual Machine image.  The following uses a different image (Windows Server) but the process is the same: </p> <p>Mount SMB Azure file share on Windows</p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#connecting-file-share-to-linux-to-read-andor-save-data","title":"Connecting File Share to Linux to read and/or save data","text":"<p>These command-line based intructions show how to install the necesssary software and create a connection to a file share using SMB.    Like the windows example, this would be a method for accessing data on in cloud storage so that you can remove </p> <p>[Mount SMB Azure file share on Linux]https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux?tabs=smb311</p>"},{"location":"index2021/session_moving_data/how_to_azure_files/#performance-issues-with-using-file-shares-and-a-work-around","title":"Performance issues with using File Shares and a work-around","text":"<p>File shares are not as fast as a virtual machine disk, and those are not as fast as a disk on your physcial computer, or even as fast as on-premise Network Attached storage.  If your process does a lot of reading/writing and needs to be faster, one solution is to 'stage' the data to the VM disk</p> <ol> <li>assuming you have file share storage and a new VM with a large enough disk to hold data</li> <li>connect/mount the file share storage as describe above to the VM</li> <li>before running your program, copy the input data from file share storage to the VM disk, (e.g. <code>C:\\</code> for Windows or perhaps the homedir /mnt/home in linux ) Ensure you've created a large enough VM OS Disk to hold your data</li> <li>run your software, selecting this folder</li> <li>when the program/script is completed, copy the ooutput back to your file share</li> <li>shutdown and delete the VM</li> <li>access the output data from file share d</li> </ol>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/","title":"How to move data between the MSU HPC and Azure","text":""},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#introduction","title":"Introduction","text":"<p>A common research cloud computing activity is moving data between cloud and on-premise (local) systems.   Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. </p> <p>Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage.  The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work.  I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory)  </p>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-1-using-scp-with-a-virtual-machine","title":"Method 1. using scp with a virtual machine","text":"<p>Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation.  This method is useful for one-time workflow of copy, process, save results.   </p>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#requirements","title":"Requirements","text":"<ul> <li>an account on the MSU HPCC</li> <li>basic knowledge of Linux</li> <li>know how to create and use a Azure Virtual Machine</li> </ul>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#a-little-about-the-scp-utility","title":"A little about the <code>scp</code> utility","text":"<p>The HPC runs Linux, and The <code>cp</code> utility copies files from one folder to another.   The <code>scp</code> utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and <code>ssh</code> access.   There are many programs to help with network file transfers but <code>rsync</code> and <code>rclone</code> are two command (and really great) programs to checkout.  We will stick with <code>scp</code> for this example </p> <p>The basic format of the scp command is <code>scp user@remote.system.com:path/to/remote/file path/to/copy_of_file</code></p> <p>For examples see http://www.hypexr.org/linux_scp_help.php</p> <p>Method 1a. simple method for a one-time copy to an Azure VM: </p> <p>Steps:  1. find the file on the MSU HPCC that you want to copy.  Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already.      - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this:      - first, note the folder you are running this from (it defaults to the VM home directory)     - <code>scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext</code>     - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp     - enter your NetID password (it is not saved or visible on the command line)     - consider using ssh keys instead of your password (which is a whole 'nother lesson)     - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys </p> <ol> <li>Now you can access the file using the software from the I think of this as  \"pulling\" data from HPC to the VM disk. </li> </ol>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-2-azcopy","title":"Method 2. azcopy","text":""},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#requirements_1","title":"Requirements","text":"<ul> <li>A Storage account.  We created one in the first session, but create a storage account in your resource group if you don't have one yet. </li> <li>Create a container in storage account to hold files. This can be a Blob or Azure Files container</li> <li>You must be owner of the storage account, and able to assign permissions ('roles').  Azure requires special persmissions grant that are NOT granted by default to use azcopy.  Details in the instructions below</li> <li>OR you must be willing to go through the process of creating a \"SAS Token\" :  see my instructions for creating SAS token</li> </ul> <p>Assuming you have a storage account with a blob container already created.  In the portal, open the storage account container. </p> <p>Azure provides a command line tool <code>azcopy</code> which you can download for windows, mac and Linux.   see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10</p> <p>How to install the azcopy utility </p> <ol> <li>Login to MSU HPCC  <code>ssh &lt;netid&gt;@hpcc.msu.edu</code></li> <li>download a copy of azcopy.  This is the URL from Late september 2021:     <code>curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz</code></li> <li>untar and put in your home directory    <code>tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz</code></li> </ol> <p>How to use azcopy to upload to Azure using the \"AD Login\"</p> <ol> <li>Get a SAS URL from the Azure portal as described above</li> <li>Log-in to HPCC</li> <li>assuming your copy of <code>azcopy</code> is in your home directory, run a command like the following.  Note that the URL must but enclosed in single quotes (not double quotes)</li> </ol> <p>`azcopy copy myfile.csv 'https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken'</p> <p>For example, this copies a file and renames it when it's stored.  The container \"from-hpcc\" in this case must already be created.  </p> <p><code>azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&amp;st=2021-10-08T05:22:52Z&amp;se=2021-10-08T13:22:52Z&amp;sip=35.9.12.1-35.9.12.255&amp;spr=https&amp;sv=2020-08-04&amp;sr=c&amp;sig=abscus'</code></p> <p>References:  - Getting Started with azcopy  - azcopy login reference  - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD)  - Generate SAS tokens for your storage containers  *(note I found this in the \"cognitive services\" documentation)</p>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#alternative-methods","title":"Alternative Methods","text":""},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-3-azure-data-factory","title":"Method 3. Azure data factory","text":"<p>We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. </p> <p>If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility. </p>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-4-python","title":"Method 4. Python","text":"<p>We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3.  </p> <p>To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python.  See https://wiki.hpcc.msu.edu/display/ITH/Using+conda.   </p>"},{"location":"index2021/session_moving_data/how_to_hpc_and_cloudstorage/#method-5-python-with-url","title":"Method 5. Python with URL","text":"<p>Another approach that does not require the Azure SDK, is  URL access, the same as for <code>azcopy</code>  via the <code>requests</code> library.  For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code</p> <pre><code>import requests\nimport csv\nimport os\nazure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&amp;st.... etc\"\ndata = []  # see note below*\nwith requests.get(azure_url, stream=True) as r:\n  lines = (line.decode('utf-8') for line in r.iter_lines())\n  for row in csv.reader(lines):\n     data.append(row)\n\nlen(data)\n</code></pre> <ul> <li>don't put this code into github with the SAS url.  Use a technique to read from command line or environment </li> <li>This would work anywhere, not just the HPC.  </li> <li>This is the same example in the slides for this session</li> </ul>"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/","title":"Exercise: moving data using storage URL","text":"<p>The goal of the exercise is to show one of the many ways of get data out of your cloud storage account,  especially as way to share a file using a URL</p> <ol> <li>Upload a file to cloud storage. </li> </ol> <p>get a file, any file and get it into cloud storage in any way you like.  If you already have a file in  Azure Blob storage container, you can skip this step.  If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal.  (I don't recommend this for large files for for many files)</p>"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#upload-file-via-portal","title":"Upload file via portal","text":"<ol> <li>Find a data file in any format on your computer.   Let's called it <code>mydata.txt</code></li> <li>Open the Azure portal and go to your storage account in your resource group</li> <li>In your storage account create container, if you don't want to use an existing container<ol> <li>click \"containers\" on the left side menu</li> <li>above the list of containers is a \"+\" icon, click that to create a container</li> <li>For Name, call it \"democontainer\"</li> <li>For public access level, leave it as \"private\"</li> </ol> </li> <li>Open the container in the portal</li> <li>click \"the upload\" link near the top</li> <li>select a file to upload- any file will work for this excercise</li> </ol>"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#get-a-url-to-download-this-file-back-to-your-own-laptop-or-a-different-computer","title":"Get a URL to download this file back to your own laptop (or a different computer)","text":"<ol> <li>determine your laptop's IP address</li> <li>Google \"what's my IP address\"</li> <li> <p>copy it or save that IP address for later   To share with a colleague you'd use their IP address for this step</p> </li> <li> <p>click on the file you just uploaded and a new form appears on the right</p> </li> <li>on that form is a link near the top \"generate SAS\"  - click that link<ul> <li>for more details, see documentation Creating Container SAS</li> </ul> </li> <li>Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got</li> <li>Click the \"Generate SAS ...URL\" button</li> <li>Copy the Blob SAS URL to the clipboard</li> </ol> <p></p>"},{"location":"index2021/session_moving_data/moving_data_with_url_activity/#test-download","title":"Test Download","text":"<p>In a web browser, paste the URL to see if you can re-download your own file. </p> <p>To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL</p>"},{"location":"index2021/session_serverless/","title":"Session 6: Serverless Cloud Computing","text":"<p>example real-world cloud application</p> <p>Introductory Material by topic </p> <ul> <li> <p>Overview of Serverless</p> </li> <li> <p>About Linux Containers with readings and activities</p> </li> </ul>"},{"location":"index2021/session_serverless/#serverless-and-faas-readings","title":"Serverless and FaaS Readings","text":"<p>As you read these materials, do you think  \"serverless\" resources are IaaS or PaaS?   They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" </p> <p></p> <ul> <li> <p>Re-visit Chapter 4 Computing as a service </p> </li> <li> <p>An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon</p> </li> <li> <p>All About Azure Functions: https://www.serverless360.com/azure-functions</p> </li> <li> <p>Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/</p> </li> </ul> <p>Azure Functions triggers and bindings conceptstabs=csharp</p> <p>An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., &amp; Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349</p>"},{"location":"index2021/session_serverless/#activities","title":"Activities","text":"<p>https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/</p> <p>For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line</p> <p>*This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell</p>"},{"location":"index2021/session_serverless/#fellowship-meeting","title":"Fellowship Meeting","text":"<p>November 12, 2021 : Zoom</p> <ul> <li>Announcements, survey request</li> <li>Discussion of Previous Weeks</li> <li>Introduction the Session materials</li> <li>Talk and demonstration: a cloud-based web application for gene function prediction</li> </ul>"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/","title":"Linux Containers &amp; the Cloud","text":""},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#for-session-7-overview-of-serverless","title":"For Session 7: Overview of Serverless","text":"<p>The container metaphor relfects the nature of a standardized box can be carried on ships, trains, and trucks at different scales</p>"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#introduction","title":"Introduction","text":"<p>Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment.  However containers have several advantages to virtual machines which is why Google invested in their invention 15 yrs ago.   </p> <ul> <li>you can use code to define exactly what will go into a container, making it reproducible.  You can to this with VMs but it's more difficult and/or dependent on the cloud company (e.g an AWS linux VM is different from an Azure Linux VM)/   </li> <li>you can run a container on any vendor or your laptop or even the HPC</li> <li>because you define what is installed in a container, the configuration of complex software is easier and portable.   In addition you can find container solutions from others, or from the software producers themselves.  </li> </ul> <p>Notes</p> <p>Containers often are for running web applications, and great for running complex web systems, but they can be used for other types of servers, or for batch computing as well.  Most of the examples may involve running a website. </p> <p>\"Docker\" is the company that popularized container technology and made it easy to share ideas, but they are only one of several systems that work with the Linux Container specification.    Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub)  So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\").  On the HPC we use Singularity.  However to get started I suggest using Docker, installing docker desktop, and following docker tutorials.   Azure is compatible with docker (that's what we use) </p> <p>You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop.   Most likely no one else can access it, but it's great for development and testing.    Azure has many docker-like features, and you can build and use containers with Azure without installing Docker on your computer, but I recommend working from your computer first to ensure it works</p> <p>The main code file that docker looks for is named \"Dockerfile\" with no extension, and so we say we are using a 'dockerfile' to build a container however this is just the default and the file name can be anything when using the command line</p> <p>You will hear alot about a technology platform called \"Kubernetes\" which was invented (at Google) to be able to manage dozens,hundreds or thousands of containers working together to support large web applications (like Google but also Walmart.com).  This is called \"container orchestration.\"   You don't need Kubernetes to run single or even a couple of containers.   There are other solutions, or you can connect them yourself.   Using Kubernetes can be an entire career but the promise is easy building an elastic cluster for HPC-style computing.   </p> <p>The \"serverless\" infrastructure of Azure is built on containers.   Containers are the heart of how the cloud works, and provide a way for developers of complex research software to provide a mechanism for users to launch their software quickly.  Many bioinformatics or genomics packages now include</p> <p>Containers are complex and especially how they work but if you can use them in practice you don't need to know the details.  </p>"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#reading","title":"Reading","text":"<p>An Introduction to Containers from a company called \"Rancher\" which sells software manage containers</p> <p>Chapter 6: Using and Managing Containers from our textbook \"Cloud Computing for Science and Engineering\" </p> <p>Docker Overview</p> <p>Azure Container Service Overview</p>"},{"location":"index2021/session_serverless/linux_containers_and_the_cloud/#activity","title":"Activity","text":"<ul> <li> <p>Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure</p> </li> <li> <p>Docker Orientation and setup</p> </li> <li> <p>For Python Users: How to Run Jupyter Notebook on Docker</p> </li> <li> <p>optional for shell scripters and command line users: complete this shell script that launches an Rstudio session on azure container instance</p> </li> </ul>"},{"location":"index2021/session_serverless/serverless_overview/","title":"Introduction to Serverless and Azure","text":""},{"location":"index2021/session_serverless/serverless_overview/#for-session-7-overview-of-serverless","title":"For Session 7: Overview of Serverless","text":"<p>*Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * </p> <p>The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance.    Traditional IT is a collection of massive servers with many purposes and features that do it all.   Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud.  We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS)</p> <p>\"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that.  </p> <p>Many problems that \"serverless\" can be applied to</p> <ul> <li>short and 'stateless' function execution, where functions can scale at will (Python, Java, C, C# etc)</li> <li>event processing, handling huge streams of data in small chunks </li> <li>components of a cloud-based workflow</li> <li>web application engines</li> </ul> <p>Main distinction for 'serverless' is that even though in the end of course  your website or function run on a server somewhere that has an operating system installed on it, you don't have to know.   </p> <p>Server Process:       provission machine --&gt; install OS --&gt; install software --&gt; add your code, read your data and run --&gt; delete and/or keep it maintained</p> <p>Serverlesss Process:       provision resource --&gt; add code --&gt; and run</p> <p>Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues.   But what if you just wanted to have one step in your work be isolated, and also run only when needed?</p> <p>Key points about serverless</p> <ul> <li>goal is to have aa workflow of components that communicate with each other, but can be indepedently managed</li> <li>a primary communication method is using web api's, aka REST aka </li> </ul>"},{"location":"index2021/session_serverless/container_scripts/rstudio_container_script/","title":"Containers on Azure: example Script","text":"<pre><code>echo \"Starting the setup for running Rstudio Server on Azure\"\n\nAZUSER=   # add your account name here, no space between the = sign\nAZGROUP=  # enter your resource gropu here, no space between the = sign\necho \"Enter Rstudio pw (for user rstudio):\"\nread CONTAINERPW\nDOCKERIMAGE=rocker/geospatial # or rocker/tidyverse  \nAZCONTAINERNAME=cf21-demo-container-$AZUSER\n\n # you must enter the values here for your storage account by finding the key in the Azure portal\n\nAZFILESACCOUNT=y\nAZFILESSHARE=z\nAZFILESKEY=x\n# docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create\n# create the container instance, which starts if the Dockerfile has an entry point\n# by assigning a '--dns-name-label' we give it a public IP address\necho \"please wait while the container instance is created\"\naz container create -g  $AZGROUP --name  $AZCONTAINERNAME \\\n    --os-type Linux --location eastus  \\\n    --cpu 4 \\\n    --memory 16 \\\n    --image $DOCKERIMAGE --ports 8787  \\\n    --dns-name-label ${AZUSER}rstudio \\\n    --secure-environment-variables PASSWORD=$CONTAINERPW\n\n\n    # --assign-identity  x \\\n    # --azure-file-volume-account-key $AZFILESKEY \\\n    # --azure-file-volume-account-name $AZFILESACCOUNT \\\n    # --azure-file-volume-share-name $AZFILESSHARE \\\n    # --azure-file-volume-mount-path /mnt/azfiles \n\n\n# NOTE this is not an https connection and hence is insecure and not recommended\n# see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl \n# for a method for using https\n\n# show the way to log in\nFQDN=`az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv`\necho \"your RStudio is running on \"\necho \"https://${FQDN}:8787\"\n\n# how to stop and/or delete the container.  \n# stop it if you are taking a break from using it\n# az container stop --name $AZCONTAINERNAME -g $AZGROUP\n# delete if you can\n# az container delete --name $AZCONTAINERNAME -g $AZGROUP\n</code></pre>"},{"location":"references/","title":"Azure Resources","text":""},{"location":"references/#general-resources","title":"General Resources","text":"<p>Main Azue Documentation : https://docs.microsoft.com/en-us/azure/ </p> <p>List of All Azure Services : https://portal.azure.com/#allservices </p> <p>Azure Tips and Tricks : https://microsoft.github.io/AzureTipsAndTricks/</p> <p>Azure Portal \"How to\" series - focused on using the Azure portal to do several different things.  This is mostly about the services themselves, not the portal, and many topics do not apply to us (e.g. Azure Arc) but there are some very useful videos : https://youtube.com/playlist?list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR</p> <p>These look like really good intros to Azure, but requires a time investment.  The examples are not really research computing examples but may be valuable learning examples.  Most of these lessons were taken from other 'learning paths' and are still oriented towards IT professionals</p> <p>Microsoft Learn:    - Azure for Researchers part 1: Introduction to Cloud Computing   - Azure for Researchers part 2: Cloud Security and Cost Management</p>"},{"location":"references/#interface-azure-portal","title":"Interface: Azure Portal","text":"<p>Azure Portal Documentation :  https://docs.microsoft.com/en-us/azure/azure-portal/ </p> <p>Microsoft Azure Hierarchy: Organize your Azure resources effectively</p> <p>Re-organize your portal view by creating a new dashboard (optional) : https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards</p> <p>Azure portal productivity Tips : https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html#azure-portal-productivity-tips</p> <p>https://microsoft.github.io/AzureTipsAndTricks/blog/tip329.html</p>"},{"location":"references/#interface-command-line","title":"Interface: Command Line","text":"<p>Command-line progamming of Cloud Services</p> <ul> <li> <p>Azure PowerShell (Windows) https://docs.microsoft.com/en-us/powershell/azure/ </p> <ul> <li>Introduction to PowerShell : https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-3.0.0 </li> </ul> </li> <li> <p>Azure Command Line Interface (CLI) (MacOS, Linux): https://docs.microsoft.com/en-us/cli/azure </p> <ul> <li>Introduction to Azure CLI https://docs.microsoft.com/en-us/cli/azure/get-started-with-azure-cli?view=azure-cli-latest </li> </ul> </li> <li> <p>Hybrid inferface: using the CLI inside the Azure Portal    You can install and use the <code>az</code> CLI program on your own computer, but Azure also has a way you can use the CLI without installing anything, with a cloud-based terminal interface called the \"cloud shell.\"   For an overview see https://docs.microsoft.com/en-us/azure/cloud-shell/overview and for a great 'quickstart' see https://docs.microsoft.com/en-us/azure/cloud-shell/quickstart for a quick tutorial for how to use it.     In the quickstart, the first example shows you how to create a resource group using the CLI in the cloudshell.  If you don't have permissions to create a new resource group, skip to the next example (\"Create a Linux VM\") and put your own resource group in the command for the <code>-g</code> parameter and perhaps use a very unique name for the VM parameter. </p> </li> </ul>"},{"location":"references/#storage","title":"Storage","text":"<p>Create a Storage Account: </p> <p>https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account </p> <p>Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/ </p> <p>Blob Storage Documentation: https://docs.microsoft.com/en-us/azure/storage/blobs/ </p> <p>Create and Manage a Storage Account:  https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account </p> <p>Using the CLI with Storage Reference: https://docs.microsoft.com/en-us/cli/azure/storage/account </p> <p>Using PowerShell Storage Reference: https://docs.microsoft.com/en-us/powershell/module/azure.storage </p> <p>Create blob storage with CLI:</p> <p>https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli </p> <p>Create blob storage with PowerShell:</p> <p>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-powershell </p>"},{"location":"references/#compute","title":"Compute","text":"<p>Overview of Compute Options: https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-overview </p> <p>Choosing an Azure Compute Service (Decision Tree):  https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree</p>"},{"location":"references/#interface-arm-templates","title":"Interface: ARM templates","text":"<p>Azure Resource Manager Templates are JSON-formatted configuration files that dictate which resources to create.   </p> <p>Overview of ARM templates:  https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview</p> <p>explore quick start ARM templates (web): https://azure.microsoft.com/en-us/resources/templates/</p> <p>explore quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates</p> <ul> <li>many of these github repositories include a \"deploy to Azure\" button that will run the template via the portal and create resources. </li> </ul>"},{"location":"references/#programming-with-sdks","title":"Programming with SDKs","text":""},{"location":"references/#r-and-azure","title":"R and Azure","text":"<p>https://blog.revolutionanalytics.com/2018/12/azurestor.html </p> <p>https://cloudblogs.microsoft.com/opensource/2019/07/01/azurer-available-create-manage-monitor-azure-services-r/ </p> <p>https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide </p> <p>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/r-packages-supported-by-azure-machine-learning </p> <p>https://github.com/Azure/AzureContainers </p> <p>https://github.com/Azure/AzureR </p> <p>https://github.com/Azure/AzureRMR </p>"},{"location":"references/#python-and-azure","title":"Python and Azure","text":"<p>https://azure.microsoft.com/en-us/develop/python/ </p> <p>https://docs.microsoft.com/en-us/azure/python/ </p> <p>https://github.com/Azure/azure-sdk-for-python </p> <p>https://github.com/Azure/azure-storage-python </p> <p>https://azure.github.io/azure-sdk/releases/latest/all/python.html (Note that pypi.org/project/azure/  is deprecated/obsolete if you find that via google)</p>"},{"location":"references/#matlab-and-azure","title":"MATLAB and Azure","text":"<p>https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/06/29/running-matlab-on-azure-provision-a-matlab-distributed-computing-server-using-azure-vms/ </p> <p>https://github.com/mathworks-ref-arch/matlab-on-azure </p> <p>https://www.itcentralstation.com/products/comparisons/mathworks-matlab_vs_microsoft-azure-machine-learning-studio </p> <p>https://www.mathworks.com/solutions/cloud.html </p>"},{"location":"references/#microsoft-azure-cosmos-db","title":"Microsoft Azure Cosmos DB","text":"<p>CosmosDB is a very large scale data system that can act like other database systems including SQL, MongoDB (a popular no-sql database), and others. It's advantage is that it can handle extremely large data sets  (65tB) but is easy to get started.    Google and AWS have similar offereings ( \"BigQuery\" and \"Aurora\" respectively). </p> <p>If your data is not large, consider using SQL data systems which are also very widely used (and can be used on your own computer)</p> <p>Intro: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction</p> <p>It can be free to use, but you have to turn that on when creating the service for your account: https://docs.microsoft.com/en-us/azure/cosmos-db/free-tier</p> <p>You can run a notebook inside the databaase to queery data with python : </p> <ul> <li>Notebook Description: https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks </li> <li>Service announcement: https://azure.microsoft.com/en-us/blog/analyze-and-visualize-your-data-with-azure-cosmos-db-notebooks/</li> <li>Video: https://www.youtube.com/watch?v=OrnZMkP5Eq4&amp;list=PLLasX02E8BPBKgXP4oflOL29TtqTzwhxR&amp;index=7</li> </ul>"},{"location":"references/#cloud-architecture","title":"Cloud Architecture","text":"<p>This section has resources for advanced to intermediate cloud users who are interested in much more details that most researchers will ever need, and are really geared for IT staff.  However, sometimes to find insight into how to approach your problem (especially for cloud timing ooptimazation projects) these may have useful sections. </p> <p>Microsoft Azure Infrastructure Services for Architects by John Savill, Oct 2019, available from the MSU Library : http://catalog.lib.msu.edu/record=b13538669~S39</p> <p>Azure has changed since 2019 but may still be relevant</p>"},{"location":"session_bigdata/","title":"Session 5: Big Data on Azure Cloud Featuring Spark","text":"<p>You may have heard of 'Big Data' as a concept, which is a complex topic and at the heart of data science, introduced by Google in 2004.   \"Big Data\" processing generally means building a cluster of computers to apply parallel techniques to both store and analyze huge amounts of data.  </p> <p>Big data is truly big: hundreds of billions of datapoints or graphs with billions of edges, petabytes of data (1000 Terabytes).   However many of us more modest data sets find they are large enought that we can't work with them on our laptops or even a very a large computer.  To accomplish our data  processing task we look for ways to split up the work with parallel methods.  Modern big data tools offer this possibility without resorting to custom coding or manually processing.   </p> <p>While big data technology doesn't require cloud computing, most cloud companies have a services that provide data processing clusters with a few clicks.  The goal of this single session is introduce you to basic concepts of  'big data' processing and peek at how it works and what it may do for you.   Your Python or R script Many applications can't take advantage  of it of big data, or they have their own parallel systems.  for those that it could help, it may save tremendous amount of time and make your research more repoducible than DIY data partitioning that requires manual handling. </p>"},{"location":"session_bigdata/#videos","title":"Videos","text":"<ol> <li>Using Azure Databricks Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services.    ( MSU log-in required for video)</li> <li>Using Azure Databricks Part 2: Demonstration with Python Doug Krum, Data Architect, Analytics and Data Solutions, MSU IT Services.    ( MSU log-in required for video)</li> </ol> <p>These are detailed explanations of the commercial version of Apache Spark from the Databricks company, and exactly how to create and use a Databricks cluster on Azure to run Python code</p>"},{"location":"session_bigdata/#readings","title":"Readings","text":"<p>Slide Deck: Overview of Big Data with Spark for Researchers</p> <p>Tools And Technologies For The Implementation Of Big Data, Richard J. Self, Dave VoorhisChapter 10 from \"Applications of Big Data for National Security.\" http://dx.doi.org/10.1016/B978-0-12-801967-2.00010-0  Copyright \u00a9 2015 Elsevier Inc. All rights reserved.</p> <p>PDF copy, for use by Cloud Computing Fellowship only (link is access restricted).  The book is available as an electronic copy from the MSU Library</p> <p>While the book itself is really not of interest to us, this particular chapter is one of the better and more readable introductions to \"big data\" I've seen, written for professionals like yourselves.    Dr. Self studies ethics and big data for University of Derby in the UK. </p> <p>Textbook: Cloud Computing for Science and Engineering</p> <ul> <li> <p>Chapter 7 \"Scaling Deployments\", only sections 7.4 \"MapReduce and Bulk Synchronous Parallelism\" and 7.5 \"Graph Data\ufb02ow Execution and Spark.\"    This chapter discusses parallelism and begins with a focus on High Performance Computing (HPC).  If you are familiar with HPC, feel free to read the entire chapter which may help put \"big data\" in context for you (it did for me).   </p> </li> <li> <p>Chapter 8 \"Data Analytics in the Cloud\"     This is a technical introduction to big data including the first open source program \"Hadoop\" followed by \"Spark\"  We will only concentrate on spark for this session as it's much more approachable and more modern.   There are a handful of examples, but example 8.2.1 should be approachable any one with exposure to college-level Math (approximating Pi using infinite series)</p> </li> </ul> <p>Introduction to Apache Spark part of the Azure Databricks Documentation This is the intro to an excellent tutorial on using Apache spark with Azure.  Read the introduction only (see activities below for info on the tutorial)</p>"},{"location":"session_bigdata/#for-r-users","title":"For R users","text":"<p>The Spark big data system we introduce above is focused on Python and it's native language (calls \"Scala\").  However you can use R commands with Spark, and Databricks has the option of creating an R-based notebook.   Note this notebook is more similar to Python/Jupyter notebooks than Rstudio notebooks, but is an easy way to interactivtly issue  R commands.    Follow the video above up to entering commands in a notebok, and instead of python, select an R notebook.  </p> <p>The easiest way to use R with Spark is with the package sparklyr from Rstudio.  </p> <p>\"Mastering Spark with R\" hosted on https://therinspark.com/ is a free book is very readable and comprehensive resource for learning all about big data focused on R and Spark. </p> <ul> <li>This is a full book, so only suggested reading for those who deecide to use Databricks/Spark with R in their projects.  The book above describes how to use it in great detail. </li> <li>As described in the video and slides above, Databricks is a commercial version of the open source Apache Spark, and the free/open version of Spark can be installed on a laptop for testing without Databricks.  The book has details for that. </li> <li>While it does not describe how to install databricks, all of the examples are useable in an R notebook in Azure databricks</li> <li>The code you develop with Spark on your laptop can be moved to a cluster built in the cloud. </li> </ul> <p>In addition to putting using R in Jupyter style notebooks, you can install and run a web-version of Rstudio inside of Databricks to get the full features of spark inside Rstudio.  It requires some setup, see RStudio on Azure Databricks from Microsoft.  </p>"},{"location":"session_bigdata/#activities","title":"Activities","text":"<p>There are dozens of tutorials related to databricks / Apache spark which is a complex product with many ways to access. This is a curated list  geared towards researchers</p> <p>Create an Azure Databricks workspace  which is part of Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal.   The quickstart  tutorial is based on running SQL (database structured query language) which may not be useful if you have not familiarity with SQL</p> <p>Introduction to Spark Data Frames with Python and SQL</p> <p>A job is a way to run non-interactive code in an Azure Databricks cluster.   Doug Krum discusses using Jobs in the videos above.  For details about Jobs and how they work, see Databricks Data Science &amp; Engineering: Jobs  or to simply try a quick example see  Running Jobs in Databricks Quickstart (with Python)</p>"},{"location":"session_bigdata/principles_using_databricks/","title":"DRAFT Using Databricks and References","text":""},{"location":"session_bigdata/principles_using_databricks/#basic-function","title":"Basic function","text":"<p>Spark is a cluster technology that connects to special storage, performs parallel work and reports performance.  It runs on Azure using a combination of VMs, Storage disks, blob storage and networking.   Spark has commands and tools to help you parallelize your python, R or Javacode to tackle problems too big for one computer.  </p> <p>AzureDatabricks is a webservice to allow you create, start, stop, destroy Spark clusters by abstracting all the  resource creation for spark clusters.   When you create an \"Azure Databricks\" resource Azure creates the pieces necessary  to run the webserver and setup the storage system for your data and code, along with all the stuff related to user accounts based on existing Aure user accounts.   ADB calls this webservice the \"workspace\" as it's a place to build multiple clusters and run multiple programs.  </p> <p>You log-in to the ADB web service which has forms to build Spark clusters on demand - you don't have to provision any of the Azure resources.  In fact the resources that ADB creates can't be changed by you manually.  </p> <p>ADB lets you work with yoru clusters in several ways : submitting your program as a \"job\" the runs on a spark cluster, or with an interactrive notebook like Python Notebooks or R notebooks.     In addition ADB provides a way you can connect to it via a command line on your computer remotely, rather than forcing you to use it's web interface.  </p> <p>You can upload data files either via your notebook code, directlh in the ADB web interface, or with the command line.  These data files are then available to your code that runs on the cluster.  Becasue the Spark cluster uses special form of  parallel data storage, you can't upload files to it directly from Azure (like you would with other Azure storage)/  however ADB does allow you to attach/connect blob storage to the cluster directly instead of using the spark data system. </p> <p>ADB by itself can not run code.  You use ADB to first create a spark cluster, then the cluster can run your code.  Hence to do some data operations, you must first create a cluster that can then run the code to operate on the data, even if those operations don't really requires a full power of a cluster (the code needs to run somewhere.). </p>"},{"location":"session_bigdata/principles_using_databricks/#how-tos","title":"How tos","text":"<p>Create and use an ADB service: use azure portal (link), then go to the resource in the  How to upload into databricks: </p> <p>1) use the UI (link) 2) in a cluster, use the </p> <p>Can I upload files into the DB file system without creating a cluster?  Is there a way to see the files  on the DB file system easily from outside of the cluster?</p> <p>I want to use Rstudio and the instructions say to run a python notebook that uploads a shell script into the file system which seems like a really convoluted way to interact with the file system, or do any kind of adminstration</p> <p>why are there so many disks created in the auto-generated resource group</p> <p>I have participant roles limited to the resource groups I create for them, so they don't accidentally delete anything that's not theirs.    That seems like it will be a problem when they go to try to build a DB and it creates a new RG. </p> <p>Job clusters much cheaper - interactive is default, but much more expensive</p> <p>old school RDD, had to do all your own </p> <p>Dataframes + Catalyst</p>"},{"location":"session_cloud_storage/","title":"Session 3: Cloud Storage","text":""},{"location":"session_cloud_storage/#introduction","title":"Introduction","text":"<p>Central to using cloud for nearly all services is storing data.   Cloud storage is quite different from what most are used to related to saving a file to your disk or USB removable media or even our HPC.   During our workshop on creating a VM we didn't use cloud storage, we simply create a VM \"virtual disk\" that is attached to the VM just like your hard drive is attached to your own computer.   However there are disadvantages to this :    1. the main OS disk is typically deleted when the VM is deleted, although you can create a 'durable' disk to share   1. the data on the main OS disk is tied to that Virtual Machine and hence that operating system, that is, it's typically inaccessible from other cloud services    1. it is limited in size and scope  The largest of virtual disks are around 1 TB.  Azure Cloud storage accounts are limited to 5 TB and you may have multiple storage accounts.    1. You can only move data to/from a virtual or shared disk storage using a virtual machine   1. Most importantly virtual disks very expensive compared to cloud storage </p> <p>Cloud storage was engineered to save millions of files for millions of users and will take some changes to your approach to understanding how it works. </p>"},{"location":"session_cloud_storage/#meeting-september-30-200-330pm","title":"Meeting September 30 2:00-3:30pm","text":"<ul> <li> <p>Discussion and Review of previous sessions: </p> <ul> <li>Using the Portal</li> <li>Creating and Using Virtual Machines</li> </ul> </li> <li> <p>Seminar What is cloud storage? Azure Cloud Storage for Researchers</p> </li> <li>Azure Storage Pricing Exercise </li> </ul>"},{"location":"session_cloud_storage/#readings","title":"Readings","text":"<ul> <li>Storage as a Service from \"Cloud Computing for Science and Engineering\"  </li> <li>Azure Documentation: Introduction to the core Azure Storage services  </li> <li>Table of Azure Storage Product Offerings</li> <li>Optional: this is long (27 minutes) but a good basic introduction to Azure storage:  Azure Training: Explore Azure Storage services ( free training from Microsoft Learn)</li> <li> <p>optional Understanding block blobs, append blobs, and page blobs</p> </li> <li> <p>Introduction to Azure managed disks  This has more techincal background than necessary but could be very helpful.  </p> </li> </ul>"},{"location":"session_cloud_storage/#activities","title":"Activities","text":"<ul> <li>Download and install the Azure Cloud Storage Explorer  See the \"Download now\" button at the top of that page.  You may review the content of the page</li> <li>complete exercises in Creating Azure Cloud Storage Accounts to create and use storage</li> </ul> <p>https://learn.microsoft.com/en-us/azure/storage/files/storage-files-quick-create-use-windows?source=recommendations</p>"},{"location":"session_cloud_storage/#post-session-discussion-points","title":"Post-session discussion points","text":"<p>There are several options when creating a storage account.   For example, what is the difference LRS vs GRS?  Is the documentation describing these clear or confusing?   What conditions might you consider LRS vs GRS?  Is it worth the cost?</p> <p>How would you share data with colleagues outside of MSU using cloud storage?    Where did you find the information for how to do that (Microsoft, Azure, Blog post, other)?   Let's say need to share 5gb of data.  After doing the pricing exercise above just for storage, what are the costs for each upload and download of 5gb?  Does it make a difference if it's Blob or File storage?</p>"},{"location":"session_cloud_storage/#optional-activities","title":"Optional Activities:","text":"<p>The following two activities walk through attaching Azure files to a VM so you can use it just like any other disk.   This is only one method for moving data to/from cloud storage to your VM, but it does not require changing your program code. </p> <p>For Windows Users: Using File Storage with Windows VM </p> <p>Microsoft Tutorial: Create an SMB Azure file share and connect it to a Windows VM using the Azure portal</p> <p>Notes: - The tutorial has you create a storage account, but you can re-use the one you've already created (and change the names), or follow the tutorial and create another one.  - Not all versions of Windows can use this.  For much more detail, see the Azure documentation page \"Mount SMB Azure file share on Windows\"</p> <p>For Linux Users: Mounting File Storage with Linux VMs using NFS</p> <p>Microsoft Tutorial: Create an NFS Azure file share and mount it on a Linux VM using the Azure portal</p> <p>How to mount Azure Files on Linux using SMB </p> <p>Notes:  - SMB (invented by Microsoft for Windows) and NFS (invented by Sun Microsystems from Unix) are competing methods for attaching network storage.   Both were created for on-premise servers, but Azure Files storage brings this to the cloud. - this tutorial uses command line, and requires an ssh connection to the VM you create. - Knowledge of Linux systems (mount points, fstab, etc) required </p> <p>Optional: Python And Blob Storage</p> <p>This describes an a different method for moving files to/from cloud storage: using code.   This does not require you to 'mount' the storage to your VM. </p> <p>For Intermediate Python users, and if you have time and interest, consider this tutorial from Azure: Quickstart: Manage blobs with Python v12 SDK</p> <p>Requirements:</p> <ul> <li>knowledge of Python </li> <li>use the blob storage account you created in the exercise above or createa a new one</li> <li>familiarity with Azure portal </li> <li>Python installed on your computer (suggest python 3.6 minimal)</li> <li>familiarity with the terminal and command line</li> </ul> <p>**Optional: Using Managed Disks with Linux</p> <p>Azure Learning Tutorial : Add and size disks in Azure virtual machines</p> <p>Notes:  - Uses the Azure Command line interface which we have not discussed.  For </p>"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/","title":"Exercise: Creating Azure Cloud Storage Accounts","text":"<p>These exercises are for the Cloud Computing Fellowship session on cloud storage.   They focus on creating the account(s) necessary to use storage.  </p>"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Download the Storage Explorer</li> <li>Review Storage documentation for basic concepts. Please review materials for this session to understand cloud storage and the different types that Azure offers </li> <li>A valid subscription. </li> <li>A storage account is not always required for some tutorials, but if so, create a storage account with the first item.  </li> </ol>"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#azure-quickstart-tutorials","title":"Azure Quickstart Tutorials","text":""},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#storage-account","title":"Storage Account","text":"<p>We created a storage account in one of the first activities using the portal, and you may use that storage account for many of the other activities below.  However  here is the Azure documentation for doing so if you want to review or practice creating a new one: </p> <p>Create a storage account</p> <p>*Note in the above there are options for \"Portal\", \"PowerShell\", \"Azure CLI\" and \"Template\" but the Portal version is what we covered so far. </p>"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#blob-storage","title":"Blob Storage","text":"<p>Azure Quickstart: Upload, download, and list blobs with the Azure portal</p> <p>The Azure Storage explorer is a desktop application for Mac and Windows, useful for occasional checking and working with cloud storage: </p> <p>Azure Quickstart: Use Azure Storage Explorer to create a blob</p>"},{"location":"session_cloud_storage/exercise_creating_azure_cloud_storage/#file-storage","title":"File Storage","text":"<p>In the following exercise, you can use your existing storage account, and skip to the section \"create-an-azure-file-share\" but feel free to create an additional storage account if you want to experiment (the storage account itself does not )</p> <p>Quickstart: Create and manage Azure file shares</p>"},{"location":"session_cloud_storage/storage_pricing_exercise/","title":"Storage pricing exercise","text":"<p>Prior to doing this exercise, See the reading and lecture slides linked in this session for definitions of terms. </p> <p>How large, approximately, is your data?  If you are unsure, estimate 100 gb.   How much would it cost to keep it in the cloud?</p> <p>Compare the pricing for Blob, Files and Disk storage for 6 months</p> <p>Aspects Of Storage:</p> <ul> <li>Redunancy: Always slect \"LRS\" as that is almost always sufficient.  </li> <li>Storage prices are not the same across regions, but the default (\"East US\") works for this exercise</li> <li>Consider only the \"Hot\" storage of the different tiers (\"Premium\", \"Hot\", \"Cool\", and \"Archive\")<ul> <li>for some high performance applications, Premium is required, but look at the price difference! </li> </ul> </li> <li>Operations, Transactions and data transfer costs<ul> <li>charged per 10K operations </li> <li>really hard to estimate unless you know your workload</li> <li>very low costs, e.g. reading 10K Blobs costs 1/2 of one cent.  </li> <li>I would not bother estimating this cost unless you know you will have very high disk operations</li> </ul> </li> </ul> <p>Types of Storage to Compare: </p> <ul> <li> <p>Azure Blob Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/blobs/  select \"Hierachcial namespace\"    </p> </li> <li> <p>Azure Files Pricing: https://azure.microsoft.com/en-us/pricing/details/storage/files/ </p> </li> <li> <p>Managed Disk Pricing : https://azure.microsoft.com/en-us/pricing/details/managed-disks/ </p> <ul> <li>note these are in different sizes and types, select 128gb size if you are estimating 100gb data, Standard SSD</li> <li>when you create a disk in the protal, it defaults to 1 TiB size, which is quite expensive / month     </li> </ul> </li> </ul>"},{"location":"session_cloud_storage/storage_pricing_exercise/#optional-compare-with-on-premise-storage-costs","title":"Optional: compare with on-premise storage costs","text":"<p>The MSU HPC offers 1TB storage free to any MSU Researcher with redundant backups and high-speed access, with each additional 1TB for $125/year.  Since this is network attached storaage is this comparable to Azure Files or Azure Blob storage?</p> <p>If you need 2TB storage ( 1 free + 1 paid), what is the approximate Azure cost for 2000gb for 12 months, ignoring all operatinal costs (just storage)?    There are a few options for redundancy (global vs local) and other aspects.   What is the cheapest combination of options?   </p>"},{"location":"session_datasystems/","title":"Session 4: Data Servers on the Cloud","text":""},{"location":"session_datasystems/#introduction","title":"Introduction","text":"<p>Data servers (like Relational Databases) can be a powerful tool for even small research projects.   When we say \"Data Servers\" or \"Data Systems\"  we mean any server with data processing capabilities that you connect to with a client to send data, commands and receive results.   The most widely used and classic example is the relational database management system (RDBMs) invented in the 1970s, but there are many other types.  A central advantage of data servers is ability to handle many conncurrent connections.  Connections can be from many users, a web application serving many uers, or many other concurrent processes.    Like other systems (such as VMs, File storage servers, big data tools, etc), these data systems don't require cloud computing, but cloud companies offer database services such taht with a few clicks you can have a server that would take a week to provision and years to maintain.  A data server could be a productive addition to your cloud architecturee, or the central aspect of your fellowship project.  </p> <p>I have use databases with many research projects that had significant data entry burden requiring many work-hours of students typing in data, or shared systems.   </p>"},{"location":"session_datasystems/#readings","title":"Readings","text":"<ul> <li> <p>Introduction to Data Servers on the Cloud Slide Presentation </p> </li> <li> <p>Chapter 4. Databases From the free textbook \"Big Data and Social Science: Data Science Methods and Tools for Research and Practice\" by Foster, Ghani, Jarmin, Kreuter and Lane.  The book itself could be a valuable resource for learning about the data science methods that you may se on the cloud.  </p> </li> <li> <p>Textbook Chapter 3s: Blog Post from eScience: Azure\u2019s new CosmosDB Planet-Scale Database</p> </li> </ul> <p>Difference between SQL and 'NoSQL' style databases</p> <p>Towards DataScience blog Introduction to Databases for Data Scientists Note this blog post may require a free account but reading in an incognito or private window worked for me</p> <p>A description of SQL vs NoSQL from a company called xplenty Which Modern Database Is Right for Your Use Case? this has many adds/pop-ups but is a good read</p>"},{"location":"session_datasystems/#activities","title":"Activities","text":"<p>Azure offers a database user interface for your computer called Azure Data Studio and has a tutorial for using, but you need to create a database server first.   </p> <p>If you are interested in using SQL for your project, consider the following two activities based on the Open Source database system Postgresql</p> <ol> <li>Quickstart: Create an Azure Database for PostgreSQL server by using the Azure portal<ul> <li>I suggest using a password rather than ssh key for now to make it easier, but not recommend for long-term use</li> <li>record the admin user name and password you used when creating the database</li> <li>in the Azure portal, visit the Postgresql Database resource page, and look at the connection strings page to use in the next tutorial</li> </ul> </li> <li> <p>Quickstart: Use Azure Data Studio to connect and query PostgreSQL</p> </li> <li> <p>In depth SQL Tutorial: After completing the two activities above, If you are interested in starting with SQL, this free tutorial looks pretty good.  Let us know if you tried it and it was not helpful:  </p> </li> <li>PostgreSQL Tutorial from TutorialsPoint.com .  </li> <li>Note: A Database server can house many \"databases\" , and sometimes a database is called a \"schema\" so you can use the database server you created above, and the same steps for how to connect to the server, then create a new database inside the server for the tutorial.  </li> <li>In the tutorial above, the chapter  \"Environmental Setup\" that walks you through installing Postgresql server on your laptop which also provides you a command-line interface on your laptop.  You could augment that chapter by provisioning a Postgresql server in Azure (see link above) and connecting to it. </li> <li> <p>If you don't want to install Postgresql on your laptop, you can either 1) use the Azure Data Studio, but only for SQL commands (not commands like <code>\\help</code> (see the activity #2 above ), OR 2) if you are familiar with command line, the Azure Cloud shell comes with the postgresql command <code>psql</code> as shown in Activity #1 above.  </p> </li> <li> <p>Delete the database in your resource group when you have finished with the tutorial.  If you would like to estimate costs for using database, keep it for a few days, then visit the \"Cost Analysis\" page of your resource group in the Azure portal.  SQL services can get expensive quickly compared to VMs, but installing and running postgresql server software is a daunting task and comes with security risks.  </p> </li> </ol> <p>Using a Database Server in the cloud has many layers so if you are interested in using SQL feel free to reach out for help for incorporating SQL into your research.   </p>"},{"location":"session_datasystems/#references","title":"References","text":"<p>A list of the commands you may use to manage a database for the Postgresql variety: https://zaiste.net/posts/postgresql-primer-for-busy-people/</p>"},{"location":"session_datasystems/#optional-data-analytics-on-the-google-platform","title":"Optional : Data Analytics on the Google Platform","text":"<p>Google Offers a service called \"BigQuery\" which does not require you to create a server, only an account.  It can process huge amounts of data, and has several datasets available for free.  It also has </p> <p>You may try BigQuery for free in their Sandbox, with only a Google Account.  If you have a gmail account, use that to log in with an incognito/private browser window.   You may try your msu.edu email but it may or may not work. </p> <p>In the following tutorial you may ignore mentions of \"firebase\" which is another database offering for web apps from google</p> <p>Using the BigQuery sandbox </p> <p>If you are a python user, Google offeres a free notebook service called \"Co-Lab\" and you can connect to both google drive and big query from Colab.  </p> <ul> <li>getting started with Colab : https://colab.research.google.com/notebooks/intro.ipynb   Log-in to Colab using https://colab.research.google.com/ </li> <li>intro to BigQuery in Colab: https://colab.research.google.com/notebooks/bigquery.ipynb</li> <li>Complex tutorial examining periodicity in weather data: https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery</li> </ul> <p>Google Colab + Google BigQuery + GoogleDrive is definitely cloud computing but not in the sense we usually think about it as these are all SAAS level services, chained together via a cloud computing backdrop.  </p>"},{"location":"session_datasystems/data_servers_intro_for_researchers_edited_with_typora/","title":"Data servers intro for researchers edited with typora","text":"Overview of Data Servers and Databases on the Cloud for Researchers    class: cloudtitle,center, middle  # Data Servers on the Cloud for Researchers  ### Pat Bills, IT Services ADS  for the [MSU Cloud Computing Fellowship](../session_datasystems)  ---  # Again, Why are we talking about Data?    **Session Goal:** understand the principles, how and why to use data servers in your research - we all have data to deal with - a common research struggle is working with complex data, or collaborating with others - Databases can offer a solution for collaboration among researchers and parallel processes - cloud computing offers Data servers  \"as a service\" (PAAS)   - without cloud these systems require a collection of hards, a month of installation, infrastructure expertise - Databases are common place in industry and have been used by researchers for decades - Potential gateway to whole new realm of solutions for data workflows  ---  # Client/Server architecture  - designed in the 1970s, common-place now - client does very little processing, used to send/receive messages - server houses all the data and processing power - now clients are apps and many have significant prrocessing power (chrome) - Most Research workflow:  download data and process it on our machine  ![server](https://assets-global.website-files.com/5debb9b4f88fbc3f702d579e/5ea0baf0b2840153a46b9128_Client-Server-Achitecture.png)  ---  # What is a server?   - Running Program  - listens on specific port  - accepts messagess that match it's protocol/format  - optionally include mechanism for secure authetication   - sends messages and data back using same protocol/format  ---  # What is a server? web server example  - listens for and accepts messages using the 'http' protocol (on port 80)  - the http protocol tells  the web server which content to fetch (via the URL), and what formats the client can use (html)  - the server returns a message indicating the format of the content (html, PDF, etc), other info, and the content itself  -  the browser client determines what to do convert the content to something you can  read     ---  # Clients and Servers  each server requires a specific protocol, so typically you can't mix clients and servers BUT   - some clientss are smart and can alter protocol to work with multipel server  - some sereves are smart and can respond to differnet protocols.   A data serever rmay have a webs interface  For example, many database clients can communicate with many flavorrs of SQL dataabases  - communication protocols are text and binarry, and client apps provide GUIs of those  - servers accept commands, programs, or data, formatted in propeer protocol - clients let you type to thee commands and format into th eprotocol for you  ---  # Client/Server Connections  - `user -&gt; connects to server host -&gt; enters commands -&gt;  client formats and sends  ---&gt; server accepts commands --&gt; run process and returns value`  - `user &lt;-- client displays results &lt;- client accepts results and displays`  - communication can be about data, but also about server configuration, client output format, etc   ---  # Client/Server : essential for data systems  This session is focused on data systems that use a client/server model but we use services every day - email - remote desktop : the 'server' is a windows programs that returns views of the screen - most apps ( I have to use on to remote start my car ) - others?    ![db server architecture](img/db_server_topology.png)  ---  # Cloud was made to  serve  The cloud was invented to host servers  Large institutions have to run servers for many aspects of their work  in addition to data      # Steps for Client-Server-ing  1. install a server    - physical machine or a VM that is running server software 2. configure server    - network, securrity, user aaccounts, storagee, server prefs/config    - use managed cloud service (restuarant)  3. install client    - download any number of compatible programs  ---    ---  # Server Connection Terms  - *host*: computer that runs the server software \"host\" and id by it's internet address - *port*: too allow muliple servers linux has 65K ports - *user vs admin*  : accounts on the server , admin has full power, user limited.  For DIY server, you are the admin - *database vs server* : a \"database server\" can have multiple \"databases\" becuase servers are typicaly shared - *SSL* : secure sockets layer required to encrypt the communication for security, Azure takes care of this - *Connection string* : the combination of these parameters used to connect to a database, formated for the Client - *Client* : can be a package or library used inside a programming language  ---  # Server Locality  *Servers can run anywhere*   - on your laptop, running alongside your other  programs.  The *host* is called `localhost`     - on a computer on campus (on-premise) the host is something like myservername.mydepartment.msu.edu   - on a VM that you create in the cloud :  myvmname.east.azure.net (IAAS)  - as part of a service offerring, provisioned for you (PAAS)  - the service itself, you don't control the server, only access data serevices (SAAS)  #   # Example session : terminal client  #### Demo of Terminal session to Postgresql Server   - Create a Azure Postgresql Database Server  - Connect to the server with a command line interface  ![Example PSQL Terminal Session](img/psql_terminal_session.png)  ---  # Example Session : GUI client    #### Demonstration using a free Graphical Client to connect to a Postgresql Database hosted on Azure    ![Example DB gui](img/database_gui_example.png)  ---  # Example Session : Scripting Client    # Example Data Command Language: SQL  - Structured Query Language for Relational Databases - by far most common data processsing language since 1970s - declarative not procedural   - like ordering from a restaurant - you state what you want, with no direction for how to prepare - easy to learn and use and use the basics - like other Data Command languages, based the data model  = tabular data, linked on common ID values.    ---  # Example Data Command Language: SQL  This is not a course on SQL but for Example to return rows of a table  - *SELECT* the columns to show  - *FROM* the table  - **WHERE** a logical condition to match data in the rows - ordering   list some data for all flights for today in the US:    <pre><code>SELECT flight_num, airport_code, airline, takeoff_time, aircraft_id \nFROM flights WHERE fight_date = '2021-10-28' and country='US'\n</code></pre>  1. -   ---    --- # Cloud-scale Database Services  We covered a \"Big Data\" system last seesion (Spark) but cloud companies provide a data service for really big data.  These are proprietary, on-of-a-kind systems that can work on truly huge amouts of data  - Google BigQuery (google invented the concept and unbelievable huge) - AWS Redshift - Azure ComosDB - Azure DataExplorer aka Kusto  do not need to provision any resources, only an \"account\" in which you can store your data, queries/scripts, and the output.   Data storage is inside the db and  output can be exported to cloud storage in various formats  - SAAS for large database  ---  # Cloud-scale Database Services: Azure Cosmos DB  - Primarily a NoSQL database, but has a SQL API to make it easy - Compatible with other common open source NoSQL database \"MongoDB\" - Getting data ingested requires using a windows program, or using Azure DataFactory to move data from Cloud storage into Cosmos DB - Could be useful if you are analyzing a very large amount of semi-structured data that may already be in JSON format and don't want to manage a big data system like Databricks.  - Resource [Introduction to Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction) and the Azure [Quick Start using Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/sql/create-cosmosdb-resources-portal)  ---  # Azure Data Explorer : Analytics as a Service    [Data Analytics Service on Cluster Computing  aka *\"Kusto\"*](https://docs.microsoft.com/en-us/azure/data-explorer/data-explorer-overview)  - Useful for fast analytics of large data without provisioning a server - Data is read-only and  can't be changed.  - SQL-like query language called KQL unique to Kusto: [Overview with link to free example](https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/) - Create a cluster: https://portal.azure.com/#create/Microsoft.AzureKusto then use https://dataexplorer.azure.com/   ![Kusto Example](img/azure_kusto_example.png) ---  # Google Detour    #### We could use a collection of Google services to accomplish data analytics on the cloud:   - Google Drive: Files as a Service - Google Colab: Python/R/SQL as a Service : free notebooks hosted in Google Drive` - Google BigQuery : Data query as a service    - [CoLab Example (PSB's drive)](https://colab.research.google.com/drive/1e_nObJODQ61-0NtaMI-jlEvT9eHgvkmd) - [Weather Tutorial using Google Services](https://cloud.google.com/blog/products/data-analytics/whats-the-weather-like-using-colab-to-get-more-out-of-bigquery)     that access huge public dataset demonstrates the power of this approach  #### *Google Colab + Google BigQuery + GoogleDrive*  - definitely cloud computing   - is it cloud computing in the way we think about it?  ---  # Cloud Serivce Levels and Responsibility  - any server connected to the internet has security  - many ways to mitigate the risk including cloud private networking, firewalls, encryption - When chosing data services, consider responsibilities for security and configuration    - Infrastructure = IAAS : cheaper, more work, more responsibility, more risk    - Services = PAAS/SAAS:  more expensive, faster provisioning, less risk  ![Service levels](../img/service_levels_and_user_responsibility_stack.svg)   ---  # Questions?  ![Example database diagram from US BLM](img/exampledatabase-FGDC-Cadastral-Standard-ERD-The-National-Integrated-Land-System-NILS-is-a-joint.png)  *example Database Diagram from [Towards a Standard for the Cadastral Domain: Proposal to establish a Core Cadastral Data Model, 2002 Van Oosterom &amp; Lemmen](https://www.researchgate.net/publication/27349321_Towards_a_Standard_for_the_Cadastral_Domain_Proposal_to_establish_a_Core_Cadastral_Data_Model)*"},{"location":"session_datasystems/table_of_responsibilties_by_service_level/","title":"Table of responsibilties by service level","text":"Layer Responsibility On-Prem IAAS (VM) PAAS SAAS Network Connectivity &amp; Security Campus IT Service Service Service Hardware Disk Failures You Service Service Service Operating System Updates, installation, security You You Service Service Security Software Install and maintain You You Service Service Server Software Install, maintain You You Service Service Server Configuration Tune, Speed, You You You (limited) Service User Configuration Who can access, user accounts You You You Service Code/Data You You You You"},{"location":"session_how_to_cloud/","title":"Session 2: What is the cloud and how does it work?  An introduction using storage and virtual machines","text":""},{"location":"session_how_to_cloud/#about-this-session","title":"About this Session","text":"<p>We are providing materials and activities for this session for you to read and attempt at your own pace.   Please attempt these and see how far you can get.   Feel free to post on Microsoft Teams if you have any issues, find things that need correcting, or have general questions.   </p> <p>We will host an optional, additional, in-person session to provide help to anyone who wants to attend, Friday September 23 2pm to 3:30p.  Since this is outside of pre-arranged schedule, anyone who would like help but can't attend during this please contact us and we will arrange a time for you.   </p> <p>We will discuss all of this material and more during our next regularly scheduled in-person session Friday September 30th. </p>"},{"location":"session_how_to_cloud/#overview","title":"Overview","text":"<p> When many people think of \"cloud computing\" they think of computers in the cloud, or virtual machines.   Cloud computing companies offer much more than just virtualized hardware, but this is a good place to start.   This session is designed to be a hands-on workshop where we walk-through creating the resources needed for to run a computer in the cloud, logging into this computer, copying data and using that data in a program.    At the end of the session you should have a good introduction of what it means to \"cloud compute.\"</p>"},{"location":"session_how_to_cloud/#overview-presentation","title":"Overview Presentation","text":"<p>Cloud Concepts &amp; Virtualization Slides (PDF)</p>"},{"location":"session_how_to_cloud/#about-the-azure-portal","title":"About the Azure Portal","text":"<p>We demonstrated the azure portal quickly in our last session when we set a budget alert.   The following dives into more detail about 'resource groups' which is the core of how Azure is organized.  Note that, as we get started, fellows have access to just a single resource group that we've created for you.  You can't create your own but you can create as many resources as yuo need inside this single resource group.  </p>"},{"location":"session_how_to_cloud/#azure-portal-reading","title":"Azure Portal Reading","text":"<p>Top-down description of how Azure is organized</p>"},{"location":"session_how_to_cloud/#azure-portal-activity","title":"Azure Portal Activity","text":"<p>Using the Azure Portal : tutorial and video</p>"},{"location":"session_how_to_cloud/#optional-follow-ons","title":"Optional Follow-ons:","text":"<p>Azure Storage</p> <p>The Activity above had you creat a 'storage account' with no background.   If you are interested in learning more about storage, this is a prety good, high-level introduction : </p> <p>Edureka Azure Storage Tutorial  (there are several pop-ups and ads, but it's a good level of of information )</p> <p>You will see there are different types of storage, but all types must be inside a \"storage account\" and this \"storage account\" must be inside a resource group.  </p> <p>We will re-visit concepts and usage of cloud storage in detail, as it's a core aspect of cloud computing.    </p>"},{"location":"session_how_to_cloud/#virtual-machines","title":"Virtual Machines","text":"<p>We introduced \"virtualization\" during our introduction.  For IT this means flexibly creating multiple resources on one piece of hardware using software.  The main use case is many virtual computers (or servers) on one large computer hardware.   This was create prior to cloud, but when you create your own computer in the cloud, it's based on the technology.  To a user it may seem very similar, but to the systems IT engineer, it's very different.     However these readings may help give you an </p>"},{"location":"session_how_to_cloud/#readings","title":"Readings:","text":"<ul> <li>Chapter 4: Computing as a Service from \"Cloud Computing for Science and Engineering\", Ian Foster and Dennis B. Gannon, September 2017</li> <li>What is a Virtual Machine (VM)?  Introduction from Microsoft</li> <li>What is a Virtual Server? Youtube Video from  IBM describing how companies (including MSU!) use virtualization to run multiple computers on one server to optimize the use of space in a data center. </li> <li>What's the difference between cloud and virtualization? from RedHat, a Linux Operating system company</li> </ul> <p>Activity: A long activity to create (and delete) a Virtual Machine with the Azure Portal for both windows and Linux. </p>"},{"location":"session_how_to_cloud/#why-create-a-vm","title":"Why create a VM","text":"<p>What is a VM good for?   The activity above does not discuss why you'd create a VM and connect with remote desktop, only that you can do it.   We will discuss that at our next session.  Can you think of possible use cases for your research, or other types of research, for a remote computer that could be very powerful or very small?</p>"},{"location":"session_how_to_cloud/azure_organization/","title":"Azure Organization","text":"<p>This is a brief description of how Azure cloud services are organized for those just getting started with Azure.  It's my own take on this topic written with researchers in mind.  However it should not replace Azure official documentation.  The link below has a great summary of how it's setup.  However you may ignore all the other sections in the \"Azure setup guide\" as this is geared for IT professionals adoption cloud for their own organization</p> <p>Microsoft Azure Documentation: Organize your Azure resources effectively</p> <p></p> <p>Azure is organized by directories of user accounts and subscriptions.  All resources must be created in exactly one \"subscription\" which is a method for billing and for setting permissions.  Your organizations \"directory\" is where your user account lives, but you may have access to multiple subscreiptions with one user.  MSU created a \"Cloud Computing Fellowship\" subscription for all activities and resources for this, and we added your MSU directory accounts this subscription.   </p> <p>Cloud computing components are known as \"resources,\" which AWS defines as \"an entity you can work with.\"   Anything you can create using a cloud interfaces is a \"resource.\"   </p> <p>To help with more organization, in Azure, resources belong to a resource group.   Resource groups can collect resources by project which could still have hundreds or just a few resources.  There is no restriction and up to you to organize how it works for you.  For example, a lab could have a resource group for each member, or perhaps a resource group for each project, and members collaborate on those projects.   </p> <p>It's also possible to restrict access to resource groups, e.g. a resource group for a project may only allow those who are working on the project access to that resource group.  Azure has other organizational tools such management groups across subscriptions, complex identity management and role-based access control (RBAC) that we won't cover here.  </p> <p>However, this is mostly for organization and resources may be accessed from one resource group to another, and even across subscriptions.   Applying this organization scheme requires practice and sometimes vigilance.   </p> <p>For most campuses, researchers will want to have their IT department create the subscriptions and billing as they often can get discounted prices or fee waivers.   When your research group is ready to pay for services here at MSU, see the link to the \"cloud services request form\" on https://tech.msu.edu/network/cloud-services/ </p> <p>Summary of top-down Azure Organization: </p> <ul> <li>Directory : (MSU account). All account must come from a directory (but an account can be multiple directories)<ul> <li>Management groups : we won't use these, for admins to manage multiple subscriptions)<ul> <li>Subscription : tied to a billing account, and where all resources are created.  <ul> <li>Resource Group : organizational tool for resources.  Think of it as a \"folder\" in your file system<ul> <li>Resource : any cloud entity you may work with (e.g. create, configure, destroy)</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Finally, it is possible to log-in to the Azure portal (e.g. your MSU account) and not have a valid subscription and not be able to create or access any resources.  If you have never used Azure before, you may be asked to create a free trial.   If are a you need to use Azure (e.g. for training) and do not have access to an MSU subscription, you may want to use a non-MSU email address and create your own account.  </p> <p>Azure \"tags\" add added to resources (including resource groups) and are a way to identify and locate resources by search as for many other services.   They are optional but highly recommended to use a tagging scheme to help organize your resources and for cost analysis.   You can use any keys and any values you find useful.  </p>"},{"location":"session_how_to_cloud/azure_organization/#azure-locations-or-regions","title":"Azure Locations or Regions","text":"<p>Subscriptions are for accounting only and don't represent concrete cloud resources.  However cloud resource must reside in computer somewhere, and hence have a location.   Locations for cloud providers for can be thought of inside one of their massive data centers.  In Azure, \"region\" and \"location\" are used interchangably (some interfaces use 'location, some use 'region')</p> <p>Resources and Resource groups must be assigned a location when you create them.   considerations are 1) does the location actually provide the services you need (not all locations have all cutting edge products) and 2) is the location close to you to reduce time it takes for data to cross the internet to/from you and finally 3) is there some restriction based on your country of origin.   </p> <p>Most of the time, simply choose the default which is East US which almost always has the latest features.  For some advantage for data transfer, choose (US North Central US).   However as a rule select a location/region and use that across all of your resources so that, for example, your data files in storage are close to (in the same data center as) a computer you may create. </p> <p>Regions become very important for companies that offer services around the world and want to reduce the connection time for their customers.  It's also possible to have back-ups of resources in different region to protect against natural disasters.  </p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/","title":"Exercise: Azure Portal Walk-through and Storage account creation","text":"<p>MSU Cloud Computing Fellowship </p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to the web interface to manage Microsoft Azure cloud services.   Prior to doing this exercise, please read  Azure Organization For more background on how azure is structured.   </p> <p>For definition of terms used in this walkthrough , refer to our Cloud Glossary  including \"resource\", \"azure resource manager\" and \"resource group\"  or our list of cloud references for introduction to cloud computing. </p> <p>For this activity we'll be using the web interface which Azure calls the \"Portal\" but that is only one of several ways to interface with Azure that we will learn about.   Many of the activities you can accomplish in the portal you can accomplish with the other (command line or code) interfaces. </p> <p>Azure's own overview of the Portal is here: https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-overview  Please refer to that as well as this material.  </p> <p>There is a corresponding video that we've made that includes infrmation about the portal, and also creating a storage account.  </p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#orientation-to-the-azure-portal","title":"Orientation to the Azure Portal","text":"<p>The link above is to a video that walks through the description and tutorial steps below, hosted on  MSU MediaSpace ( requires MSU Log-in).  Note this video also walks through creating a storage account.   </p> <p> This assumes you have an Azure account and a valid subscription.   For the purposes of this introduction, we assume that your account currently does not have ability to create a new subscription, resource group, </p> <ol> <li>Log-in to https://portal.azure.com with your MSU Netid.   <ol> <li>If you  are a current member of the fellowship and you have difficulty logging in, please contact us right away. </li> </ol> </li> <li>orientation: dashboard view.     Azure portal first presents a \"dashboard\" which is organized into panels that show some aspect of your cloud account.  You may alter the panels on this dashboard  to show you the services and aspects of azure that are most important to you.   For information on how to create customize your dashboard, see \"Create a dashboard in the Azure portal.\"    In the standard, default version of the dashboard the first panel is a list of resources.  If you have not created any resources yet you won't see anything.  We will explorer resources later in this introduction.     The standard dashboard panes are a list of your current resources (which may be in multiple resource groups), an advertisement with a link to learn about some new Azure service, and more links to create things the Azure has decided are most important to you.   We will focus on the \"All Resources Pane\"    If you click on anything here you can almost always use the back button to get back to the dashboard, or use the menu (described below)</li> <li>Top Bar Menu: the top menu ( three horizontal bars) is are links to many of the things also on the main dashboard. The \"home\" view is not the same as the dashboard but is a list of links to things Azure guess you may want to create, and a list of all of your resources.   If you click \"resource groups\" in this list, you should see only one resource group (if any) unless you've been added to others or a different subscription. </li> <li>Search bar: in the middle of the top of the screen is white box in which you can type search terms include the kind of resource you want to see or create, or part of the name of specific resource you've created.    This is what I use to create and find resources most of the time (and rarely use the links provided), more on that later. </li> <li> <p>Shortcut buttons: the next few icons are short cuts to other functionality in the portal that we will cover in the future.  Most are not critical. </p> </li> <li> <p>A note about portal navigation:  When you click anything in the portal, it creates a new window without reloading the browser and with an X at the top right.  This mimics a \"close window\" function and You can use the X return to the dashboard, or you may simply use the menu and go to where you need to  </p> </li> </ol> <p>Notice that like most things there are 4-5 ways to get to anywhere.  </p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#bonus-what-can-you-do-here","title":"Bonus: What can you do here?","text":"<p>The primary purpose of using the portal and your resource group is to create things, and manage and monitor those things.   For the purpose of this activity - since you don't really have anything - we can simply look at the 'activity log' in the left side-panel near the top.    - this opens a new table of columns Operation name, Status, Time, Time stamp, etc that is probably empty for you.    - Tables of information like this in the portal have filters at the top.  The default activity is just for the previous 6 hours.   If you click on the Find that filter called \"timespan\" and select 1 week (or longer) you can see when I created the resource group and the budget.    </p> <p></p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#optional-activity-creating-a-storage-account-with-the-azure-portal","title":"Optional Activity: creating a \"storage account\" with the Azure portal","text":"<p>If you would like to explore the azure portal by creating a new resources, then read on.    We have not talked about cloud storage, and you don't need to know about Cloud storage to complete this tutorial.  This is simply an exercise to see how to create something use the Azure portal, and cloud storage is a benign (and very inexpensive) resource to use an example.  </p> <p>Note that a \"storage account\" is not the same as \"disk\" you will see when you create a virtual machine.  We will discuss the difference in detail in the session on storage. </p> <p>Requirements:</p> <ul> <li>An Azure Account with valid subscription</li> <li>A Resource group</li> </ul> <p>All members of the current Cloud Computing Fellowship cohort have these things</p>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#creating-a-storage-account-tutorial-step-by-step","title":"creating a \"storage account\" tutorial step-by-step.","text":"<ol> <li>Log-in to the Azure portal if you have not already:  https://portal.azure.com</li> <li>Click the menu (top left, three horizontal bars) to open it</li> <li>Select \"home\" from the menu - this ensures we all have the same view</li> <li>In the upper part of the screen is a list of \"Azure Services\" : click \"create a resource\" \\    Yes we could have click \"storage accounts\" instead but we want to demonstrate how to use the next screen...</li> <li>This \"create a resource\" screen is where you can create almost any service Azure offers, and additional services created by third-parties or companies that are not Microsoft.   When you are starting, ensure you are creating a service from Microsoft (we'll show you how in the next step)</li> <li>Note there are now two search bars: one at the top of the screen, and on a bit lower titled \"Search services and marketplace\" - use that second search bar</li> <li>in the lower search bar, type \"Storage account\"   Note that \"storage\" alone lists many other kinds of resources. </li> <li>You may see a list of several services, select (click) the first one labelled \"Storage account\" (icon looks like a green spreadsheet).   </li> <li>The description of the service will say the provider, which should be Microsoft, if not go back using the back button and search for storage account again. </li> <li>Click \"create\" under \"Storage account\"</li> <li>The azure resource creation screens mostly work like this:   there are so many settings Azure has split these up into groups which are listed horizontally across the top.   You may work though these by clicking each group, OR finish a screen, and click \"Next..\" button on the bottom of the form.   At any time you may click \"Review and Create\" and if you've missed some crucial setting, Azure will not let you create the resource without fixing it.  We will go page-by-page for these settings</li> <li> <p>Basics: </p> <ol> <li>Subscription: Cloud Computing Fellowship</li> <li>Resource Group: Select your resource group (you may only have the one) \\     You may see a \"create new\" link below that but it may not work and for this tutorial we using an existing resource group</li> <li> <p>Storage Account Name:  </p> <ul> <li>some resources have restrictions on naming.  Next to storage account is an \"i\" in a circle that has more information.  For storage accounts, they must be unique in region, and only numbers and  lowercase letters are allowed.  I don't know if Non-US letters are allowed (e.g.\u7bb1)</li> <li>use your MSU ID (NetID) when you name things so help me keep track and also to help find a name that is unique.  So, replace \"NETID\" with your MSU NetID here:  \"stNETIDccf22\"   e.g. stbillspatccf22</li> <li>If you are repeating this tutorial, simply add a \"2\" or \"B\" e.g. \"stbillspatccf22B\"  We can delete these experiments later.  </li> </ul> </li> <li> <p>Region (Location):  You may leave US East.  Click in here to see the options.   In practice, pick the region that is closest to you or where your data will be moving to (e.g. North Central US for MSU) but there are other considerations. </p> </li> <li>select Performance: Standard</li> <li>Redundancy: change from GeoRedundant to \"Locally Redundant\" (LRS).  We won't see a difference, and LRS is cheaper \\</li> <li>beneath that, leave the \"make read access....\" box checked. </li> <li>Click \"next...Advanced\"</li> <li>Advanced: Leave all of these settings as-is.  click 'next...'  </li> <li>Networking: leave all of these settings as-is for this tutorial. click 'next...'</li> <li>Data Protection: leave all as is.  These settings allow you to recover files up to 7 days after deleting or over-writing. click 'next...'</li> <li>Encryption: leave all as is.  click 'next...'</li> <li>Tags</li> <li>tags are optional but, eventually highly recommended.  For now you can leave them blank.  </li> <li>Review and create</li> <li>review gives you a chance to double check your settings before committing</li> <li>click \"create\"</li> <li>Deployment</li> <li>Azure calls the process of creating cloud resources a \"deployment.\"   This term comes from the software engineering process of first \"building\" an application or utility (or \"compiling\" which is often not necessary for scripting languages like Python or R) and then moving that application onto the IT servers that make it available.  On your own computer you download software that is already \"built\" (e.g. MS Word) and installing it is a form of deployment.   </li> <li>Deployment takes a while as the Azure Resource Manager takes your order and runs the code to generate the cloud resource you've described. </li> <li>You may leave this page and the deployment will continue in the background.   </li> <li>finish and review</li> <li>When the deployment is complete, in the top bar of the Azure portal, You'll see a number badge on the  \"Notification\" icon indicating the number of messages you have (probably just 1 ).   Click on the Notifications icon to show this message.   </li> <li>the message should be something like:          Deployment succeeded         Deployment 'resourcename_12345678901234' to resource group 'group name' was successful.</li> <li>\"Go to Resource\" button will open the Portal page with options for the resource</li> <li>\"Pin to Dashboard\" will create a  new tile that is a shortcut to this resource on your dashboard for easy access.   If you want to experiment with dashboard arranging then it's ok to click this and easy to remove later from your Portal Dashboard (it will be added to the bottom)</li> </ol> </li> <li> <p>Examine Resource (storage )     We have not talked about how storage works but the storage resource page is a good example to learn how the Portal is organized.  </p> <ol> <li>If you didn't already click \"go to resource\", open the top menu and click \"home\"</li> <li>the Portal \"Home\" has a list of \"recent resources\" and this should be at the top.  </li> <li>Click on this new cloud storage to view aa</li> </ol> </li> </ol>"},{"location":"session_how_to_cloud/azure_portal_walkthrough/#about-portal-resource-pages","title":"About Portal \"Resource\" Pages","text":"<p>Most cloud resources in the portal have a list of categories on the left side, and pages for each category in the center.  The first page is the \"Overview\"  which has the resource group, subscription, and other info important for that resource.   this followed by the \"Activity Log\" showing how the resource has been used.   Each of the following items on the left side is a new page of additional options to alter how the resource is configured.  For example if you click the \"tags\" section you see the tags you added (if any) and can modify or add new tags. </p> <p>Some of the options are not available on the forms when you create the resource, or the names of the options on these resource pages do not match the forms when you created the resources.   In that case you may have to use two steps to configure the resource as you like, or better consider using a programmatic interface</p> <p>Again we did not discuss any of the characteristics of cloud storage or how to use it but you should now have enough familiarity with the azure portal to follow other tutorials to create and use storage or other resources.  </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/","title":"Exercise: Creating and Connecting to a Virtual Machine (VM) for both Windows and Linux","text":"<p>Link to Video for the Windows version of exercise.  On mediaspace.msu.edu which requires a log-in</p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal.  </p> <p>There are two nearly identical activities, and you only need complete one of them:  </p> <ol> <li>creating a Windows virtual machine and connecting with a graphic interface (GUI), namely Remote Desktop (rdp) to demonstrate how you may use full graphic software (like Rstudio, Matlab, etc) on a cloud computer</li> <li>creating a Linux Virtual machine and connection with the command line to demonstrate how you may use a terminal interface (or scripting) on a cloud computer.   </li> </ol> <p>We will use a pre-configured virtual machine with software already installed for both versions.  When creating a VM you can use an Azure template and there are many of these.  The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available.   For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/   and for the list of tools installed, see https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included  Azure has a new product called \"Azure Machine Learning\" that we may cover in a future session. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-both-activities","title":"Requirements for both activities","text":"<p>You need an Azure account with an active subscription, and a resource group of your own to work in.   Fellows have these things provided.  </p> <p>This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough.  In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise.  For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section</p> <p>It's helpful to have basic understanding of the \"Client-Server\" model of computing as the VM we create will be running servers (remote desktop server for Windows, and ssh command line server for Linux)</p> <p>Finally we find that there are many layers of concepts related in this exercise related to IT Infrastructure, and we are happy to provde clarification as needed. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-windows-virtual-machine","title":"Creating a Windows Virtual Machine","text":"<p>This section is based on Windows, and is recommended for everyone as it is the easy way to connect to remote machine.    For an equivalant exercise based on Linux, scroll down.  If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements-for-windows-vms","title":"Requirements for Windows VMs","text":"<p>To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client.  </p> <ul> <li>MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12</li> <li>Linux users install http://xrdp.org/</li> <li>Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.</li> </ul>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select **Data Science Virtual Machine - Windows 2019 **</p> <p>The \"Plans\" section has a description of the template if you would like to know more. </p> <p>Click the \"start with a pre-set configuration\" option. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-select-the-pre-set-configuration","title":"2. select the pre-set configuration","text":"<p>These configurations help to select your VM size based on your activity.  We will use the default options and click \"Continue to create a VM\" </p> <p>The options do not affect the outcome of the exercise so at this step explore each option</p> <p>Click \"Continue to create a VM\"</p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","title":"3. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid).  As we create additional resource groups for this </p> </li> <li> <p>Virtual machine name  Name: CF21-netid-dsvmtest    One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing.   In the name above, replace \"netid\" with your own MSU netid.  Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \" Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future. </p> </li> <li> <p>Region  Select \"(US) North Central US\"</p> </li> <li> <p>Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. </p> </li> <li>Image should be \"Data Science Virtual Machine - windows...\"   if this is change you may </li> <li>Azure Spot Instance  leave unchecked.   </li> <li>Size   You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step.     This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00  </li> <li>Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.   Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. <ul> <li>username : use any user name you will easily remember, perhaps your netid</li> <li>password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use</li> </ul> </li> <li>Licensing  Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure.   Leave this box unchecked and Azure will add the extra charges (a few cents per hour) for the use of Windows.    </li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages except for Basics page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags","title":"Tags","text":"<p>For this exercise, using tags will be essential for identifying which components go to which VM.  If you need more information see session 2 page  for a readings about tags.   Do the following: </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2_vm</code> or similar unique value. </li> <li>click \"review and create\" </li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this VM.  Mine says <code>0.1920 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p> <p>You should kkip down the the Viewing VM Resources section below/ </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#optional-creating-a-linux-virtual-machine","title":"Optional:  Creating a Linux Virtual Machine","text":"<p>This sections is nearly identical to the section above with Windows, but uses Ubuntu Linux, and does not use a graphical interface (although with some work this is possible). </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#requirements","title":"Requirements","text":"<p>To connect to Linux you need an terminal or command line interface with an <code>ssh</code> client software.  If you have used the MSU HPC, this is the same method for connection.  </p> <ul> <li>On Mac, the Terminal.app has ssh</li> <li>On Modern version of Windows, the cmd.exe command prompt has an <code>ssh</code> command built in</li> <li>Linux desktop/laptops come with an ssh client</li> </ul>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#creating-a-linux-virtual-machine","title":"Creating a Linux Virtual Machine","text":"<p>If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#1-selecting-the-resource-template_1","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select Data Science Virtual Machine - Ubuntu 20.04</p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#2-configure-the-vm-using-the-azure-portal","title":"2. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#basics_1","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid). </p> </li> <li> <p>Virtual machine name  Name: dsvm-YOURNETID-ccf22    Use your actual NetId , for example \"dsvm-billspat-ccf22\"</p> </li> </ol> <p>Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \"</p> <p>Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future. </p> <ol> <li>Region  You may select \"(US) North Central US\" or any other US-based region.   </li> <li>Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message. </li> <li>Security Type Leave as 'standard'</li> <li>Image should be \"Data Science Virtual Machine - Unbuntu..\"   if this is changed you may have to select it again from the list.   Any Linux image is fine for this tutorial as </li> <li>Run with Azure Spot discount  leave unchecked.   </li> <li>Size   You can leave the size that is currently selected, which is based on the pre-set configuration from the previous step.       This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00   Click \"see all sizes\" if you are feeling adventurous --  there are maybe 100 options.  (click the  <code>[x]</code> in upper right to close the size selector window)</li> <li>Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.   </li> <li>Authentication Type  For the purpose of this exercise, select \"password\"  SSH Keys are strongly recommened but to keep this simple we will use a password. </li> <li> <p>UserName Select a User name and account that you will easily remember, because you will need it to log-in to the new VM. You can use your MSU NetID for your username so it's easy to remember.</p> </li> <li> <p>password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use</p> </li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#disks-and-other-settings_1","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages, except for 'Basics' page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#tags_1","title":"Tags","text":"<p>Using the Azure portal to create VM creates several resources (up to 12).  Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources.  I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources.   </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2</code></li> <li>click \"review and create\" </li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#review-and-create_1","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this Linux VM.  Mine says <code>0.0730 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p> <p>Linux Users continue to the next section</p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#viewing-vm-resources-in-your-resource-group-windows-and-linux","title":"Viewing VM Resources in your Resource group (Windows and Linux)","text":"<p>While the deployment is in progress you may explore the operation details or click any of the resources that have been created. </p> <ol> <li>Open your resource group in the portal:  <ol> <li>click the portal menu on the top left, and select \"resource groups\"</li> </ol> </li> <li>From the list, select your CF21 group. </li> <li>When the deployment is finished, you should see several new resources <ul> <li>They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip </li> <li>The second column is the \"type\" which helps identify what they are</li> </ul> </li> </ol> <p> click for a large view in a new tab/window</p> <ol> <li>Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)</li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#the-vm-resource-page","title":"The VM Resource Page","text":"<p>To see the details for your virtual machine, click the VM in your resource group if you haven't already. </p> <p> click for larger view</p> <p>There are many details here but some immediate things to notice: </p> <ul> <li>in the top row are buttons to connect, start, restart and stop the vvm.   </li> <li>in the top, \"essentials\" section the  \"status\" should be \"running.\"</li> <li>on the right side is the assigned IP address which you need to connect.   Highlight and copy and paste this address.   If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)</li> </ul>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting","title":"Connecting","text":""},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-windows-vm-using-remote-desktop-protocol-rdp-client","title":"Connecting to a Windows VM using Remote Desktop Protocol (RDP) client","text":"<p>You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both.  </p> <p>Every VM created in Azure has an \"IP Adress\" or internet address, and we use this to connect to.  </p> <p>The following Azure documentation describes how to connect to a Windows VM:  https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon</p> <p>Here are more detailed instructions: </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with RDP  (remote desktop protocol)  is a Microsoft method for connecting to the graphical desktop.  For Mac/Linux requires additional software (mentioned at the beginning of this page).  </p> <ul> <li> <p>In the Azure portal:</p> <ul> <li>click \"connect\" and select \"rdp\" if it isn't already.  </li> <li>click \"download RDP file\" button and save the <code>.rdp</code> file anywhere on your computer that you find it again</li> </ul> </li> <li> <p>On your computer:</p> <ul> <li>after it's downloaded, find the  <code>.rdp</code> file and double click to open it which should start your remote desktop software.   Mac users must have installed the Microsoft Remote Desktop client app </li> <li>ignore any security or error messages, click \"connect\"</li> <li>Enter the user name and password you used when you created the VM. </li> </ul> </li> <li> <p>Alternatively you may also open your RPD software, create a new connection, and copy the IP address listed in the portal, in the Azure VM.  and paste the IP address that is listed on the resource page for the VM.   </p> </li> </ul> <p></p> <ul> <li>When you connect, if the VM is not running, you will get an error message.  Here is what the Windows screen looks like: </li> </ul> <p></p> <p>This is because we are using a temporary certificate but it is secure.  Click \"Yes\" </p> <ul> <li>Enter the Username and password you used when  configuring the VM in the \"Basics\" section above.  <ul> <li>you may be able to simply enter the user name and password directly</li> <li>If not, in the  Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK.  If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. </li> </ul> </li> </ul> <p>Once you connect, you may see Windows starting up and installing things.  Feel free to close any windows.  Once the installations are finished, you may use the machine as you would any other windows computer.  If you type Rstudio in the search box, you may launch an  Rstudio session on this remote computer.    It also has Python, many python libs and Jupyter notebook.  </p> <p>We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p> <p>Optional: Connect to the Windows DSVM with ssh </p> <p>This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH.   If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter <code>ssh &lt;username&gt;@&lt;ipaddress&gt;</code></p> <p>Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page.   </p> <p>This is similar to how you connect to the MSU HPC, if you are HPC user. </p> <p>You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. </p> <p>When you log-in you will be connected to the Windows command prompt (e.g. <code>C:\\Users\\username&gt;</code> </p> <p>To Exit, type <code>exit</code> at the command prompt. </p> <p>Next Steps: For information on turning off the VM and for eventually deleting the VM, scroll down below the Linux section as these operations are the same in the Azure portal for Linux or Windows virtual machines.  </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#connecting-to-a-linux-vm-using-ssh","title":"Connecting to a Linux VM using SSH","text":"<p>We will connect and use this remote VM running the Linux operating system with a command line connection.  It is possible to use a graphical connection but requires additional setup beyond the scope of the short exercise.  </p> <p>In addition this assumes you have some familiarity with using the command line and starting your terminal program.  </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with SSH </p> <p>this is the standard method of connecting with ssh, but we've included as much detail as possible for those who are new to using ssh. </p> <ul> <li>On the main \"overview\" page of the VM resource, find the \"Public IP Address\" on the top right side.   Copy this IP address to the clipboard, or make a note of it.   Mine was 20.98.28.63.   Note that these VMS also have an internal IP address that start with 10.x.x.x that will not work for connecting from your laptop.  Use the Public IP address.  not all VMs have a public IP address but this one will.  </li> <li>also make a note of the User ID and password you used to create the VM above</li> <li> <p>side note, in the \"connect\" form of the VM resource pages, it describes how to use an ssh key,  even though we did not create an ssh key when we created a VM.  If you did not create an ssh key, you do not need to follow these instructions. </p> </li> <li> <p>on your desktop/laptop, start your terminal program on MacOS/Linux or <code>cmd.exe</code> if you using Windows. </p> </li> <li>Enter the command as displayed, which is something like <code>ssh vmusername@vmipaddress</code>   In my case, my command is <code>ssh patbills@20.98.28.63</code></li> <li>If this is the first time connection, you'll get the standard ssh warning <code>\"The authenticity of host '20.98.28.63 (20.98.28.63)' can't be established.\"</code> simply say \"yes\" and enter</li> <li>Enter the password you used when  configuring the VM in the \"Basics\" section above.  (note that ssh does not show any key movement or * when you type a password)</li> <li>it takes a while to connect for the fist time as the VM configures software and prepares your user account</li> </ul> <p>You may use the machine as you would any other linux computer. For more information about what software is installed, see  We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#starting-and-stopping-the-vm-both-windows-and-linux","title":"Starting and Stopping the VM (both Windows and Linux)","text":"<p>There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use  Windows to turn it off.  The VM is then \"stopped.\"   In a Linux ssh session you may use a command like <code>sudo shutdown -h now</code>   When the Operating system is shut off, and hence tthe VM is not running, but it is still \"allocated.\"  When you turn it back on, it will come on immediately.  1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM.  Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up.  This is cheaper then the first method in the long run 1. Delete it.   </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#stopping-deallocating-the-vm-with-the-portal","title":"Stopping (deallocating) the VM with the Portal:","text":"<ol> <li>Go to the resource page for the VM, if you are not already. </li> <li>If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. </li> <li>The Status field near the top of this screen will indicate running or stopped.  </li> <li>Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. </li> <li>There is a warning about losing your IP address, with a check box to reserve it.<ul> <li>If you plan on deleting the VM now, click \"ok\"</li> <li>If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK</li> <li>The default is to use a \"dynamic\" address which is assigned every time you turn on the VM</li> <li>When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine</li> <li>the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. </li> <li>you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal</li> <li>Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off.  That is approx $2.70/month</li> </ul> </li> <li>It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep.   The main reason for this is for security.  </li> </ol>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#deleting-the-resources-both-windows-and-linux","title":"Deleting the Resources (both Windows and Linux)","text":"<ol> <li>Open the Resource group as above</li> <li>When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify.   Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button)</li> <li>If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\"  For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views .  If you add filter on tag, then you may select all the items that are shown, and delete those. </li> <li>after selecting confirm the deletion by typing \"yes\"</li> </ol> <p>Creating resources just to delete them may seem wasteful however we will cover how to save a \"snapshot\" and/or \"image\" of your VM's disk so that you may re-use any work to install and configure software withtout incurring charges.  </p>"},{"location":"session_how_to_cloud/azure_vm_walkthrough/#more-references","title":"More References","text":"<p>Azure has very abbreviated versions of this exercise if you would like another perspective.  They assume you can create your own resource group (which you don't have the ability to do currently in the fellowship)  </p> <p>https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview#next-steps </p> <p>**Data Science Use Case Tutorials from Azure: **</p> <ul> <li> <p>Windows: This tutorial uses products that Azure no long supports, and for Windows users they really push to use their \"Azure Machine Learning\" product.   However the Windows DSVM offers a really fast way to get access to a windows desktop graphical interface  https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things </p> </li> <li> <p>Linux: https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough</p> </li> </ul> <p>If you follow these, just remember to delete the resources you create when you are done exploring</p> <p>Return to the Session 2 page</p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/","title":"Exercise: Creating a Windows Virtual Machine (VM)","text":"<p>Please see our updated version that covers both Windows and Linux</p> <p></p> <p>Link to Video for this exercise on mediaspace.msu.edu (requires log-in)</p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#about","title":"About","text":"<p>This is an exercise and introduction to creating Virtual Machines (VMs) and related resources using the Azure Portal.  This exercise assumes you understand how to use the Azure Portal, which is covered in the Azure Portal Walkthrough.  In addition it's helpful to know what a virtual machine is but it's not crucial to complete the exercise.  For more information on VMs see the slides from session 2 and readings from the \"Virtual Machine Background\" section</p> <p>We will use a pre-configured virtual machine with software already installed.  When creating a VM you can use an Azure template and there are many of these.  The Data Science Virtual Machine (DSVM) from Azure has R, Python and many data science and statistical libraries available.   For more information about the Azure DSVM see https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/</p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements","title":"Requirements","text":"<p>You need an account in azure with an active subscription, and a resource group of your own to work in.   Fellows have these things provided.  </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-and-connecting-to-a-windows-virtual-machine","title":"Creating and Connecting to a Windows Virtual Machine","text":""},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#requirements_1","title":"Requirements","text":"<p>To connect to a Windows VM desktop, it's recommend you use the Microsoft Remote Desktop client.  </p> <ul> <li>MacOS : install the Microsoft Remote Desktop Client, only available on the App Store: https://apps.apple.com/app/microsoft-remote-desktop/id1295203466?mt=12</li> <li>Linux users install http://xrdp.org/</li> <li>Windows Users ensure you have the client : In the search box on the taskbar, type Remote Desktop, and then select Remote Desktop Connection.</li> </ul>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#creating-a-windows-virtual-machine","title":"Creating a Windows Virtual Machine","text":"<p>If at any point, or if you are exploring, you can't seem to get the configuration correct (or there is a validation error you can't fix), starting over will not create any resources or incur charges.   Go back to step 1 below. </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#1-selecting-the-resource-template","title":"1. Selecting the Resource Template","text":"<p>In the Azure Portal open the top left menu, and click \"+ Create a resource\" option (the first option)</p> <p>In the create resource search box, type \"data science virtual machine\"</p> <p>In the options select **Data Science Virtual Machine - Windows 2019 **</p> <p>The \"Plans\" section has a description of the template if you would like to know more. </p> <p>Click the \"start with a pre-set configuration\" option. </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#2-select-the-pre-set-configuration","title":"2. select the pre-set configuration","text":"<p>These configurations help to select your VM size based on your activity.  We will use the default options and click \"Continue to create a VM\" </p> <p>The options do not affect the outcome of the exercise so at this step explore each option</p> <p>Click \"Continue to create a VM\"</p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#3-configure-the-vm-using-the-azure-portal","title":"3. Configure the VM using the Azure Portal","text":"<p>The resource creation forms work as described in the Azure Portal but since we used a pre-set configuration some of the values will be completed. </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#basics","title":"Basics","text":"<ol> <li> <p>The Subscription should be \"Cloud Computing Fellowship\" and resource group should be your CF resource group (with your netid).  As we create additional resource groups for this </p> </li> <li> <p>Virtual machine name  Name: CF21-netid-dsvmtest    One option is to combine the project (e.g. the fellowship), your net id, and some description of what you are doing.   In the name above, replace \"netid\" with your own MSU netid.   </p> </li> </ol> <p>Note that different resources have different naming restrictions.  For example VMs the rules are \"can be almost anything, but Azure resource names cannot contain special characters \\/\"\"[]:|&lt;&gt;+=;,?*@&amp;, whitespace, or begin with '_' or end with '.' or '-' \"</p> <p>Note if you have an existing VM with this name, add a number 2 or other suffix.  We will delete this VM and create something more suitable in the future.  1. Region  Select \"(US) North Central US\" 1. Availability Options select \"No infrastructure Redundancy required\"    this option is for critical infrastructure that needs to withstand a serious outage (e.g. if a hurricane affects a data center).    You may also see an \"availability zone\" option appear (perhaps with an error message \"The value must not be empty\").  Selecting \"\"No infrastructure Redundancy required\" in the availability zone will remove the \"availability zone\" field and error message.  1. Image should be \"Data Science Virtual Machine - windows...\"   if this is change you may  1. Azure Spot Instance  leave unchecked.  1. Size   You can leave the size that is currently selected.     This is how you select the specifications for CPU and memory.  The size you for this exercise doesn't matter for the outcome, but it will show prices which may be interesting.  If you click this drop-down menu you may see some other sizes and prices.  The Monthly price assumes 24 hour/day operation.  Your price to experiment will often be less than $1.00 1. Administrator Account    Just like you need to log-in to your own computer, you must create a user account for the VM.   Select a User name and account that you will easily remember, because you will need it to log-in to the new VM.      * username : use any user name you will easily remember, perhaps your netid     * password : something you can remember, but is complex to be secure.  Do not use your MSU password or any other passwords you use 1. Licensing  Unlike Linux, Windows requires a license, and this option are for organization with an arrangement with Azure.   Leave this box unchecked.  </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#disks-and-other-settings","title":"Disks and Other Settings","text":"<p>For this exercise we'll be using the default values for almost all the pages except for Basics page.    However you are encouraged to look through these options to see what is involved in creating a virtual machine.  The Azure VM documentation covers many of them.   For example a VM requires several networking components.   The good news is that Azure will name and create these for you, which will see.  </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#tags","title":"Tags","text":"<p>Using tags will be essential for identifying which components go to which VM. This is the metadata associated with these resources.  I suggest using a tag like \"activity\" to indicate which of our activities was used to create these resources.   </p> <ol> <li>Click \"tags\" in the top row of options (just before 'review and create')</li> <li>In the first row, For Name, type <code>activity</code> and for the Value type  <code>session2</code></li> <li>click \"review and create\" </li> </ol>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#review-and-create","title":"Review and Create","text":"<p>If there are errors the form name will have a red dot next to it.  Go back to that form and see what may be the issue. </p> <p>If the Validation passed, it will display the approximate hourly cost to use this VM.  Mine says <code>0.1920 USD/hr</code></p> <p>Click \"Create\" and the deployment will start.  It will take at most 15 minutes.  </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#4-the-resources","title":"4. The Resources","text":"<p>While the deployment is in progress you may explore the operation details or click any of the resources that have been created. </p> <ol> <li>Open your resource group in the portal:  <ol> <li>click the portal menu on the top left, and select \"resource groups\"</li> </ol> </li> <li>From the list, select your CF21 group. </li> <li>When the deployment is finished, you should see several new resources <ul> <li>They will have the same name prefix \"CF21netid-dsvm\" but may have a suffix indicating the kind of resource (e.g. CF21-netid-dsvm1-ip </li> <li>The second column is the \"type\" which helps identify what they are</li> </ul> </li> </ol> <p> click for a large view in a new tab/window</p> <ol> <li>Select the item with type \"virtual machine\" and click on the name to open its resource page (for example, cf21-billspat-dsvmtest item in the screenshot above)</li> </ol>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#5-the-vm-resource-page","title":"5. The VM Resource Page","text":"<p>To see the details for your virtual machine, click the VM in your resource group if you haven't already. </p> <p> click for larger view</p> <p>There are many details here but some immediate things to notice: </p> <ul> <li>in the top row are buttons to connect, start, restart and stop the vvm.   </li> <li>in the top, \"essentials\" section the  \"status\" should be \"running.\"</li> <li>on the right side is the assigned IP address which you need to connect.   Highlight and copy and paste this address.   If you click the link on the address, it will take you to a new resource page just for the IP address (which is a distinct resource assigned to this VM resource)</li> </ul>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#6-connecting","title":"6. Connecting","text":"<p>You may connect to this VM running the Windows operating system with either graphical desktop, a command line connection, or both.  </p> <p>The following Azure documentation describes how to connect to a Windows VM:  https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon</p> <p>Here are more detailed instructions: </p> <p>There is a 'connect' link above the 'essentials' list, and a connect link on the left side - they both go to the same place. </p> <p>Connect with RDP  (remote desktop protocol)  is a Microsoft method for connecting to the graphical desktop.  For Mac/Linux requires additional software (mentioned at the beginning of this page).  </p> <ul> <li>Click \"connect\" and select \"rdp\" if it isn't already.  </li> <li>click \"download RDP file\" button and save the <code>.rdp</code> file anywhere on your computer that you find it again</li> <li> <p>after it's download, and if you Mac users have installed the RDP client, then double click the <code>.rdp</code> file to open your remote desktop software. </p> </li> <li> <p>On windows, any security or error messages, click \"connect\"</p> </li> <li> <p>Alternatively you may also open your RPD software without downloading the RDP file, and copy the IP address listed on and paste the IP address that is listed on the resource page for the VM</p> </li> </ul> <p></p> <ul> <li>When you connect, if the VM is not running, you will get an error message.  Here is what the Windows screen looks like: </li> </ul> <p></p> <p>This is because we are using a temporary certificate but it is secure.  Click \"Yes\" </p> <ul> <li>Enter the Username and password you used when  configuring the VM in the \"Basics\" section above.  <ul> <li>you may be able to simply enter the user name and password directly</li> <li>If not, in the  Windows Security window, select More choices and then Use a different account. Enter the credentials for an account on the virtual machine and then select OK.  If the user account you entered does not work, you may have to put your user account in domain\\username form, and in this case, the domain is the name of the virtual machine and it is entered as vmname\\username, with a back-slash in-between, and with the same password. </li> </ul> </li> </ul> <p>Once you connect, you may see Windows starting up and installing things.  Feel free to close any windows.  Once the installations are finished, you may use the machine as you would any other windows computer.  If you type Rstudio in the search box, you may launch an  Rstudio session on this remote computer.    It also has Python, many python libs and Jupyter notebook.  </p> <p>We will cover how to transfer code and files to a VM in a later session. </p> <p>When you finished with your remote session you may simply close the remote windows (leaving the VM running.  See below for how to turn it off and delete it. </p> <p>Optional: Connect to the Windows DSVM with ssh </p> <p>This windows machine has an SSH Server running, and the security settings from the pre-configured version allow connections from SSH.   If you are familiar with ssh and the command line, you may start the CMD.EXE on your windows computer, or the Mac Terminal, and enter <code>ssh &lt;username&gt;@&lt;ipaddress&gt;</code></p> <p>Where the username is the user you put for your VM when you created it, and the Public IP address is listed on the VM Resource page.   </p> <p>This is similar to how you connect to the MSU HPC, if you are HPC user. </p> <p>You will be asked to add the host to your list hosts, and enter the password you used when you created the VM. </p> <p>When you log-in you will be connected to the Windows command prompt (e.g. <code>C:\\Users\\username&gt;</code> </p> <p>To Exit, type <code>exit</code> at the command prompt. </p>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#7-starting-and-stopping-the-vm","title":"7. Starting and Stopping the VM","text":"<p>There are three ways to \"stop\" or turn off a VM. 1. when connected to it, e.g. in the remote desktop, use  Windows to turn it off.  The VM is then \"stopped.\"  The VM is not running, but it is still \"allocated.\"  When you turn it back on, it will come on immediately.  1. Use the Azure portal to \"stop\" the VM which shuts down Windows (gracefully if possible) and 'deallocates' the VM.  Restarted the VM appears to be the same process, but Azure must allocate resources first to run it, then power it up.  This is cheaper then the first method in the long run 1. Delete it.   </p> <p>Stopping (deallocating) the VM with the Portal: </p> <ol> <li>Go to the resource page for the VM, if you are not already. </li> <li>If you are just entering the portal, find your resource group, find the VM in your resource group (identified as a VM in the \"type\" column of the list of resources), and click to open the resource page. </li> <li>The Status field near the top of this screen will indicate running or stopped.  </li> <li>Find the Start and Stop buttons near the top of this screen and click \"stop\" if the machine is running. </li> <li>There is a warning about losing your IP address, with a check box to reserve it.<ul> <li>If you plan on deleting the VM now, click \"ok\"</li> <li>If you plan on restarting the VM and reconnecting, first check the box \"reserve the IP\" then click OK</li> <li>The default is to use a \"dynamic\" address which is assigned every time you turn on the VM</li> <li>When using a dynamic address, you must copy/paste the ip address, or re-download the RDP connection file everytime you restart the machine</li> <li>the solution is to use a \"Static IP\" either when you create the VM, or assigning one after the VM is created. and checking the box does so. </li> <li>you can also convert to a static IP with the portal, but it is not a straightforward process, see https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-static-private-ip-arm-pportal</li> <li>Pricing for a static ip is here: https://azure.microsoft.com/en-us/pricing/details/ip-addresses/ which as of now is $0.0036/hour which is charged even if the VM is turned off.  That is approx $2.70/month</li> </ul> </li> <li>It's a good idea to leave VMs in a \"stopped (deallocated)\" state if you are not using them for computations or providing a service, just as you would turn off or put your laptop to sleep.   The main reason for this is for security.  </li> </ol>"},{"location":"session_how_to_cloud/azure_windows_vm_walkthrough/#8-deleting-the-resources","title":"8. Deleting the Resources","text":"<ol> <li>Open the Resource group as above</li> <li>When creating resources using the template as we did above, the resources associated with this VM will all start with the same prefix, so they are easy to identify.   Select them with checkboxes, and click the \"Delete\" button which is on the top right of the screen (not the \"delete resource group\" button)</li> <li>If it's not obvious which resources are all included, you may also use the \"tag\" you created to filter what is listed and only show those with the same \"tag.\"   For more information see https://docs.microsoft.com/en-us/azure/azure-portal/manage-filter-resource-views .  IF you add filter on tag, then you may select all the items that are shown, and delete those. </li> <li>after selecting confirm the deletion by typing \"yes\"</li> </ol>"},{"location":"session_introduction/","title":"MSU Cloud Computing Fellowship 2022-23","text":""},{"location":"session_introduction/#1-introduction-to-the-2022-23-msu-cloud-computing-fellowship","title":"1: Introduction to the 2022-23 MSU Cloud Computing Fellowship","text":"You don't have to face the clouds alone"},{"location":"session_introduction/#welcome","title":"Welcome!","text":"<p>This is the first 'session' of the MSU Cloud Computing Fellowship (CCF) for 2022-2023.  For a description of the program and how sessions are organized, see the CCF home page</p> <p>The goals of this introductory session are to orient you to this program, introduce ourselves to each other, provide some background on cloud computing, set up our technology, and discuss what all of our expectations are.  </p> <p>If possible during the first week of this semester, please complete the following activities prior to our first synchronous meeting September 2.   If you have any issues, trouble with these activities, or won't be able to attend the introductory meeting, or have any questions at all about your participating in the fellowship, please contact us.  </p>"},{"location":"session_introduction/#activities","title":"Activities:","text":"<p>Introduce yourself on Microsoft Teams</p> <p>You should have all been given access to a Team \"MSU ICER Cloud Computing Fellowship\" via your NetID.    </p> <ul> <li>Please log in to Teams (via the web https://teams.microsoft.com/ or using the Teams client)</li> <li>Post a new message in the \"general\" channel just saying \"hello\" and include your name, department and how you prefer to be addressed.   </li> <li>If necessary MSU IT has documentation about MS Teams here:  https://tech.msu.edu/technology/collaborative-tools/spartan365/  ( the link on that page requires yet another MSU log-in)</li> </ul> <p>Confirm Access to Azure Portal</p> <ul> <li>Go to https://portal.azure.com.</li> <li>Log in with your MSU netid and password.</li> <li>Ensure you can access the Azure main web \"portal.\"  </li> <li>You don't need to (and shouldn't) create any new resources or work with this website; simply confirm you have access.   You may see a list of \"resources\" and will introduce Azure during our first meeting. </li> </ul>"},{"location":"session_introduction/#readings","title":"Readings","text":"<ul> <li>Chapter 1: Orienting in the cloud universe from \"Cloud Computing for Science and Engineering\", Foster and Gannon      ( Alternative link to publisher preview chapter  )</li> <li>Using Cloud Computing for Academic Research, Mahmoud Parvizi (draft version).   </li> <li>Optional Historical Note Who Coined 'Cloud Computing'? by Antonio Regalado, October 2011, MIT Technology Review</li> </ul>"},{"location":"session_introduction/#introductions","title":"Introductions","text":"<ul> <li>Mahmoud Parvizi, Instructor &amp; Research Consultant, ICER<ul> <li>Past experience &amp; current role</li> <li>Cloud facilitator</li> <li>Participant in first Fellowship cohort</li> </ul> </li> <li>Patrick Bills, Instructor &amp; Staff, Data Management &amp; Analytics Data Science Team. </li> <li>Brian O'shea, Director, MSU Institute for Cyber-Enabled Research (ICER)</li> <li>Danielle Barnes, Associate Director, Data Management &amp; Analytics (DMA), MSU IT Services. </li> </ul> <p>A video of our introductions recorded in 2021 is avaialble on MSU MediaSpace (requires MSU log-in).   </p>"},{"location":"session_introduction/#participant-introductions-discussion","title":"Participant Introductions &amp; Discussion","text":"<p>Introductions from the 2022-23 Cloud Computing Fellows:</p> <ul> <li>About you: your preferred name and pronouns, which degree program or department if faculty. </li> <li>Research synopsis and methods</li> <li>Previous experience with reseach computing including cloud computing (if any)</li> <li>Current research computing hurdles, roadblocks, challenges &amp; triumphs</li> <li>Your goals for this fellowship<ul> <li>For example, how could cloud computing support yuor research?  What do you think the cloud is or is good for, in general?</li> </ul> </li> </ul>"},{"location":"session_introduction/#fellowship-program-overview","title":"Fellowship Program Overview","text":"<p>Review our \"syllabus\" on the home page of this website for the schedule and topics we will cover.   </p> <p>Program synopsis:</p> <ul> <li>Fall semester materials, activities, seminars and discussions (Pat Bills):    <ul> <li>Goal, scope and expectation;</li> <li>structure (pre-session materials and activities, \"textbook\");</li> <li>in-person meeting approx bi-weekly and excluding holidays;</li> <li>our expectations.</li> </ul> </li> <li>Winter/Spring semester Projects (Mahmoud Parvizi):<ul> <li>Goal, scope and expectation;</li> <li>Proposal write-up and presentation early January;</li> <li>Check-points to discuss progress and hurdles</li> <li>Office hours &amp; help</li> <li>Final presentation during Symposium late april</li> </ul> </li> </ul>"},{"location":"session_introduction/#goals","title":"Goals","text":"<p>Help you get an understanding of:</p> <ul> <li>what is cloud computing?</li> <li>what is cloud computing useful for? </li> <li>when should it use it for my research computing?</li> <li>how can I use it?</li> <li>Understanding of the context of the technology we are learning about.   </li> </ul> <p>Help you get some practical experience</p> <ul> <li>apply cloud to some aspect of your own research</li> <li>apply cloud to generic/canned research-like problem</li> </ul> <p>Non Goals:</p> <ul> <li>prepare you for a cloud computing certification (there are many existing resources for that.  )</li> <li>become experts in everything </li> <li>build a dot-com empire</li> <li>cover all aspects of cloud</li> </ul>"},{"location":"session_introduction/#introduction-to-computing-and-cloud-computing","title":"Introduction to Computing and Cloud Computing","text":"<ul> <li>Seminar, Pat Bills</li> <li>References: <ul> <li>The NIST definition of cloud computing </li> </ul> </li> <li>Discussion </li> </ul>"},{"location":"session_introduction/#demonstration-using-the-azure-portal","title":"Demonstration: Using the Azure Portal","text":"<p>A quick, live demonstration orienting you to the Azure portal and working with budgets.  Our next session activities will include a detailed workshop on creating cloud computing resources such as a virtual machine. </p> <p>Tutorial: \"Setting a Cost Alert Using the Azure Portal\"</p> <p>More information about the azure portal including a video walk-through of the Azure portal is available in Session 2 activities. </p>"},{"location":"session_introduction/#questions-and-discussion","title":"Questions and Discussion","text":"<ul> <li>What things are at the top of your mind as you begin this program?  </li> <li>Which of these topics resonates with your previous experience using computing or cloud computing (if any)?</li> </ul>"},{"location":"session_introduction/#post-session","title":"Post-session","text":"<p>After our introduction, you may have more qeustions than answers.  Here are additional readings for details related </p>"},{"location":"session_introduction/#readings_1","title":"Readings","text":""},{"location":"session_introduction/#additional-cloud-background","title":"Additional Cloud background","text":"<p>These resources are abstract introductions or discussions about cloud computing, mostly from an academic perspective.  However \"academic\" can also mean those responsible for maintaining a university's IT infrastructure or websites.   </p> <ul> <li> <p>Wikipedia article on cloud computing is actually pretty good</p> </li> <li> <p>[M. Armbrust et al. \"Above the Clouds: A Berkeley View of Cloud Computing. Technical Report UCB/EECS-2009-28 \"University of California at Berkeley, Electrical Engineering and Computer Sciences, 2009 PDF](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf}     Written only 3 years after the launch of AWS, this is very insightful discussion of the value of cloud computing</p> </li> <li> <p>I. Porres, T. Mikkonen, A. Ashraf, eds.  \"Developing Cloud Software Algorithms, Applications, and Tools.\" TUCS General Publication, No 60, October 2013 ISBN 978-952-12-2952-7 (pdf)</p> </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/","title":"Brief introduction to cloud computing research","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#introducing-cloud-computing-for-research","title":"Introducing cloud computing for research","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-using-microsoft-azure-for-the-msu-cloud-computing-fellowship","title":"Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship","text":"<p>Patrick Bills, Michigan State University</p>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-1","title":"Part 1:","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#the-computing-in-cloud-computing","title":"the \"computing\" in cloud computing","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#understanding-of-computing","title":"Understanding of computing","text":"<p>Fellowship Goal: help you connect cloud computing to your research in a meaningful way</p> <p>our original question:  - How can cloud computing benefit help your research?</p> <p>Let's re-frame the question for this discussion: - Which kind of computing could help my research? - Can I find support for that kind of computing using cloud services?</p>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-is-computing-computing-vocabulary","title":"What is computing? Computing Vocabulary","text":"<ul> <li>cloud computing is marketed to IT systems administrators, software developers, and managers -- not for us (unless you are a systems engineer). </li> <li>The primary function of cloud computing is to provide \"infrastructure\" aka the \"back-end\" or back room of a company's IT department, so we ware going to learn about that. </li> <li>cloud computing is defined and sold based on abstractions of physical components of  computers and other infrastructure such as network.   </li> <li> <p>Learning about IT infrastructure may be helpful understanding the context of the computing and what you may need. </p> </li> <li> <p>Could you purchase your own infrastructure (computers, networks, disks, etc) and run it \"on-premise\" and get the same benefit as cloud computing?  Or have your institution do that?  Sometimes yes!   </p> </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-major-components-of-computer","title":"About Computing: Major components of computer","text":"<ul> <li>User software (scripts, user code, etc)</li> <li>Base Software</li> <li>Operating System</li> <li>Input/Ouput (I/O) </li> <li>Central Processor (CPU) &amp; Memory (RAM)</li> <li>Computer Architecture (model type)</li> <li>Storage - local disk</li> <li>Storage - external ( attached or via network )</li> <li>Network</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-what-is-a-server","title":"About Computing: What is a server?","text":"<p>Cloud computing is all about \"servers,\" so we should define that. </p> <p>A server is any computer connected to a network, running software that listens for, and responsed to, messages  - The 'server' is actually the software, not the hardware   - The computer that runs the software is the 'host'  - A 'client' is software sends the message, and receives and interprets the response.   - the form the message can take is the API.  </p>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-example-server-web-server","title":"About Computing: Example Server: Web server?","text":"<ul> <li>client is the web browser</li> <li>message = URL which includes address, url paths, and additional parameters </li> <li>response = the code for the web page</li> <li>client interprets the code and renders the page.   </li> <li>an alternate client could be a script, or the <code>curl</code> utility</li> <li><code>https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1</code></li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-other-types-of-servers","title":"About Computing: Other Types of Servers","text":"<ul> <li>Database Client: special database client (not web browser) sends data commands as messages, response is tabular outputs</li> <li>File Servers  Share files.  We use Cloud file sync services, but </li> <li>Collaboration Email, calendaring etc</li> <li>Enterprise Data Systems for loading, cataloging, transforming business data</li> <li>Security Firewalls, Proxy, network traffic management</li> <li>Monitoring system health data collection, accessible via another web server</li> <li>Web-based services For example D2L.  </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-computing-servers-and-networks","title":"About Computing: Servers and Networks","text":"<p>Networking Requirements to access a server:</p> <ul> <li>the server must be on the same network as you to receive your message  </li> <li>the more accessible the network, the more vulnerable, so partitioning is used</li> <li>servers that accept messages from the Internet are a major security risk</li> <li>network failure stops all work for everyone</li> <li>designing efficient, robust, and secure networks is a major resource drain</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#too-much-hardware-virtualization-to-the-rescue","title":"Too much hardware? Virtualization to the rescue","text":"<ul> <li> <p>IT Departments 'serve' large user communities with large amounts of infrastructure, which is very in Techniques were invented to separate the 'server' or 'network' from the hardware.   </p> </li> <li> <p>Virtualization: single box with a layer of software to share among different software.  Software-defined networks: </p> </li> <li>Many servers could be created and managed with software on a single hardware  </li> <li>Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud.</li> <li>Networks followed suite with software to determine routes and paritioning on single physical layout</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-2","title":"Part 2:","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#nature-of-cloud-computing","title":"Nature of Cloud Computing","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#some-motivation-at-amazoncom","title":"Some Motivation at Amazon.com","text":"<ul> <li>Massive IT infrastructure supports  the Amazon store and company </li> <li>They wanted to sell shopping application as a service to a company like Target who didn't want to r-un their own store. T This required the software developers to have lots of flexible infrastructure (servers) to run on.  </li> <li>They found team to build a service (with software) could spend 70% of their time setting up the 'back end' </li> <li>They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development.    What they wanted in days actually took months.  </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#eureka-moment-for-amazon-we-could-sell-it","title":"Eureka moment for Amazon: we could sell it","text":"<ul> <li>Amazon automated their IT department so teams could order and provision the servers they needed on demand beyond just virtualization (\"everything was an API\")</li> <li>They got really good at running very large data centers for many customers as cheaply as possible and on-demand for Amazon.com and  other stores and services.   </li> <li>They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it.  </li> <li>Their customers were other IT departments Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\"</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#nist-defintion-of-cloud","title":"NIST defintion of cloud","text":"<p>Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics </p> <ul> <li>On-demand self-service. </li> <li>Measured service: pay for what you get.   </li> <li>Broad network access: accessible from the internet</li> <li>Rapid elasticity: no limits from a customer perspective.  This word was invented by AWS</li> <li>Resource pooling: single resources serve many customers.  </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-is-cloud-computing-cloud-concepts-vs-cloud-providers","title":"What is Cloud Computing? Cloud concepts vs Cloud Providers","text":"<ul> <li> <p>Three major cloud providers are in a constant arms race, literally (Azure vs. Amazon competed for a $10B defense contract):  Azure, Amazon Web Services and Google Cloud Platform</p> </li> <li> <p>Offerings are very similar so all are great choices</p> </li> <li>other options, smaller companies, open source options (used by Indiana University JetSteam HPC,  Osiris project from MSU, UMich, Wayne State and IU.   Cyverse for running jobs.</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#benefits-of-cloud-computing-for-research","title":"Benefits of Cloud Computing for Research","text":"<ul> <li>Customized Computing: can create customized resources only when you need it</li> <li>Elastic/On-demand: can run ad-hoc computations on those on-demand resources</li> <li>Instant service: </li> <li>Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. </li> <li>Cost effective: unlike commerical applications, more users does not mean more revenue.   Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend.   </li> <li>Others? </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#benefits-of-cloud-for-research","title":"Benefits of Cloud for Research","text":"<p>Restatement of goals of this fellowship: </p> <ul> <li>Learn which types of computing resources are beneficial to your research</li> <li>Learn how to use Cloud to create those resources</li> <li>Use the services packaged by cloud companies to discover new resources</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","title":"Learning how to learn about cloud","text":"<ul> <li>Training materials and documentation is written for IT professionals</li> </ul> <p>- Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes.   &lt;!-- That can make it difficult to decipher which kind of cloud service will work best for your use case.  -  As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. -  There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need.  - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. </p>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","title":"What documentation is available for researchers?","text":"<p>There are general, conceptual introductions and dicussions for academics.   </p> <ul> <li>https://cloud4scieng.org/  Book and website from Ian Foster (U. Chicago) and Dennis Gannon (IU) , the text used for this fellowship. </li> <li>https://cloudmaven.github.io/documentation/  from the eScience institute, University of Washington. Unmaintained.  source code</li> <li>https://cloudbank-project.github.io/cb-resources/  succesor to the cloudmaven? <ul> <li>Cloudbank training videos</li> </ul> </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud-caveats-and-help","title":"Learning how to learn about cloud: Caveats and help","text":"<p>As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective.  </p> <ul> <li> <p>The cloud services themselves are always changing </p> </li> <li> <p>There are new services and bundles created all the time that may be competing or superior choices for doing research</p> </li> <li>If you are unsure, ask us.  See the contact page or use our Teams channel.    </li> <li>Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#theme-using-workflow-and-computational-thinking","title":"Theme: Using workflow and computational thinking","text":"<ul> <li>Karl Popper stated that \"non-reproducible single occurrences are of no significance to science\" ( K Popper, \"The Logic of Scientific Discovery\", English translation from Routledge, London, 1992, p. 66.) and this is a significant issue for research based on computing</li> </ul> <ul> <li>A major advantage to using workflows or code for provisioning your cloud computing components is that you can turn them off and delete them when you are done, and restart when needed.   .  -Our first uses of cloud will use forms to create resources, but we encourage you to automation where possible </li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-cloud-security","title":"About Cloud Security","text":"<p>Security and Risk management are important issues even for researchers who's data are open  - If your computer is a server, your responsibility just increased 100X: these are prime targets.    Consider each component of a server to be a point of vulnerability.  - Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above.  Our textbook has a nice chaper outlining cloud security - We will cover methods to reduce security risks but it's important to consider the risk of hacking from the beginning</p>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#hpcc-vs-cloud","title":"HPCC vs Cloud","text":"<ul> <li> <p>Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing.  </p> </li> <li> <p>The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit</p> </li> <li>Many systems not designed for HPC can be adjusted to run in that environment.  However, just like many workflows are difficult to port from HPC to cloud, some cloud workflows are difficult run on HPC (but never say never).  Especially windows-based software. </li> <li>I will cover some of these types of systems in future sessions</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","title":"Acknowledging bias in access to cloud computing across research cultures","text":"<p>It's widely recognized that AI is frequently bias.   For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so </p> <ul> <li>There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture, and background.  System Engineering is it's own discipline and Cloud computing is arcane -our goal is to reduce conceptual barriers to using this technology</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#discussion","title":"Discussion","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#part-3","title":"Part 3:","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#introduction-to-the-azure","title":"Introduction to the Azure","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#using-the-azure-portal","title":"using the Azure Portal","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-azure","title":"About Azure","text":"<ul> <li>We have funding for using Azure cloud, and we have experience using Azure. </li> <li>If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (using a gmail address or other non-MSU email address). </li> <li>Each participant has a budget for using Azure and a \"resource group\" to create resources</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#about-cloud-costs","title":"About Cloud Costs","text":"<ul> <li>Cost management is a major hurdle for adopting CC </li> <li>(Almost) everything you do in Azure has a cost</li> <li>Costs often acrue over time, wether the resource is in use or not</li> <li>Deleting resources when are not using is a great way to reduce cost</li> <li>We want to encourage you to experiment!  Using a very powerful machine for an hour may cost only $0.50  </li> <li>Just be aware that creating something and leaving it on will deplete your budget</li> <li>Solution: \"Budget Alerts\"</li> </ul>"},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#activity-using-the-azure-portal","title":"Activity : Using the Azure Portal","text":""},{"location":"session_introduction/brief_introduction_to_cloud_computing_research/#demonstration","title":"Demonstration","text":""},{"location":"session_introduction/cost_alert/","title":"MSU Cloud Computing Fellowship: Session 1","text":""},{"location":"session_introduction/cost_alert/#costs-and-budgets-with-microsoft-azure","title":"Costs and Budgets with Microsoft Azure","text":"<p>(Almost) everything you do in Azure has a cost, and costs for resources often acrue over time, wether the resource is in use or not.   This is a  short excercise to recieve an email when you have spent a certain amount of money.   This can be valuable if you are experimenting and forget to  delete a resource that you no longer need. </p> <p>For this work, You must first have a 'budget' in your resource group.  We created a budget for 2022 for all fellowship participants that you can use for creating alerts.  </p> <p>This does not explain any other aspect of Azure or the Azure portal.  There are more materials for that in Session 2.   If you get stuck, you may want to review those and come back. </p> <p>If at any point you have an issue, please contact us! </p>"},{"location":"session_introduction/cost_alert/#adding-cost-alert-to-your-resource-group","title":"Adding \"cost alert\" to your resource group.","text":"<ul> <li>Log into https://portal.azure.com</li> <li>You should see a single resource group, or be put into one automatically.  </li> <li>Open your resource group if is not already</li> <li>The left side bar had properties for the resource group. </li> <li>In the left side-bar, select \"budgets\" (scroll down)</li> <li>You should see a single budget named with the template \"ccf22__budget\" <li>Click on that budget</li> <li>click 'edit budget' link near the top left</li> <li> <p>review the information, then at the bottom, click 'next'</p> </li> <li> <p>We are now adding an 'alert' to that budget.  Enter the following</p> </li> <li>alert condition: type = Actual</li> <li>enter a percentage, say 50%. </li> <li>under action group, leave it as 'none'</li> <li>for email put your preferred email (I don't know if gmail etc will work)</li> <li>you can also add me if you like as a second email billspat@msu.edu</li> <li>select your preferred language, if it's available</li> <li>click 'Save'</li> <p>You may add additional alerts if you want to be reminded at different thresholds of spending, e.g. 25%, 50%, 80%.  </p> <p>I hope these instructions were clear but again, any questions please contact us using email or MS Teams.  </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/","title":"Lecture introduction to cloud computing research","text":""},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#introducing-cloud-computing-for-research","title":"Introducing cloud computing for research","text":""},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#practical-introduction-for-researchers-using-microsoft-azure-for-the-msu-cloud-computing-fellowship","title":"Practical Introduction for Researchers using Microsoft Azure for the MSU Cloud Computing Fellowship","text":"<p>Patrick Bills, Michigan State University</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#part-1-what-is-computing","title":"Part 1: what is computing","text":"<p>You come to us with each a unique set of experiences with computing, with more or less experience depending on your previous needs.  </p> <p>A challenge we have seen for the many years we've been helping people is understanding the context of computing in their research to understand the tools they have available</p> <p>Goal: help you connect cloud computing to your research in a meaningful way</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-in-cloud-computing","title":"What is computing in Cloud Computing","text":"<p>Part of this fellowship will be examining the 'computing' part of cloud computing. </p> <p>The application asks the question : \"How can cloud computing help your research?\"</p> <p>We may want to re-frame the question:</p> <p>\"What kinds of computing could help my research? How can cloud services support that kind of computing?\"</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-in-cloud-computing_1","title":"What is computing in Cloud Computing","text":"<p>Which is a reframing of first, understanding computational technology in general and cloud second. </p> <p>For example, while MSU provides email, storage, and high performance computing, it does not provide services for \"big data\" category, or relational databases for researchers.   But you can provision such a service in minutes using the cloud. </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-computing-vocabulary","title":"What is computing? Computing Vocabulary","text":"<ul> <li> <p>cloud computing is marketed to IT professionals and managers.  They are who will make the recommendations for checks to be written.  Cloud computing must tick their boxes.   Services are organized and documented for them, not for us. </p> </li> <li> <p>while cloud computing abstracts away the physical components of a computer but companies use computing concepts as metaphors.  see above.   </p> </li> <li> <p>many of the capabilities that cloud computing offers could be done by purchasing computer hardware and software, setting it up and manageing it inside your lab.   These concepts may help you </p> </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-major-components-of-computer","title":"What is computing: Major components of computer","text":"<ul> <li>User software (scripts, user code, etc)</li> <li>Base Software</li> <li>Operating System</li> <li>Input/Ouput (I/O) </li> <li>Central Processor (CPU) &amp; Memory (RAM)</li> <li>Computer Architecture (model type)</li> <li>Storage - local disk</li> <li>Storage - external ( attached or via network )</li> <li>Network</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-what-is-a-server","title":"What is Computing: What is a server?","text":"<p>The 'Client/server' model invented in the 60s is so successful that we use servers for our daily lives and don't think about it (except when the server is down).  This model of computing is important because it's at the basis for of cloud computing.   </p> <p>A server is any computer that is running software that listens for messages, and then responds.   - The 'server' is actually the software  - The computer that runs the software is the 'host'  - A 'client' is software sends the message, and receives and interprets the response.   - the form the message can take is the API.  </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-what-is-a-web-server","title":"What is Computing: What is a Web server?","text":"<ul> <li>client is the web browser</li> <li>message = URL which includes address, url paths, and additional parameters </li> <li>response = the code for the web page</li> <li>client interprets the code and renders the page.   </li> <li>an alternate client could be a script, or the <code>curl</code> utility</li> <li><code>https://www.amazon.com/dp/B09VXBNTJ1/ref=sr_1_93?brr=1</code></li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-data-server-example","title":"What is Computing: Data Server Example","text":"<ul> <li>Client: special database client (not web browser)</li> <li>message : insert these 5 rows of data  <li>response: <code>inserted 5 rows</code></li> <li>message: select rows of students in Math 101</li> <li>response:  data such as </li> <pre><code>\"First Name\",\"Last Name\",\"Email\",\"Level\"\n\"Lucy\",\"Grant\",\"l.grant@randatmail.com\",\"7\"\n\"Emily\",\"Russell\",\"e.russell@randatmail.com\",\"5\"\n\"Annabella\",\"Ferguson\",\"a.ferguson@randatmail.com\",\"8\"\netc\n</code></pre>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-major-components-of-server-computer","title":"What is computing: Major components of server computer","text":"<p>The components are nearly the same as a personal computer</p> <ul> <li>Server Software set to listen on network</li> <li>(remote management systems)</li> <li>Operating System (hardened for security)</li> <li>Central Processor (CPU) &amp; Memory (RAM) (large)</li> <li>Computer Architecture (designed for high availability)</li> <li>Storage - local disk (designed for high availability)</li> <li>Storage - external ( attached or via network )</li> <li>Network (high-speed)</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#computing-concept-virtualization","title":"Computing Concept: Virtualization","text":"<p>Given the strain on IT Departments to provide servers dynamically and the time to provision the hardware to do so, and the fact that many servers are idle much of the time.  A technique of hosting multiple software servers on a single hardware unit was invented.   </p> <ul> <li>1 server =  1 box : too many boxes</li> <li>many virtual servers = 1 box: more efficient use of hardware</li> <li>Servers could be provisioned automatically!   </li> <li>Virtualization was a necessary conceptual and technological innovation to pave the way for cloud computing and is widely used both on-premise and in the cloud.</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-computing-servers-and-networks","title":"What is Computing: Servers and Networks","text":"<p>Networking Requirements to access a server:</p> <ul> <li>the server must be on the same network as you to receive your message  </li> <li>some networks block some traffic (for security)</li> <li>servers that accept messages from the Internet are a major security risk</li> <li>network failure stops all work for everyone</li> <li>IT spend a lot of time designing efficient, robust, and secure networks</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#computing-concept-software-defined-networks","title":"Computing Concept: Software-defined networks","text":"<ul> <li>A server on a network accessible to possible hackers is increases security vulnerability</li> <li> <p>Data networks can be designed to partition servers so only accessibles from some locations, or with credentials, or with a single point of entry e.g. gateway)</p> </li> <li> <p>In 1990s nnetwork systems configurable by software </p> </li> <li>Like virtual machines, system architecture could be flexibly changes with software.  </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history","title":"What is Cloud Computing? History","text":"<p>Amazon want to provide their store as a service to a company like Target who didn't want to run their own store. They found it very difficult to re-organize their IT infrastructure, and be flexible. </p> <p>In a start-up (or a research group!)  A software team could spend 70% of their time setting up the 'back end' </p> <p>It took months to get the infrastructure in place.   They ran massive data centers and need to automate. </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history_1","title":"What is Cloud Computing? History","text":"<p>The IT department at Amazon was tasked with rapidly responding to any need the Amzon store developers needed to build new features immeidately </p> <ul> <li>They called all the infrastructure needed to run a massive dot-com \"muck\" and saw this as a secondary supporting role to application development.   </li> <li>Teams could order and provision the IT servers they needed via the web forms and did not need to burden the IT staff, individual teams in IT worked with each others services with APIs.  </li> <li>They were great a running very large data centers for many customers as cheaply as possible.  And not just for Amazon.com but other stores </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-history_2","title":"What is Cloud Computing? History","text":"<ul> <li> <p>Amazon IT configured all of their components to communicate with software APIs, very novel at the time, and used software to make it super efficient to configure all the hardware, at a massive scale</p> </li> <li> <p>They realized that their innovations would help any IT organization and especially internet start-ups like themselves, and that they could sell it.  </p> </li> <li> <p>Their original and main customers are IT departments of organizations.</p> </li> </ul> <p>Blog Post from 2006: \"We Build Muck, So You Don\u2019t Have To\"</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-nist-defintion-of-cloud","title":"What is Cloud Computing? NIST defintion of cloud","text":"<p>Government offices interested in purchasing cloud computing needed a definition of it to differentiate from other kinds of computing, hence... the NIST definition of cloud computing essential characteristics </p> <ul> <li>On-demand self-service. </li> <li>Measured service: pay for what you get.   </li> <li>Broad network access: accessible from the internet</li> <li>Rapid elasticity: no limits from a customer perspective.  This word was invented by AWS</li> <li>Resource pooling: single resources serve many customers.  </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#other-web-based-services-that-are-not-cloud-computing","title":"Other Web-based services that are not cloud computing","text":"<ul> <li> <p>Web hosting Focused on providing offered many of these features but was limited in service offerings.   I've used a company called dreamhost since early 2000 to provide websites for non-profits and commercial customers, but also email and storage and limited database services.  </p> </li> <li> <p>Co-location Bring your own hardware, eg. Data Center only</p> </li> <li> <p>Server Rental Servers on the internet you could use for various things, primarily web sites &amp; applications.   (Rackspace) </p> </li> <li> <p>Other remote computing services example sending your accounting data to an external service for processing (which now seems quaint).  EDS from the 80s 90s by Ross Perot provided IT and Data services to major corporations primarily GM. </p> </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-is-cloud-computing-cloud-concepts-vs-cloud-providers","title":"What is Cloud Computing? Cloud concepts vs Cloud Providers","text":"<ul> <li> <p>Three major cloud providers are in a constant arms race to capture the large contracts (e.g. Azure vs. Amazon competed for a $10B defense contract):  Azure, Amazon Web Services and Google Cloud Platform</p> </li> <li> <p>Offerings are very similar so all are great choices</p> </li> <li>Many others provide Cloud : Oracle, IBM, Salesforce, </li> <li>Thousands of companies of specialized services to support the major vendors (e.g. for billing, management, security, etc)</li> <li>There is an open source version of cloud computing called \"OpenStack\" used by universities to build their own private or non-profit clouds.   MSU/UMich uses that for the Osiris project.   Indiana University uses it for their machine called \"JetSteam\"</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing","title":"Service-level Model of Cloud Computing","text":"<p>Again, from the the NIST definition of cloud computing a perspective based on levels of service and responsibility of the consumer: </p> <ul> <li>Infrastructure as a service:  Replacement for hardware but perhaps not software levels.   This is often compared to making a data center and uses many of the terms.  You need understanding of computing architecture as these services </li> <li>Platform as a service: Everything in between:  pre-configured and managed infrastructure</li> <li>Software as a service: Little to no configuration is needed but these system may be programmable and integrated with other services.  E.g. Office 365, Google Drive</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing_1","title":"Service-level Model of Cloud Computing","text":"<ul> <li>\"service levels\" are only a model (or abstraction) for discussion cloud computing, widely used in the IT fields. </li> <li>\"X as a service\" where X is some aspect of IT, usually along the axis of customer responsibility.   </li> <li>the model is abused like all concepts or acronyms in IT:  </li> <li>How well does this model apply to the services that cloud providers give us?  Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing-food-analogy","title":"Service-level Model of Cloud Computing Food Analogy","text":"<p>Compare : - Restaurant vs Box Prepared food vs. Cooking from scratch vs. Farming - Google Search vs Google Docs vs Google Cloud Platform </p> <p>to push the analogy further, what would a growing supply company provide to a farmer vs a gardener?   As we begin, we are gardners, not farmers and hence the cloud companies may not cater to us.  We want 1 shovel, not dozens, or a huge tractor.  </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#service-level-model-of-cloud-computing_2","title":"Service-level model of Cloud Computing","text":"<p>For many cases, the \"plaform\" is the sweet-spot for researchers </p> <ul> <li>do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable.     </li> <li>These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#nist-service-level-model-and-responsibility","title":"NIST Service-level model and Responsibility","text":"<p> The \"Shared responsibility\"* model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>Like the concept that cloud simply makes creating servers easier, cloud goes a step further and packages servers+software and calls that a service. </p> <p>Case Study on Open Source system as Cloud service: **MySQL **</p> <p>Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data.   Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app) and millions of websites. </p> <ul> <li>project: https://www.mysql.com/products/community/ and  https://mariadb.org/</li> <li>DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved</li> <li>Azure MySQL Service (e.g PaaS): Azure Database for MySQL <ul> <li>AWS MySQL Service: Amazon RDS for MySQL</li> <li>Google MySQL Service Cloud SQL </li> </ul> </li> <li> <p>other companies, such as Aiven for MySQL</p> </li> <li> <p>Spin-offs: Amazon also offers AWS Aurora  which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper </p> </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_1","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>Could you run this yourself?  You would need: </p> <ul> <li>network (from university = free) (with opening in firewall)</li> <li>hardware (any old PC will do, so say 'free')</li> <li>software (free)</li> <li>install, configuration, understanding (not free!)</li> <li>keeping hackers away (not free!!!)</li> <li>keeping it updates, fixing hardware, helping others (not free)</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_2","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>Compare cost of DIY with cloud service:</p> <ul> <li>provisioning and using a server in minutes on cloud (not free)</li> <li>cloud company provides configuration, security, and hardware maintance (not free)</li> <li>time to write your manuscript instead of spending on time on your MySQL server ( priceless )</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-services-and-the-packaging-of-open-source-systems_3","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>What would a \"SaaS\" offering for tabular data look like?  A \"Google Docs\" for Databases?  Perhaps https://www.airtable.com/ ?</p> <p>How about a SaaS Map and Geospatial Processing system?   Google Earth Engine or ESRI story maps</p> <ul> <li>In General Before you reach for the  Cloud legos, look to see if there is a SaaS solution for your problem</li> <li>For this fellowship, using a SaaS is not the goal of the projects, but to strech and try using Cloud in order to learn it</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#cloud-for-research","title":"Cloud for Research","text":"<p>What are the benefits from research perspective for cloud computing?</p> <ul> <li>Custom: can create customized resources only when you need it</li> <li>On-demand: can run ad-hoc computations on those on-demand resources</li> <li>Reproducible: a computation can be re-run as needed, meaning cloud resources can be easily re-recreated to re-run your computations. </li> <li>Cost effective: unlike commerical applications, more users does not mean more revenue.   Budgets are fixed and the pay-as-you-go model requires vigilance to not over-spend.   </li> <li>Others? </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud","title":"Learning how to learn about cloud","text":"<ul> <li>Training materials and documentation is written for IT professionals</li> </ul> <p>- Our goal as researchers is to get our work (or the work of our lab) done, not to build systems used by hundreds of people or for business purposes.   &lt;!-- That can make it difficult to decipher which kind of cloud service will work best for your use case.  -  As Dr. Parvizi writes, cloud is very different from using traditional research-oriented technology like workstations or HPC. -  There are hundreds of services to choose from but we find many researchers will reach for the conceptually straightfoward path of creating cloud computers and install what they need.  - Our goal for this fellowship is to provide context and background, and help you explore some of the so-called \"cloud native\" technologies like \"serverless\" systems that let you run your scripts without dealing with operating system installs. </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#what-documentation-is-available-for-researchers","title":"What documentation is available for researchers?","text":"<p>There are general, conceptual introductions and dicussions for academics.   </p> <ul> <li>https://cloud4scieng.org/  Book and website from Ian Foster and Gannon (U. Chicago), the text used for this fellowship. </li> <li>https://cloudmaven.github.io/documentation/  from the eScience institute of the University of Washington.   It doesn't appear to be maintained but may have some good resources.  Original github repositories are https://github.com/cloudmaven</li> <li>https://cloudbank-project.github.io/cb-resources/  Seems to be a succesor to the 'cloudmaven' documentation above as members from cloudmaven are contributing here. <ul> <li>Cloudbank training videos</li> </ul> </li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#learning-how-to-learn-about-cloud-caveats-and-help","title":"Learning how to learn about cloud: Caveats and help","text":"<p>As part of this fellowship, our goal is to help you translate documentation written for the systems and developer perspectives into a research perspective.  </p> <ul> <li> <p>The cloud services themselves are always changing </p> </li> <li> <p>There are new services and bundles created all the time that may be competing or superior choices for doing research</p> </li> <li>If you are unsure, ask us.  See the contact page or use our Teams channel.    </li> <li>Cloud companies have help desks and many resources for anyone using their services or potential customers and we may be able to connect you with those. </li> </ul> <p>.   This does not necessarily have to be a complete programming system, but some combination of well written instructions and a collection of scripts so that your colleague (or yourself 6 months from now) can recreate everything you need.   --&gt;</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#about-cloud-security","title":"About Cloud Security","text":"<p>Security and Risk management is an important issue even for researchers who's data may not be sensitive or even open source.   </p> <ul> <li> <p>Finding a readable list of security recommendations for cloud computing is a challenge for all the reasons outlined above.  Our textbook has a nice chaper outlining cloud security</p> </li> <li> <p>The \"Shared responsibility\" model for cloud computing takes a model of computing components, and shows how much of each component the user is responsible for security. </p> </li> </ul> <ul> <li>If your computer is a server, your responsibility just increased 100X as these are primary targets for hacking.    Consider each component of a server to be a point of vulnerability.   </li> </ul> <p>We will come back to this model as we gain deeper understanding of research computing on the cloud.  </p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#costs-and-budget-overview","title":"Costs and Budget overview","text":"<ul> <li>Each participant has a budget for their Azure resources.   </li> <li> <p>If you need to use Google or AWS we need to make additional arrangements but your first step would be to acquire a free starter account with these companies (e.g. using a gmail address). </p> </li> <li> <p>Costs are more than just dollars for services.  Consider <code>[Total Cost] = ( $ + Time + Risk )</code></p> </li> <li><code>[Total Time] = ( development time + wait time + compute time )</code></li> <li>Risk is rarely non-significant.  Never say \"I won't get hacked...\"</li> <li>In the Service level spectrum, the higher level \"platform\" services may have higher monetary costs but often reduce time and risk</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#hpcc-vs-cloud","title":"HPCC vs Cloud","text":"<p>Dr. Parvizi's white paper outlines the challenges of adapting HPC workflows to cloud computing.  </p> <p>The HPC is amazing effective at running all kinds of systems at very list cost, if any, to MSU researchers, but not all are the best fit </p> <ul> <li>Big Data systems</li> <li>Long-running Data Systems like database servers</li> <li>Web-based applications</li> <li>Windows</li> <li>Systems with complex or specific configuration needs</li> </ul>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#acknowledging-bias-in-access-to-cloud-computing-across-research-cultures","title":"Acknowledging bias in access to cloud computing across research cultures","text":"<p>It's widely recognized that AI is frequently bias.   For example, Azure Voice recognition did not work for a female researcher who developed voice-controlled surgery, so </p> <p>There is inherent bias in the interfaces, design and definitions in the engineerig of technology in terms of gender, culture and our goal is to reduce conceptual barriers to using this technology</p>"},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#additional-comments-from-instructors-and-organizers","title":"Additional comments from instructors and organizers","text":""},{"location":"session_introduction/lecture_introduction_to_cloud_computing_research/#source-materials","title":"Source Materials","text":"<p>https://softwaresim.com/blog/introduction-to-cloud-computing-for-research/</p>"},{"location":"session_organization/","title":"Special Session 7: Cloud Services Organization","text":""},{"location":"session_organization/#goals","title":"Goals","text":"<p>We hope to provide you with the following understanding of: </p> <ul> <li>what are the \"service levels\" and the related responsibilities for different kinds of cloud resources, and how does that help you choose a service</li> <li>what options for interacting with cloud services</li> <li>Understand difference between the cloud manager and resource you've created</li> <li>Know how to use program to automate the creation and deletion of cloud resources </li> <li>How to find basic cost estimates</li> </ul>"},{"location":"session_organization/#introduction","title":"Introduction","text":"<p>We might think of using cloud computing in 3 areas: using the resources (which is our real goal), definining and creating these resources, and manageing them.  </p> <p>We may need a virtual machine to run our program to calculate or analyze our data, but we need to determine the properties of that virtual machine and create it first.  Surrounding all of that is how we interact with the cloud service to do that, how we estimate and observe the costs, manage and identify all the other components a cloud VM needs, and  make it as secure as possible.   </p> <p>I'm lumping all of these last pieces into 'managing' cloud resources.  It may be the most boring of all the topics.   The concepts may cover any resource you create in the cloud, and in general apply to all cloud service providers.  However the details of how you do it are very specific to each cloud vendor.   In fact the methods may be convoluted or less than straightforward, so there are many companies that provide additional tools just to manage cloud resources in a more consistent or easier way than the cloud providers allow you</p>"},{"location":"session_organization/#service-level-model-of-cloud","title":"Service Level Model of Cloud","text":"<p>The NIST definition of cloud computing defines service models, but what does \"X as a service\" actually mean, and where are the lines drawn?   Like the species concept in biology, it's not always cut and dried, but can be thought of as a spectrum</p> <ul> <li>Infrastructure (aaS):  Nuts and bolts, DIY, Lego.  You need understanding of computing architecture as these services </li> <li>Everything in between:  Platforms or pre-configured and managed infrastructure</li> <li>Software (aaS): Little to no configuration is needed but these system may be programmable and integrated with other services.  E.g. Office 365, Google Drive</li> </ul> <p></p> <p>The sweet-spot for researchers who do not have time to aquire the expertise to manage low-level infrastructure and need something more flexible and programmable than Software, are the platforms.  These are often more expensive than DIY infrastruture, but are faster to provision and provide security controls. </p>"},{"location":"session_organization/#cloud-services-and-the-packaging-of-open-source-systems","title":"Cloud \"Services\" and the Packaging of Open Source Systems","text":"<p>Case Study on Open Source system as Cloud service: **MySQL **</p> <p>Open source, free Relational database, e.g. SQL. Relational databases store tabular, linked data.   Used by some bioinformatics packages (e.g. https://orthomcl.org/orthomcl/app) and millions of websites. </p> <ul> <li>project: https://www.mysql.com/products/community/ and  https://mariadb.org/</li> <li>DIY on Azure instructions (eg Iaas): someone's DIY Mysql - don't follow these, they are old and may not work, just an example of the steps involved</li> <li>Azure MySQL Service (e.g PaaS): Azure Database for MySQL <ul> <li>AWS MySQL Service: Amazon RDS for MySQL</li> <li>Google MySQL Service Cloud SQL </li> </ul> </li> <li> <p>other companies, such as Aiven for MySQL</p> </li> <li> <p>Spin-offs: Amazon also offers AWS Aurora  which is a cloud scale database service that is MySQL-compatible see Amazon Aurora Paper </p> </li> </ul> <p>What would a \"SaaS\" offering for your research look like?  A \"Google Docs\" for your databases?  How about a \"PasS\" that you could build?   Would it be reproducible by anyone doing the kind of research you do? </p>"},{"location":"session_organization/#costs","title":"Costs","text":"<p>Review: About Cloud Costs</p> <p>Cautionary Tale: Google Cloud Charged Me $1000 For This Mistake by Kunal Vaidya on Medium.   *tl;dr: he forgot to turn off a service even though he was no longer using it.   Good news it, Google does grant 1-time forgiveness if you can prove you are using the service to learn about it (e.g. you are student). *</p>"},{"location":"session_organization/#interfaces","title":"Interfaces","text":"<p>In session one we talked about the client/server model of computing which is so ubiquotous is seems like the only model of computing.  </p> <p>The core of the cloud model is that \"everything has an API\" or Application Programming Interface:  the commands that can be used for code-to-code interaction. </p> <p>Reading:  </p> <ul> <li>Interfacing with Cloud Services</li> <li>About the Microsoft Resource Manager: https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/overview</li> </ul> <p>Acivity: </p> <ul> <li>Create a Linux virtual machine with the Azure Command Line Interface ( CLI) </li> </ul> <p>Note the \"Interface\" is for interacting with Azure to manage resources.  The resources them selves will have their OWN interface.   </p>"},{"location":"session_organization/#moving-data","title":"Moving Data","text":"<p>Moving Data in the cloud</p>"},{"location":"session_organization/#staying-organized-in-azure","title":"Staying Organized in Azure","text":"<p>You've seen that using the web portal to create a virtual machine creats a dozen resources.   Then you may have other resources (e.g. a storage account) you want to connect to them.  How do you keep them all straight?  </p>"},{"location":"session_organization/#naming-things","title":"Naming things","text":"<p>Microsoft suggestion for creating names: https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming</p> <p>Why do names have an \"Environment\" element?</p> <p>IT professionals tend to think of the world in two ways:  the stuff I'm doing to try things, and the stuff I've done that now the world can use.  That's because once a system is open or connected to a public interface, they have to keep it running.   Some use the term \"production\" or in-production. </p> <ul> <li>development (dev):  in progress experimental versions, never intended for public use, strictly for our use</li> <li>test:  optional state, the system is as close to finished as possible and given to staff to do formal testing to ensure it's ready for publication</li> <li>production (prod): final version released to the public</li> <li>optional \"preview\" or \"beta\" : companies use this to get themselves off the hook.   It's not really done and they may just remove the service, no guarantees.  </li> </ul> <p>A production environment is deploying resources so that they are unchanged, stable and don't have down time.  A \"site reliability engineer\" (SRE) is paid to avoid downtime.  </p> <p>Why do they call out 'region' in this naming scheme?  For global web companies, they may deploy duplicate resources in many regions.    In addition resources that interaction should be in the same region, e.g. a storage acccount and a VM that uses it should be in the same region to keep the connection fast.  </p> <p>using Azure 'Tags'</p> <ul> <li>Optional: Short note about Using Azure Tags for Organization ( Pat Bills, MSU)</li> <li>\"Use tags to organize your Azure resources and management hierarchy\" from Microsoft</li> </ul> <p> Microsoft suggested naming scheme for Azure resources</p>"},{"location":"session_organization/#monitoring","title":"Monitoring","text":"<p>You want to keep an eye on the resources you create: how healthy are they, are they performing as expected?  Is there some problem that makes them slow or unresponsive?  This is especially true of servers, created by IT staff, that others are using that need to stay up and running.    For us as researchers creating resources to do our calculations, we want to know how long it's taking and hence how much will it cost?  Do we need to add more power to get it to work?   </p> <p>This is an esoteric topic and is really specific to each type of service, but it's something to consider as 1) you may need to engage in a resource outside of the azure portal (e.g. in a VM, log-in and check the performance with standard tools like 'top' in Linux and the task manger in Windows) 2) create (and pay for!) yet another cloud resource for collective and 'managed' monitoring.     </p> <p>Why use cloud monitoring at all?  If you were running a bunch of your own computers in your lab, you would just sit down and check on them using tools the operating system provided.  In many systems you open and read the 'logs' or text files with a stream of the events and times they occured.  </p> <p>Machines in the cloud provide new challenges.  An obvious one is to be able to see statistics for many resources at once.   How then does Azure collect data from each machine into central place and then let you browse it?    A second challenge is, what happens to that information for a virtual machine that has crashed and is unresponsive, or has been intentionally turned off and deleted?   </p>"},{"location":"session_organization/#monitoring-examples","title":"Monitoring Examples","text":"<p>For Azure virtual machines, Azure offers \"Azure Monitor\".   Using it is completely optional and I don't have activities related to this service.   If for your project you are working with a group of VM's, you are interested in performance, or you need performance information because your analysis is not completing then I would investigate this service. </p>"},{"location":"session_organization/azure_tags/","title":"Azure tags","text":""},{"location":"session_organization/azure_tags/#using-tags-to-organize-resources-in-azure","title":"Using Tags to organize resources in Azure","text":"<p>Tags are notes to yourself about the resource, use them for metadata.  </p> <p>As the number of cloud resources blossom (e.g. cloud sprawl) it can be important to find related resources quickly.  The azure portal has a way to see resource within and across resource groups using different filtering methods.    One of those is the with resource meta-data, and you can add meta data using 'tags.'</p> <p>In my group we always have a tag with the key \"created by\" and value the netid of the creator.   This may be redundant here becuase all the resources you create will be a in resource group with your NetID already in it, but add this for practice. </p> <p>You may consider using a tag like \"project\" with value for the project if either 1) a project may have multiple resource goups or 2) a resource group would have multiple projects.  </p> <p>For now you have only one resource group, but tags are also used to find things across different resource groups, e.g. if by project name. </p> <p>Tags can be added and removed at will from resources without altering the resource, so add as many tags as you want when starting to see how they may work.   </p>"},{"location":"session_organization/azure_tags/#example-usage","title":"Example usage:","text":"<p>When creating resources using the wizard, many resources are created at once. For example creating a virtual machine may create 12 resources.  Adding a tagl to ID those resources together can really help to delet them. </p> <ul> <li>use the Portal to create a test virtual machine (VM), which creates 12 resources</li> <li>add a unique tag to those during the VM creation process, e.g.  tag \"id\" = \"test VM Oct 1\"</li> <li>when you later need to delete the VM becuase you are done with it, or it wasn't what you needed, you can filter resources in your group on this this so you can select those 12 resources, and not any others, without having to hunt for them by name. </li> </ul>"},{"location":"session_organization/exercise_vm_via_cli/","title":"Exercise vm via cli","text":""},{"location":"session_organization/exercise_vm_via_cli/#cli-interface-tutorial-exercise","title":"CLI Interface Tutorial / Exercise","text":"<p>MSU Cloud Computing Fellowship, Pat Bills, IT Services</p> <p>This tutorial walks through using the CLI with code you can copy, modify and try.   This will run in the Azure portal \"cloud shell\" if you have set it up to use the CLI interface (not the PowerShell interface)</p> <p>You can refer to the original tutorial which is perhaps more clear, but doesn't quite fit our situation : Quickstart: Create a Linux virtual machine with the Azure CLI</p> <p>If you follow this - please don't delete your resource group!  </p> <p>In the code below, lines that start with <code>#</code> are comments only, but the other lines are commands.  You can copy/paste one command at at time into the CLI of the cloud shell.  Since these are long commands, a long command can be broken up using the line-continuation character which is the back-slash <code>\\</code> so one command are all the lines until the last one that does not end with a back-slash</p>"},{"location":"session_organization/exercise_vm_via_cli/#first-launch-azure-cloud-shell","title":"First, Launch Azure Cloud Shell","text":"<p>The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.</p> <p>To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also open Cloud Shell in a separate browser tab by going to https://shell.azure.com/bash. Select Copy to copy the blocks of code, paste it into the Cloud Shell, and select Enter to run it.</p>"},{"location":"session_organization/exercise_vm_via_cli/#try-running-the-following-commands","title":"Try running the following commands","text":"<pre><code># create a VM and all of the items needed for it  : OS Disk, network security group, etc.  \n# replace the names with your own group and other names.  \n# Remember to change the group and VM name\n\naz vm create \\\n  --resource-group mygroupname \\\n  --name mytestvm \\\n  --image Debian \\\n  --public-ip-sku Standard \\\n  --admin-username azureuser \\\n  --tags 'activity=cli_tutorial' \\\n  --generate-ssh-keys\n</code></pre> <p>Here is a real example command for my own resource group: </p> <pre><code>az vm create \\\n --resource-group ccf22_billspat \\\n --name billspat-tutorial-vm \\\n --image Debian \\\n --public-ip-sku Standard\n --admin-username billspat \\\n --tags 'activity=cli_tutorial' \\\n --generate-ssh-keys\n</code></pre> <p>The output will look something like this: </p> <p><pre><code>{\n  \"fqdns\": \"\",\n  \"id\": \"/subscriptions/047e742e-cb26-41e6-a9d6-9d42c67f43e6/resourceGroups/ccf22_billspat/providers/Microsoft.Compute/virtualMachines/billspat-tutorial-vm\",\n  \"location\": \"northcentralus\",\n  \"macAddress\": \"00-22-48-8F-48-C2\",\n  \"powerState\": \"VM running\",\n  \"privateIpAddress\": \"10.4.0.5\",\n  \"publicIpAddress\": \"20.236.78.140\",\n  \"resourceGroup\": \"ccf22_billspat\",\n  \"zones\": \"\"\n}\n</code></pre> Copy and paste that somewhere for reference last. </p> <p>Now give that VM a purpose and install a web server.  There are many webserver that you can install, but nginx is easy to install and open source.  You can do this in two ways</p> <p>1) use the CLI to run a command on the VM directly <pre><code>az vm run-command invoke \\\n   --resource-group mygroupname \\\n   --name mytestvm \\\n   --command-id RunShellScript \\\n   --scripts \"sudo apt-get update &amp;&amp; sudo apt-get install -y nginx\"\n</code></pre></p> <p>2) use SSH to connect to the VM and run it directly.  that will be for another tutorial! </p> <p>The output from the command above will be something like</p> <pre><code>{\n  \"value\": [\n    {\n      \"code\": \"ProvisioningState/succeeded\",\n      \"displayStatus\": \"Provisioning succeeded\",\n      \"level\": \"Info\",\n      \"message\": \"Enable succeeded: \\n[stdout]\\ne libnginx-mod-http-xslt-filter.\\r\\nPreparing to unpack .../23-libnginx-mod-http-xslt-filter_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-http-xslt-filter (1.14.2-2+deb10u4) ...\\r\\nSelecting previously unselected package libnginx-mod-mail.\\r\\nPreparing to unpack .../24-libnginx-mod-mail_1.14.2-2+deb10u4_amd64.deb ...\\r\\nUnpacking libnginx-mod-mail (1.14.2-2+deb10u4) ...\\r\\nSelect  etc\n</code></pre> <p>Open port 80 for web traffic</p> <p>By default, only SSH connections are opened when you create a Linux VM in Azure. Use az vm open-port to open TCP port 80 for use with the NGINX web server:</p> <pre><code>az vm open-port --port 80 --resource-group mygroupname --name mytestvm\n</code></pre> <p>check that it's working</p> <p>Put the IP address from the output above (or use the portal to find it) into your browser to see if you can connect,. If so, then great!  you've just built a web server.   </p> <p>Delete everything</p> <p>You can't delete your how resource group, but luckily we used tags to create the VM so we can just delete resource by tag. </p> <p>You can use the portal to delete these resources, but if here are commands to do it with the CLI.  You can delete things by name, like this</p> <pre><code> az vm delete \\\n  --resource-group mygroup \\\n  --name myvm\n</code></pre> <p>but every resource has a unique ID, and can be deteled using that ID with the command  <code>az resource delete --ids IDVALUE</code>   You can get those IDs using <code>az resource list...</code></p> <pre><code># list all resources just created  (change the tag to match what you used if necessary)\naz resource list --tag activity=cli_tutorial\n\n# The CLI can filter and change the format of it's output\n# list ONLY the resource IDs using the \"query\" and tabular output\naz resource list --tag activity=cli_tutorial --query \"[].id\" -o table\n\n# delete them all using a shell loop (tsv does not output a header line)\nIDS=$(az resource list --tag activity=cli_tutorial --query \"[].id\" -o tsv)\nfor id in $IDS; do az resource delete --ids $id; done\n</code></pre>"},{"location":"session_organization/exercise_vm_via_cli/#complete-example-commands-using-my-resource-group","title":"Complete example commands (using my resource group)","text":"<pre><code>az vm create \\\n  --resource-group ccf22_billspat \\\n  --name billspat-tutorial-vm \\\n  --image Debian \\\n  --public-ip-sku Standard \\\n  --admin-username billspat \\\n  --tags 'activity=cli_tutorial' \\\n  --generate-ssh-keys\n\n# copy and paste the output of that\n\naz vm run-command invoke \\\n   --resource-group ccf22_billspat \\\n   --name billspat-tutorial-vm \\\n   --command-id RunShellScript \\\n   --scripts \"sudo apt-get update &amp;&amp; sudo apt-get install -y nginx\"\n\naz vm open-port --port 80 --resource-group ccf22_billspat --name billspat-tutorial-vm\n\n# list all resources just created \naz resource list --tag activity=cli_tutorial\n\n# list ONLY the resource IDs using the \"query\" and tabular output\naz resource list --tag activity=cli_tutorial --query \"[].id\" -o table\n\n# delete them all using a shell loop (tsv does not output a header line)\nIDS=$(az resource list --tag activity=cli_tutorial --query \"[].id\" -o tsv)\nfor id in $IDS; do az resource delete --ids $id; done\n</code></pre> <p>bonus points: set shell variables for the resource group and name and use them in the commands.  For example </p> <pre><code>RG=ccf22_billspat\nVMNAME=billspat-tutorial-vm\naz vm create \\\n  --resource-group $RG \\\n  --name $VMNAME \\\n  --image Debian \\\n  --public-ip-sku Standard \\\n  --admin-username billspat \\\n  --tags 'activity=cli_tutorial' \\\n  --generate-ssh-keys\n\n# ... do other stuff, then delete\n\n az vm delete \\\n  --resource-group $RG \\\n  --name $VMNAME\n</code></pre>"},{"location":"session_organization/exercise_vm_via_cli/#references","title":"References:","text":"<ul> <li>Quickstart: Create a Linux virtual machine with the Azure CLI https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-cli</li> <li>Azure Command-Line Interface (CLI) documentation https://learn.microsoft.com/en-us/cli/azure/</li> <li>All <code>az vm...</code> command options : https://learn.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest</li> <li>Use tags to organize your Azure resources (with the Azure CLI)! https://techcommunity.microsoft.com/t5/azure/use-tags-to-organize-your-azure-resources-with-the-azure-cli/m-p/1798955</li> <li></li> </ul>"},{"location":"session_organization/iam/","title":"Identity and Access/Authorization Management : Cloud IAM","text":"<p>is how access and authorization are handled for a given cloud resource.  Robust security controls are a critical element for any organization with a cloud presence, and access management is no exception.</p> <p>\u201cIAM\u201d refers to a cloud company's collection of services and APIs for managing access and authorization for resources.  If you create a storage account, who has access and how can they access it?     Can a VM read/write/delete from a particular File share?   </p> <p>Identity management is a huge topic for all of IT, not just for cloud.   Can one server talk to another?  Even apps have identity, especially if the intention of an app is to access resources, or maybe even create additional resources.    If you write a program that is running in a VM or as part of an app, can your program create new resources, say a serverless feature like a function, or read from a database?   </p> <p>The challenge for understanding IAM in cloud is that many of the servers or services you create will also have their own user authentication methods. Sometimes a cloud provider may add features to a service (like a database, or Machine learning services, or big data) such that the cloud user (.e.g. the user account you use to log-in to the portal) can automatically have access to the resource you've created.   That does not have to be true. Azure takes this a step further and uses the same identity system used to allow us to access teams and office which means the folks at our U who control  those kinds of access can also grant acceess to cloud resources.    </p> <p>In addition to granting basic access of an account into a resource, we can define the kind of access.  This in security is called a 'role'   You are 'owners' of your  resource groups meaning you can do almost anything, but we could also grant 'read' access to some of your resources to another person?   This is called \"Role-based Access Control\" or RBAC.   Azure defines hundreds of roles for different levels of access to various services.   </p> <p>All cloud vendors have a service for storing passwords.  For example, if we create a database service like Postgres, it will have it's own user id's and  passwords for connecting and pulling data.   If we ahve an app that needs access, or jupyter notebook, we could use our own IDs, but if we want to  keep our own ID safe, Azure recommends creating a service account that is actually kind of a computer account.    That was you don't have use your own account for this VM to access storage, and also it means this VM could be used by multipe people.  d There is another concept in IAM you will see frequently and that is a \"service account\" or in Azure terms a \"service principle.\"   If you have a VM  running a process that yuo need to then access another service (could be storage, but could also be things like data systems, or other services</p>"},{"location":"session_organization/iam/#use-cases","title":"Use Cases","text":"<p>Storage account.  There are several ways to grant access to files inside a storage account to anyone but yourself.  1) grant access to a particular account</p>"},{"location":"session_organization/iam/#readings","title":"Readings","text":"<p>Great but detailed overview of IAM across different cloud providers: </p> <p>https://acloudguru.com/blog/engineering/comparing-aws-azure-and-google-cloud-iam-services</p>"},{"location":"session_organization/intro_to_cloud_interfaces/","title":"Interfacing with Cloud Services","text":"<p>Cloud Services are by design DIY or on-demand and hence need a programming interface to create cloud resources.  This is only possible becuase inside the data center, computer configuration can be done completely with code, also knows as \"Infrastructure as Code\" (IaC).  Amazon's insight was that they could slap a website on top of that, put a system for tracking (metering) usage, and sell it.  </p> <p></p> <p>All of the cloud companies as their base use a web interface, so-called REST API.   Knowing the details of REST is not important but it's often the basis for all of the other style of interfaces.  </p> <p>Here is an example web api URL for weather forecast, with parameters for coordinates, units and format of output</p> <p><code>https://www.7timer.info/bin/astro.php?lon=113.2&amp;lat=23.1&amp;ac=0&amp;unit=metric&amp;output=json&amp;tzshift=0</code> </p> <p>Very few researchers would ever use the REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work.  </p> <p>In Azure, everything you could possibly create is called a \"resource:\" a machine, a data service, a single network address.   The system to work with Azure resources is the \"Azure Resource Manager\" or ARM and the primary interface for the Resource Manager is their web (REST) api.    You may see references to resources in documentation and that means any web doo-dad. </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#summary-of-cloud-interfaces","title":"Summary of Cloud Interfaces","text":"<p>This summary is focused on Microsoft Azure, but the other cloud companies have similar concepts.   In addition to this guide, Chapter 1 of our text \"Cloud Computing for Science and Engineering\" has an excellent description and examples of these interfaces with examples from AWS.  See the section of that chapter titled \"Accessing a cloud service\" in https://s3.us-east-2.amazonaws.com/a-book/Orienting.html</p>"},{"location":"session_organization/intro_to_cloud_interfaces/#graphical-web-interface","title":"Graphical Web Interface","text":"<p>Most people want a graphical user interface, and for azure that's the \"Portal\" or https://portal.azure.com.  For Google cloud it's the \"console\" and for AWS it's also called the console.  See below for an introduction to using the portal.   Note that the Azure portal and Google console both have web-based terminals that allow you to use the CLI directly in the web interface.    </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#desktop-applications","title":"Desktop Applications","text":"<p>Azure provides some desktop applications for working with a few of the widely used cloud services : </p> <ul> <li>Azure Storage Explorer: https://azure.microsoft.com/en-us/features/storage-explorer/     Can create cloud storage and upload/download data.  We will use that for our session on Storage</li> <li>Azure Data Studio:  https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?view=sql-server-ver15      Can connect to and work with data systems (such as databases ) that are on your computer, on a system on campus, or hosted in Azure</li> </ul>"},{"location":"session_organization/intro_to_cloud_interfaces/#command-line","title":"Command Line","text":"<p>For those not familar with the command line at all, see https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal for linux and for Windows Powershell see https://programminghistorian.org/en/lessons/intro-to-powershell</p> <p>The command line interface is a great way to interact with cloud services because it's imperative and all options are specified in a single command.   With the web interface, you may have to hunt through the user interface to find the checkbox for an option, but for command line </p> <p>Azure has two command line interfaces:  The \"CLI\" which is based on Linux and will work in any linux or Mac terminal (or shell script) and the \"Powershell\" interface which is for Windows Powershell users.   Since Powershell has been ported to Linux and Mac and the Linux Shell  and Azure CLI can also be used on Windows, so both are operating system independent but in practice, Windows users use powershell and everyone else uses the CLI.   Your choice depends on the kinds of other systems you'll be working with.  For example, the MSU HPC uses Linux command shell  but Windows servers and other Windows services like SQLServer work well with Powershell. </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#sdk-software-developer-kit","title":"SDK : Software Developer Kit","text":"<p>A \"software developer kit\" is simply a collection of utilities, libraries/packages and documentation for a specific language to work with a specific service.  All the cloud vendors have SDKs, and they all have SDKs for Python.    SDK simply means you can create, delete, interact with cloud services from your program.</p> <p>Why leave python or R if don't have to?</p>"},{"location":"session_organization/intro_to_cloud_interfaces/#python-sdk","title":"Python SDK","text":"<p>All cloud vendors have SDKs to work with Python.   After installing the SDK, you import the libraries and issue commands to create resources, then use those cloud resources to do work via client libraries (either Azure libraries or others).   Azure has extensive documentation for using Python: https://docs.microsoft.com/en-us/azure/developer/python/?view=azure-python</p> <p>Example Azure code to create cloud storage, compared with how you would see the resources in the azure portal, and similar commands using the CLI : https://docs.microsoft.com/en-us/azure/developer/python/azure-sdk-example-storage?tabs=cmd</p> <p>Note that Azure also has a service \"Azure Cloud Functions\" that run python that are not the same thing as the SDK.  These are 'serverless' resources (similar to AWS Lambda), which we will learn about later in the course. </p> <p>Both AWS and Google Cloud have Python SDKs, and probably other vendors.  </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#rest","title":"REST","text":"<p>Knowing the details of REST is not important but it's the basis for all of the other style of interfaces.  </p> <p>Here is an example web api URL for weather forecast, with parameters for coordinates, units and format of output</p> <p><code>https://www.7timer.info/bin/astro.php?lon=113.2&amp;lat=23.1&amp;ac=0&amp;unit=metric&amp;output=json&amp;tzshift=0</code> </p> <p>The parameters to the weather data fetch program are lon, lat, ac, unit, output=json, tzshift, and they are embedded in the URL itself.   </p> <p>This is caled a \"request,\" and using a web API often requires sending parameters not just sin the URL, but as an attachment or in the 'body' of the request.  Browsers don't have an automatic way of doing that, so we use scripts (python Requests library) or special programs for testing Web APIs that can send parameters and data in the request body.  </p> <p>This is a good explanation of REST and part 2 describes the details. </p> <p>https://medium.com/extend/what-is-rest-a-simple-explanation-for-beginners-part-1-introduction-b4a072f8740f</p> <p>The Azure REST api is a an interface to the Azure Resource Manager via the web.   Requests sent can get information about your resources, or create new resources, just like the portal, the command line and the SDKs.   Those other interfaces typically translate to the REST API.  Knowing about it may help diagnose why your method for interfacing with Azure is not working but not necesary to learn.    For examples and more detail, see https://learn.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-rest</p> <p>Few of us would ever use the Azure REST api directly, instead would use the web interface or even better the command line or programming language interface which achieves the same goal with less work.  </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#r","title":"R","text":"<p>Unlike the other vendors, Microsoft maintains an SDK for R Users which allows you to create cloud services directly from Rstudio.  See their github pages https://github.com/Azure/AzureR and excellent documentation throughout the packages.  </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#cloud-company-templating-frameworks","title":"Cloud company templating frameworks","text":"<p>In addition to the \"SDKs\" for existing languages, cloud companies often have their own frameworks for using code to build (provision) infrastructure.  For Azure, these are \"ARM Templates\" and for AWS it's Cloud Formation. </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#azure-arm-templates","title":"Azure: ARM templates","text":"<p>Azure has a system for submitting a template, or essentially a configuration file to the Azure Resource Manager (ARM) that dictates which cloud resources are to be created.   For Azure these are JSON-formatted files  that are \"declaritive\" (rather than procedural or imperative like Python).   The best way to understand these is to explore the many that Microsoft posts on github, and to try them.   If you do, be mindful to delete any resources you create so as not to be charged for them. </p> <pre><code>- Overview of ARM templates: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview\n- Quick start ARM templates (github): https://github.com/Azure/AzureStack-QuickStart-Templates\n</code></pre> <p>You may see reference to \"Bicep\" templates.  This is simplified ARM templating language that may be easier to write, debug and maintain than the JSON format of ARM templates.  </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#aws-cloud-formation","title":"AWS: Cloud Formation","text":"<p>AWS also has templating language similar to Azure Resource Manager templates called cloud formation.  If you are using AWS for your project, and want to automate the creation and deployment of resources, this may be a good option. </p> <p>AWS Documentation:</p> <ul> <li>What is AWS CloudFormation? </li> <li>How does AWS CloudFormation work?</li> </ul>"},{"location":"session_organization/intro_to_cloud_interfaces/#third-party-programming-with-terraform","title":"Third-party programming with Terraform","text":"<p>There are other ways to 'program the cloud' from companies outside of the big three.  One widely used frame is \"Terraform\" from Hashicorp, not affiliated with any cloud company.   The advantage to Terraform is that it's declarative in that you specific what you want, unlike say the Python or command line interface, where you have to create items with commands one at a time.  </p> <p>Terraform is used by cloud professionals becuase it's designed to keep the resources youve created running and allow you to modify them in place.   If you find you are using scripting to build resources (which is great!) but your scripts are becomming combersome to maintain and your cloud architecture is complex, consider using Terraform.  </p> <pre><code>- Terraform: https://www.terraform.io\n- Can work with any vendor including Azure\n- Often more readable than ARM templates, Syntax remarkably simple \n- Focus on maintaining consistent systems ( declarative) \n- Does not cover all services, but can fall back to ARM templates when necessary\n</code></pre>"},{"location":"session_organization/intro_to_cloud_interfaces/#building-cloud-from-cloud","title":"Building Cloud from Cloud","text":"<p>This may not be an 'interface' but is operationally similar.  It's possible to use some of the above interfaces on existing cloud services, e.g.   creating new cloud resources automaticaly from existing cloud resources.   Your cloud architecture may need different types of resources, or parameterized resources only as needed (e.g. depending data inputs, a web-gateway for cloud on demand).    </p> <p>For example Azure Logic Apps can create resources when they are run (e.g. provision and start a computer) and a logic app can be triggered by events such as when a new file is created, or using a web api (e.g. REST POST command that sends data and parameters).   This adds significant complexity and is only valuable for event-based systems opens up using the cloud as a big computer programming language. </p>"},{"location":"session_organization/intro_to_cloud_interfaces/#references","title":"References","text":"<p>See our references page for curated Azure links.   For AWS, see </p> <ul> <li>https://aws.amazon.com/tools/ </li> <li>about the AWS CLI: https://aws.amazon.com/cli/</li> <li>Demo Using Python Notebook with AWS: https://s3.us-east-2.amazonaws.com/a-book/s3.html</li> </ul>"},{"location":"session_organization/costs/azure_cloud_cost_basics/","title":"Intro to Cloud Costs on Azure","text":"<p>You've heard us say that nearly everything Azure has a cost, but how can you tell how much?</p> <p> </p> <p>Short video (3:30) Demonstrating Azure Portal Cost Analysis, on MSU MediaSpace (log-in required)</p> <p>The content below assumes you have knowledge of how to use the Azure Portal, basic cloud operations, what a virtual machine is. See the links and materials for session 2: how to cloud for the necessary background. </p>"},{"location":"session_organization/costs/azure_cloud_cost_basics/#1-pricing-pages","title":"1. Pricing Pages.","text":"<p>All cloud vendors have pricing pages that describe how they meter and charge for services.  For Azure this is https://azure.microsoft.com/en-us/pricing/#product-pricing</p> <p>However I usually find the page I need quickly by simply googling <code>azure &lt;service name&gt; pricing</code> for example I wanted to see how much a static IP address costs in azure so googling 'azure static ip pricing' takes me to https://azure.microsoft.com/en-us/pricing/details/ip-addresses/</p> <p>Some of these pages are  straightforward, but like the one above has addition knowledge.  What does this mean in practice?  For example, what does \"classic\" vs \"ARM\" even means? There is a link at the top of the page but this may take time to read and understand.  I'll tell you that we will never use 'classic' and only use 'resource manager (ARM).' so look at the ARM Prices.</p> <p>This kind of background info is very common for services.  </p>"},{"location":"session_organization/costs/azure_cloud_cost_basics/#2-build-something-and-check-the-cost","title":"2. Build something and check the cost","text":"<p>The other option is the empircal method: build something, use it, review the costs, and estimate.  </p> <p>At the resource group in the protal ( see  Azure Organization), there is a link on the left-side menu, near the bottom labelled \"Cost Analysis\"   - click that</p> <p>This is a live report of your current costs, with the ability to filter by time period, resource type, tags, and other things.   </p> <p>Near the middle are rouded buttons controlling the view you see.   At the right side of this is a button \"Add Filter\"  which you can click to show costs only for some resources.  For example if you click that and select \"Service Name\" and then \"virtual machines\" you will see the costs for the current month. </p> <p>A powerful filtering technique is to use tagging in Azure, which is akin to adding meta-data to resources.   See the Cloud Glossary </p> <p>In many of the filtering mechanisms in Azure (including costs), the tag names (keys) use use are listed in the options for filtering.    </p> <p>Carefully select the date range for which you want an estimate, especially if your trial run started a few days ago in the previous month as the default is a monthly estimate.  Use a custom date range for the time period that makes sense for the costs you want to observe. </p> <p></p> <p>Example Azure Cost Analysis Screen, filtered by Tag.  Click for larger view</p>"},{"location":"session_organization/costs/azure_cloud_cost_basics/#3-pricing-calculators","title":"3. Pricing Calculators","text":"<p>All the cloud companies have pricing calculators and they may be good for very rough estimates but I always multiple by 1.2 as I'm sure I missed some crucial resource that I didn't know I needed or didn't know costs money.  </p> <p>For Azure it's https://azure.microsoft.com/en-us/pricing/calculator/</p>"},{"location":"session_organization/costs/azure_cloud_cost_basics/#summary-and-other-notes","title":"Summary and other notes","text":"<p>Combining these three methods is how we can estimate costs. </p> <p>Notes: </p> <ul> <li> <p>Pricing often depends on the location or region you select.  Most regions in the US are the same price.   </p> </li> <li> <p>Data transfer costs are really hard to estimate.   Transfer into the cloud (Ingress) is often free but out of the cloud (egress) usually has a charge.  This is because companies with web products *(e.g. websites, web stores, image sites, etc) make money when customers view their pages (more customers =&gt; more costs =&gt;but more revenue).  However note that MSU has a deal with Azure and data transfer from Azure to MSU is (mostly) free.   One way to mitigate data transfer costs in Research is to transfer large data inputs into azure, but only take out the smaller output (results, summaries).  </p> </li> </ul>"},{"location":"session_organization/costs/azure_cloud_cost_basics/#azure-pricing-resources","title":"Azure Pricing Resources","text":"<p>Quickstart: Explore and analyze costs with cost analysis</p> <p>Video from John Saville on cost estimation including the pricing calculator: Master the Azure Pricing Calculator Jun 17, 2021</p>"},{"location":"session_organization/moving_data/","title":"Index","text":""},{"location":"session_organization/moving_data/#moving-data-in-the-cloud","title":"Moving Data in The Cloud","text":""},{"location":"session_organization/moving_data/#excercises","title":"Excercises","text":"<ul> <li>Exercise: moving data using storage URL</li> <li>Attaching Azure Files to a Virtual machine for reading and writing data</li> <li>Creating and re-using a data disk for virtual machines: Attach a managed data disk to a Windows VM by using the Azure portal</li> <li>Linux VMs: command line option using 'scp' command  Use SCP to move files to and from a Linux VM</li> <li>How to move data between the MSU HPC and Azure for an example using the <code>azcopy</code> utility, and other techniques   Requires an MSU HPC account offers free account to use HPC. However, this technique is applicable to any other mac or linux system you have access to. </li> </ul>"},{"location":"session_organization/moving_data/#optional-readings","title":"Optional Readings","text":"<ul> <li> <p>Adding a data disk to virtual machine (review):    A second disk may be faster to access than </p> <ul> <li>Linux: https://docs.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal</li> <li>Windows: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal</li> </ul> </li> <li> <p>Chapter 3 Using Cloud Storage Services in Cloud Computing for Science and Engineering </p> <ul> <li> <p>Focus on the Introduction and Section 3.3 (Azure)</p> </li> <li> <p>This chapter is written for python programmers, and starts with Amazon Web Services (AWS) examples, then moves to Azure examples in comparison to AWS.   If you are not a programmer or haven't heard of AWS storage (known as 'S3'), then skim through to get an idea of how you may use these.  </p> </li> </ul> </li> </ul>"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/","title":"Creating a Storage Account SAS token","text":""},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/#for-allowing-access-to-storage-from-another-service-or-person","title":"for allowing access to storage from another service or person","text":"<p>How can you provide another person't account, or more frequently an Azure service of some kind access to your storage account.   Granting access to each different service one by one may not be feasible,  Instead you can provide the service (or user) a special code that allows access.  One such code in Azure is a \"shared access signature\" (SAS).  You to the end of a storage URL To grant access to the storage acccount without having to log-in.  This is necessary when you want to copy data into storage account using another service or processs, for example copying files from your computer (or the HPC) to storage using the <code>azcopy</code> command.   </p> <p>You need to  create this token from a command or from the portal for each container (or even one for each blob) with parameters including an expiration time and the address of where you are accessing it from.  There are other ways to grant access to an azure storage container, but here is the documentation from Azure: Grant limited access to Azure Storage resources using shared access signatures (SAS)</p> <p>To generate a SAS token using the Azure portal (service SAS): </p> <ul> <li> <p>in the Portal, navigate to your storage account \u2192 containers \u2192 your container</p> </li> <li> <p>On the left side, click \"Shared access Tokens\"</p> </li> <li> <p>on the form for SAS token enter values as follows: </p> </li> <li> <p>Signing method : \"Account Key\" (this is the default and should be selected)</p> </li> <li> <p>Signing key : could be either Key 1 or Key 2</p> </li> <li> <p>Permissions : </p> </li> <li>click in the box that says \"read\" to see the list of permissions</li> <li>if you are copying from HPC to Azure, check all the boxes</li> <li> <p>if you are copying from Azure to HPC, check Read and perhaps List</p> </li> <li> <p>Specify the signed key Start and Expiry times.  </p> </li> <li>The key is temporary, and defaults to 24hrs.  </li> <li>You may want to change the \"expiry\" date to one a few days in the future, or </li> <li> <p>for a month or so if you'll be using azcopy to transfer files for the semester.   If you specify a long time, you should restrict the IP address access (see below)</p> </li> <li> <p>The allowed IP addresses field is optional and specifies an IP address or a range of IP addresses from which to accept requests. If the request IP address doesn't match the IP address or address range specified on the SAS token, it won't be authorized, so it must be correct.   </p> </li> <li>If you want to be extra secure and restrict to systems you are copying your data from.  For example your own computer</li> <li>If you are using MSU ICER, as of Fall 2021 this IP range should include all ICER/HPCC gateways : 35.9.12.1-35.9.12.255</li> <li>You could also use the MSU VPN address range and restrict to systems logged in via VPN.  Find that from IT Services</li> <li>For your or a colleague computer, google \"what's my IP\" to get your IP address</li> <li> <p>If you have authorization issues, then leave the IP field blank, but suggest limiting the time the key is active since anyone in the world could use it</p> </li> <li> <p>Allowed protocols: leave at HTTPS (do not select HTTP and HTTPS as HTTP is not secure)</p> </li> <li> <p>Click Generate SAS token and URL.</p> </li> </ul> <p>The Blob SAS token query string and Blob SAS URL will be displayed in the lower area of window.</p> <p>Copy the Blob SAS URL (or token or both), and save in a secure location.  They'll only be displayed once and cannot be retrieved once the window is closed.  Treat the SAS token like a temporary password</p> <p>You can use the \"Blob SAS URL\" for most copy operations.  It includes the container but not the file name.  If you want to use a different file name from the original, you'll have to construct your own URL. </p> <p>To construct an SAS URL, append the SAS token (URI) to the URL for a storage service as follows</p> <pre><code>`https://mystorageaccount.blob.core.windows.net/mycontainername/destination_file_name.ext?reallylongSAStokengoesatend`\n</code></pre> <p>If you need to change any aspect of this token (the dates, the IP addresses, etc) you have click Generate and get a new token (the old token may still work however)</p> <p>See How to move data between the MSU HPC and Azure for an example using the <code>azcopy</code> utility</p>"},{"location":"session_organization/moving_data/creating_a_container_sas_token_from_the_azure_portal/#references","title":"References","text":"<ul> <li>Best practices when using SAS token</li> <li>Instructions these are based on (from Azure Cognitive Services)</li> <li>CLI command to generate SAS token: https://docs.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az_storage_container_generate_sas</li> </ul>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/","title":"How to move data between the MSU HPC and Azure","text":""},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#introduction","title":"Introduction","text":"<p>A common research cloud computing activity is moving data between cloud and on-premise (local) systems.   Many universities provide great local systems at low costs, and some research groups have existing systems they've invested in, whereas cloud computing is an on-going costs. </p> <p>Azure has a rich data ecosystem and there are many methods to copy data from our local research cluster ([MSU ICER HPCC) to Azure Storage.  The follow are examples of methods that I've used, and all assume you are moving data to \"Azure Blob\" storage but may require minor adjustment to use \"Azure Files\" storage which should also work.  I don't discuss \"queue\" or \"table\" storage at all and that my require other services to use (events or data factory)  </p>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-1-using-scp-with-a-virtual-machine","title":"Method 1. using scp with a virtual machine","text":"<p>Sometimes you don't need a durable storage account at all, you just need to get some data onto the virtual machine you are using for computation.  This method is useful for one-time workflow of copy, process, save results.   </p>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#requirements","title":"Requirements","text":"<ul> <li>an account on the MSU HPCC</li> <li>basic knowledge of Linux</li> <li>know how to create and use a Azure Virtual Machine</li> </ul>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#a-little-about-the-scp-utility","title":"A little about the <code>scp</code> utility","text":"<p>The HPC runs Linux, and The <code>cp</code> utility copies files from one folder to another.   The <code>scp</code> utility allows us to do that across the network, using a secure method, providing you have an account on the remote system and <code>ssh</code> access.   There are many programs to help with network file transfers but <code>rsync</code> and <code>rclone</code> are two command (and really great) programs to checkout.  We will stick with <code>scp</code> for this example </p> <p>The basic format of the scp command is <code>scp user@remote.system.com:path/to/remote/file path/to/copy_of_file</code></p> <p>For examples see http://www.hypexr.org/linux_scp_help.php</p> <p>Method 1a. simple method for a one-time copy to an Azure VM: </p> <p>Steps:  1. find the file on the MSU HPCC that you want to copy.  Note the location and full path 1. create your Virtual Machine in Azure that you will use for your computations if it isn't already.      - if the file is particularly large, make sure to create a VM disk that is large enough to contain it 1. log-in to the virtual machine with the username and password you created (with remote desktop, or for Linux with ssh) 1. if you are using Windows with remote desktop, start cmd.exe to get a terminal, if on Linux, you are already on the terminal 1. use an scp command like this:      - first, note the folder you are running this from (it defaults to the VM home directory)     - <code>scp mynetid@hpcc.msu.edu:path/to/file.ext file.ext</code>     - you may be asked to accept the host 'fingerprint' if this is the first time you are using scp     - enter your NetID password (it is not saved or visible on the command line)     - consider using ssh keys instead of your password (which is a whole 'nother lesson)     - see https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys </p> <ol> <li>Now you can access the file using the software from the I think of this as  \"pulling\" data from HPC to the VM disk. </li> </ol>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-2-azcopy","title":"Method 2. azcopy","text":""},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#requirements_1","title":"Requirements","text":"<ul> <li>A Storage account.  We created one in the first session, but create a storage account in your resource group if you don't have one yet. </li> <li>Create a container in storage account to hold files. This can be a Blob or Azure Files container</li> <li>You must be owner of the storage account, and able to assign permissions ('roles').  Azure requires special persmissions grant that are NOT granted by default to use azcopy.  Details in the instructions below</li> <li>OR you must be willing to go through the process of creating a \"SAS Token\" :  see my instructions for creating SAS token</li> </ul> <p>Assuming you have a storage account with a blob container already created.  In the portal, open the storage account container. </p> <p>Azure provides a command line tool <code>azcopy</code> which you can download for windows, mac and Linux.   see https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10</p> <p>How to install the azcopy utility </p> <ol> <li>Login to MSU HPCC  <code>ssh &lt;netid&gt;@hpcc.msu.edu</code></li> <li>download a copy of azcopy.  This is the URL from Late september 2021:     <code>curl -O https://azcopyvnext.azureedge.net/release20210920/azcopy_linux_amd64_10.12.2.tar.gz</code></li> <li>untar and put in your home directory    <code>tar -xvzf azcopy_linux_amd64_10.12.2.tar.gz</code></li> </ol> <p>How to use azcopy to upload to Azure using the \"AD Login\"</p> <ol> <li>Get a SAS URL from the Azure portal as described above</li> <li>Log-in to HPCC</li> <li>assuming your copy of <code>azcopy</code> is in your home directory, run a command like the following.  Note that the URL must but enclosed in single quotes (not double quotes)</li> </ol> <p>`azcopy copy myfile.csv 'https://storageaccount.blob.core.windows.net/containername/myfile.csv?SASToken'</p> <p>For example, this copies a file and renames it when it's stored.  The container \"from-hpcc\" in this case must already be created.  </p> <p><code>azcopy copy 2008.csv 'https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&amp;st=2021-10-08T05:22:52Z&amp;se=2021-10-08T13:22:52Z&amp;sip=35.9.12.1-35.9.12.255&amp;spr=https&amp;sv=2020-08-04&amp;sr=c&amp;sig=abscus'</code></p> <p>References:  - Getting Started with azcopy  - azcopy login reference  - Authorize access to blobs with AzCopy and Azure Active Directory (Azure AD)  - Generate SAS tokens for your storage containers  *(note I found this in the \"cognitive services\" documentation)</p>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#alternative-methods","title":"Alternative Methods","text":""},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-3-azure-data-factory","title":"Method 3. Azure data factory","text":"<p>We will cover what \"Azure Data Factory\" is in session 4, but this is included in this session for completeness. </p> <p>If you have some familiarity with Azure data factory, note that a \"source\" for Azure Data Factory\" can be an 'sftp' or 'secure file transfer protocol' which most systems that have 'ssh' (secure shell) access allow, and is simlar to using the 'scp' or 'secure copy' utility. </p>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-4-python","title":"Method 4. Python","text":"<p>We won't really cover using Python to copy files to/from blob storage, but see the optional exercise for using Azure cloud storage in Python in session #3.  </p> <p>To use Azure python SDK on the HPC you need to installed the azure python sdk in a python environment in your home directory, for example using the Anaconda distribution of Python.  See https://wiki.hpcc.msu.edu/display/ITH/Using+conda.   </p>"},{"location":"session_organization/moving_data/how_to_hpc_and_cloudstorage/#method-5-python-with-url","title":"Method 5. Python with URL","text":"<p>Another approach that does not require the Azure SDK, is  URL access, the same as for <code>azcopy</code>  via the <code>requests</code> library.  For example, to download a CSV file from cloud storage, generate a SAS URL just for that file in the portal, and run this code</p> <pre><code>import requests\nimport csv\nimport os\nazure_url = \"https://cf21billspatstorage.blob.core.windows.net/from-hpcc/airlinedata_2008.csv?sp=racwdl&amp;st.... etc\"\ndata = []  # see note below*\nwith requests.get(azure_url, stream=True) as r:\n  lines = (line.decode('utf-8') for line in r.iter_lines())\n  for row in csv.reader(lines):\n     data.append(row)\n\nlen(data)\n</code></pre> <ul> <li>don't put this code into github with the SAS url.  Use a technique to read from command line or environment </li> <li>This would work anywhere, not just the HPC.  </li> <li>This is the same example in the slides for this session</li> </ul>"},{"location":"session_organization/moving_data/moving_data_with_url_activity/","title":"Exercise: moving data using storage URL","text":"<p>The goal of the exercise is to show one of the many ways of get data out of your cloud storage account,  especially as way to share a file using a URL</p> <ol> <li>Upload a file to cloud storage. </li> </ol> <p>get a file, any file and get it into cloud storage in any way you like.  If you already have a file in  Azure Blob storage container, you can skip this step.  If you want to use Storage Explorer that works, too. For the sake of complete and consistent exercise, we will use a small file and upload it with the portal.  (I don't recommend this for large files for for many files)</p>"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#upload-file-via-portal","title":"Upload file via portal","text":"<ol> <li>Find a data file in any format on your computer.   Let's called it <code>mydata.txt</code></li> <li>Open the Azure portal and go to your storage account in your resource group</li> <li>In your storage account create container, if you don't want to use an existing container<ol> <li>click \"containers\" on the left side menu</li> <li>above the list of containers is a \"+\" icon, click that to create a container</li> <li>For Name, call it \"democontainer\"</li> <li>For public access level, leave it as \"private\"</li> </ol> </li> <li>Open the container in the portal</li> <li>click \"the upload\" link near the top</li> <li>select a file to upload- any file will work for this excercise</li> </ol>"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#get-a-url-to-download-this-file-back-to-your-own-laptop-or-a-different-computer","title":"Get a URL to download this file back to your own laptop (or a different computer)","text":"<ol> <li>determine your laptop's IP address</li> <li>Google \"what's my IP address\"</li> <li> <p>copy it or save that IP address for later   To share with a colleague you'd use their IP address for this step</p> </li> <li> <p>click on the file you just uploaded and a new form appears on the right</p> </li> <li>on that form is a link near the top \"generate SAS\"  - click that link<ul> <li>for more details, see documentation Creating Container SAS</li> </ul> </li> <li>Leave all form fields as they are, except in the \"allowed IP addresses\", put your computers IP you just got</li> <li>Click the \"Generate SAS ...URL\" button</li> <li>Copy the Blob SAS URL to the clipboard</li> </ol> <p></p>"},{"location":"session_organization/moving_data/moving_data_with_url_activity/#test-download","title":"Test Download","text":"<p>In a web browser, paste the URL to see if you can re-download your own file. </p> <p>To share with someone else, put in a new IP address in the form above, and click \"Generate SAS...\" to get a new URL</p>"},{"location":"session_serverless/","title":"Session 6: Serverless, Containers, and FaaS","text":"<p> example real-world cloud application</p>"},{"location":"session_serverless/#what-is-serverless","title":"What is \"Serverless?\"","text":"<p>There are many definitions that include more or less categories of cloud services.   The primary concept is you create an 'exectution environment' to run your code, but you don't manage any aspect of the server.  You can focus on your application or code and not the operating system. </p> <p>We will talk about two kinds of \"serverless\" computing: </p> <ul> <li>Cloud Functions: running code on demand in response to a trigger or event.  This is sometimes called \"Function as a Service\" </li> <li>Linux Containers: sandbox environment for running software, even more abstract than Virtual Machines, s</li> </ul> <p>The relationship is the Cloud functions use Linux Containers as the basis for their architecture on Azure.  However you can use Azure Functions without working with containers or even knowing that fact but if you need extreme customization.    </p> <p></p>"},{"location":"session_serverless/#serverless-readings","title":"Serverless Readings","text":"<p>As you read these materials, do you think  \"serverless\" resources are IaaS or PaaS?   They sure feel like infrastructure as they require significant configuration, but run like PaaS, hence they are often called \"Function as a Service.\" </p> <ul> <li> <p>Re-visit Chapter 4 Computing as a service </p> </li> <li> <p>An additional report Serverless Computing and FaaS \"Observations about Serverless Computing, With a few examples from AWS Lambda, Azure Functions and Open Whisk\" by Dennis Gannon</p> </li> </ul>"},{"location":"session_serverless/#containers","title":"Containers","text":"<p>Containers are a widespread technology not just for Azure.   </p> <ul> <li>About Linux Containers from Pat Bills, with readings and activities</li> </ul>"},{"location":"session_serverless/#functions","title":"Functions","text":"<ul> <li> <p>All About Azure Functions: https://www.serverless360.com/azure-functions</p> </li> <li> <p>Example pricing for Azure functions: https://azure.microsoft.com/en-us/pricing/details/functions/</p> </li> </ul> <p>Azure Functions triggers and bindings conceptstabs=csharp</p>"},{"location":"session_serverless/#case-studies-and-tutorials","title":"Case Studies and Tutorials","text":"<p>An Introduction for Academics and links to Use Case in Bioinformatics : Grzesik, P., Augustyn, D. R., Wyci\u015blik, \u0141., &amp; Mrozek, D. (2021). Serverless computing in omics data analysis and integration. Briefings in bioinformatics, bbab349. Advance online publication. https://doi.org/10.1093/bib/bbab349</p>"},{"location":"session_serverless/#activities","title":"Activities","text":"<p>Links and activities related to containers are in the Container Overview page.  </p> <p>For Python programmers who have used the azure commaand line: Quickstart: Create a Python function in Azure from the command line</p> <p>*This is a long and very command line oriented tutorial which requires installation of components on your computer, or using the CloudShell</p>"},{"location":"session_serverless/#fellowship-meeting","title":"Fellowship Meeting","text":"<p>November 4, 2022 </p> <ul> <li>Discussion of Previous Weeks</li> <li>Introduction the Session materials</li> <li>Talk and demonstration: a cloud-based web application for gene function prediction: GenePlexus: a web-server for gene discovery using network-based machine learning </li> </ul>"},{"location":"session_serverless/_draft%20conrent%20Why%20Containers/","title":"draft conrent Why Containers","text":"<p>Why Containers?</p> <p>challenge for IT systems administrators is efficiencly managing all the servers and systems they are respnosible for.   in the history of cloud we described how Amazon wrote control software for all of this, and create \"API\" or consistent interface to all of this server management software, so anyone could hook into this.   </p> <p>containers take this a step further in that they are very software controlled system.    </p> <p>A server is a software application, and like any software you might use to compute something, has </p> <p>This article https://queue.acm.org/detail.cfm?id=2898444  describes how google started using containers early in their journey to scale their systems to billions of applications.  They in essence were building a cloud-like system internally for their own sake.  At one point the determined to rebuild and repackage this as an open system for everyone to use. and the result is Kubernetes.  </p> <p>Kubernetes is not for everyone.   You may see articles like the one above extolling it's virtues, and if you are manageming many systems that you need to keep up and running for customers (high availability) then it's amazing.   For researchers it may be overkill.   </p> <p>There are other options to using Kubernetes to running cluster (e.g. parallel) processes efficiently.    In addition, we should consider why we are running our systems:  are these systems for us and our labs, or for broader public use?</p> <p>For example, workflow systems.    Using containers and an orchestration system like Kubernetes, I can run a script that will launch several parts to</p> <p>Building management APIs around containers rather than machines shifts the \"primary key\" of the data center from machine to application. This has many benefits: (1) it relieves application developers and operations teams from worrying about specific details of machines and operating systems; (2) it provides the infrastructure team flexibility to roll out new hardware and upgrade operating systems with minimal impact on running applications and their developers; (3) it ties telemetry collected by the management system (e.g., metrics such as CPU and memory usage) to applications rather than machines, which dramatically improves application monitoring and introspection, especially when scale-up, machine failures, or maintenance cause application instances to move. </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/","title":"Docker Tutorial for Researchers featuring Jupyter Lab","text":"<p>for the 2022 MSU Cloud Computing Fellowship Session 6: Serverless, Containers, and FaaS</p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#introduction","title":"Introduction","text":"<p>This is a walkthrough for using Docker containers on your desktop and in the cloud using Microsoft Azure.  </p> <p>See the main page for this session and also the introduction to containers along with other links for background information. </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#requirements-to-follow-along","title":"requirements to follow along","text":"<ul> <li>azure account</li> <li>updated Azure command line utlities installed (az cli)</li> <li>logged into to Azure using <code>az login</code></li> <li>examples depend on the Jupyter lab stack being available in Dockerhub (valid November 2022)</li> </ul> <p>Notes: </p> <p>Docker is not the only system for using containers, but it's the most popular and I won't cover the others.  I mention this because the main documentation for the container we will be using (Jupyter stack) describes using 'Podman' but we will stick with Docker for now.   </p> <p>A reminder that Docker is a company that hosts a service to upload/download container images, and the name of the softwae ('docker') that can run containers and the name of a file ('Dockerfile' ) to create containers.    </p> <p>Windows users: Docker was created for Linux but Microsoft has worked hard to make it viable for Windows users as well.   The primary examples in this tutorial for for the command line will be for Mac/Linux, but there should be an equivalent option for Windows users.   One way to make your windows computer more like Linux is to install the Windows Subsystem for Linux (WSL) which would provide you with a Terminal program that runs the \"bash\" shell There are three parts to this tutorial: </p> <ol> <li>working with containers on your computer (this document)</li> <li>Launching containers on Azure ( in development )</li> <li>Creating your own containers ( in development )</li> </ol> <p>Let's get started.</p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-1-using-docker-on-your-computer","title":"Part 1. Using Docker on your computer","text":""},{"location":"session_serverless/docker_tutorial_for_researchers/#step-1-install-docker","title":"step 1: install Docker","text":"<p>Docker offers many products, some of which are underlying tools to use docker.   You minimally need the \"Docker Engine\" to run and manage docker containers via the command line (only).   However they also offer \"Docker Desktop\": a GUI to work with images and containers, connect and download from Dockerhub, set preferences, and includes all the other tools they make (Docker Compose, etc).   </p> <p>Hence we will install Docker Desktop to get everything but this tutorial will primarily work with Docker via command line interface.   Most software that is based on docker will have instructions for running it using the command line.  </p> <p>Install docker desktop using instructions here: https://docs.docker.com/desktop/</p> <p>Windows users: Microsoft has provided some good information on their site for using docker with the WSL, but you must install that first : https://learn.microsoft.com/en-us/windows/wsl/install then see  https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers</p> <p>Note that Docker Desktop works differently on Mac and Windows.  I recommend that you take some time to review the introduction from Docker desktop.  Minimally, we want to open the \"dashboard\" and to that you find the docker icon  in the system tray on windows, and menu bar on Mac, and select \"dashboard\" .  This may be helpful: https://docs.docker.com/desktop/use-desktop/#the-docker-menu </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-2-findselect-an-image-to-run-from-the-internet","title":"Step 2. Find/Select an image to run from the Internet","text":"<p>Many programs and servers have a \"dockerized\" version of software someone has prepared, often linked on the software  web page or in a a README file, and you could use almost anything with this tutorial.  However for this tutorial we'll be running JupyterLab to use python notebooks on our laptop.    </p> <p>The Jupyter Stacks project offers many different containers with different amounts of software installed (or 'stacked') along with Jupyter lab.  The important section is  https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks describing each of their offerings.    </p> <p>I will install \"datascience-notebook\"  using instructions similar but not exactly the same as theirs.    R users could follow along using instructions from the \"Rocker\" project</p> <p>Containers when published are minimally named as follows (this is the URI for the container):</p> <p><code>registryaddress/author/imagename:tag</code></p> <ul> <li>Author can be a person or an organization</li> <li>Imagename is what the author named the container image</li> <li>tag is like a version, but is not limited to version (but is limited in size).   Example tags could be 'v3' and the latest version is 'latest' by convention.   </li> <li>Registry address is usually not needed because we are always using Dockerhuib.   However The full name of container we pull from Dockerhub (99% are hosted on Dockerhub) includes the docker address, or </li> </ul> <p><code>docker.io/author/imagename:tag</code>   but the docker software automatically puts docker.io when needed</p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-3-download-and-run-the-image-as-a-container-using-the-command-line","title":"Step 3. Download and run the image as a container using the command line","text":"<p>In your terminal or cmd.exe program, use this command: </p> <pre><code> docker run -p 8888:8888  --name jupyter-datascience jupyter/datascience-notebook:latest\n</code></pre> <p>You can do something similar in the desktop dashboard, but only if you log-in to a repository like DockerHub.  So for this tutorial we'll be using the command line.   See https://docs.docker.com/desktop/use-desktop/images/ for more on the desktop interface for using Images.  </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#command-breakdown-for-docker-run","title":"Command breakdown for \"docker run\":","text":"<ul> <li>docker - main program to work with images/containers</li> <li>run - command to docker.  others include 'pull' to get image. this command will automatically pull the image from dockerhub first if you don't have it on your computer </li> <li>-p = port if the image runs a server, all servers need a 'port' to listen on, and you have to tell docker which port on your own computer you want to connect to the container. Note we could have used any port ( &gt; 1024) but using the same port makes it easy to remember.  See this doc for descriptions of ports.  The important thing is anything over &gt;1024 is fair game to use, but software tends to have a port they use by convention.   Jupyter lab uses 8888.   Rstudio uses 8787. and Postgresql uses 5432,  just because.</li> <li>name this is optional and you can use whatever name you need to help organize your containers.  If you don't provide it, Docker will assign a random name.  when you have several images/containers running for a complex system or as you develop new containers, assigning names willhelp you keep track.     </li> </ul> <p>If all goes well you will see download progress, and then part of the log or command output: </p> <pre><code>[I 2022-11-11 04:59:32.704 ServerApp] Jupyter Server 1.23.0 is running at:\n[I 2022-11-11 04:59:32.704 ServerApp] http://801ec4713575:8888/lab?token=57fb181bc074c193095db3df8c245521d3acb83530078d73\n[I 2022-11-11 04:59:32.705 ServerApp]  or http://127.0.0.1:8888/lab?token=57fb181bc074c193095db3df8c245521d3acb83530078d73\n[I 2022-11-11 04:59:32.705 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[C 2022-11-11 04:59:32.707 ServerApp]\n\n    To access the server, open this file in a browser:\n        file:///home/jovyan/.local/share/jupyter/runtime/jpserver-6-open.html\n    Or copy and paste one of these URLs:\n        http://801ec4713575:8888/lab?token=57fb181bc074c193095db3df8c245521d3acb83530078d73\n     or http://127.0.0.1:8888/lab?token=57fb181bc074c193095db3df8c245521d3acb83530078d73\n</code></pre> <p>When Jupyter Lab runs, it outputs messages, and Docker is simply forwarding those message to the \"log\" of output, which when you run on your computer shows up in your terminal.    You can also view the log in the Docker desktop user interface. </p> <p>To open Jupyter lab, use the last URl in the list.  </p> <p>Note about ports:  These Jupyter lab docker images are set to run on port 8888 and will always report that.  However, if you use a different port in the command, then that is the one  you want to use.   For example the command  <code>docker run -p 9999:8888 jupyter/datascience-notebook:latest</code> the URL would be <code>http://127.0.0.1:9999/... etc</code> but the log message will still say 8888 becuase that's the port used by the container internally - it doesn't know about the external port map.    The moral is to try to use the same port to reduce confusion.  </p> <p>When you run the jupyter notebook, you may see a page asking for a token.  Follow the instructions on the page to proceed.</p> <p>If it worked and you can log in, you can create a notebook, do some python (or R or Julia) and save the notebook.  Great!  But when you save, where does it go?  Right now, everything is stored inside the container.   If you shut down the container, that is all lost, because internal container storage is ephemeral.   </p> <p>In the same terminal you ran the command, use Ctrl+C to cancel it and stop running.   You can also use the Docker desktop GUI to start and stop containers.  </p> <p>Note if you run this again, you'll get the error</p> <pre><code>docker: Error response from daemon: Conflict. The container name \"jupyter-datascience\" is already in use by container \"...\". You have to remove (or rename) that container to be able to reuse that name.\n</code></pre>"},{"location":"session_serverless/docker_tutorial_for_researchers/#working-with-containers","title":"Working with Containers","text":"<p>After creating a container and stopping it, you can do a couple of things: re-start the container, delete it, start a second instance of the image in a new container, or list all your containers.  Note these containers are distinct from the images from which they are made.   </p> <p>Using the docker desktop user interface</p> <p>You can accomplish all of the activities below using the \"Dashboard\" section of the Docker desktop user interface, which lists all of the containers on your system along with any images you've downloaded.   See https://docs.docker.com/desktop/use-desktop/ for an introduction.  </p> <p>Using docker command line to manage containers</p> <ol> <li>re-run the container - it's still good!  It's just paused.  </li> </ol> <p><code>docker container restart jupyter-datascience</code></p> <p>Note you use the name you assigned the container when you ran it, not the name of the \"image\"</p> <ol> <li>delete the container </li> </ol> <p><code>docker container rm jupyter-datascience</code></p> <p>You can run now a new one (perhaps to alter the port, or other options).  The syntax is based on the Linux 'rm' command </p> <ol> <li>start a different container from the same image</li> </ol> <p><code>docker run -p 8889:8888  --name jupyter-datascience2  jupyter/datascience-notebook:latest</code></p> <p>In this example I used a different port number, which would allow you to run both containers at the same.  I don't think, for this image, there is a reason to do that, but it's possible. ` 4. And many others...</p> <p>https://docs.docker.com/engine/reference/commandline/container/</p> <p>For example list all the containers on the system <code>docker container ls -a</code></p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#step-4-connecting-docker-to-your-local-files","title":"Step 4. Connecting docker to your local files","text":"<p>Containers are great because they are unchanging environments you can run repeatedly.  They are not great because they are unchanging environments and anything you 'save' or change is lost when you shut down or delete the container.   Computing is not very valuable unless you can save your output.   Docker containers are walled off from your computer unless you explicitly connect a folder from your disk to a folder location in the container.    There are two ways to do this but we are using \"volumes\" (see docker Volumne documentation for details).  </p> <p>The goal is to take a folder on your computer and tell Docker to make it look like it's a sub folder somewhere in the container.  The folder on your computer is up to you, but the location in the docker image is very dependent on the structure and nature of the container.    Some have strict requirments.   </p> <p>Steps to use volumes on your computer </p> <ol> <li>create the folder</li> <li>use Docker desktop to give permission to use the folder</li> <li>run the container with the command to 'mount' the folder into the Linux container</li> </ol>"},{"location":"session_serverless/docker_tutorial_for_researchers/#volumes-step-1-create-the-folder","title":"Volumes step 1. Create the folder","text":"<p>let's create a folder on your comptuer.  You can use wahatever you want, and this is just an example. </p> <p>Create folder a folder called \"notebooks\" in your Documents folder.  You can put it anywhere but for this tutorial we will assume the notebooks folder to be used with docker will be in the following location</p> <ul> <li>Mac: <code>/Users/&lt;username&gt;/Documents/notebooks.</code></li> <li>Windows: <code>C:\\users\\&lt;userid&gt;\\Documents\\notebooks</code> </li> </ul>"},{"location":"session_serverless/docker_tutorial_for_researchers/#volumes-step-2-give-docker-permission-to-use-the-folder","title":"Volumes step 2. Give Docker permission to use the folder","text":"<p>To prevent your system from being deleted by roque containers, Docker requires you to grant it permission to use a folder in a container.   There is a way to edit the configuration file for Docker to allow access to folders on your computer, but here we'll use the Docker Desktop GUI app.  </p> <p>Open the Docker Desktop Dashboard, and then open preferences (gear icon in top right of Dashboard). Inside preference, open the \"resources\" section.  Inside that is an \"advanced\" sub-menu; select \"file sharing\" that list folders Docker can access.  Click the blue \"(+)\" icon on the bottom right to add the \"notebooks\" folder you just created in Documents.  </p> <p>The Jupyter stack containers have a long discussion on this in the documentation, but in short, there is a special user account inside the container, and to see notebooks yuo have to create a subfolder in that account's home directory.  The user is named \"jovyan\" and so the home directory inside the container is \"/home/jovyan\" and that's where the notebooks are looked for. </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#volumes-step-3-add-volume-when-running-the-container","title":"Volumes step 3.  Add volume when running the container","text":"<p>To add a volume to the Jupyter stack containers, you add a command parameter with a pair of folders: the one on your computer and the path thats used in the container : </p> <p><code>-v /path/on/your/computer:/path/inside/container</code></p> <p>On your computer it makes sense, but what about the container side of the \":\" ?  I know from the  Jupyter Stacks documentation that this image uses the folder <code>/home/jovyan/</code> so we add \"notebooks\" to this path and Docker connects the folder 'notebooks' on our computer to folder 'notebooks' to inside the the container.</p> <p>**Mac/Linux:  **</p> <p>You cam use mac environment variables to reference your home directory.  </p> <p>Given a  'notebooks' folder in Documents folder, the command would be </p> <pre><code>docker run -p 8888:8888 -v $HOME/Documents/notebooks:/home/jovyan/notebooks  jupyter/datascience-notebook:latest\n</code></pre> <p>On Windows is similar but we could not bet the environment variable to work, so you'll have to put in your user name:</p> <pre><code>docker run -p 8888:8888 -v c:\\\\users\\\\&lt;your user id&gt;\\\\Documents\\\\notebooks:/home/jovyan/notebooks  jupyter/datascience-notebook:latest\n</code></pre> <p>Now when you open the browser and copy/paste the URL for the new notebook server you've started (with the token), you'll see the \"notebooks\" folder on the left side, and any notebook you save there can be found on your computer.    </p> <p>note that there are aother potentially more sophisticated ways of using Volumes than this, but this works for us!   see the docker documenttaion for details.  </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-2-using-azure-to-run-containers","title":"Part 2: using Azure to run containers","text":"<p>Azure has several services for running containers or based on containers.  For this example we will work with Azure Container Instances.  (this link is the same as on the main page of the serverless session)</p> <p>If you have the [Azure command line utility installed] on your computer,  and you know the name of your resource group ( for 2022-23 fellows we use the pattern \"ccf22_\".    You can run the Jupyter Lab container with just one command line:  <pre><code>az container create --resource-group \"put your resource group name here\" --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest --dns-name-label \" put a unique name here\" --ports 8888\n</code></pre> <p>Note if you don't want to install the Azure command line (which is not small!) then you can use the Azure Cloud Shell</p> <ul> <li> <p>\"resource-group\" = your group, which you can find with the command <code>az group list</code></p> </li> <li> <p>\"name\" is the name of the container that could be anything, in the example below I use \"jupyterlab\" but could also be named for the project you are working on.  It may be useful to add more information about how you ser using it , say \"jupyterlab-testing\" or add your netid to it.  </p> </li> <li> <p>\"dns-name-label\" is used to create the URL that you will go to so it has to be unique.  One option is to use your NetID as part of the name, e.g. \"jupyterlab-sparty\"</p> </li> <li> <p>\"image\" this is the URL of the image we need to tell Azure which container \"registry\" to look to, and for Docker that's <code>docker.io</code> The image I used in the command below is the Jupyter stacks data science image, but you could use any image that has a web server, for example </p> </li> </ul>"},{"location":"session_serverless/docker_tutorial_for_researchers/#about-this-command","title":"About this command","text":"<p>Just like the command on your own computer, this maps port 8888 used by the Jupyter server to the same number on the host.   </p> <p>This once creates the Azure container instance resource in your group,  uploads and configures the docker image, and starts the container.  </p> <p>the output is a long text in JSON format that has some crucial information in it.   You can always get this information again with the 'show' commands like this</p> <p><code>az container show -g $RG --name jupyterlab</code></p> <p>but also from the Azure portal.   The information you need in the output is this: </p> <pre><code>\"ipAddress\": {\n    \"dnsNameLabel\": \"jupyterlab-billspat\",\n    \"fqdn\": \"jupyterlab-billspat.northcentralus.azurecontainer.io\",\n    \"ip\": null,\n    \"ports\": [\n      {\n        \"port\": 8888,\n        \"protocol\": \"TCP\"\n      }\n    ],\n    \"type\": \"Public\"\n  },\n</code></pre> <p>and the FQDN is the fully qualified domain name or web address where the server is running.  Note it starts with the 'dns-name-label' parameter you entered above.   </p> <p>Put the \"FQDN\" in a browser, and add <code>:8888</code>    So for me, the URL is  \"http://jupyterlab-billspat.northcentralus.azurecontainer.io:8888\"  - but that's not enough!   You still need the security token!  </p> <p>The challenge with getting the token is that when running on azure (unlike docker on your computer) you don't see the logs of the running container, and the token is output in the logs.   There are two ways (at least) to get it: </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#getting-the-docker-container-logs-via-command-line","title":"getting the docker container logs via command line","text":"<p><code>az container logs --resource-group \"your resource group name here\" --name \"the --name option you used above here\"</code></p> <p>lists all the logs, but we just want the token.  Here is what I run on my mac to filter the logs using <code>grep</code> </p> <p><code>az container logs --resource-group \"ccf22_billspat\" --name \"jupyterlab-test\" | grep token</code></p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#getting-the-docker-container-logs-using-the-azure-portal","title":"getting the docker container logs using the Azure portal:","text":"<ul> <li>open portal.azure.com, go to your Resource Group if it's not already open</li> <li>find the new container instance in the list of resources, then open it up.   </li> <li>inside that screen, look for the \"containers\" section on the left side.  Then select the container (mine isa called \"jupyterlab-test\", select \"logs\", look in the looks for the token and copy and paste it</li> </ul>"},{"location":"session_serverless/docker_tutorial_for_researchers/#using-cloud-storage-with-azure-container-instances","title":"Using Cloud Storage with Azure Container instances.","text":"<p>Recall from the Storage session, when you create an Azure storage container, inside that you can created different types of storage, primarily \"blob\" or \"files.\"   Files are modeled on network storage, hence easier to connect to running systems directly.   </p> <p>If you have an Azure File share in one of your Azure Storage containers, you can connect to it </p> <p>The following doc from Azure describes how to use the Azure CLI and Bash to get the necessary information about file share and connect it to a container instance.  https://learn.microsoft.com/en-us/azure/container-instances/container-instances-volume-azure-files</p> <p>Here is a shortened version based on the Portal</p> <ol> <li> <p>Create a File share if you don't one already: </p> </li> <li> <p>Create or use your existing storage account in the portal </p> </li> <li> <p>Using the Portal open the storage account resource, then go to \"File shares\" on the left side and create a new file share using the \"[+ File share]\" button at the top.  It can be named anything you like.   If performance is not crucial, select \"hot\" tier storage.  </p> </li> <li> <p>Get some security information from the portal  </p> </li> </ol> <p>STORAGE_ACCOUNT_NAME: the main name of the storage account in which you created the File share SHARE_NAME the name of the file share you  just created (or are using) STORAGE_KEY this takes the most work to find.    - in the Portal, open the storage account main page (not the file share, but the storage account)    - on the left side, find \"Access Keys\"   - this will list the storage account name, and 2 keys   - each key list both the key by itself, and a \"connection string\" useful for other services   - you can use either key, it doesn't matter.  Use the \"show\" button to show the key so you can copy/paste it</p> <ol> <li>Run the container as before, but now with file share: </li> </ol> <p>Note in the command below, I'm using the \"line continuation\" characther \"\\\" that works for Bash shell and maybe Powershell.  If you are using Windows you may have to adjust the syntax</p> <p>In the command below, replace the </p> <pre><code>az container create --resource-group \"put your resource group name here\" \\\n --name jupyterlab --image docker.io/jupyter/datascience-notebook:latest \\\n --dns-name-label \" put a unique name here\" --ports 8888 \\\n --azure-file-volume-account-name STORAGE_ACCOUNT_NAME \\\n --azure-file-volume-share-name SHARE_NAME \\\n --azure-file-volume-account-key STORAGE_KEY \\\n --azure-file-volume-mount-path /home/jovyan/notebooks\n</code></pre> <p>For example : </p> <pre><code>az container create --resource-group \"ccf22_billspat\" \\\n --name jupyterlab-test --image docker.io/jupyter/datascience-notebook:latest \\\n --dns-name-label \"jupyterlab-test\" --ports 8888 \\\n --azure-file-volume-account-name stbillspatccf22 \\\n\n --azure-file-volume-share-name ccf22billspat \\\n --azure-file-volume-account-key dve+w+fw8XUSLE91pKO2i6.....etc....KV49ZHYEY07qsvBBpnPV9+AStjQ7vFg== \\\n --azure-file-volume-mount-path /home/jovyan/notebooks\n</code></pre> <p>The web address for the Juypter lab server, after looking up the security Token using the methods describe above is: </p> <p><code>jupyterlab-test.northcentralus.azurecontainer.io:8888/lab?token=7e0ef407a591f10cfb358850c25cdc6529742309366382f0</code></p> <p>note that if you use Azure Blob storage, you can read/write to it using Python commands without having to connect when you build the container.  You need the connection string and to have the Azure python packages installed (see below for inforemation on how to modify the datascience-notebook image to install more python packages)</p> <p>Creating containers using the Azure Portal</p> <p>The portal has nice forms for creating container instances, but you will still need the three storage account information as described above.  </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#managing-containers-in-azure","title":"Managing Containers in Azure","text":"<p>If you stop the instance you are no longer charged.  You can start/stop from the command line or from the portal</p> <pre><code>az container stop --resource-group ccf22_billspat --name jupyterlab-test\n# later...\naz container start --resource-group ccf22_billspat --name jupyterlab-test\n# this does take a while, but may be easier than recreating it.  \n</code></pre> <p>However to keep your Resource group tidy, if you are finished with a container instannce for a while you should delete it. </p> <p><code>az container delete --resource-group ccf22_billspat --name jupyterlab-test</code></p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#azure-container-instance-alternate-method","title":"Azure Container Instance Alternate Method","text":"<p>There are several ways to do this - of course there are, this is Microsoft!   </p> <p>Microsoft worked with the Docker company to get commands built into the <code>docker</code> utility to be able to run docker files via your laptop.    In Docker-world, a 'context' is how the container is run, which could be different folders on  your laptop, some kind of fancy docker server, or a cloud service. </p> <p>The following are pretty clear instructions for using the Docker 'context' for connection to Azure container instance (ACI) and when you <code>docker run</code> the container will load on Azure instead of your laptop.  It's not clear to me exactly which is a better method, however with this method you get all the options available to you via the docker run command, except mounting a volume from your laptop of course.  </p> <p>https://devblogs.microsoft.com/devops/publishing-azure-container-instances-from-docker-cli/</p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#yet-another-method-for-docker-containers-from-microsoft-visual-studio-code","title":"Yet another method for Docker Containers from Microsoft : Visual Studio Code","text":"<p>If you are a Visual Studio Code user, there is a Docker plugin for editing Dockerfiles and running them on Azure : https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker</p> <p>I have not tested this but if it may be useful for debugging a complex Dockerfile. </p>"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-iii-diy","title":"Part III.  DIY!","text":"<p>While you may find a ready made Docker image that has all you need, chances are you'll need to modify it for your own work, and that means making your own images.   </p> <ol> <li>Select a Base Image.  We always start with an existing image.  Could be a very basic version of Linux that we install everything into, or an existing full image that we just add a little to. </li> <li>Write a Dockerfile : instructions for adding things to the base image (install software, configuration, copying code or data)</li> <li>Build: from the Dockerfile create an image.  <ul> <li>on your own computer using the Docker software</li> <li>on a remote repository, like Azure which lets you build on their system</li> </ul> </li> <li>Option: upload to a remote repository to be able to pull the image from other places</li> <li>Run: run to create a container from the image<ul> <li>the image you just built on your computer, or</li> <li>from the remote repository you just uploaed to (see optional step above) (e.g pull from remote and run)</li> </ul> </li> </ol> <p>There is documentation from Docker about what does into a dockerfile, but I find that confusing as they talk about each command, but not how the commands go together.  There are many tutorials for building Dockerfiles to run websites, but not many (if any) for researchers!  </p> <p>We've been using Docker images from Jupyter-Stacks.  Here is their example Dockerfile that installs python packages on to their base image: https://github.com/jupyter/docker-stacks/blob/main/scipy-notebook/Dockerfile    This is a bit complex example but it has many of the ingredients of a standard Dockerfile. </p> <p>Main sections: </p> <ul> <li>FROM always start with a base container.  They </li> <li>ARGS set variables to re-use later in the file.  This makes it easy to change in just one place</li> <li>RUN run a linux command in the base container to install something, or set configuration.  Note that most of these try to bundle as many commands as possible into on <code>RUN</code> to save space, and hence use the \"Line continuation\" character to make the command readable.  In the linux shell is usually the back slash or <code>\\</code>  - when you see that it means continue on the next line for this command.  You will also see <code>&amp;&amp;</code> operator which says keep going and run the next command.   These two things allow for very very long commands to run at once (and make the container smaller)</li> <li>COPY copy something from your computer into the container : data, code, configuration files, etc</li> </ul> <p>This example uses the example Notebook file you downloaded for Part 1 above, but let's download it again.  </p> <p>The datascience Jupyter is great, but what if you want to do Natural Language analysis?  We need the [NLTK] package for that, along with the data file for stop words.   Let's create new container that starts with the Jupyter Stacks data science image, and adds those things.   </p> <pre><code>FROM jupyter/datascience-notebook:latest\nRUN  pip install nltk &amp;&amp; python -c 'from nltk import download; download(\"stopwords\")'\n</code></pre> <p>To build a new image called \"jupyter_nltk\", save this as a file called \"Dockerfile\" in a folder by itself and run </p> <pre><code>cd \"folder where yuor docker file is\"\ndocker build -t jupyter_nltk:latest -f Dockerfile .\n</code></pre> <p>Note the command has a period / dot at the end and that's required if the docker file is in the directory from which your run the command</p> <p>To run this new container, use this command.  Notice that since this Image is on your </p> <p>let's say you also wanted to copy a notebook file called \"example.ipynb\" from the same directory that the docker  into this container for demonstration.   You could do this: </p> <pre><code>FROM jupyter/datascience-notebook:latest\nRUN  pip install nltk &amp;&amp; python -c 'from nltk import download; download(\"stopwords\")'\nCOPY example.ipynb $HOME\n</code></pre>"},{"location":"session_serverless/docker_tutorial_for_researchers/#part-iii-bonusdiy-containers-in-azure","title":"Part III Bonus:DIY containers in Azure","text":"<p>This is the culmination of all of knowledge above, and actually what researchers most likely need to do:  run a container that they have created in the cloud </p> <p>The key concept here is a container registry, which contains \"repositories\" which are history and versions of container images.  A registry is a web application to build and store Docker images.   Dockerhub is the most widely used container repository and you could use that, but with Azure you can make your own private registry. </p> <p>Here are instructions for using Dockerhub: https://www.docker.com/blog/how-to-build-and-test-your-docker-images-in-the-cloud-with-docker-hub/ . Dockerhub is a great option if you want to share your images with others (at no cost to you!).  However We will be using Azure since we are running a container on Azure.   </p> <p>A note about terminology:   A \"registry\" is a service that can hold many images.  Each image has versions (e.g. tags, latest, v1, v2, v2022, etc), and so this is called a \"repository\"</p> <p>you create your own registry/repository that is private just to you (and or your lab or workgroup).   There is a fee for this but it's not much.   The advantage to Azure Container registries is you can keep them private, and you can create the repository and build images with the <code>az</code> comnmand line (or the protal as usual)</p> <p>see https://learn.microsoft.com/en-us/cli/azure/acr?view=azure-cli-latest about the ACR service.  </p> <p>Microsoft also has a tutorial for creating an Azure Container Registry using a container image from their own public registry https://learn.microsoft.com/en-us/azure/container-registry/container-registry-quickstart-task-cli that is pretty good.  However the steps below build upon the Dockerfile created above. </p> <p>1. Create a registry to hold your images</p> <p>Create an ACR (azure container repository)/ with the command line (replace ACR name and resource group name to match yours ): </p> <p><code>az acr create -n &lt;UNIQUEREGISTRYNAME&gt; -g RESOURCEGROUPNAME --sku Standard</code></p> <p>2. then use that ACR to build the Docker image from your local Dockerfile. </p> <p>First, use <code>cd</code> to change to the directory with your dockerfile in it with <code>cd /path/to/my/Docker/folder</code></p> <p>Assuming there is a Dockerfile in the current directory (e.g. if your terminal is in the same folder as the Dockerfile above)</p> <p><code>az acr build -t jupyter-nltk:latest --file Dockerfile --registry UNIQUEREGISTRYNAME .</code></p> <p>Command ends with a single \"dot\" indicating we are using the Dockerfile that is present in this folder.  </p> <p>3. Run the container on ACI from the ACR</p> <p>Once built, you can create containers from this image.   By default any Container registry you created in Azure is private (unlike the public Dockerhub).   So when you want to use image that's hosted in a private Azure container registry like the one created above, you must supply credentials to access the registry.</p> <p>get the  full name of the container registry login server using the command line (or the Portal):</p> <p><code>az acr show --name &lt;UNIQUEREGISTRYNAME&gt; --query loginServer</code></p> <p>(this does not have storage account mounted):</p> <p>az container create --resource-group \"ccf22_billspat\" \\  --name jupyterlab-nltk --image jupyterlab-nltk:latest \\  --dns-name-label \"jupyterlab-nltk\" --ports 8888 </p> <p>You can find the web address by visiting the portal, using <code>az container show</code> as described above, and you'll also need to the token from the logs, which is also described. </p> <p>I put a collection of code  to combine the steps for this online: https://gist.github.com/psbills/5d42a55d53f0403ba5770b876dd74a3d</p> <p>This should work on Mac, Linux, and the Azure Cloud shell.  (Not tested on Windows)</p>"},{"location":"session_serverless/linux_containers_and_the_cloud/","title":"Linux Containers, Research, &amp; the cloud","text":""},{"location":"session_serverless/linux_containers_and_the_cloud/#for-session-6-serverless-cloud-computing","title":"For Session 6: Serverless Cloud Computing","text":"<p>The container metaphor for this kind of computing relfects how a standard-sized box can be carried on ships, trains, and trucks at different scales</p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#about-this-material","title":"About this material","text":"<p>Understading this material is not necessary to use cloud computing, and being advanced is optional for the cloud computing fellowship.  However, Linux containers are the heart of much of the cloud works, and becoming more prevelant for running complex research software.  </p> <p>Container technology was invented to support IT Systems (to run servers), like many things we discussed in the first session.   However value was discovered for research (reproducibility, configuraiton management) and it's become more common to find research software and projects that provide a 'Dockerfile' and instructions for running using containers.   Some workflows, especially in bioinformatics, are complete container based.   One reason is that   containers can be run (and be useful) on your own computer, on an on-premise server, and especially in the cloud with nearly identical results.     </p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#vms-are-great-but","title":"VMs are great, but...","text":"<p>The abstraction of a \"Virtual Machine\" (VM) solves the problem of requiring 1-1 physcial hardware-to-server.  Now you can have one large computer that can host many smaller VMs which is more efficient.  In addition, a VM can be saved as a \"virtual hard drive\" and turned off, or moved to a different physical hardware, or even backedup.  Otherwise IT system administrators may have have to re-install everything over again.  </p> <p>However becauase of the architecture there Virtual Machines can be unflexible.    When you created your vitual machine, you specified how much memory you needed and how much disk space you needed.   The physical machine must then reserve a part of it's memory and disk permanently, even if you your VM may not be working that hard.   One IT Manager of a virtualization system reported that most of the VMs were only using 5% of what they had reserved.  That's very inefficient!  However the people that created the VMs (people like you ) wanted to ensure they had enough compute power to get done what they needed.    Another problem is that each VM has a full copy of an operating system, like any computer.  So a physical computer, you are responsible for keeping the operating system up-to-date, secure, and free from viruses.   What if there was a way to share a large computers memory, diskspace and underlying operating system dynamically?</p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#introduction-to-containers","title":"Introduction to Containers","text":"<p>Many different groups contributed to solutions to the problems of process isolation and management including Google.  The most popular from a company called \"Docker.\"   Docker is a company, a technology/method, software you install on your computer, and a place to host shared containers (a repository or hub)  So you may hear about \"Docker containers\" but this is a brand name (like \"Kleenex\").    On the MSU HPC we use Singularity containers but for now focus on Docker, which works with Azxure.  </p> <p>Like Virtual Machines, containers are a means to abstract a running system so that we can bundle muliple \"machines\" on larger equipment.   Unlike virtual machines, containers share the resources dynamically and are much more isolated.   In addition, unlike virtual machines, Docker containers can be created from a code/configuration file that specifies what goes in them.  That means someone can give you this file, and you can \"run\" it to create a whole system that does what you need, one time or many times.   </p> <ul> <li>you can use code to define exactly what will go into a container, making it reproducible.  Techincally you can to this with VMs with different kinds of platforms, but it's more difficult and requires more detailed knowledge of operating system</li> <li>you can run a container on any cloud service, or your laptop or even the HPC</li> <li>because you define what is installed in a container, the configuration of complex software is easier and portable.   </li> <li>The Docker company created this format to be easy to use, so you can find someone who hs written the container code file to launch your system, or if you create complex software system for your research, you could provide a container file that makes it easy for others to run yuor scientific software.   This is not uncommond for bioinformatics software.  </li> </ul>"},{"location":"session_serverless/linux_containers_and_the_cloud/#how-can-i-use-it-on-my-computer","title":"How can I use it on my computer?","text":"<p>You can use Docker on your desktop, and launch containers and use the software in a container, which is like running a website right on your laptop.   Most likely no one else can access it, but it's great for development and testing.   </p> <p>The Docker is primarily an invisible background process, hidden system files, and CLI commands.  However for Windows and Mac, the \"docker desktop\" wraps a user interface around those things.  </p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#how-can-i-used-them-on-the-cloud","title":"How can I used them on the Cloud?","text":"<p>Azure offers several options, but to start</p> <ul> <li> <p>Azure Container Instances (ACI)</p> </li> <li> <p>Azure alternative to \"Docker hub\" is the Azure Container Registry (ACR).   You can use the ACR to build images for you so you don't have to install docker to use them on Azure. </p> </li> </ul>"},{"location":"session_serverless/linux_containers_and_the_cloud/#why-use-containers-on-the-cloud","title":"Why use containers on the cloud","text":"<p>The goal of using VMs and Containers can overlap.  However there are some advantages to using Container Instances : </p> <ul> <li>You can create a working container instance from code without having to install anything manually as you do with a VM.   The alternatives for VM is to find an existing VM image inthe azure marketplace, or to save your disk and use that as a template for additional VMs.   </li> <li>You can run exactly the same software configuration on your laptop, on Azure, or on any other cloud vendor</li> <li>Dockerfiles can be shared with a colleague easier than sharing a VM disk image</li> <li>When a container instance is off, there is no charge.   Yes!   That's because resources are only allocated when it's running. </li> <li>Much less to manage.  When a VM you are responsible for keeping the operation system up to date, all security patches installed and ensuring it does not get hacked.   </li> <li>Better security since you are not maintaining an operating system.  There are still some security implications for containers that run servers, but much fewer since you are reponsible for the application only.   </li> </ul>"},{"location":"session_serverless/linux_containers_and_the_cloud/#advantages-of-vms-over-aci","title":"Advantages of VMs over ACI","text":"<ul> <li>more control over networking</li> <li>many more options for machine types and sizes.  Container instances are limited </li> <li>many more options for disk configurations, etc</li> <li>if you need to optimize performance or need very high performance from a single machine, VMS may be better choice</li> <li>more familiar and so conceptually easier to use</li> <li>can use Azure VM Scale Sets for multiple VMS (there is probably a similar service for )</li> </ul>"},{"location":"session_serverless/linux_containers_and_the_cloud/#what-can-i-use-it-for","title":"What can I use it for?","text":"<p>Following this process, you may find that a large research software project has a \"Dockerfile\" as part of it's code base.   This is a set of instructions for building everything needed to run the software using containers.  You may find that two commands <code>docker build</code> and <code>docker run</code> are all you need to have a working environment to use a program.   </p> <p>Containers often are for running complex cloud-based applications that have manu components:  Web servers, database servers, message managers, etc.   Using containers allows companies to manage the components of the application instaed of all of the hardware and operating systems of the systems.  This is a major shift and why it's called \"serverless.   </p> <p>However containers can be useful for batch computing, that is running a calculation or building a machine learning model.   With servers, you start a container and leave it running.   But you can also \"docker run,\" the containers could take input, do their work, and exit.    Everything needed to complete the calculation is bundled in the container, and does not pollute your computer with special software installs.  </p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#what-is-kubernetes","title":"What is Kubernetes?","text":"<p>You will see a technology called Kubernetes mentioned everywhere.    This is for \"orchestrating\" many containers: helping to create and launch many complete interrelated components, let components talk to each other, keeping them running, reporting on their healht, and for most companies now, scale them automaticaly by creating replicas to meet demand.     Kubernetes is not widely used in research because of it's complexity but if you have complete workflows or systems to maintain it may be worth investigating.  </p> <p>You don't need Kubernetes to run single or even a couple of containers, but could is known to be utilized for large compute clusters, running spark, or even HPC-type workloads.    For small numbers of containers There are other solutions (such as Azure Batch ), or you can connect them yourself with coordinating code.   Using Kubernetes can be an entire career but may be necessary when building complex systems with containers.    </p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#reading","title":"Reading","text":"<p>An Introduction to Containers from a company called \"Rancher\" which sells software manage containers</p> <p>Chapter 6: Using and Managing Containers from our textbook \"Cloud Computing for Science and Engineering\" </p> <p>Great series introducting Docker For Science  This is better than what I've written so far!  </p> <p>Another very colloquial but helpful introduction to containers from \"MyGreatLearning.com\" : https://www.mygreatlearning.com/blog/docker-tutorial/ </p> <p>This describes a really important use case of containers which is to enhance reproducibility.  How often have you been told \"this code works for me\" but you are unable to run it, or it's a huge task to get everything installed just right.   Reproducibility is crucial software development requires a complex developer or running environment.  Even simply the differences between Mac, Windows, and Linux!   </p> <p>Docker Overview</p> <p>Azure Container Service Overview</p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#tutorial","title":"Tutorial","text":"<p>There are many many tutorials, blogs, videos, etc for Container Technology.   That didn't stop me from making one of my own, but geared for you, the researcher: Docker Tutorial for Researchers featuring Jupyter Lab. </p>"},{"location":"session_serverless/linux_containers_and_the_cloud/#activities","title":"Activities","text":"<ul> <li> <p>For Windows users :  Get started: Set up Linux Containers on Windows 10 and check the Pre-requisites . Also note on Windows and only windows you can run either a Linux container or a Windows container.   The vast majority of published containers, and the containers we'll be using are Linux, and that's what this tutorial covers. </p> </li> <li> <p>Quickstart: Deploy a container instance in Azure using the Azure portal : copy a simple web application into a container and run it on Azure.  We aren't suggesting you run a web application for your project, but almost all of the tutorials are about </p> </li> <li> <p>Docker Orientation and setup</p> </li> <li> <p>For Python Users: How to Run Jupyter Notebook on Docker</p> </li> <li> <p>Jupyter Hub: running Jupyter with everything installed just right can be problematic:  The Jupyter Stacks Project is to create bundles to include everything you need for a particular kind of research.   Note I have not tried to get this running on Azure - could it be done?   Would it be helpful?</p> </li> <li> <p>optional for shell scripters and command line users: complete this shell script that launches an Rstudio session on azure container instance</p> </li> <li> <p>Optional training activity: Introduction to Kubernetes from Microsoft. </p> </li> </ul>"},{"location":"session_serverless/serverless_overview/","title":"Introduction to Serverless Functions","text":"<p>For Session 6: Overview of Serverless</p> <p></p> <p>*Graphic credit: Instana https://www.instana.com/blog/introduction-to-serverless-computing/ * </p>"},{"location":"session_serverless/serverless_overview/#intro","title":"Intro","text":"<p>The buzzword 'serverless' by those who wove a fabric of cloud systems weaving together VMs, Networks, disks and storage which require significant provisioning and maintance.    Traditional IT is a collection of massive servers with many purposes and features that do it all.   Replicating that infrastructure in the cloud is using the \"Infrastrcture as a Service\" (IaaS) feature of the cloud.  We have talked before about the disadvantages of that for researchers, and a suggestion to look for ready-made solutions which are \"Platform as a Service\" (PaaS)</p> <p>\"Serverless\" is essentially PaaS because you don't manage and deal with a server, just the functionality that you need for your work but it's a bit deeper and more than that.  </p>"},{"location":"session_serverless/serverless_overview/#many-problems-that-serverless-functions-can-be-applied-to","title":"Many problems that \"serverless\" functions can be applied to","text":"<ul> <li>short focused function execution, </li> <li>many short functions triggered by external event (validate credit card)</li> <li>simplifying a main application into smaller functional units</li> <li>event processing, handling huge streams of data in small chunks </li> <li>components of a cloud-based workflow</li> </ul>"},{"location":"session_serverless/serverless_overview/#how-to-start-a-serverless-function","title":"how to start a serverless function?","text":"<ul> <li>if using http, use web api to send data via URL  http://getweather.myfunction.azure?zipcode=48824</li> <li>can listen for when a file is saved to a blob container or files folder</li> <li>other Azure events, database, etc</li> </ul>"},{"location":"session_serverless/serverless_overview/#provisioning-and-running-code-comparision","title":"Provisioning and Running code comparision","text":"<p>VM Server: </p> <pre><code>provision resources (VM, network etc) --&gt; install OS --&gt; install software --&gt; add code --&gt;\ngive permission to read storage --&gt; write to storage\n\nupload inputs --&gt; start run --&gt; outputs saved to disk or storage\n</code></pre> <p>other tasks: update operating system and software, </p> <p>Serverlesss Function Process: </p> <pre><code>provision resource (app service) --&gt; grant permission to read storage --&gt; publish code and config\n\nrun on trigger --&gt; inputs from binding --&gt; outputs to binding\n</code></pre> <p>Both run on a server, but or serverless Azure maintains the server - you don't even really care what it is.  Both require cloud storage, and both require adapting your code to run in the particular environment, but with serverless you don't need to think about security iissues.   But what if you just wanted to have one step in your work be isolated, and also run only when needed?</p>"},{"location":"session_serverless/serverless_overview/#example-function","title":"Example function","text":"<p>https://github.com/bsab/azure-function-python-blob</p>"},{"location":"session_serverless/container_scripts/rstudio_container_script/","title":"Containers on Azure: example Script","text":"<pre><code>echo \"Starting the setup for running Rstudio Server on Azure\"\n\nAZUSER=   # add your account name here, no space between the = sign\nAZGROUP=  # enter your resource gropu here, no space between the = sign\necho \"Enter Rstudio pw (for user rstudio):\"\nread CONTAINERPW\nDOCKERIMAGE=rocker/geospatial # or rocker/tidyverse  \nAZCONTAINERNAME=cf22-demo-container-$AZUSER\n\n # you must enter the values here for your storage account by finding the key in the Azure portal\n\nAZFILESACCOUNT=y\nAZFILESSHARE=z\nAZFILESKEY=x\n# docummentation for this command: https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest#az_container_create\n# create the container instance, which starts if the Dockerfile has an entry point\n# by assigning a '--dns-name-label' we give it a public IP address\necho \"please wait while the container instance is created\"\naz container create -g  $AZGROUP --name  $AZCONTAINERNAME \\\n    --os-type Linux --location eastus  \\\n    --cpu 4 \\\n    --memory 16 \\\n    --image $DOCKERIMAGE --ports 8787  \\\n    --dns-name-label ${AZUSER}rstudio \\\n    --secure-environment-variables PASSWORD=$CONTAINERPW\n\n\n    # --assign-identity  x \\\n    # --azure-file-volume-account-key $AZFILESKEY \\\n    # --azure-file-volume-account-name $AZFILESACCOUNT \\\n    # --azure-file-volume-share-name $AZFILESSHARE \\\n    # --azure-file-volume-mount-path /mnt/azfiles \n\n\n# NOTE this is not an https connection and hence is insecure and not recommended\n# see https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-group-ssl \n# for a method for using https\n\n# show the way to log in\nFQDN=`az container show --name $AZCONTAINERNAME -g $AZGROUP --query ipAddress.fqdn --output tsv`\necho \"your RStudio is running on \"\necho \"https://${FQDN}:8787\"\n\n# how to stop and/or delete the container.  \n# stop it if you are taking a break from using it\n# az container stop --name $AZCONTAINERNAME -g $AZGROUP\n# delete if you can\n# az container delete --name $AZCONTAINERNAME -g $AZGROUP\n</code></pre>"},{"location":"session_serverless/docker_cloud_build_demo/readme/","title":"Example Docker on Azure","text":"<p>This is a minimal example of building and running a docker container using Azure Container Registry and  Azure Container Instances.  Uses the smallest docker file in the world, which simply adds the NLTK python library  to an existing JupyterLab server from Jupyter Docker Stacks</p> <p>Using an admin password for an Azure container registry is not the most secure solution for the purposes of this tutorial works.   </p>"},{"location":"session_serverless/docker_cloud_build_demo/readme/#requirements","title":"requirements","text":"<ul> <li>azure account</li> <li>updated Azure command line utlities installed (az cli)</li> <li>logged into to Azure using az login</li> <li>an existing resource group</li> <li>Based on and depends on the Jupyter lab stack being available, see https://jupyter-docker-stacks.readthedocs.io/en/latest/</li> <li>Dockerfile in the current directory</li> </ul>"},{"location":"session_serverless/docker_cloud_build_demo/readme/#using-this-code","title":"Using this code.","text":"<p>The shell script code (sh) contains commands that will use Azure to build and run a docker container.   However it is not complete and you need to edit for it to work.  Open the script in a text editor and look where to add your own resource group and Azure ID.  </p>"},{"location":"session_serverless/docker_cloud_build_demo/readme/#run-options","title":"Run Options:","text":"<ul> <li>use your own terminal if the <code>az</code> cli is installed</li> <li>use the Microsoft Azure cloud shell if you have set it to use the CLI</li> <li>run the whole program at once (see below)</li> <li>copy and paste sections to examine how they run.  </li> </ul>"},{"location":"session_serverless/docker_cloud_build_demo/readme/#run","title":"Run:","text":"<p>several of the commands take a while to complete, especially the build command.  After editing the script and adding your resource group and ID.  To run in a Mac/Linux terminal, use</p> <pre><code>az login\n# optionally set the subscription if you have are in multiple\nsource docker_build_jupyter_on_azure_demo.sh\naz_jupyter_create\n</code></pre> <p>the relevant information will be printed on the screen, and carefully cut out the token from the log output to put into the web browser. </p> <p>when you are done with the container, you can remove it and the container registry in the same, or a new terminal using </p> <pre><code>source ./docker_build_jupyter_on_azure_demo.sh\naz_jupyter_cleanup\n</code></pre> <p>written for the MSU Cloud Computing Fellowship</p>"}]}